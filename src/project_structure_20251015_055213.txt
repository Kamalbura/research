PROJECT STRUCTURE AND PYTHON FILES LOG
================================================================================
Root Directory: C:\Users\burak\Desktop\research\src
Output File: C:\Users\burak\Desktop\research\src\project_structure_20251015_055213.txt
Generated: 2025-10-15 05:52:13
================================================================================

================================================================================
DIRECTORY TREE STRUCTURE
================================================================================
Root Directory: C:\Users\burak\Desktop\research\src
Generated: 2025-10-15 05:52:13

├── scheduler/
│   ├── __pycache__/
│   │   └── unified_scheduler.cpython-311.pyc (35,241 bytes)
│   ├── components/
│   │   ├── __pycache__/
│   │   │   ├── battery_predictor.cpython-311.pyc (14,518 bytes)
│   │   │   ├── ipc_bridge.cpython-311.pyc (21,971 bytes)
│   │   │   ├── security_advisor.cpython-311.pyc (17,914 bytes)
│   │   │   └── thermal_guard.cpython-311.pyc (17,678 bytes)
│   │   ├── tests/
│   │   │   ├── conftest.py (9,929 bytes)
│   │   │   ├── run_tests.py (10,648 bytes)
│   │   │   ├── test_battery_predictor.py (8,691 bytes)
│   │   │   ├── test_integration.py (24,331 bytes)
│   │   │   ├── test_ipc_bridge.py (15,008 bytes)
│   │   │   ├── test_security_advisor.py (15,056 bytes)
│   │   │   ├── test_thermal_guard.py (10,973 bytes)
│   │   │   └── test_unified_scheduler.py (19,150 bytes)
│   │   ├── battery_predictor.py (14,320 bytes)
│   │   ├── ipc_bridge.py (16,820 bytes)
│   │   ├── security_advisor.py (18,997 bytes)
│   │   └── thermal_guard.py (16,485 bytes)
│   ├── strategies/
│   │   ├── __pycache__/
│   │   │   ├── __init__.cpython-311.pyc (798 bytes)
│   │   │   ├── base.cpython-311.pyc (1,384 bytes)
│   │   │   ├── expert.cpython-311.pyc (2,905 bytes)
│   │   │   ├── hybrid.cpython-311.pyc (2,084 bytes)
│   │   │   └── rl.cpython-311.pyc (2,875 bytes)
│   │   ├── __init__.py (558 bytes)
│   │   ├── base.py (456 bytes)
│   │   ├── expert.py (1,723 bytes)
│   │   ├── hybrid.py (862 bytes)
│   │   └── rl.py (1,582 bytes)
│   └── unified_scheduler.py (36,670 bytes)
├── telemetry/
│   ├── __pycache__/
│   │   └── heartbeat.cpython-311.pyc (6,930 bytes)
│   └── heartbeat.py (4,265 bytes)
├── project_structure_20251015_055213.txt (0 bytes)
└── test_results.json (443 bytes)


================================================================================
PYTHON FILE CONTENTS
================================================================================

Found 19 Python files:
   1. scheduler\components\battery_predictor.py
   2. scheduler\components\ipc_bridge.py
   3. scheduler\components\security_advisor.py
   4. scheduler\components\tests\conftest.py
   5. scheduler\components\tests\run_tests.py
   6. scheduler\components\tests\test_battery_predictor.py
   7. scheduler\components\tests\test_integration.py
   8. scheduler\components\tests\test_ipc_bridge.py
   9. scheduler\components\tests\test_security_advisor.py
  10. scheduler\components\tests\test_thermal_guard.py
  11. scheduler\components\tests\test_unified_scheduler.py
  12. scheduler\components\thermal_guard.py
  13. scheduler\strategies\__init__.py
  14. scheduler\strategies\base.py
  15. scheduler\strategies\expert.py
  16. scheduler\strategies\hybrid.py
  17. scheduler\strategies\rl.py
  18. scheduler\unified_scheduler.py
  19. telemetry\heartbeat.py

--------------------------------------------------------------------------------

FILE 1/19: scheduler\components\battery_predictor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\battery_predictor.py
Size: 14,320 bytes
Modified: 2025-10-14 06:28:46
------------------------------------------------------------
#!/usr/bin/env python3
"""Battery physics-based predictor with Peukert equation, temperature compensation, and real-time SOC estimation.

This module implements sophisticated battery modeling for UAV mission planning:
- Peukert's equation for non-linear discharge behavior under varying loads
- Temperature compensation for Li-Po performance degradation
- Real-time State of Charge (SOC) estimation using INA219 voltage/current data
- Predictive remaining flight time calculation with power envelope forecasting
"""

from __future__ import annotations

import math
import time
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from collections import deque


@dataclass
class BatterySpec:
    """Li-Po battery specification parameters."""
    
    nominal_capacity_ah: float  # Amp-hours at 1C discharge rate
    nominal_voltage_v: float    # Nominal cell voltage (typically 3.7V for Li-Po)
    peukert_exponent: float     # Peukert constant (1.0-1.4 for Li-Po, typically ~1.2)
    series_cells: int           # Number of cells in series (3S = 3, 4S = 4, etc.)
    internal_resistance_mohm: float  # Internal resistance in milliohms
    temp_coeff_percent_per_c: float  # Capacity temperature coefficient (%/°C)
    cutoff_voltage_per_cell_v: float  # Minimum safe voltage per cell
    
    @property
    def total_nominal_voltage_v(self) -> float:
        """Total battery pack nominal voltage."""
        return self.nominal_voltage_v * self.series_cells
    
    @property
    def cutoff_voltage_total_v(self) -> float:
        """Total battery pack cutoff voltage."""
        return self.cutoff_voltage_per_cell_v * self.series_cells


@dataclass
class BatteryState:
    """Current battery state from sensor readings."""
    
    timestamp_ns: int
    voltage_v: float
    current_a: float
    temperature_c: Optional[float] = None
    power_w: Optional[float] = None
    
    def __post_init__(self):
        if self.power_w is None:
            self.power_w = self.voltage_v * self.current_a


@dataclass
class BatteryPrediction:
    """Battery state prediction and health metrics."""
    
    soc_percent: float                    # State of charge (0-100%)
    remaining_capacity_ah: float          # Remaining amp-hours
    remaining_time_s: float               # Time until cutoff at current load
    effective_capacity_ah: float          # Temperature-compensated capacity
    voltage_under_load_v: float           # Predicted voltage accounting for internal resistance
    discharge_rate_c: float               # Current discharge rate (C-rating)
    health_score: float                   # Battery health (0-100%, 100% = new)
    critical_warning: bool                # True if battery critically low
    temperature_derating_factor: float    # Temperature impact on capacity (0-1)


class BatteryPredictor:
    """Real-time battery physics predictor using Peukert equation and temperature compensation."""
    
    def __init__(
        self,
        battery_spec: BatterySpec,
        history_window_s: float = 300.0,  # 5 minutes of history
        critical_soc_threshold: float = 15.0,  # Critical battery warning threshold
        temperature_reference_c: float = 25.0,  # Reference temperature for capacity rating
    ):
        self.spec = battery_spec
        self.history_window_s = history_window_s
        self.critical_threshold = critical_soc_threshold
        self.temp_reference = temperature_reference_c
        
        # Rolling history for trend analysis
        self.state_history: deque[BatteryState] = deque(maxlen=1000)
        
        # Coulomb counting accumulator
        self.cumulative_ah_consumed = 0.0
        self.last_update_ns: Optional[int] = None
        
        # Battery aging model (simplified)
        self.cycle_count = 0
        self.age_factor = 1.0  # 1.0 = new battery, decreases with age
    
    def update(self, state: BatteryState) -> BatteryPrediction:
        """Update battery model with new sensor readings and return prediction."""
        
        # Add to history and prune old entries
        self.state_history.append(state)
        self._prune_history(state.timestamp_ns)
        
        # Update coulomb counter
        self._update_coulomb_counting(state)
        
        # Calculate temperature-compensated capacity
        temp_factor = self._temperature_compensation_factor(state.temperature_c)
        effective_capacity = self.spec.nominal_capacity_ah * temp_factor * self.age_factor
        
        # Calculate discharge rate (C-rating)
        discharge_rate_c = abs(state.current_a) / self.spec.nominal_capacity_ah
        
        # Apply Peukert's equation for non-linear discharge
        peukert_capacity = self._apply_peukert_equation(effective_capacity, discharge_rate_c)
        
        # Calculate State of Charge using voltage and coulomb counting
        voltage_soc = self._voltage_to_soc(state.voltage_v)
        coulomb_soc = max(0.0, 100.0 * (1.0 - self.cumulative_ah_consumed / peukert_capacity))
        
        # Weighted combination (more weight on coulomb counting during discharge)
        if abs(state.current_a) > 0.1:  # Discharging
            soc = 0.3 * voltage_soc + 0.7 * coulomb_soc
        else:  # At rest
            soc = 0.8 * voltage_soc + 0.2 * coulomb_soc
        
        soc = max(0.0, min(100.0, soc))
        
        # Calculate remaining capacity and time
        remaining_ah = (soc / 100.0) * peukert_capacity
        
        if abs(state.current_a) > 0.01:  # Avoid division by zero
            remaining_time_s = (remaining_ah / abs(state.current_a)) * 3600.0
        else:
            remaining_time_s = float('inf')
        
        # Account for voltage drop under load
        voltage_drop = abs(state.current_a) * (self.spec.internal_resistance_mohm / 1000.0)
        voltage_under_load = state.voltage_v - voltage_drop
        
        # Calculate health score based on capacity fade and internal resistance
        health_score = self.age_factor * 100.0
        
        # Critical warning logic
        critical_warning = (
            soc < self.critical_threshold or 
            voltage_under_load < self.spec.cutoff_voltage_total_v or
            state.temperature_c is not None and (state.temperature_c > 60.0 or state.temperature_c < -10.0)
        )
        
        return BatteryPrediction(
            soc_percent=soc,
            remaining_capacity_ah=remaining_ah,
            remaining_time_s=remaining_time_s,
            effective_capacity_ah=effective_capacity,
            voltage_under_load_v=voltage_under_load,
            discharge_rate_c=discharge_rate_c,
            health_score=health_score,
            critical_warning=critical_warning,
            temperature_derating_factor=temp_factor,
        )
    
    def _prune_history(self, current_time_ns: int) -> None:
        """Remove history entries older than the window."""
        cutoff_ns = current_time_ns - int(self.history_window_s * 1e9)
        while self.state_history and self.state_history[0].timestamp_ns < cutoff_ns:
            self.state_history.popleft()
    
    def _update_coulomb_counting(self, state: BatteryState) -> None:
        """Update cumulative amp-hour consumption using trapezoidal integration."""
        if self.last_update_ns is None:
            self.last_update_ns = state.timestamp_ns
            return
        
        dt_s = (state.timestamp_ns - self.last_update_ns) / 1e9
        if dt_s > 0 and dt_s < 3600:  # Sanity check: max 1 hour between updates
            # Only count discharge (positive current)
            if state.current_a > 0:
                ah_delta = state.current_a * dt_s / 3600.0
                self.cumulative_ah_consumed += ah_delta
        
        self.last_update_ns = state.timestamp_ns
    
    def _temperature_compensation_factor(self, temp_c: Optional[float]) -> float:
        """Calculate capacity derating factor due to temperature."""
        if temp_c is None:
            return 1.0
        
        temp_delta = temp_c - self.temp_reference
        # Li-Po batteries lose ~1-2% capacity per degree below 25°C
        # and gain slightly above (but with reduced cycle life)
        if temp_delta < 0:
            # Cold derating: more severe
            factor = 1.0 + (temp_delta * self.spec.temp_coeff_percent_per_c / 100.0)
        else:
            # Warm derating: less impact on capacity but affects longevity
            factor = 1.0 + (temp_delta * self.spec.temp_coeff_percent_per_c * 0.5 / 100.0)
        
        return max(0.3, min(1.2, factor))  # Clamp to reasonable range
    
    def _apply_peukert_equation(self, base_capacity_ah: float, discharge_rate_c: float) -> float:
        """Apply Peukert's equation to account for non-linear discharge behavior."""
        if discharge_rate_c <= 0:
            return base_capacity_ah
        
        # Peukert's equation: Capacity = Rated_Capacity * (Rated_Current/Actual_Current)^(n-1)
        # where n is the Peukert exponent
        peukert_factor = (1.0 / discharge_rate_c) ** (self.spec.peukert_exponent - 1.0)
        return base_capacity_ah * peukert_factor
    
    def _voltage_to_soc(self, voltage_v: float) -> float:
        """Convert battery voltage to approximate State of Charge using discharge curve."""
        # Simplified Li-Po discharge curve (per cell)
        voltage_per_cell = voltage_v / self.spec.series_cells
        
        if voltage_per_cell >= 4.1:
            return 100.0
        elif voltage_per_cell >= 3.9:
            return 90.0 + 10.0 * (voltage_per_cell - 3.9) / 0.2
        elif voltage_per_cell >= 3.8:
            return 70.0 + 20.0 * (voltage_per_cell - 3.8) / 0.1
        elif voltage_per_cell >= 3.7:
            return 40.0 + 30.0 * (voltage_per_cell - 3.7) / 0.1
        elif voltage_per_cell >= 3.6:
            return 20.0 + 20.0 * (voltage_per_cell - 3.6) / 0.1
        elif voltage_per_cell >= 3.4:
            return 5.0 + 15.0 * (voltage_per_cell - 3.4) / 0.2
        else:
            return max(0.0, 5.0 * (voltage_per_cell - 3.0) / 0.4)
    
    def get_power_trend_analysis(self, window_s: float = 60.0) -> Dict[str, float]:
        """Analyze power consumption trends over specified window."""
        if len(self.state_history) < 2:
            return {"trend_w_per_s": 0.0, "avg_power_w": 0.0, "peak_power_w": 0.0}
        
        current_time = self.state_history[-1].timestamp_ns
        cutoff_time = current_time - int(window_s * 1e9)
        
        recent_states = [s for s in self.state_history if s.timestamp_ns >= cutoff_time]
        
        if len(recent_states) < 2:
            return {"trend_w_per_s": 0.0, "avg_power_w": 0.0, "peak_power_w": 0.0}
        
        powers = [s.power_w or 0.0 for s in recent_states]
        avg_power = sum(powers) / len(powers)
        peak_power = max(powers)
        
        # Linear trend calculation
        first_state = recent_states[0]
        last_state = recent_states[-1]
        dt_s = (last_state.timestamp_ns - first_state.timestamp_ns) / 1e9
        
        if dt_s > 0:
            power_trend = ((last_state.power_w or 0.0) - (first_state.power_w or 0.0)) / dt_s
        else:
            power_trend = 0.0
        
        return {
            "trend_w_per_s": power_trend,
            "avg_power_w": avg_power,
            "peak_power_w": peak_power,
        }
    
    def predict_mission_viability(
        self, 
        target_duration_s: float, 
        expected_avg_power_w: float
    ) -> Dict[str, any]:
        """Predict if battery can sustain target mission duration at expected power level."""
        if not self.state_history:
            return {"viable": False, "reason": "no_battery_data"}
        
        latest_state = self.state_history[-1]
        prediction = self.update(latest_state)
        
        # Calculate expected current draw
        expected_current_a = expected_avg_power_w / latest_state.voltage_v
        expected_discharge_rate_c = expected_current_a / self.spec.nominal_capacity_ah
        
        # Apply Peukert and temperature effects
        temp_factor = self._temperature_compensation_factor(latest_state.temperature_c)
        effective_capacity = self.spec.nominal_capacity_ah * temp_factor * self.age_factor
        peukert_capacity = self._apply_peukert_equation(effective_capacity, expected_discharge_rate_c)
        
        # Calculate time to empty at expected power level
        available_ah = prediction.remaining_capacity_ah
        time_to_empty_s = (available_ah / expected_current_a) * 3600.0 if expected_current_a > 0 else float('inf')
        
        viable = time_to_empty_s >= target_duration_s
        margin_s = time_to_empty_s - target_duration_s
        margin_percent = (margin_s / target_duration_s) * 100.0 if target_duration_s > 0 else 0.0
        
        return {
            "viable": viable,
            "time_to_empty_s": time_to_empty_s,
            "target_duration_s": target_duration_s,
            "margin_s": margin_s,
            "margin_percent": margin_percent,
            "expected_power_w": expected_avg_power_w,
            "current_soc_percent": prediction.soc_percent,
            "reason": "insufficient_capacity" if not viable else "viable",
        }


def create_default_lipo_spec(capacity_ah: float, series_cells: int) -> BatterySpec:
    """Create a default Li-Po battery specification."""
    return BatterySpec(
        nominal_capacity_ah=capacity_ah,
        nominal_voltage_v=3.7,
        peukert_exponent=1.15,  # Typical for quality Li-Po
        series_cells=series_cells,
        internal_resistance_mohm=10.0 * series_cells,  # Rough estimate
        temp_coeff_percent_per_c=-1.5,  # 1.5% capacity loss per degree below 25°C
        cutoff_voltage_per_cell_v=3.3,  # Conservative cutoff for longevity
    )


__all__ = [
    "BatterySpec",
    "BatteryState", 
    "BatteryPrediction",
    "BatteryPredictor",
    "create_default_lipo_spec",
]

============================================================

FILE 2/19: scheduler\components\ipc_bridge.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\ipc_bridge.py
Size: 16,820 bytes
Modified: 2025-10-14 06:28:46
------------------------------------------------------------
#!/usr/bin/env python3
"""POSIX IPC bridge for ultra-low-latency cryptographic algorithm switching.

This module implements shared memory and semaphore-based inter-process communication
to minimize latency when switching between PQC suites, DDOS detection models, and
scheduling policies. Key optimizations:
- Memory-mapped algorithm parameters to eliminate ROM→RAM copying
- Semaphore-based coordination for lock-free algorithm activation
- Pre-warmed model states to reduce cold-start latency 
- Atomic configuration updates to prevent race conditions
"""

from __future__ import annotations

import mmap
import os
import struct
import time
import threading
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
import tempfile
from pathlib import Path


try:
    import posix_ipc
    HAS_POSIX_IPC = True
except ImportError:
    # Fallback for systems without posix_ipc
    import threading
    HAS_POSIX_IPC = False


class IPCMode(Enum):
    """IPC implementation modes."""
    POSIX_SHM = "posix_shm"        # POSIX shared memory + semaphores
    MMAP_FILE = "mmap_file"        # File-backed memory mapping
    THREADING = "threading"        # Thread-based fallback


@dataclass
class AlgorithmConfig:
    """Configuration for a cryptographic algorithm or model."""
    algorithm_id: str
    config_data: bytes            # Serialized configuration 
    memory_size_bytes: int        # Required memory size
    warmup_time_ms: float         # Time to activate from cold
    active: bool = False          # Currently active?
    last_used_ns: Optional[int] = None


@dataclass
class IPCStats:
    """Performance statistics for IPC operations."""
    switch_count: int = 0
    total_switch_time_ms: float = 0.0
    avg_switch_time_ms: float = 0.0
    max_switch_time_ms: float = 0.0
    cache_hits: int = 0
    cache_misses: int = 0
    memory_usage_mb: float = 0.0


class IPCBridge:
    """High-performance IPC bridge for algorithm switching."""
    
    def __init__(
        self,
        name: str = "pqc_scheduler",
        max_algorithms: int = 16,
        shared_memory_size_mb: int = 64,
        mode: IPCMode = IPCMode.POSIX_SHM,
        warmup_pool_size: int = 3,
    ):
        self.name = name
        self.max_algorithms = max_algorithms
        self.shared_memory_size = shared_memory_size_mb * 1024 * 1024
        self.mode = mode if HAS_POSIX_IPC else IPCMode.THREADING
        self.warmup_pool_size = warmup_pool_size
        
        self.algorithms: Dict[str, AlgorithmConfig] = {}
        self.stats = IPCStats()
        
        # IPC primitives
        self.shared_memory: Optional[Any] = None
        self.memory_map: Optional[mmap.mmap] = None
        self.semaphore: Optional[Any] = None
        self.lock = threading.Lock()
        
        # Pre-warmed algorithm pool
        self.warm_pool: Dict[str, Any] = {}
        self.warmup_thread: Optional[threading.Thread] = None
        self.shutdown_event = threading.Event()
        
        self._initialize_ipc()
        self._start_warmup_thread()
    
    def _initialize_ipc(self) -> None:
        """Initialize IPC mechanisms based on selected mode."""
        
        if self.mode == IPCMode.POSIX_SHM and HAS_POSIX_IPC:
            try:
                # Create POSIX shared memory segment
                shm_name = f"/{self.name}_shm"
                self.shared_memory = posix_ipc.SharedMemory(
                    shm_name,
                    posix_ipc.O_CREAT,
                    size=self.shared_memory_size
                )
                
                # Memory map the shared memory
                self.memory_map = mmap.mmap(
                    self.shared_memory.fd,
                    self.shared_memory_size,
                    mmap.MAP_SHARED,
                    mmap.PROT_READ | mmap.PROT_WRITE
                )
                
                # Create coordination semaphore
                sem_name = f"/{self.name}_sem"
                self.semaphore = posix_ipc.Semaphore(
                    sem_name,
                    posix_ipc.O_CREAT,
                    initial_value=1
                )
                
                print(f"[IPC] Initialized POSIX shared memory: {shm_name}")
                
            except Exception as e:
                print(f"[WARN] POSIX IPC failed, falling back to file mapping: {e}")
                self.mode = IPCMode.MMAP_FILE
                self._initialize_file_mapping()
        
        elif self.mode == IPCMode.MMAP_FILE:
            self._initialize_file_mapping()
        
        else:  # THREADING fallback
            print("[IPC] Using threading fallback mode")
    
    def _initialize_file_mapping(self) -> None:
        """Initialize file-backed memory mapping."""
        try:
            # Create temporary file for memory mapping
            temp_dir = Path(tempfile.gettempdir()) / "pqc_scheduler"
            temp_dir.mkdir(exist_ok=True)
            
            self.shm_file = temp_dir / f"{self.name}_shm.dat"
            
            # Create file with required size
            with open(self.shm_file, 'wb') as f:
                f.write(b'\0' * self.shared_memory_size)
            
            # Memory map the file
            with open(self.shm_file, 'r+b') as f:
                self.memory_map = mmap.mmap(
                    f.fileno(),
                    self.shared_memory_size,
                    mmap.MAP_SHARED,
                    mmap.PROT_READ | mmap.PROT_WRITE
                )
            
            print(f"[IPC] Initialized file-backed mapping: {self.shm_file}")
            
        except Exception as e:
            print(f"[WARN] File mapping failed, using threading: {e}")
            self.mode = IPCMode.THREADING
    
    def register_algorithm(
        self, 
        algorithm_id: str, 
        config_data: bytes,
        warmup_callback: Optional[Callable[[], Any]] = None
    ) -> bool:
        """Register an algorithm for fast switching."""
        
        if len(self.algorithms) >= self.max_algorithms:
            print(f"[WARN] Maximum algorithms ({self.max_algorithms}) reached")
            return False
        
        config = AlgorithmConfig(
            algorithm_id=algorithm_id,
            config_data=config_data,
            memory_size_bytes=len(config_data),
            warmup_time_ms=0.0,  # Will be measured during warmup
        )
        
        with self.lock:
            self.algorithms[algorithm_id] = config
            
            # Store warmup callback for background preparation
            if warmup_callback:
                self._schedule_warmup(algorithm_id, warmup_callback)
        
        print(f"[IPC] Registered algorithm: {algorithm_id} ({len(config_data)} bytes)")
        return True
    
    def switch_algorithm(self, algorithm_id: str, timeout_ms: float = 100.0) -> bool:
        """Switch to specified algorithm with minimal latency."""
        
        start_time = time.time()
        
        if algorithm_id not in self.algorithms:
            print(f"[WARN] Unknown algorithm: {algorithm_id}")
            return False
        
        # Acquire coordination lock/semaphore
        if not self._acquire_lock(timeout_ms):
            print(f"[WARN] Failed to acquire lock for {algorithm_id}")
            return False
        
        try:
            config = self.algorithms[algorithm_id]
            
            # Check if algorithm is pre-warmed
            if algorithm_id in self.warm_pool:
                # Fast path: algorithm already warm
                self._activate_warm_algorithm(algorithm_id)
                self.stats.cache_hits += 1
            else:
                # Slow path: cold start required
                self._cold_start_algorithm(algorithm_id)
                self.stats.cache_misses += 1
            
            config.active = True
            config.last_used_ns = time.time_ns()
            
            # Deactivate other algorithms
            for other_id, other_config in self.algorithms.items():
                if other_id != algorithm_id:
                    other_config.active = False
            
            # Update statistics
            switch_time_ms = (time.time() - start_time) * 1000
            self.stats.switch_count += 1
            self.stats.total_switch_time_ms += switch_time_ms
            self.stats.avg_switch_time_ms = (
                self.stats.total_switch_time_ms / self.stats.switch_count
            )
            self.stats.max_switch_time_ms = max(
                self.stats.max_switch_time_ms, switch_time_ms
            )
            
            print(f"[IPC] Switched to {algorithm_id} in {switch_time_ms:.2f}ms")
            return True
            
        finally:
            self._release_lock()
    
    def _acquire_lock(self, timeout_ms: float) -> bool:
        """Acquire coordination lock with timeout."""
        
        if self.mode == IPCMode.POSIX_SHM and self.semaphore:
            try:
                self.semaphore.acquire(timeout=timeout_ms / 1000.0)
                return True
            except posix_ipc.BusyError:
                return False
        else:
            # Use threading lock with timeout
            return self.lock.acquire(timeout=timeout_ms / 1000.0)
    
    def _release_lock(self) -> None:
        """Release coordination lock."""
        
        if self.mode == IPCMode.POSIX_SHM and self.semaphore:
            self.semaphore.release()
        else:
            try:
                self.lock.release()
            except RuntimeError:
                pass  # Lock not held by this thread
    
    def _activate_warm_algorithm(self, algorithm_id: str) -> None:
        """Activate a pre-warmed algorithm (fast path)."""
        
        warm_instance = self.warm_pool[algorithm_id]
        
        if self.memory_map:
            # Copy configuration to shared memory
            config = self.algorithms[algorithm_id]
            offset = hash(algorithm_id) % (self.shared_memory_size - len(config.config_data))
            self.memory_map.seek(offset)
            self.memory_map.write(config.config_data)
            self.memory_map.flush()
    
    def _cold_start_algorithm(self, algorithm_id: str) -> None:
        """Cold start an algorithm (slow path)."""
        
        config = self.algorithms[algorithm_id]
        start_time = time.time()
        
        # Simulate algorithm initialization
        # In real implementation, this would load model weights, etc.
        time.sleep(0.001)  # 1ms simulated cold start
        
        warmup_time = (time.time() - start_time) * 1000
        config.warmup_time_ms = warmup_time
        
        if self.memory_map:
            # Write to shared memory
            offset = hash(algorithm_id) % (self.shared_memory_size - len(config.config_data))
            self.memory_map.seek(offset)
            self.memory_map.write(config.config_data)
            self.memory_map.flush()
    
    def _schedule_warmup(self, algorithm_id: str, warmup_callback: Callable[[], Any]) -> None:
        """Schedule algorithm for background warmup."""
        
        if len(self.warm_pool) >= self.warmup_pool_size:
            # Evict least recently used algorithm
            lru_id = min(
                self.algorithms.keys(),
                key=lambda aid: self.algorithms[aid].last_used_ns or 0
            )
            if lru_id in self.warm_pool:
                del self.warm_pool[lru_id]
        
        # Warm up in background thread
        def warmup_worker():
            try:
                instance = warmup_callback()
                with self.lock:
                    self.warm_pool[algorithm_id] = instance
                print(f"[IPC] Warmed up algorithm: {algorithm_id}")
            except Exception as e:
                print(f"[WARN] Warmup failed for {algorithm_id}: {e}")
        
        thread = threading.Thread(target=warmup_worker, daemon=True)
        thread.start()
    
    def _start_warmup_thread(self) -> None:
        """Start background thread for algorithm warmup management."""
        
        def warmup_manager():
            while not self.shutdown_event.wait(5.0):  # Check every 5 seconds
                try:
                    self._maintain_warm_pool()
                except Exception as e:
                    print(f"[WARN] Warmup manager error: {e}")
        
        self.warmup_thread = threading.Thread(target=warmup_manager, daemon=True)
        self.warmup_thread.start()
    
    def _maintain_warm_pool(self) -> None:
        """Maintain optimal warm pool based on usage patterns."""
        
        # Identify frequently used algorithms
        current_time_ns = time.time_ns()
        recent_threshold_ns = current_time_ns - (300 * 1e9)  # 5 minutes
        
        frequent_algorithms = [
            aid for aid, config in self.algorithms.items()
            if config.last_used_ns and config.last_used_ns > recent_threshold_ns
        ]
        
        # Ensure frequent algorithms are warmed up
        for algorithm_id in frequent_algorithms[:self.warmup_pool_size]:
            if algorithm_id not in self.warm_pool:
                print(f"[IPC] Pre-warming frequently used algorithm: {algorithm_id}")
                # Would trigger warmup here in real implementation
    
    def get_active_algorithm(self) -> Optional[str]:
        """Get currently active algorithm ID."""
        
        for algorithm_id, config in self.algorithms.items():
            if config.active:
                return algorithm_id
        return None
    
    def get_performance_stats(self) -> IPCStats:
        """Get IPC performance statistics."""
        
        # Update memory usage
        if self.memory_map:
            self.stats.memory_usage_mb = self.shared_memory_size / (1024 * 1024)
        
        return self.stats
    
    def cleanup(self) -> None:
        """Clean up IPC resources."""
        
        self.shutdown_event.set()
        
        if self.warmup_thread and self.warmup_thread.is_alive():
            self.warmup_thread.join(timeout=1.0)
        
        if self.memory_map:
            self.memory_map.close()
        
        if self.mode == IPCMode.POSIX_SHM and HAS_POSIX_IPC:
            if self.shared_memory:
                self.shared_memory.close_fd()
                try:
                    self.shared_memory.unlink()
                except:
                    pass
            
            if self.semaphore:
                try:
                    self.semaphore.unlink()
                except:
                    pass
        
        elif self.mode == IPCMode.MMAP_FILE and hasattr(self, 'shm_file'):
            try:
                self.shm_file.unlink()
            except:
                pass
        
        print("[IPC] Cleaned up resources")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()


# Convenience functions for common use cases

def create_pqc_suite_bridge(suites: List[str]) -> IPCBridge:
    """Create IPC bridge optimized for PQC suite switching."""
    
    bridge = IPCBridge(
        name="pqc_suites",
        max_algorithms=len(suites) + 2,  # Extra slots for DDOS models
        shared_memory_size_mb=32,
        warmup_pool_size=3,
    )
    
    # Register PQC suites
    for suite in suites:
        config_data = suite.encode('utf-8')  # Minimal config for demo
        bridge.register_algorithm(suite, config_data)
    
    return bridge


def create_ddos_model_bridge() -> IPCBridge:
    """Create IPC bridge optimized for DDOS model switching."""
    
    bridge = IPCBridge(
        name="ddos_models",
        max_algorithms=4,  # XGBoost, Transformer, fallback heuristics
        shared_memory_size_mb=128,  # Larger for model weights
        warmup_pool_size=2,
    )
    
    # Register DDOS detection models
    models = ["xgboost_light", "transformer_heavy", "heuristic_fallback"]
    for model in models:
        config_data = f"model:{model}".encode('utf-8')
        bridge.register_algorithm(model, config_data)
    
    return bridge


__all__ = [
    "IPCMode",
    "AlgorithmConfig", 
    "IPCStats",
    "IPCBridge",
    "create_pqc_suite_bridge",
    "create_ddos_model_bridge",
]

============================================================

FILE 3/19: scheduler\components\security_advisor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\security_advisor.py
Size: 18,997 bytes
Modified: 2025-10-15 05:52:09
------------------------------------------------------------
#!/usr/bin/env python3
"""Security advisor that bridges DDOS detection models to PQC suite selection decisions.

This module integrates XGBoost and Transformer-based DDOS detection with cryptographic
suite scheduling, implementing a multi-tier defense strategy:
- Light-weight XGBoost for continuous monitoring (90% F1 score, low CPU)
- Heavy-weight Transformer with attention for confirmation (99.9% accuracy)  
- Dynamic threat level mapping to appropriate PQC security postures
- MQTT-inspired lightweight alert mechanism for GCS notification under congestion
"""

from __future__ import annotations

import time
import json
import hashlib
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
from enum import Enum
from collections import deque


class ThreatLevel(Enum):
    """DDOS threat classification levels."""
    NONE = "none"               # No threat detected
    SUSPICIOUS = "suspicious"   # Anomalous but not confirmed
    CONFIRMED = "confirmed"     # DDOS confirmed by heavy model
    CRITICAL = "critical"       # Severe ongoing DDOS attack


class DDOSDetectionTier(Enum):
    """Detection model tiers with different performance characteristics."""
    LIGHTWEIGHT = "lightweight"    # XGBoost - Fast, 90% F1, always running
    HEAVYWEIGHT = "heavyweight"    # Transformer - Accurate, 99.9%, on-demand


@dataclass
class NetworkMetrics:
    """Network performance metrics for DDOS detection."""
    timestamp_ns: int
    packet_loss_pct: float
    rtt_avg_ms: float
    rtt_p95_ms: float
    throughput_mbps: float
    goodput_mbps: float
    jitter_ms: Optional[float] = None
    out_of_order_pct: Optional[float] = None
    retransmission_rate: Optional[float] = None
    connection_attempts_per_s: Optional[float] = None


@dataclass 
class DDOSPrediction:
    """DDOS detection prediction with confidence and metadata."""
    timestamp_ns: int
    threat_level: ThreatLevel
    confidence_score: float         # 0.0-1.0 prediction confidence
    detection_tier: DDOSDetectionTier
    features_used: List[str]       # Feature names used in prediction
    model_latency_ms: float        # Time taken for prediction
    anomaly_scores: Dict[str, float]  # Per-feature anomaly scores
    raw_prediction: Optional[float] = None  # Raw model output if available


@dataclass
class SecurityPosture:
    """Recommended security configuration based on threat assessment."""
    pqc_suite: str                  # Recommended PQC suite
    ddos_detection_tier: DDOSDetectionTier  # Active detection level
    traffic_throttling: bool        # Should throttle traffic?
    alert_frequency_s: float        # How often to send status alerts
    emergency_fallback: bool        # Use emergency low-bandwidth mode?
    confidence_score: float         # Confidence in recommendation
    reasoning: str                  # Human-readable explanation


class SecurityAdvisor:
    """Intelligent security advisor for UAV cryptographic scheduling."""
    
    def __init__(
        self,
        lightweight_threshold: float = 0.7,    # XGBoost anomaly threshold
        heavyweight_threshold: float = 0.85,   # Transformer confirmation threshold  
        escalation_window_s: float = 30.0,     # Time window for threat escalation
        alert_cooldown_s: float = 60.0,        # Min time between GCS alerts
        feature_weights: Optional[Dict[str, float]] = None,
    ):
        self.lightweight_threshold = lightweight_threshold
        self.heavyweight_threshold = heavyweight_threshold
        self.escalation_window_s = escalation_window_s
        self.alert_cooldown_s = alert_cooldown_s
        
        # Feature importance weights for composite scoring
        self.feature_weights = feature_weights or {
            "packet_loss_pct": 0.25,
            "rtt_p95_ms": 0.20,
            "throughput_mbps": 0.15,
            "goodput_mbps": 0.15,
            "jitter_ms": 0.10,
            "out_of_order_pct": 0.10,
            "retransmission_rate": 0.05,
        }
        
        # Detection history for trend analysis
        self.prediction_history: deque[DDOSPrediction] = deque(maxlen=1000)
        self.network_history: deque[NetworkMetrics] = deque(maxlen=1000)
        
        # State tracking
        self.current_threat_level = ThreatLevel.NONE
        self.active_detection_tier = DDOSDetectionTier.LIGHTWEIGHT
        self.last_alert_sent_ns: Optional[int] = None
        self.escalation_start_ns: Optional[int] = None
        
        # Pre-encrypted alert codes for lightweight GCS communication
        self.alert_codes = self._generate_alert_codes()
    
    def analyze_threat(
        self, 
        metrics: NetworkMetrics, 
        lightweight_score: Optional[float] = None,
        heavyweight_score: Optional[float] = None,
    ) -> Tuple[DDOSPrediction, SecurityPosture]:
        """Analyze current threat level and recommend security posture."""
        
        # Store metrics for trend analysis
        self.network_history.append(metrics)
        self._prune_history(metrics.timestamp_ns)
        
        # Generate DDOS prediction
        prediction = self._generate_prediction(
            metrics, lightweight_score, heavyweight_score
        )
        
        # Store prediction 
        self.prediction_history.append(prediction)
        
        # Update threat level with temporal logic
        self._update_threat_level(prediction, metrics.timestamp_ns)
        
        # Generate security posture recommendation
        posture = self._recommend_security_posture(prediction, metrics)
        
        return prediction, posture
    
    def _generate_prediction(
        self,
        metrics: NetworkMetrics,
        lightweight_score: Optional[float],
        heavyweight_score: Optional[float],
    ) -> DDOSPrediction:
        """Generate DDOS prediction from available model scores and metrics."""
        
        start_time = time.time()
        
        # If heavyweight score available, use it with high confidence
        metrics_ts = metrics.timestamp_ns

        if heavyweight_score is not None:
            threat_level = (
                ThreatLevel.CRITICAL if heavyweight_score > 0.95 else
                ThreatLevel.CONFIRMED if heavyweight_score > self.heavyweight_threshold else
                ThreatLevel.SUSPICIOUS if heavyweight_score > 0.5 else
                ThreatLevel.NONE
            )
            
            prediction = DDOSPrediction(
                timestamp_ns=metrics_ts,
                threat_level=threat_level,
                confidence_score=heavyweight_score,
                detection_tier=DDOSDetectionTier.HEAVYWEIGHT,
                features_used=["transformer_attention_weights", "sequence_patterns"],
                model_latency_ms=(time.time() - start_time) * 1000,
                anomaly_scores={"heavyweight_score": heavyweight_score},
                raw_prediction=heavyweight_score,
            )
            
        # Otherwise use lightweight score or heuristics
        elif lightweight_score is not None:
            threat_level = (
                ThreatLevel.SUSPICIOUS if lightweight_score > self.lightweight_threshold else
                ThreatLevel.NONE
            )
            
            prediction = DDOSPrediction(
                timestamp_ns=metrics_ts,
                threat_level=threat_level,
                confidence_score=lightweight_score,
                detection_tier=DDOSDetectionTier.LIGHTWEIGHT,
                features_used=["xgboost_features"],
                model_latency_ms=(time.time() - start_time) * 1000,
                anomaly_scores={"lightweight_score": lightweight_score},
                raw_prediction=lightweight_score,
            )
            
        else:
            # Fallback to heuristic-based detection
            prediction = self._heuristic_prediction(metrics, start_time, metrics_ts)
        
        return prediction
    
    def _heuristic_prediction(self, metrics: NetworkMetrics, start_time: float, timestamp_ns: int) -> DDOSPrediction:
        """Fallback heuristic DDOS detection when ML models unavailable."""
        
        # Calculate composite anomaly score from network metrics
        anomaly_scores = {}
        composite_score = 0.0
        
        # Packet loss anomaly (threshold: >5%)
        loss_anomaly = min(1.0, metrics.packet_loss_pct / 10.0)
        anomaly_scores["packet_loss"] = loss_anomaly
        composite_score += loss_anomaly * self.feature_weights.get("packet_loss_pct", 0.0)
        
        # RTT anomaly (threshold: >200ms for P95)
        rtt_anomaly = min(1.0, max(0.0, (metrics.rtt_p95_ms - 50.0) / 500.0))
        anomaly_scores["rtt_p95"] = rtt_anomaly
        composite_score += rtt_anomaly * self.feature_weights.get("rtt_p95_ms", 0.0)
        
        # Throughput degradation (expect >5 Mbps normally)
        throughput_anomaly = max(0.0, (5.0 - metrics.throughput_mbps) / 5.0)
        anomaly_scores["throughput"] = throughput_anomaly
        composite_score += throughput_anomaly * self.feature_weights.get("throughput_mbps", 0.0)
        
        # Goodput vs throughput ratio (should be >0.8 normally)
        if metrics.throughput_mbps > 0:
            goodput_ratio = metrics.goodput_mbps / metrics.throughput_mbps
            goodput_anomaly = max(0.0, (0.8 - goodput_ratio) / 0.8)
        else:
            goodput_anomaly = 1.0
        anomaly_scores["goodput_ratio"] = goodput_anomaly
        composite_score += goodput_anomaly * self.feature_weights.get("goodput_mbps", 0.0)
        
        # Determine threat level from composite score
        if composite_score > 0.8:
            threat_level = ThreatLevel.SUSPICIOUS
        elif composite_score > 0.4:
            threat_level = ThreatLevel.SUSPICIOUS
        else:
            threat_level = ThreatLevel.NONE
        
        return DDOSPrediction(
            timestamp_ns=timestamp_ns,
            threat_level=threat_level,
            confidence_score=composite_score,
            detection_tier=DDOSDetectionTier.LIGHTWEIGHT,
            features_used=list(anomaly_scores.keys()),
            model_latency_ms=(time.time() - start_time) * 1000,
            anomaly_scores=anomaly_scores,
            raw_prediction=composite_score,
        )
    
    def _update_threat_level(self, prediction: DDOSPrediction, timestamp_ns: int) -> None:
        """Update current threat level with temporal logic and escalation."""
        
        # Escalation logic: if suspicious detections persist, escalate
        if (prediction.threat_level in {ThreatLevel.SUSPICIOUS, ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}
            and self.escalation_start_ns is None):
            self.escalation_start_ns = timestamp_ns
        
        # Check if we should escalate due to persistent suspicious activity
        if (self.escalation_start_ns is not None and 
            prediction.threat_level == ThreatLevel.SUSPICIOUS):
            
            elapsed_s = (timestamp_ns - self.escalation_start_ns) / 1e9
            if elapsed_s > self.escalation_window_s:
                # Escalate persistent suspicious activity to confirmed
                self.current_threat_level = ThreatLevel.CONFIRMED
                return
        
        # Direct updates for confirmed/critical threats
        if prediction.threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
            self.current_threat_level = prediction.threat_level
            self.escalation_start_ns = None  # Reset escalation timer
        elif prediction.threat_level == ThreatLevel.NONE:
            # Clear threat state
            self.current_threat_level = ThreatLevel.NONE
            self.escalation_start_ns = None
        else:
            # Update to suspicious if not already escalated
            if self.current_threat_level == ThreatLevel.NONE:
                self.current_threat_level = ThreatLevel.SUSPICIOUS
    
    def _recommend_security_posture(
        self, 
        prediction: DDOSPrediction, 
        metrics: NetworkMetrics
    ) -> SecurityPosture:
        """Recommend security configuration based on threat assessment."""
        
        # Map threat level to PQC suite selection
        suite_mapping = {
            ThreatLevel.NONE: "cs-mlkem768-aesgcm-mldsa65",      # Balanced default
            ThreatLevel.SUSPICIOUS: "cs-mlkem768-aesgcm-mldsa65", # Keep balanced for now
            ThreatLevel.CONFIRMED: "cs-mlkem1024-aesgcm-mldsa87", # High security
            ThreatLevel.CRITICAL: "cs-mlkem1024-aesgcm-mldsa87",  # Maximum security
        }
        
        # Detection tier recommendations
        if self.current_threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
            detection_tier = DDOSDetectionTier.HEAVYWEIGHT
        else:
            detection_tier = DDOSDetectionTier.LIGHTWEIGHT
        
        # Traffic throttling logic
        should_throttle = (
            self.current_threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL} or
            metrics.packet_loss_pct > 8.0 or
            metrics.rtt_p95_ms > 300.0
        )
        
        # Alert frequency based on threat level
        alert_frequencies = {
            ThreatLevel.NONE: 300.0,        # 5 minutes when all clear
            ThreatLevel.SUSPICIOUS: 120.0,  # 2 minutes when suspicious
            ThreatLevel.CONFIRMED: 30.0,    # 30 seconds when confirmed
            ThreatLevel.CRITICAL: 10.0,     # 10 seconds when critical
        }
        
        # Emergency fallback for severe conditions
        emergency_fallback = (
            self.current_threat_level == ThreatLevel.CRITICAL or
            metrics.packet_loss_pct > 15.0 or
            metrics.throughput_mbps < 1.0
        )
        
        # Generate reasoning
        reasoning_parts = [
            f"Threat level: {self.current_threat_level.value}",
            f"Detection confidence: {prediction.confidence_score:.2f}",
        ]
        
        if should_throttle:
            reasoning_parts.append("throttling due to high loss/latency")
        if emergency_fallback:
            reasoning_parts.append("emergency fallback due to severe degradation")
        
        reasoning = "; ".join(reasoning_parts)
        
        return SecurityPosture(
            pqc_suite=suite_mapping[self.current_threat_level],
            ddos_detection_tier=detection_tier,
            traffic_throttling=should_throttle,
            alert_frequency_s=alert_frequencies[self.current_threat_level],
            emergency_fallback=emergency_fallback,
            confidence_score=prediction.confidence_score,
            reasoning=reasoning,
        )
    
    def should_send_alert(self, current_time_ns: int) -> bool:
        """Check if it's time to send a status alert to GCS."""
        if self.last_alert_sent_ns is None:
            return True
        
        elapsed_s = (current_time_ns - self.last_alert_sent_ns) / 1e9
        return elapsed_s >= self.alert_cooldown_s
    
    def generate_lightweight_alert(
        self, 
        posture: SecurityPosture, 
        current_time_ns: int
    ) -> Optional[bytes]:
        """Generate lightweight encrypted alert packet for GCS communication."""
        
        if not self.should_send_alert(current_time_ns):
            return None
        
        # Create compact alert payload
        alert_data = {
            "t": int(current_time_ns / 1e6),  # Timestamp in milliseconds
            "tl": self.current_threat_level.value[:1],  # First char of threat level
            "dt": posture.ddos_detection_tier.value[:1],  # First char of detection tier
            "th": 1 if posture.traffic_throttling else 0,
            "ef": 1 if posture.emergency_fallback else 0,
            "c": int(posture.confidence_score * 100),  # Confidence as 0-100
        }
        
        # Use pre-encrypted codes for efficiency
        threat_code = self.alert_codes.get(self.current_threat_level, b"UNKN")
        
        # Combine JSON data with threat code
        json_bytes = json.dumps(alert_data, separators=(',', ':')).encode('utf-8')
        alert_packet = threat_code + b"|" + json_bytes
        
        self.last_alert_sent_ns = current_time_ns
        return alert_packet
    
    def _generate_alert_codes(self) -> Dict[ThreatLevel, bytes]:
        """Generate pre-encrypted alert codes for lightweight communication."""
        # In a real implementation, these would be properly encrypted
        # For now, use simple hash-based codes
        codes = {}
        for threat in ThreatLevel:
            code_str = f"PQC_ALERT_{threat.value.upper()}"
            code_hash = hashlib.md5(code_str.encode()).hexdigest()[:8]
            codes[threat] = code_hash.encode('ascii')
        return codes
    
    def _prune_history(self, current_time_ns: int) -> None:
        """Remove old history entries to manage memory."""
        # Keep last 10 minutes of data
        cutoff_ns = current_time_ns - int(600 * 1e9)
        
        while self.prediction_history and self.prediction_history[0].timestamp_ns < cutoff_ns:
            self.prediction_history.popleft()
        
        while (self.network_history and 
               self.network_history[0].timestamp_ns < cutoff_ns):
            self.network_history.popleft()
    
    def get_threat_analysis_summary(self) -> Dict[str, Any]:
        """Get comprehensive threat analysis summary for logging/debugging."""
        recent_predictions = list(self.prediction_history)[-10:]
        
        if not recent_predictions:
            return {"status": "no_data"}
        
        # Calculate recent trends
        threat_levels = [p.threat_level.value for p in recent_predictions]
        confidence_scores = [p.confidence_score for p in recent_predictions]
        
        return {
            "current_threat": self.current_threat_level.value,
            "active_detection_tier": self.active_detection_tier.value,
            "recent_predictions": len(recent_predictions),
            "avg_confidence": sum(confidence_scores) / len(confidence_scores),
            "threat_trend": threat_levels,
            "escalation_active": self.escalation_start_ns is not None,
            "time_since_last_alert_s": (
                (time.time_ns() - self.last_alert_sent_ns) / 1e9 
                if self.last_alert_sent_ns else None
            ),
        }


__all__ = [
    "ThreatLevel",
    "DDOSDetectionTier", 
    "NetworkMetrics",
    "DDOSPrediction",
    "SecurityPosture",
    "SecurityAdvisor",
]

============================================================

FILE 4/19: scheduler\components\tests\conftest.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\conftest.py
Size: 9,929 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""Test configuration and utilities for the scheduler test suite."""

import pytest
import tempfile
import os
import shutil
from unittest.mock import Mock
from src.scheduler.components.battery_predictor import BatterySpecs


@pytest.fixture(scope="session")
def temp_directory():
    """Create a temporary directory for test files."""
    temp_dir = tempfile.mkdtemp(prefix="scheduler_tests_")
    yield temp_dir
    # Cleanup after all tests
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)


@pytest.fixture
def standard_battery_specs():
    """Standard Li-Po battery specifications for testing."""
    return BatterySpecs(
        nominal_voltage_v=14.8,
        nominal_capacity_ah=4.0,
        max_discharge_rate_c=8.0,
        min_voltage_v=11.1,
        max_voltage_v=16.8,
        peukert_exponent=1.25,
        internal_resistance_mohm=45.0,
        temp_coefficient_per_c=-0.004
    )


@pytest.fixture
def high_performance_battery_specs():
    """High-performance Li-Po battery specifications for testing."""
    return BatterySpecs(
        nominal_voltage_v=22.2,  # 6S battery
        nominal_capacity_ah=6.0,
        max_discharge_rate_c=15.0,
        min_voltage_v=16.8,     # 2.8V per cell minimum
        max_voltage_v=25.2,     # 4.2V per cell maximum  
        peukert_exponent=1.15,  # Better efficiency
        internal_resistance_mohm=30.0,  # Lower resistance
        temp_coefficient_per_c=-0.003
    )


@pytest.fixture
def degraded_battery_specs():
    """Degraded/aged Li-Po battery specifications for testing."""
    return BatterySpecs(
        nominal_voltage_v=14.8,
        nominal_capacity_ah=2.5,  # Reduced capacity due to aging
        max_discharge_rate_c=5.0,  # Reduced discharge capability
        min_voltage_v=11.1,
        max_voltage_v=16.8,
        peukert_exponent=1.4,   # Worse efficiency when aged
        internal_resistance_mohm=80.0,  # Higher resistance
        temp_coefficient_per_c=-0.006  # More temperature sensitive
    )


@pytest.fixture
def mock_xgboost_model():
    """Mock XGBoost model for security advisor testing."""
    model = Mock()
    model.predict_proba.return_value = [[0.8, 0.2]]  # Low threat by default
    model.feature_importances_ = [0.3, 0.25, 0.2, 0.15, 0.1]
    return model


@pytest.fixture
def mock_transformer_model():
    """Mock Transformer model for security advisor testing."""
    model = Mock()
    model.predict.return_value = [[0.85, 0.15]]  # Low threat by default
    model.eval.return_value = model  # For PyTorch compatibility
    return model


@pytest.fixture
def sample_network_features():
    """Sample network traffic features for security testing."""
    return {
        'packet_rate': 150.0,
        'byte_rate': 75000.0,
        'unique_src_ips': 12,
        'unique_dst_ports': 8,
        'avg_packet_size': 500.0,
        'tcp_syn_rate': 10.0,
        'tcp_syn_ack_ratio': 0.9,
        'udp_rate': 30.0,
        'icmp_rate': 1.0,
        'connection_count': 25
    }


@pytest.fixture
def ddos_attack_features():
    """Network traffic features indicating DDOS attack."""
    return {
        'packet_rate': 15000.0,     # Very high packet rate
        'byte_rate': 2000000.0,     # High byte rate
        'unique_src_ips': 1,        # Single source (amplification attack)
        'unique_dst_ports': 1,      # Single target port
        'avg_packet_size': 133.0,   # Small packets
        'tcp_syn_rate': 12000.0,    # SYN flood
        'tcp_syn_ack_ratio': 0.1,   # Few responses
        'udp_rate': 3000.0,         # UDP flood component
        'icmp_rate': 0.0,
        'connection_count': 1       # Single connection
    }


@pytest.fixture(autouse=True)
def reset_global_state():
    """Reset any global state between tests."""
    yield
    # Add any global state cleanup here if needed


class TestFixtures:
    """Test the test fixtures themselves."""
    
    def test_battery_specs_fixtures(self, standard_battery_specs, high_performance_battery_specs, degraded_battery_specs):
        """Verify battery specification fixtures are valid."""
        # Standard battery
        assert standard_battery_specs.nominal_voltage_v > 0
        assert standard_battery_specs.nominal_capacity_ah > 0
        assert standard_battery_specs.max_discharge_rate_c > 0
        
        # High performance should have better specs
        assert high_performance_battery_specs.nominal_capacity_ah > standard_battery_specs.nominal_capacity_ah
        assert high_performance_battery_specs.max_discharge_rate_c > standard_battery_specs.max_discharge_rate_c
        
        # Degraded should have worse specs
        assert degraded_battery_specs.nominal_capacity_ah < standard_battery_specs.nominal_capacity_ah
        assert degraded_battery_specs.max_discharge_rate_c < standard_battery_specs.max_discharge_rate_c
        assert degraded_battery_specs.internal_resistance_mohm > standard_battery_specs.internal_resistance_mohm
    
    def test_network_features_fixtures(self, sample_network_features, ddos_attack_features):
        """Verify network traffic feature fixtures are realistic."""
        # Normal traffic should be reasonable
        assert 0 < sample_network_features['packet_rate'] < 1000
        assert sample_network_features['unique_src_ips'] > 1
        assert 0.5 < sample_network_features['tcp_syn_ack_ratio'] < 1.0
        
        # DDOS features should show attack characteristics
        assert ddos_attack_features['packet_rate'] > 10000  # Very high rate
        assert ddos_attack_features['unique_src_ips'] <= 3   # Few sources
        assert ddos_attack_features['tcp_syn_ack_ratio'] < 0.5  # Poor response ratio
    
    def test_mock_model_fixtures(self, mock_xgboost_model, mock_transformer_model):
        """Verify ML model mocks behave correctly."""
        # Test XGBoost mock
        prediction = mock_xgboost_model.predict_proba([[1, 2, 3, 4, 5]])
        assert len(prediction) == 1
        assert len(prediction[0]) == 2  # Binary classification
        assert sum(prediction[0]) == pytest.approx(1.0, abs=0.01)  # Probabilities sum to 1
        
        # Test Transformer mock
        prediction = mock_transformer_model.predict([[1, 2, 3, 4, 5]])
        assert len(prediction) == 1
        assert len(prediction[0]) == 2  # Binary classification


# Utility functions for tests

def create_test_telemetry_sequence(count=10, base_voltage=14.8, voltage_decline_rate=0.1):
    """Create a sequence of realistic telemetry snapshots."""
    import time
    from src.scheduler.unified_scheduler import TelemetrySnapshot
    
    snapshots = []
    base_time = time.time_ns()
    
    for i in range(count):
        snapshot = TelemetrySnapshot(
            timestamp_ns=base_time + i * int(100e6),  # 100ms intervals
            battery_voltage_v=base_voltage - i * voltage_decline_rate,
            battery_current_a=-2.0 - (i % 3),  # Varying current draw
            cpu_temp_c=45.0 + i * 1.5,  # Gradual warming
            ambient_temp_c=25.0,
            network_packet_rate=100.0 + i * 10.0,
            network_byte_rate=50000.0 + i * 5000.0
        )
        snapshots.append(snapshot)
    
    return snapshots


def assert_suite_priority_order(suites):
    """Assert that PQC suites are in expected priority order (low to high security)."""
    expected_order = [
        "cs-mlkem512-aesgcm-mldsa44",   # Lowest power/fastest
        "cs-mlkem768-aesgcm-mldsa65",   # Balanced
        "cs-mlkem1024-aesgcm-mldsa87"   # Highest security/slowest
    ]
    
    for suite in suites:
        assert suite in expected_order, f"Unknown suite: {suite}"


def measure_function_performance(func, *args, **kwargs):
    """Measure function execution time and return result + timing."""
    import time
    
    start_time = time.perf_counter()
    result = func(*args, **kwargs)
    execution_time = time.perf_counter() - start_time
    
    return result, execution_time


def verify_real_time_constraint(execution_time_ms, deadline_ms, tolerance_factor=0.8):
    """Verify that execution time meets real-time constraints with tolerance."""
    assert execution_time_ms <= deadline_ms * tolerance_factor, \
        f"Execution time {execution_time_ms:.2f}ms exceeds {tolerance_factor*100}% of deadline {deadline_ms}ms"


# Pytest configuration

def pytest_configure(config):
    """Configure pytest with custom markers."""
    config.addinivalue_line("markers", "slow: marks tests as slow (deselect with '-m \"not slow\"')")
    config.addinivalue_line("markers", "integration: marks tests as integration tests")
    config.addinivalue_line("markers", "performance: marks tests as performance benchmarks")
    config.addinivalue_line("markers", "hardware: marks tests requiring hardware simulation")


def pytest_collection_modifyitems(config, items):
    """Modify test collection to add markers based on test names."""
    for item in items:
        # Mark integration tests
        if "integration" in item.name.lower() or "test_integration" in str(item.fspath):
            item.add_marker(pytest.mark.integration)
        
        # Mark performance tests
        if "performance" in item.name.lower() or "latency" in item.name.lower():
            item.add_marker(pytest.mark.performance)
        
        # Mark hardware simulation tests
        if "hardware" in item.name.lower() or "pi4" in item.name.lower():
            item.add_marker(pytest.mark.hardware)
        
        # Mark slow tests (integration, performance, hardware)
        if any(mark.name in ["integration", "performance", "hardware"] for mark in item.iter_markers()):
            item.add_marker(pytest.mark.slow)

============================================================

FILE 5/19: scheduler\components\tests\run_tests.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\run_tests.py
Size: 10,648 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""
Comprehensive test runner for the UAV scheduler test suite.
Provides organized test execution with performance reporting.
"""

import pytest
import sys
import time
import json
import os
from pathlib import Path


def run_unit_tests():
    """Run unit tests for individual components."""
    print("🔬 Running Unit Tests...")
    print("=" * 60)
    
    unit_test_files = [
        "src/scheduler/components/tests/test_battery_predictor.py",
        "src/scheduler/components/tests/test_thermal_guard.py", 
        "src/scheduler/components/tests/test_security_advisor.py",
        "src/scheduler/components/tests/test_ipc_bridge.py",
        "src/scheduler/components/tests/test_unified_scheduler.py"
    ]
    
    results = {}
    
    for test_file in unit_test_files:
        if os.path.exists(test_file):
            component_name = Path(test_file).stem.replace("test_", "")
            print(f"\n📋 Testing {component_name}...")
            
            start_time = time.time()
            result = pytest.main([
                test_file,
                "-v", 
                "--tb=short",
                "--disable-warnings",
                "-x"  # Stop on first failure
            ])
            execution_time = time.time() - start_time
            
            results[component_name] = {
                "status": "PASSED" if result == 0 else "FAILED",
                "execution_time": execution_time,
                "return_code": result
            }
            
            if result == 0:
                print(f"✅ {component_name} tests passed ({execution_time:.2f}s)")
            else:
                print(f"❌ {component_name} tests failed ({execution_time:.2f}s)")
                return False, results
        else:
            print(f"⚠️  Test file not found: {test_file}")
    
    return True, results


def run_integration_tests():
    """Run integration tests for the complete system."""
    print("\n🔗 Running Integration Tests...")
    print("=" * 60)
    
    start_time = time.time()
    result = pytest.main([
        "src/scheduler/components/tests/test_integration.py",
        "-v",
        "--tb=short", 
        "--disable-warnings",
        "-m", "not slow"  # Skip slow tests by default
    ])
    execution_time = time.time() - start_time
    
    if result == 0:
        print(f"✅ Integration tests passed ({execution_time:.2f}s)")
        return True, execution_time
    else:
        print(f"❌ Integration tests failed ({execution_time:.2f}s)")
        return False, execution_time


def run_performance_tests():
    """Run performance benchmark tests."""
    print("\n⚡ Running Performance Tests...")
    print("=" * 60)
    
    start_time = time.time()
    result = pytest.main([
        "src/scheduler/components/tests/",
        "-v",
        "--tb=short",
        "--disable-warnings", 
        "-m", "performance",
        "--durations=10"  # Show 10 slowest tests
    ])
    execution_time = time.time() - start_time
    
    if result == 0:
        print(f"✅ Performance tests passed ({execution_time:.2f}s)")
        return True, execution_time
    else:
        print(f"❌ Performance tests failed ({execution_time:.2f}s)")
        return False, execution_time


def run_hardware_simulation_tests():
    """Run hardware simulation tests (Pi 4 + Pixhawk)."""
    print("\n🖥️  Running Hardware Simulation Tests...")
    print("=" * 60)
    
    start_time = time.time()
    result = pytest.main([
        "src/scheduler/components/tests/",
        "-v",
        "--tb=short",
        "--disable-warnings",
        "-m", "hardware",
        "-s"  # Show output for hardware tests
    ])
    execution_time = time.time() - start_time
    
    if result == 0:
        print(f"✅ Hardware simulation tests passed ({execution_time:.2f}s)")
        return True, execution_time
    else:
        print(f"❌ Hardware simulation tests failed ({execution_time:.2f}s)")
        return False, execution_time


def run_all_tests():
    """Run the complete test suite with comprehensive reporting."""
    print("🚀 UAV Scheduler Test Suite")
    print("=" * 60)
    print("Testing battery-aware, thermal-aware, security-adaptive PQC scheduler")
    print("Target: Raspberry Pi 4 + Pixhawk UAV systems")
    print("=" * 60)
    
    overall_start = time.time()
    test_results = {
        "timestamp": time.time(),
        "total_duration": 0,
        "unit_tests": {},
        "integration_tests": {},
        "performance_tests": {},
        "hardware_simulation": {},
        "overall_status": "UNKNOWN"
    }
    
    # Run unit tests
    unit_success, unit_results = run_unit_tests()
    test_results["unit_tests"] = unit_results
    
    if not unit_success:
        print("\n❌ Unit tests failed - stopping test execution")
        test_results["overall_status"] = "FAILED_UNIT_TESTS"
        return test_results
    
    # Run integration tests
    integration_success, integration_time = run_integration_tests()
    test_results["integration_tests"] = {
        "status": "PASSED" if integration_success else "FAILED",
        "execution_time": integration_time
    }
    
    if not integration_success:
        print("\n❌ Integration tests failed - continuing with remaining tests")
    
    # Run performance tests
    performance_success, performance_time = run_performance_tests()
    test_results["performance_tests"] = {
        "status": "PASSED" if performance_success else "FAILED", 
        "execution_time": performance_time
    }
    
    # Run hardware simulation tests
    hardware_success, hardware_time = run_hardware_simulation_tests()
    test_results["hardware_simulation"] = {
        "status": "PASSED" if hardware_success else "FAILED",
        "execution_time": hardware_time
    }
    
    # Calculate overall results
    overall_time = time.time() - overall_start
    test_results["total_duration"] = overall_time
    
    all_passed = (unit_success and integration_success and 
                  performance_success and hardware_success)
    test_results["overall_status"] = "PASSED" if all_passed else "PARTIAL_FAILURE"
    
    # Print summary
    print("\n" + "=" * 60)
    print("📊 TEST SUITE SUMMARY")
    print("=" * 60)
    
    print(f"⏱️  Total execution time: {overall_time:.2f} seconds")
    print(f"🔬 Unit tests: {'✅ PASSED' if unit_success else '❌ FAILED'}")
    print(f"🔗 Integration tests: {'✅ PASSED' if integration_success else '❌ FAILED'}")
    print(f"⚡ Performance tests: {'✅ PASSED' if performance_success else '❌ FAILED'}")
    print(f"🖥️  Hardware simulation: {'✅ PASSED' if hardware_success else '❌ FAILED'}")
    
    if all_passed:
        print("\n🎉 ALL TESTS PASSED - Scheduler ready for deployment!")
    else:
        print("\n⚠️  SOME TESTS FAILED - Review failures before deployment")
    
    # Save detailed results
    results_file = "test_results.json"
    with open(results_file, 'w') as f:
        json.dump(test_results, f, indent=2)
    print(f"\n📄 Detailed results saved to: {results_file}")
    
    return test_results


def run_quick_tests():
    """Run a quick subset of tests for rapid development feedback."""
    print("🏃 Quick Test Suite (Development Mode)")
    print("=" * 60)
    
    start_time = time.time()
    result = pytest.main([
        "src/scheduler/components/tests/",
        "-v",
        "--tb=short",
        "--disable-warnings",
        "-x",  # Stop on first failure
        "-m", "not slow and not hardware",  # Skip slow and hardware tests
        "--maxfail=3"  # Stop after 3 failures
    ])
    execution_time = time.time() - start_time
    
    if result == 0:
        print(f"\n✅ Quick tests passed ({execution_time:.2f}s)")
        print("🚀 Ready for development iteration!")
    else:
        print(f"\n❌ Quick tests failed ({execution_time:.2f}s)")
        print("🔧 Fix issues before continuing development")
    
    return result == 0


def run_coverage_analysis():
    """Run tests with coverage analysis."""
    print("📈 Running Test Coverage Analysis...")
    print("=" * 60)
    
    try:
        result = pytest.main([
            "src/scheduler/components/tests/",
            "--cov=src/scheduler/",
            "--cov-report=html:htmlcov",
            "--cov-report=term-missing",
            "--cov-fail-under=80",  # Require 80% coverage
            "-v"
        ])
        
        if result == 0:
            print("\n✅ Coverage analysis completed")
            print("📁 HTML coverage report: htmlcov/index.html")
        else:
            print("\n❌ Coverage analysis failed or insufficient coverage")
        
        return result == 0
        
    except ImportError:
        print("⚠️  pytest-cov not installed. Install with: pip install pytest-cov")
        return False


def main():
    """Main test runner with command line options."""
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == "quick":
            success = run_quick_tests()
            sys.exit(0 if success else 1)
            
        elif mode == "unit":
            success, _ = run_unit_tests()
            sys.exit(0 if success else 1)
            
        elif mode == "integration":
            success, _ = run_integration_tests()
            sys.exit(0 if success else 1)
            
        elif mode == "performance":
            success, _ = run_performance_tests()
            sys.exit(0 if success else 1)
            
        elif mode == "hardware":
            success, _ = run_hardware_simulation_tests()
            sys.exit(0 if success else 1)
            
        elif mode == "coverage":
            success = run_coverage_analysis()
            sys.exit(0 if success else 1)
            
        else:
            print(f"Unknown test mode: {mode}")
            print("Available modes: quick, unit, integration, performance, hardware, coverage")
            sys.exit(1)
    
    else:
        # Run full test suite
        results = run_all_tests()
        success = results["overall_status"] == "PASSED"
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    # Ensure we're in the right directory
    os.chdir(Path(__file__).parent.parent.parent.parent)
    main()

============================================================

FILE 6/19: scheduler\components\tests\test_battery_predictor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_battery_predictor.py
Size: 8,691 bytes
Modified: 2025-10-14 06:28:46
------------------------------------------------------------
#!/usr/bin/env python3
"""Unit tests for battery predictor component."""

import pytest
import time
from src.scheduler.components.battery_predictor import (
    BatteryPredictor, BatteryState, BatterySpec, create_default_lipo_spec
)


class TestBatteryPredictor:
    
    def test_create_default_lipo_spec(self):
        """Test creation of default Li-Po battery specification."""
        spec = create_default_lipo_spec(5.0, 4)
        
        assert spec.nominal_capacity_ah == 5.0
        assert spec.series_cells == 4
        assert spec.nominal_voltage_v == 3.7
        assert spec.total_nominal_voltage_v == 14.8  # 3.7V * 4 cells
        assert spec.cutoff_voltage_total_v == 13.2   # 3.3V * 4 cells
        assert spec.peukert_exponent > 1.0
    
    def test_battery_predictor_initialization(self):
        """Test battery predictor initialization."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        assert predictor.spec == spec
        assert len(predictor.state_history) == 0
        assert predictor.cumulative_ah_consumed == 0.0
        assert predictor.last_update_ns is None
    
    def test_single_battery_update(self):
        """Test single battery state update."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        # Simulate fully charged battery at rest
        state = BatteryState(
            timestamp_ns=time.time_ns(),
            voltage_v=16.8,  # 4.2V per cell (fully charged)
            current_a=0.0,   # At rest
            temperature_c=25.0
        )
        
        prediction = predictor.update(state)
        
        assert prediction.soc_percent > 95.0  # Should be nearly full
        assert prediction.remaining_capacity_ah > 4.5
        assert prediction.critical_warning == False
        assert prediction.temperature_derating_factor == pytest.approx(1.0, abs=0.1)
    
    def test_discharge_behavior(self):
        """Test battery discharge behavior and coulomb counting."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        base_time = time.time_ns()
        
        # Start with full battery
        state1 = BatteryState(
            timestamp_ns=base_time,
            voltage_v=16.8,
            current_a=0.0,
            temperature_c=25.0
        )
        prediction1 = predictor.update(state1)
        initial_soc = prediction1.soc_percent
        
        # Simulate 1A discharge for 1 hour (should consume 1Ah from 5Ah capacity)
        state2 = BatteryState(
            timestamp_ns=base_time + int(3600 * 1e9),  # 1 hour later
            voltage_v=15.6,  # Lower voltage under load
            current_a=1.0,   # 1A discharge
            temperature_c=25.0
        )
        prediction2 = predictor.update(state2)
        
        # Should have consumed approximately 1Ah (20% of 5Ah capacity)
        expected_soc = initial_soc - 20.0
        assert prediction2.soc_percent < initial_soc
        assert abs(prediction2.soc_percent - expected_soc) < 10.0  # Allow some tolerance
        assert prediction2.discharge_rate_c == pytest.approx(0.2, abs=0.05)  # 1A/5Ah = 0.2C
    
    def test_temperature_compensation(self):
        """Test temperature effects on battery capacity."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        base_time = time.time_ns()
        
        # Test at reference temperature (25°C)
        state_normal = BatteryState(
            timestamp_ns=base_time,
            voltage_v=15.6,
            current_a=0.5,
            temperature_c=25.0
        )
        prediction_normal = predictor.update(state_normal)
        
        # Reset predictor for cold temperature test
        predictor_cold = BatteryPredictor(spec)
        
        # Test at cold temperature (0°C)
        state_cold = BatteryState(
            timestamp_ns=base_time,
            voltage_v=15.6,
            current_a=0.5,
            temperature_c=0.0
        )
        prediction_cold = predictor_cold.update(state_cold)
        
        # Cold temperature should reduce effective capacity
        assert prediction_cold.temperature_derating_factor < prediction_normal.temperature_derating_factor
        assert prediction_cold.effective_capacity_ah < prediction_normal.effective_capacity_ah
    
    def test_peukert_effect(self):
        """Test Peukert's equation for high discharge rates."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        # Test at low discharge rate (0.5C)
        low_rate_capacity = predictor._apply_peukert_equation(5.0, 0.5)
        
        # Test at high discharge rate (2C)
        high_rate_capacity = predictor._apply_peukert_equation(5.0, 2.0)
        
        # High discharge rate should reduce effective capacity due to Peukert effect
        assert high_rate_capacity < low_rate_capacity
        assert high_rate_capacity < 5.0  # Should be less than nominal
    
    def test_critical_warning_conditions(self):
        """Test critical battery warning conditions."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec, critical_soc_threshold=20.0)
        
        # Test low voltage warning
        state_low_voltage = BatteryState(
            timestamp_ns=time.time_ns(),
            voltage_v=13.0,  # Below safe cutoff
            current_a=1.0,
            temperature_c=25.0
        )
        prediction_low_voltage = predictor.update(state_low_voltage)
        assert prediction_low_voltage.critical_warning == True
        
        # Reset for low SOC test
        predictor_soc = BatteryPredictor(spec, critical_soc_threshold=20.0)
        
        # Simulate very low SOC by high cumulative consumption
        predictor_soc.cumulative_ah_consumed = 4.2  # Consumed 4.2Ah from 5Ah
        
        state_low_soc = BatteryState(
            timestamp_ns=time.time_ns(),
            voltage_v=14.4,  # Voltage still OK
            current_a=0.5,
            temperature_c=25.0
        )
        prediction_low_soc = predictor_soc.update(state_low_soc)
        assert prediction_low_soc.critical_warning == True
    
    def test_power_trend_analysis(self):
        """Test power consumption trend analysis."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        base_time = time.time_ns()
        
        # Add several power samples with increasing trend
        powers = [3.0, 3.5, 4.0, 4.5, 5.0]  # Watts
        for i, power in enumerate(powers):
            state = BatteryState(
                timestamp_ns=base_time + i * int(10 * 1e9),  # 10 second intervals
                voltage_v=15.0,
                current_a=power / 15.0,  # I = P/V
                power_w=power,
                temperature_c=25.0
            )
            predictor.update(state)
        
        trend = predictor.get_power_trend_analysis(window_s=60.0)
        
        assert trend["trend_w_per_s"] > 0  # Should show increasing trend
        assert trend["avg_power_w"] == pytest.approx(4.0, abs=0.5)
        assert trend["peak_power_w"] == 5.0
    
    def test_mission_viability_prediction(self):
        """Test mission viability prediction."""
        spec = create_default_lipo_spec(5.0, 4)
        predictor = BatteryPredictor(spec)
        
        # Start with partially charged battery
        state = BatteryState(
            timestamp_ns=time.time_ns(),
            voltage_v=15.6,  # ~70% charge
            current_a=0.0,
            temperature_c=25.0
        )
        predictor.update(state)
        
        # Test viable mission (low power, short duration)
        viable_mission = predictor.predict_mission_viability(
            target_duration_s=1800,  # 30 minutes
            expected_avg_power_w=3.0  # 3 watts
        )
        assert viable_mission["viable"] == True
        assert viable_mission["margin_s"] > 0
        
        # Test non-viable mission (high power, long duration)
        non_viable_mission = predictor.predict_mission_viability(
            target_duration_s=7200,  # 2 hours
            expected_avg_power_w=8.0  # 8 watts
        )
        assert non_viable_mission["viable"] == False
        assert non_viable_mission["reason"] == "insufficient_capacity"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

============================================================

FILE 7/19: scheduler\components\tests\test_integration.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_integration.py
Size: 24,331 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""Integration tests for the complete scheduler pipeline."""

import pytest
import time
import threading
import tempfile
import os
from unittest.mock import Mock, patch
from src.scheduler.unified_scheduler import UnifiedUAVScheduler, TelemetrySnapshot, SchedulerConfig
from src.scheduler.components.battery_predictor import BatteryPredictor, BatterySpecs
from src.scheduler.components.thermal_guard import ThermalGuard, TemperatureSample
from src.scheduler.components.security_advisor import SecurityAdvisor
from src.scheduler.components.ipc_bridge import IPCBridge, AlgorithmType


class TestSchedulerIntegration:
    
    @pytest.fixture
    def realistic_battery_specs(self):
        """Realistic Li-Po battery specifications for testing."""
        return BatterySpecs(
            nominal_voltage_v=14.8,
            nominal_capacity_ah=5.0,
            max_discharge_rate_c=10.0,
            min_voltage_v=11.1,
            max_voltage_v=16.8,
            peukert_exponent=1.3,
            internal_resistance_mohm=50.0,
            temp_coefficient_per_c=-0.005
        )
    
    def test_end_to_end_scheduler_pipeline(self, realistic_battery_specs):
        """Test complete end-to-end scheduler operation."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Initialize all real components
            battery_predictor = BatteryPredictor(battery_specs=realistic_battery_specs)
            thermal_guard = ThermalGuard(
                warning_temp=70.0,
                critical_temp=80.0,
                emergency_temp=85.0
            )
            
            # Mock security advisor (requires trained models)
            with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
                security_advisor = SecurityAdvisor()
                security_advisor.xgboost_model = Mock()
                security_advisor.transformer_model = Mock()
                security_advisor.xgboost_model.predict_proba.return_value = [[0.8, 0.2]]
                security_advisor.transformer_model.predict.return_value = [[0.85, 0.15]]
            
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            # Create unified scheduler
            config = SchedulerConfig(
                decision_interval_ms=100,
                enable_expert_system=True,
                enable_reinforcement_learning=False,  # Skip RL for integration test
                enable_hybrid_fusion=False
            )
            
            scheduler = UnifiedUAVScheduler(
                config=config,
                battery_predictor=battery_predictor,
                thermal_guard=thermal_guard,
                security_advisor=security_advisor,
                ipc_bridge=ipc_bridge
            )
            
            # Simulate realistic mission telemetry sequence
            mission_duration_s = 5.0
            telemetry_interval_s = 0.1
            iterations = int(mission_duration_s / telemetry_interval_s)
            
            decisions = []
            start_time = time.time()
            
            for i in range(iterations):
                # Simulate battery discharge and warming
                elapsed_time = i * telemetry_interval_s
                battery_voltage = 14.8 - (elapsed_time / 300.0) * 3.7  # Discharge over 5 minutes
                cpu_temp = 45.0 + (elapsed_time / 60.0) * 15.0  # Warm up over 1 minute
                
                telemetry = TelemetrySnapshot(
                    timestamp_ns=int((start_time + elapsed_time) * 1e9),
                    battery_voltage_v=max(battery_voltage, 11.1),
                    battery_current_a=-3.0,  # 3A discharge
                    cpu_temp_c=min(cpu_temp, 75.0),
                    ambient_temp_c=25.0,
                    network_packet_rate=150.0 + i * 2.0,  # Gradually increasing
                    network_byte_rate=75000.0 + i * 1000.0
                )
                
                # Process telemetry through full pipeline
                analysis = scheduler._process_telemetry(telemetry)
                decision = scheduler._make_scheduling_decision(analysis)
                
                decisions.append({
                    'time': elapsed_time,
                    'battery_soc': analysis.battery_analysis.soc_percentage,
                    'cpu_temp': analysis.thermal_analysis.current_temp_c,
                    'threat_score': analysis.security_analysis.combined_threat_score,
                    'recommended_suite': decision.recommended_suite,
                    'confidence': decision.confidence_score
                })
                
                time.sleep(0.01)  # Small delay to simulate real-time processing
            
            # Analyze decision sequence
            assert len(decisions) == iterations
            
            # Verify battery SOC decreases over time
            initial_soc = decisions[0]['battery_soc']
            final_soc = decisions[-1]['battery_soc']
            assert final_soc < initial_soc
            
            # Verify temperature increases over time  
            initial_temp = decisions[0]['cpu_temp']
            final_temp = decisions[-1]['cpu_temp']
            assert final_temp > initial_temp
            
            # Verify graceful degradation occurs
            suite_changes = []
            prev_suite = decisions[0]['recommended_suite']
            for decision in decisions[1:]:
                if decision['recommended_suite'] != prev_suite:
                    suite_changes.append(decision)
                    prev_suite = decision['recommended_suite']
            
            # Should have at least some adaptation as conditions change
            assert len(suite_changes) >= 0  # May not change if conditions stay stable
            
            # Cleanup
            ipc_bridge.shutdown()
    
    def test_multi_component_stress_conditions(self, realistic_battery_specs):
        """Test scheduler behavior under multiple simultaneous stress conditions."""
        with tempfile.TemporaryDirectory() as temp_dir:
            battery_predictor = BatteryPredictor(battery_specs=realistic_battery_specs)
            thermal_guard = ThermalGuard(warning_temp=65.0, critical_temp=75.0)
            
            with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
                security_advisor = SecurityAdvisor()
                security_advisor.xgboost_model = Mock()
                security_advisor.transformer_model = Mock()
            
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            scheduler = UnifiedUAVScheduler(
                battery_predictor=battery_predictor,
                thermal_guard=thermal_guard,
                security_advisor=security_advisor,
                ipc_bridge=ipc_bridge
            )
            
            # Simulate critical battery + high temperature + security threat
            stress_telemetry = TelemetrySnapshot(
                timestamp_ns=time.time_ns(),
                battery_voltage_v=11.5,  # Critical battery
                battery_current_a=-8.0,  # High discharge
                cpu_temp_c=78.0,        # Above critical thermal threshold
                ambient_temp_c=35.0,    # Hot environment
                network_packet_rate=15000.0,  # Potential DDOS
                network_byte_rate=7500000.0
            )
            
            # Mock high security threat
            security_advisor.xgboost_model.predict_proba.return_value = [[0.1, 0.9]]
            security_advisor.transformer_model.predict.return_value = [[0.05, 0.95]]
            
            # Process stress conditions
            analysis = scheduler._process_telemetry(stress_telemetry)
            decision = scheduler._make_scheduling_decision(analysis)
            
            # Should prioritize resource conservation due to multiple critical conditions
            assert decision.recommended_suite == "cs-mlkem512-aesgcm-mldsa44"
            assert "emergency" in decision.reasoning.lower() or "critical" in decision.reasoning.lower()
            assert decision.emergency_actions_required == True
            
            ipc_bridge.shutdown()
    
    def test_algorithm_switching_performance(self):
        """Test algorithm switching performance under realistic conditions."""
        with tempfile.TemporaryDirectory() as temp_dir:
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            # Prewarm algorithms for optimal performance
            ipc_bridge.prewarm_algorithms([
                AlgorithmType.EXPERT_SYSTEM,
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION
            ])
            
            switch_times = []
            algorithms_to_test = [
                AlgorithmType.EXPERT_SYSTEM,
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION,
                AlgorithmType.EXPERT_SYSTEM,  # Test switching back
            ]
            
            for target_algorithm in algorithms_to_test:
                start_time = time.perf_counter()
                switch_time = ipc_bridge.switch_algorithm(target_algorithm, priority_ms=1)
                actual_time = (time.perf_counter() - start_time) * 1000  # Convert to ms
                
                switch_times.append(actual_time)
                
                # Verify switch was recorded
                assert switch_time > 0
                assert ipc_bridge.current_algorithm == target_algorithm
            
            # Verify sub-millisecond switching performance
            avg_switch_time = sum(switch_times) / len(switch_times)
            max_switch_time = max(switch_times)
            
            assert avg_switch_time < 1.0, f"Average switch time {avg_switch_time:.3f}ms too high"
            assert max_switch_time < 2.0, f"Max switch time {max_switch_time:.3f}ms too high"
            
            ipc_bridge.shutdown()
    
    def test_concurrent_telemetry_processing(self, realistic_battery_specs):
        """Test concurrent telemetry processing from multiple sources."""
        with tempfile.TemporaryDirectory() as temp_dir:
            battery_predictor = BatteryPredictor(battery_specs=realistic_battery_specs)
            thermal_guard = ThermalGuard()
            
            with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
                security_advisor = SecurityAdvisor()
                security_advisor.xgboost_model = Mock()
                security_advisor.transformer_model = Mock()
                security_advisor.xgboost_model.predict_proba.return_value = [[0.9, 0.1]]
                security_advisor.transformer_model.predict.return_value = [[0.95, 0.05]]
            
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            scheduler = UnifiedUAVScheduler(
                battery_predictor=battery_predictor,
                thermal_guard=thermal_guard,
                security_advisor=security_advisor,
                ipc_bridge=ipc_bridge
            )
            
            results = []
            errors = []
            
            def telemetry_worker(worker_id, telemetry_count):
                """Simulate telemetry processing from different sources."""
                try:
                    for i in range(telemetry_count):
                        telemetry = TelemetrySnapshot(
                            timestamp_ns=time.time_ns() + i * int(10e6),  # 10ms intervals
                            battery_voltage_v=14.8 - worker_id * 0.1,
                            battery_current_a=-2.0 - worker_id * 0.5,
                            cpu_temp_c=50.0 + worker_id * 5.0,
                            ambient_temp_c=25.0,
                            network_packet_rate=100.0 + worker_id * 50.0
                        )
                        
                        analysis = scheduler._process_telemetry(telemetry)
                        decision = scheduler._make_scheduling_decision(analysis)
                        
                        results.append({
                            'worker_id': worker_id,
                            'iteration': i,
                            'success': analysis is not None and decision is not None,
                            'suite': decision.recommended_suite if decision else None
                        })
                        
                        time.sleep(0.001)  # Small delay between samples
                        
                except Exception as e:
                    errors.append(f"Worker {worker_id}: {str(e)}")
            
            # Launch concurrent telemetry workers
            threads = []
            worker_count = 4
            samples_per_worker = 10
            
            for worker_id in range(worker_count):
                thread = threading.Thread(
                    target=telemetry_worker,
                    args=(worker_id, samples_per_worker)
                )
                threads.append(thread)
                thread.start()
            
            # Wait for all workers to complete
            for thread in threads:
                thread.join(timeout=30.0)
                assert not thread.is_alive(), "Thread did not complete in time"
            
            # Analyze results
            assert len(errors) == 0, f"Processing errors: {errors}"
            assert len(results) == worker_count * samples_per_worker
            
            successful_results = [r for r in results if r['success']]
            assert len(successful_results) == len(results), "Some telemetry processing failed"
            
            # Verify different workers can have different suite recommendations
            worker_suites = {}
            for result in successful_results:
                worker_id = result['worker_id']
                suite = result['suite']
                if worker_id not in worker_suites:
                    worker_suites[worker_id] = set()
                worker_suites[worker_id].add(suite)
            
            # Each worker should have consistent recommendations (based on their conditions)
            for worker_id, suites in worker_suites.items():
                assert len(suites) <= 2, f"Worker {worker_id} had too many suite changes: {suites}"
            
            ipc_bridge.shutdown()
    
    def test_configuration_validation_and_updates(self, realistic_battery_specs):
        """Test configuration validation and hot updates."""
        with tempfile.TemporaryDirectory() as temp_dir:
            battery_predictor = BatteryPredictor(battery_specs=realistic_battery_specs)
            thermal_guard = ThermalGuard()
            
            with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
                security_advisor = SecurityAdvisor()
            
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            # Test invalid configuration
            invalid_config = SchedulerConfig(
                decision_interval_ms=-10,  # Invalid negative interval
                battery_critical_threshold=1.5  # Invalid threshold > 1.0
            )
            
            # Should handle invalid config gracefully
            scheduler = UnifiedUAVScheduler(
                config=invalid_config,
                battery_predictor=battery_predictor,
                thermal_guard=thermal_guard,
                security_advisor=security_advisor,
                ipc_bridge=ipc_bridge
            )
            
            # Should have fallen back to safe defaults
            assert scheduler.config.decision_interval_ms > 0
            assert scheduler.config.battery_critical_threshold <= 1.0
            
            # Test valid configuration update
            new_config = SchedulerConfig(
                decision_interval_ms=200,
                battery_critical_threshold=0.2,
                thermal_critical_temp=85.0
            )
            
            update_success = scheduler.update_configuration(new_config)
            assert update_success == True
            assert scheduler.config.decision_interval_ms == 200
            assert scheduler.config.battery_critical_threshold == 0.2
            
            ipc_bridge.shutdown()
    
    def test_hardware_simulation_smoke_test(self, realistic_battery_specs):
        """Smoke test simulating realistic Pi 4 + Pixhawk hardware conditions."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Configure for Pi 4 constraints
            battery_predictor = BatteryPredictor(battery_specs=realistic_battery_specs)
            thermal_guard = ThermalGuard(
                warning_temp=60.0,   # Pi 4 gets warm
                critical_temp=70.0,  # Pi 4 throttling point
                emergency_temp=80.0
            )
            
            with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
                security_advisor = SecurityAdvisor()
                security_advisor.xgboost_model = Mock()
                security_advisor.transformer_model = Mock()
                security_advisor.xgboost_model.predict_proba.return_value = [[0.85, 0.15]]
                security_advisor.transformer_model.predict.return_value = [[0.9, 0.1]]
            
            ipc_bridge = IPCBridge(shared_memory_dir=temp_dir)
            ipc_bridge.initialize_shared_memory()
            
            # Pi 4 optimized configuration
            pi4_config = SchedulerConfig(
                decision_interval_ms=250,  # Balanced for Pi 4 performance
                enable_expert_system=True,
                enable_reinforcement_learning=False,  # May be too heavy for Pi 4
                max_cpu_usage_percent=80.0,
                enable_thermal_throttling=True
            )
            
            scheduler = UnifiedUAVScheduler(
                config=pi4_config,
                battery_predictor=battery_predictor,
                thermal_guard=thermal_guard,
                security_advisor=security_advisor,
                ipc_bridge=ipc_bridge
            )
            
            # Simulate Pi 4 + Pixhawk mission profile
            mission_scenarios = [
                # Scenario 1: Normal cruise
                {
                    'duration_s': 2.0,
                    'battery_voltage': 14.8,
                    'current_draw': -2.0,
                    'cpu_temp_start': 45.0,
                    'cpu_temp_end': 55.0,
                    'network_load': 100.0
                },
                # Scenario 2: High performance maneuver
                {
                    'duration_s': 1.0,
                    'battery_voltage': 14.0,
                    'current_draw': -8.0,
                    'cpu_temp_start': 55.0,
                    'cpu_temp_end': 68.0,
                    'network_load': 500.0
                },
                # Scenario 3: Recovery and thermal management
                {
                    'duration_s': 2.0,
                    'battery_voltage': 13.5,
                    'current_draw': -1.5,
                    'cpu_temp_start': 68.0,
                    'cpu_temp_end': 50.0,
                    'network_load': 80.0
                }
            ]
            
            total_decisions = 0
            scenario_results = []
            
            for scenario_idx, scenario in enumerate(mission_scenarios):
                scenario_start = time.time()
                decisions_in_scenario = []
                
                iterations = int(scenario['duration_s'] / (pi4_config.decision_interval_ms / 1000.0))
                
                for i in range(max(1, iterations)):
                    progress = i / max(1, iterations - 1) if iterations > 1 else 0
                    
                    # Interpolate conditions over scenario duration
                    cpu_temp = (scenario['cpu_temp_start'] + 
                              progress * (scenario['cpu_temp_end'] - scenario['cpu_temp_start']))
                    
                    telemetry = TelemetrySnapshot(
                        timestamp_ns=time.time_ns(),
                        battery_voltage_v=scenario['battery_voltage'],
                        battery_current_a=scenario['current_draw'],
                        cpu_temp_c=cpu_temp,
                        ambient_temp_c=30.0,
                        network_packet_rate=scenario['network_load']
                    )
                    
                    # Time the processing
                    process_start = time.perf_counter()
                    analysis = scheduler._process_telemetry(telemetry)
                    decision = scheduler._make_scheduling_decision(analysis)
                    process_time_ms = (time.perf_counter() - process_start) * 1000
                    
                    decisions_in_scenario.append({
                        'processing_time_ms': process_time_ms,
                        'suite': decision.recommended_suite,
                        'confidence': decision.confidence_score,
                        'thermal_state': analysis.thermal_analysis.state.name,
                        'battery_soc': analysis.battery_analysis.soc_percentage
                    })
                    
                    total_decisions += 1
                    
                    # Verify real-time constraint compliance
                    assert process_time_ms < pi4_config.decision_interval_ms, \
                        f"Processing time {process_time_ms:.1f}ms exceeded interval {pi4_config.decision_interval_ms}ms"
                
                scenario_results.append({
                    'scenario': scenario_idx,
                    'duration': time.time() - scenario_start,
                    'decisions': decisions_in_scenario
                })
            
            # Analyze overall performance
            all_processing_times = []
            for scenario in scenario_results:
                for decision in scenario['decisions']:
                    all_processing_times.append(decision['processing_time_ms'])
            
            avg_processing_time = sum(all_processing_times) / len(all_processing_times)
            max_processing_time = max(all_processing_times)
            
            # Pi 4 performance verification
            assert avg_processing_time < 100.0, f"Average processing time {avg_processing_time:.1f}ms too high for Pi 4"
            assert max_processing_time < 200.0, f"Max processing time {max_processing_time:.1f}ms too high for Pi 4"
            assert total_decisions > 0, "No decisions were made during simulation"
            
            # Verify adaptive behavior occurred
            suite_transitions = 0
            prev_suite = None
            for scenario in scenario_results:
                for decision in scenario['decisions']:
                    if prev_suite and decision['suite'] != prev_suite:
                        suite_transitions += 1
                    prev_suite = decision['suite']
            
            # Should have some adaptation to changing conditions
            assert suite_transitions >= 0, "No suite adaptations occurred"
            
            ipc_bridge.shutdown()


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])  # -s to see print output during testing

============================================================

FILE 8/19: scheduler\components\tests\test_ipc_bridge.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_ipc_bridge.py
Size: 15,008 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""Unit tests for IPC bridge component."""

import pytest
import time
import threading
import tempfile
import os
from unittest.mock import Mock, patch
from src.scheduler.components.ipc_bridge import (
    IPCBridge, AlgorithmType, IPCMessage, SharedMemoryConfig
)


class TestIPCBridge:
    
    def test_ipc_bridge_initialization(self):
        """Test IPC bridge initialization with default parameters."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            
            assert bridge.shared_memory_size == 4096
            assert bridge.current_algorithm == AlgorithmType.EXPERT_SYSTEM
            assert bridge.algorithm_warm_pool_size == 3
            assert bridge.shared_memory_dir == temp_dir
    
    def test_shared_memory_initialization(self):
        """Test shared memory segment creation and mapping."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            
            success = bridge.initialize_shared_memory()
            assert success == True
            
            # Verify shared memory file exists
            shm_path = os.path.join(temp_dir, "scheduler_ipc")
            assert os.path.exists(shm_path)
            
            # Verify size
            assert os.path.getsize(shm_path) == bridge.shared_memory_size
    
    def test_algorithm_switching_basic(self):
        """Test basic algorithm switching functionality."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Switch to RL algorithm
            switch_time = bridge.switch_algorithm(
                target_algorithm=AlgorithmType.REINFORCEMENT_LEARNING,
                priority_ms=10
            )
            
            assert switch_time > 0
            assert bridge.current_algorithm == AlgorithmType.REINFORCEMENT_LEARNING
    
    def test_algorithm_prewarming(self):
        """Test algorithm prewarming for faster switching."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir, algorithm_warm_pool_size=2)
            bridge.initialize_shared_memory()
            
            # Prewarm algorithms
            bridge.prewarm_algorithms([
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION
            ])
            
            # Verify warm pool
            assert AlgorithmType.REINFORCEMENT_LEARNING in bridge.warm_algorithm_pool
            assert AlgorithmType.HYBRID_FUSION in bridge.warm_algorithm_pool
            
            # Switch to prewarmed algorithm should be faster
            warm_switch_time = bridge.switch_algorithm(
                target_algorithm=AlgorithmType.REINFORCEMENT_LEARNING,
                priority_ms=5
            )
            
            # Should be very fast due to prewarming
            assert warm_switch_time < 5.0  # milliseconds
    
    def test_concurrent_algorithm_switching(self):
        """Test concurrent algorithm switching from multiple threads."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            switch_results = []
            
            def switch_worker(target_algorithm, thread_id):
                try:
                    switch_time = bridge.switch_algorithm(
                        target_algorithm=target_algorithm,
                        priority_ms=thread_id
                    )
                    switch_results.append((thread_id, switch_time, True))
                except Exception as e:
                    switch_results.append((thread_id, 0, False))
            
            # Launch concurrent switches
            threads = []
            algorithms = [
                AlgorithmType.EXPERT_SYSTEM,
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION
            ]
            
            for i, alg in enumerate(algorithms):
                thread = threading.Thread(
                    target=switch_worker,
                    args=(alg, i + 1)
                )
                threads.append(thread)
                thread.start()
            
            # Wait for completion
            for thread in threads:
                thread.join(timeout=5.0)
            
            # Verify all switches completed
            assert len(switch_results) == 3
            successful_switches = [r for r in switch_results if r[2]]
            assert len(successful_switches) > 0
    
    def test_message_passing_basic(self):
        """Test basic IPC message passing."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Send message
            message = IPCMessage(
                sender_id="test_sender",
                message_type="config_update",
                payload={"battery_soc": 0.75, "thermal_state": "normal"},
                priority=5
            )
            
            success = bridge.send_message(message)
            assert success == True
            
            # Receive message
            received = bridge.receive_message(timeout_ms=100)
            assert received is not None
            assert received.sender_id == "test_sender"
            assert received.message_type == "config_update"
            assert received.payload["battery_soc"] == 0.75
    
    def test_message_queue_overflow(self):
        """Test message queue behavior under overflow conditions."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir, max_message_queue_size=3)
            bridge.initialize_shared_memory()
            
            # Fill message queue beyond capacity
            messages_sent = 0
            for i in range(5):
                message = IPCMessage(
                    sender_id=f"sender_{i}",
                    message_type="test",
                    payload={"index": i},
                    priority=i
                )
                if bridge.send_message(message):
                    messages_sent += 1
            
            # Should have dropped lower priority messages
            assert messages_sent <= 3
            
            # Receive all available messages
            received_messages = []
            while True:
                msg = bridge.receive_message(timeout_ms=10)
                if msg is None:
                    break
                received_messages.append(msg)
            
            # Should receive highest priority messages
            assert len(received_messages) <= 3
            if len(received_messages) > 0:
                priorities = [msg.priority for msg in received_messages]
                assert max(priorities) >= 2  # Higher priority messages preserved
    
    def test_performance_metrics_collection(self):
        """Test collection of IPC performance metrics."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Perform several operations
            for i in range(5):
                bridge.switch_algorithm(
                    target_algorithm=AlgorithmType.REINFORCEMENT_LEARNING,
                    priority_ms=1
                )
                bridge.switch_algorithm(
                    target_algorithm=AlgorithmType.EXPERT_SYSTEM,
                    priority_ms=1
                )
            
            metrics = bridge.get_performance_metrics()
            
            assert "switch_count" in metrics
            assert "avg_switch_time_ms" in metrics
            assert "total_messages_sent" in metrics
            assert "total_messages_received" in metrics
            
            assert metrics["switch_count"] >= 10
            assert metrics["avg_switch_time_ms"] > 0
    
    def test_algorithm_state_persistence(self):
        """Test persistence of algorithm state across switches."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Set initial state for expert system
            initial_state = {
                "rule_weights": [0.5, 0.3, 0.2],
                "threshold_values": {"battery": 0.3, "thermal": 75.0}
            }
            
            bridge.set_algorithm_state(AlgorithmType.EXPERT_SYSTEM, initial_state)
            
            # Switch to different algorithm
            bridge.switch_algorithm(AlgorithmType.REINFORCEMENT_LEARNING)
            
            # Switch back and verify state persistence
            bridge.switch_algorithm(AlgorithmType.EXPERT_SYSTEM)
            restored_state = bridge.get_algorithm_state(AlgorithmType.EXPERT_SYSTEM)
            
            assert restored_state == initial_state
    
    def test_memory_mapped_config_updates(self):
        """Test memory-mapped configuration updates."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Update configuration
            config_updates = {
                "battery_critical_threshold": 0.15,
                "thermal_warning_temp": 70.0,
                "security_threat_threshold": 0.8
            }
            
            success = bridge.update_shared_config(config_updates)
            assert success == True
            
            # Read back configuration
            current_config = bridge.get_shared_config()
            
            for key, value in config_updates.items():
                assert current_config[key] == value
    
    def test_semaphore_coordination(self):
        """Test semaphore-based coordination between processes."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            coordination_results = []
            
            def coordinated_worker(worker_id, iterations):
                for _ in range(iterations):
                    acquired = bridge.acquire_coordination_semaphore(timeout_ms=100)
                    if acquired:
                        # Critical section
                        time.sleep(0.001)  # Simulate work
                        bridge.release_coordination_semaphore()
                        coordination_results.append(worker_id)
            
            # Launch coordinated workers
            threads = []
            for i in range(3):
                thread = threading.Thread(
                    target=coordinated_worker,
                    args=(i, 5)
                )
                threads.append(thread)
                thread.start()
            
            # Wait for completion
            for thread in threads:
                thread.join(timeout=5.0)
            
            # Verify coordination worked (all workers made progress)
            assert len(coordination_results) == 15  # 3 workers × 5 iterations
            assert len(set(coordination_results)) == 3  # All workers participated
    
    def test_ipc_cleanup_and_shutdown(self):
        """Test proper cleanup and shutdown of IPC resources."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            shm_path = os.path.join(temp_dir, "scheduler_ipc")
            assert os.path.exists(shm_path)
            
            # Shutdown and cleanup
            bridge.shutdown()
            
            # Verify cleanup (shared memory file should be removed)
            assert not os.path.exists(shm_path)
    
    def test_error_handling_and_recovery(self):
        """Test error handling and recovery mechanisms."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            
            # Test operation without initialization
            success = bridge.switch_algorithm(AlgorithmType.REINFORCEMENT_LEARNING)
            assert success == False
            
            # Initialize and test invalid algorithm
            bridge.initialize_shared_memory()
            
            # Test with invalid shared memory access
            bridge.shared_memory_fd = -1  # Simulate corruption
            
            success = bridge.send_message(IPCMessage(
                sender_id="test",
                message_type="test",
                payload={},
                priority=1
            ))
            assert success == False
    
    def test_algorithm_switching_latency(self):
        """Test algorithm switching latency under various conditions."""
        with tempfile.TemporaryDirectory() as temp_dir:
            bridge = IPCBridge(shared_memory_dir=temp_dir)
            bridge.initialize_shared_memory()
            
            # Prewarm algorithms for fair comparison
            bridge.prewarm_algorithms([
                AlgorithmType.EXPERT_SYSTEM,
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION
            ])
            
            latencies = []
            
            # Measure switching latencies
            algorithms = [
                AlgorithmType.EXPERT_SYSTEM,
                AlgorithmType.REINFORCEMENT_LEARNING,
                AlgorithmType.HYBRID_FUSION
            ]
            
            for i in range(10):
                target_alg = algorithms[i % len(algorithms)]
                switch_time = bridge.switch_algorithm(target_alg, priority_ms=1)
                latencies.append(switch_time)
            
            # Verify sub-millisecond switching for prewarmed algorithms
            avg_latency = sum(latencies) / len(latencies)
            assert avg_latency < 1.0  # Should be under 1ms on average
            
            # Verify consistency (low variance)
            max_latency = max(latencies)
            min_latency = min(latencies)
            assert (max_latency - min_latency) < 2.0  # Low variance


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

============================================================

FILE 9/19: scheduler\components\tests\test_security_advisor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_security_advisor.py
Size: 15,056 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""Unit tests for security advisor component."""

import pytest
import time
import numpy as np
from unittest.mock import Mock, patch, MagicMock
from src.scheduler.components.security_advisor import (
    SecurityAdvisor, ThreatLevel, SecurityMetrics, AttackVector
)


class TestSecurityAdvisor:
    
    def test_security_advisor_initialization(self):
        """Test security advisor initialization with default parameters."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            assert advisor.threat_threshold_low == 0.3
            assert advisor.threat_threshold_high == 0.7
            assert advisor.current_threat_level == ThreatLevel.LOW
            assert len(advisor.threat_history) == 0
    
    def test_network_traffic_analysis(self):
        """Test network traffic analysis for DDOS detection."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            # Mock model predictions
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # Normal traffic pattern
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.9, 0.1]])  # Low threat
            advisor.transformer_model.predict.return_value = np.array([[0.95, 0.05]])
            
            traffic_features = {
                'packet_rate': 100.0,
                'byte_rate': 50000.0,
                'unique_src_ips': 10,
                'avg_packet_size': 500.0,
                'tcp_syn_rate': 5.0,
                'udp_rate': 20.0
            }
            
            metrics = advisor.analyze_network_traffic(traffic_features)
            
            assert metrics.threat_level == ThreatLevel.LOW
            assert metrics.xgboost_confidence > 0.8
            assert metrics.transformer_confidence > 0.9
            assert metrics.combined_threat_score < 0.3
    
    def test_high_threat_detection(self):
        """Test detection of high-threat network patterns."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            # Mock high-threat predictions
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.2, 0.8]])  # High threat
            advisor.transformer_model.predict.return_value = np.array([[0.1, 0.9]])
            
            # Suspicious traffic pattern (high packet rate, low diversity)
            traffic_features = {
                'packet_rate': 10000.0,  # Very high
                'byte_rate': 1000000.0,
                'unique_src_ips': 1,     # Single source
                'avg_packet_size': 100.0, # Small packets
                'tcp_syn_rate': 5000.0,  # SYN flood indicators
                'udp_rate': 5000.0
            }
            
            metrics = advisor.analyze_network_traffic(traffic_features)
            
            assert metrics.threat_level == ThreatLevel.HIGH
            assert AttackVector.DDOS_VOLUMETRIC in metrics.detected_vectors
            assert metrics.combined_threat_score > 0.7
    
    def test_threat_level_transitions(self):
        """Test threat level state transitions and hysteresis."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor(
                threat_threshold_low=0.3,
                threat_threshold_high=0.7,
                threat_hysteresis=0.1
            )
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # Start with low threat
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.8, 0.2]])
            advisor.transformer_model.predict.return_value = np.array([[0.9, 0.1]])
            
            traffic_low = {'packet_rate': 100.0, 'byte_rate': 50000.0}
            metrics_low = advisor.analyze_network_traffic(traffic_low)
            assert metrics_low.threat_level == ThreatLevel.LOW
            
            # Escalate to high threat
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.2, 0.8]])
            advisor.transformer_model.predict.return_value = np.array([[0.1, 0.9]])
            
            traffic_high = {'packet_rate': 5000.0, 'byte_rate': 500000.0}
            metrics_high = advisor.analyze_network_traffic(traffic_high)
            assert metrics_high.threat_level == ThreatLevel.HIGH
            
            # Moderate reduction (should stay high due to hysteresis)
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.4, 0.6]])
            advisor.transformer_model.predict.return_value = np.array([[0.3, 0.7]])
            
            traffic_moderate = {'packet_rate': 2000.0, 'byte_rate': 200000.0}
            metrics_moderate = advisor.analyze_network_traffic(traffic_moderate)
            assert metrics_moderate.threat_level == ThreatLevel.HIGH  # Hysteresis keeps it high
    
    def test_attack_vector_classification(self):
        """Test classification of different attack vectors."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.1, 0.9]])
            advisor.transformer_model.predict.return_value = np.array([[0.05, 0.95]])
            
            # Test volumetric attack detection
            volumetric_features = {
                'packet_rate': 20000.0,
                'byte_rate': 2000000.0,
                'unique_src_ips': 100,
                'avg_packet_size': 100.0
            }
            
            metrics_vol = advisor.analyze_network_traffic(volumetric_features)
            assert AttackVector.DDOS_VOLUMETRIC in metrics_vol.detected_vectors
            
            # Test protocol attack detection
            protocol_features = {
                'packet_rate': 1000.0,
                'tcp_syn_rate': 900.0,  # High SYN rate
                'tcp_syn_ack_ratio': 0.1,  # Low ACK response
                'unique_src_ips': 50
            }
            
            metrics_proto = advisor.analyze_network_traffic(protocol_features)
            assert AttackVector.DDOS_PROTOCOL in metrics_proto.detected_vectors
    
    def test_suite_security_recommendation(self):
        """Test PQC suite recommendation based on threat level."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            available_suites = [
                "cs-mlkem512-aesgcm-mldsa44",
                "cs-mlkem768-aesgcm-mldsa65",
                "cs-mlkem1024-aesgcm-mldsa87"
            ]
            
            # Low threat should allow balanced suite
            advisor.current_threat_level = ThreatLevel.LOW
            recommended_low = advisor.recommend_security_suite(available_suites)
            assert recommended_low in available_suites
            
            # High threat should prefer maximum security
            advisor.current_threat_level = ThreatLevel.HIGH
            recommended_high = advisor.recommend_security_suite(available_suites)
            assert recommended_high == "cs-mlkem1024-aesgcm-mldsa87"  # Highest security
    
    def test_threat_confidence_scoring(self):
        """Test confidence scoring for threat assessments."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # High confidence scenario (models agree)
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.9, 0.1]])
            advisor.transformer_model.predict.return_value = np.array([[0.95, 0.05]])
            
            traffic_features = {'packet_rate': 100.0}
            metrics_confident = advisor.analyze_network_traffic(traffic_features)
            
            # Low confidence scenario (models disagree)
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.8, 0.2]])
            advisor.transformer_model.predict.return_value = np.array([[0.3, 0.7]])
            
            metrics_uncertain = advisor.analyze_network_traffic(traffic_features)
            
            assert metrics_confident.combined_confidence > metrics_uncertain.combined_confidence
    
    def test_adaptive_threshold_adjustment(self):
        """Test adaptive adjustment of threat thresholds."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor(adaptive_thresholds=True)
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # Simulate consistent false positives
            for _ in range(10):
                advisor.xgboost_model.predict_proba.return_value = np.array([[0.4, 0.6]])
                advisor.transformer_model.predict.return_value = np.array([[0.5, 0.5]])
                
                traffic = {'packet_rate': 200.0}  # Normal traffic
                advisor.analyze_network_traffic(traffic)
                # Mark as false positive
                advisor.record_false_positive()
            
            # Thresholds should have adjusted upward
            assert advisor.threat_threshold_high > 0.7  # Original threshold
    
    def test_performance_monitoring(self):
        """Test performance monitoring of detection models."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # Mock inference times
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.8, 0.2]])
            advisor.transformer_model.predict.return_value = np.array([[0.9, 0.1]])
            
            start_time = time.time()
            traffic_features = {'packet_rate': 100.0}
            metrics = advisor.analyze_network_traffic(traffic_features)
            
            # Should track inference times
            assert hasattr(metrics, 'xgboost_inference_time_ms')
            assert hasattr(metrics, 'transformer_inference_time_ms')
            assert metrics.xgboost_inference_time_ms >= 0
            assert metrics.transformer_inference_time_ms >= 0
    
    def test_feature_importance_analysis(self):
        """Test feature importance analysis for explainability."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor()
            
            # Mock model with feature importance
            advisor.xgboost_model = Mock()
            advisor.xgboost_model.feature_importances_ = np.array([0.3, 0.2, 0.15, 0.1, 0.25])
            
            importance = advisor.get_feature_importance()
            
            assert len(importance) > 0
            assert all(0 <= score <= 1 for score in importance.values())
            assert abs(sum(importance.values()) - 1.0) < 0.01  # Should sum to ~1
    
    def test_threat_history_analysis(self):
        """Test analysis of threat history patterns."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor(history_window_s=60.0)
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            base_time = time.time()
            
            # Add threat history samples
            threat_levels = [0.1, 0.2, 0.8, 0.9, 0.3, 0.1]  # Attack spike pattern
            for i, threat in enumerate(threat_levels):
                advisor.xgboost_model.predict_proba.return_value = np.array([[1-threat, threat]])
                advisor.transformer_model.predict.return_value = np.array([[1-threat, threat]])
                
                traffic = {'packet_rate': 100.0 * threat}
                metrics = advisor.analyze_network_traffic(traffic)
            
            history_analysis = advisor.get_threat_history_analysis()
            
            assert history_analysis['max_threat_score'] > 0.8
            assert history_analysis['avg_threat_score'] > 0.1
            assert history_analysis['threat_spike_count'] > 0
    
    def test_integration_with_ddos_models(self):
        """Test integration with external DDOS detection models."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models') as mock_load:
            # Mock successful model loading
            mock_load.return_value = None
            
            advisor = SecurityAdvisor(
                xgboost_model_path="tests/fixtures/xgb_model.json",
                transformer_model_path="tests/fixtures/transformer_model.pt"
            )
            
            # Verify models would be loaded from specified paths
            mock_load.assert_called_once()
    
    def test_emergency_response_mode(self):
        """Test emergency response mode during severe attacks."""
        with patch('src.scheduler.components.security_advisor.SecurityAdvisor._load_models'):
            advisor = SecurityAdvisor(emergency_threshold=0.95)
            
            advisor.xgboost_model = Mock()
            advisor.transformer_model = Mock()
            
            # Simulate severe attack
            advisor.xgboost_model.predict_proba.return_value = np.array([[0.02, 0.98]])
            advisor.transformer_model.predict.return_value = np.array([[0.01, 0.99]])
            
            traffic_severe = {
                'packet_rate': 50000.0,
                'byte_rate': 10000000.0,
                'unique_src_ips': 1,
                'tcp_syn_rate': 25000.0
            }
            
            metrics = advisor.analyze_network_traffic(traffic_severe)
            
            assert metrics.emergency_mode == True
            assert metrics.combined_threat_score > 0.95
            assert AttackVector.DDOS_VOLUMETRIC in metrics.detected_vectors


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

============================================================

FILE 10/19: scheduler\components\tests\test_thermal_guard.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_thermal_guard.py
Size: 10,973 bytes
Modified: 2025-10-14 06:28:46
------------------------------------------------------------
#!/usr/bin/env python3
"""Unit tests for thermal guard component."""

import pytest
import time
from src.scheduler.components.thermal_guard import (
    ThermalGuard, TemperatureSample, ThermalState
)


class TestThermalGuard:
    
    def test_thermal_guard_initialization(self):
        """Test thermal guard initialization with default parameters."""
        guard = ThermalGuard()
        
        assert guard.warning_temp == 70.0
        assert guard.critical_temp == 80.0
        assert guard.emergency_temp == 85.0
        assert guard.current_state == ThermalState.NORMAL
        assert len(guard.temp_history) == 0
    
    def test_normal_temperature_operation(self):
        """Test thermal guard behavior under normal temperatures."""
        guard = ThermalGuard()
        
        sample = TemperatureSample(
            timestamp_ns=time.time_ns(),
            cpu_temp_c=45.0,
            ambient_temp_c=25.0
        )
        
        analysis = guard.update(sample)
        
        assert analysis.state == ThermalState.NORMAL
        assert analysis.current_temp_c == 45.0
        assert analysis.thermal_headroom_c == 35.0  # 80 - 45
        assert analysis.throttling_recommended == False
        assert analysis.emergency_shutdown == False
        assert "NORMAL" in analysis.recommended_action
    
    def test_temperature_trend_calculation(self):
        """Test temperature trend analysis with multiple samples."""
        guard = ThermalGuard(trend_window_s=10.0)
        
        base_time = time.time_ns()
        
        # Add samples with increasing temperature trend
        temperatures = [50.0, 52.0, 54.0, 56.0, 58.0]
        for i, temp in enumerate(temperatures):
            sample = TemperatureSample(
                timestamp_ns=base_time + i * int(2e9),  # 2 second intervals
                cpu_temp_c=temp
            )
            analysis = guard.update(sample)
        
        # Should detect positive temperature trend
        assert analysis.trend_c_per_s > 0
        assert analysis.trend_c_per_s == pytest.approx(1.0, abs=0.5)  # ~1°C/s rise
    
    def test_elevated_temperature_state(self):
        """Test transition to elevated temperature state."""
        guard = ThermalGuard(warning_temp=70.0, critical_temp=80.0)
        
        sample = TemperatureSample(
            timestamp_ns=time.time_ns(),
            cpu_temp_c=75.0  # Between warning and critical
        )
        
        analysis = guard.update(sample)
        
        assert analysis.state == ThermalState.ELEVATED
        assert analysis.thermal_headroom_c == 5.0  # 80 - 75
        assert "ELEVATED" in analysis.recommended_action
    
    def test_critical_temperature_state(self):
        """Test transition to critical temperature state."""
        guard = ThermalGuard(warning_temp=70.0, critical_temp=80.0)
        
        sample = TemperatureSample(
            timestamp_ns=time.time_ns(),
            cpu_temp_c=82.0  # Above critical threshold
        )
        
        analysis = guard.update(sample)
        
        assert analysis.state == ThermalState.CRITICAL
        assert analysis.throttling_recommended == True
        assert "CRITICAL" in analysis.recommended_action
    
    def test_emergency_temperature_state(self):
        """Test emergency temperature conditions."""
        guard = ThermalGuard(emergency_temp=85.0)
        
        # Test emergency due to absolute temperature
        sample_hot = TemperatureSample(
            timestamp_ns=time.time_ns(),
            cpu_temp_c=87.0  # Above emergency threshold
        )
        
        analysis_hot = guard.update(sample_hot)
        
        assert analysis_hot.state == ThermalState.EMERGENCY
        assert analysis_hot.throttling_recommended == True
        assert analysis_hot.emergency_shutdown == True
        assert "EMERGENCY" in analysis_hot.recommended_action
    
    def test_rapid_temperature_rise_emergency(self):
        """Test emergency state due to rapid temperature rise."""
        guard = ThermalGuard(rapid_rise_threshold_c_per_s=2.0)
        
        base_time = time.time_ns()
        
        # Add samples showing rapid temperature rise
        temperatures = [60.0, 65.0, 70.0]  # 5°C rise per sample
        for i, temp in enumerate(temperatures):
            sample = TemperatureSample(
                timestamp_ns=base_time + i * int(1e9),  # 1 second intervals
                cpu_temp_c=temp
            )
            analysis = guard.update(sample)
        
        # Should trigger emergency due to rapid rise (>2°C/s)
        assert analysis.state == ThermalState.EMERGENCY
        assert analysis.trend_c_per_s > 2.0
    
    def test_hysteresis_behavior(self):
        """Test hysteresis to prevent oscillation between states."""
        guard = ThermalGuard(
            warning_temp=70.0, 
            critical_temp=80.0, 
            hysteresis_c=5.0
        )
        
        base_time = time.time_ns()
        
        # Heat up to critical
        sample_critical = TemperatureSample(
            timestamp_ns=base_time,
            cpu_temp_c=82.0
        )
        analysis_critical = guard.update(sample_critical)
        assert analysis_critical.state == ThermalState.CRITICAL
        
        # Cool down slightly but not enough to exit critical (due to hysteresis)
        sample_cool = TemperatureSample(
            timestamp_ns=base_time + int(5e9),
            cpu_temp_c=78.0  # Below critical but within hysteresis band
        )
        analysis_cool = guard.update(sample_cool)
        assert analysis_cool.state == ThermalState.CRITICAL  # Should stay critical
        
        # Cool down enough to exit critical state
        sample_cooler = TemperatureSample(
            timestamp_ns=base_time + int(10e9),
            cpu_temp_c=72.0  # Below critical - hysteresis = 75
        )
        analysis_cooler = guard.update(sample_cooler)
        assert analysis_cooler.state == ThermalState.ELEVATED
    
    def test_time_to_critical_prediction(self):
        """Test prediction of time until critical temperature."""
        guard = ThermalGuard(critical_temp=80.0)
        
        base_time = time.time_ns()
        
        # Create samples with steady temperature rise
        temperatures = [60.0, 62.0, 64.0, 66.0]
        for i, temp in enumerate(temperatures):
            sample = TemperatureSample(
                timestamp_ns=base_time + i * int(5e9),  # 5 second intervals
                cpu_temp_c=temp
            )
            analysis = guard.update(sample)
        
        # Should predict time to reach 80°C based on current trend
        if analysis.time_to_critical_s is not None:
            assert analysis.time_to_critical_s > 0
            assert analysis.time_to_critical_s < 300  # Should be reasonable estimate
    
    def test_thermal_budget_analysis(self):
        """Test thermal budget analysis for additional power loads."""
        guard = ThermalGuard(critical_temp=80.0, warning_temp=70.0)
        
        # Start with moderate temperature
        sample = TemperatureSample(
            timestamp_ns=time.time_ns(),
            cpu_temp_c=65.0
        )
        guard.update(sample)
        
        # Test feasible power increase
        budget_feasible = guard.get_thermal_budget_analysis(target_power_increase_w=2.0)
        assert budget_feasible["feasible"] == True
        assert budget_feasible["projected_temp_c"] < 80.0
        
        # Test excessive power increase
        budget_excessive = guard.get_thermal_budget_analysis(target_power_increase_w=10.0)
        assert budget_excessive["feasible"] == False
        assert budget_excessive["reason"] == "insufficient_headroom"
    
    def test_suite_thermal_mapping(self):
        """Test PQC suite thermal characteristic mapping."""
        guard = ThermalGuard()
        
        mapping = guard.get_suite_thermal_mapping()
        
        # Should have entries for different PQC suites
        assert "cs-mlkem512-aesgcm-mldsa44" in mapping
        assert "cs-mlkem768-aesgcm-mldsa65" in mapping
        assert "cs-mlkem1024-aesgcm-mldsa87" in mapping
        
        # Higher security suites should have higher power/thermal impact
        low_suite = mapping["cs-mlkem512-aesgcm-mldsa44"]
        high_suite = mapping["cs-mlkem1024-aesgcm-mldsa87"]
        
        assert low_suite["typical_power_w"] < high_suite["typical_power_w"]
        assert low_suite["temp_rise_steady_c"] < high_suite["temp_rise_steady_c"]
    
    def test_optimal_suite_recommendation(self):
        """Test optimal PQC suite recommendation based on thermal state."""
        guard = ThermalGuard(critical_temp=80.0)
        
        available_suites = [
            "cs-mlkem512-aesgcm-mldsa44",
            "cs-mlkem768-aesgcm-mldsa65", 
            "cs-mlkem1024-aesgcm-mldsa87"
        ]
        
        # Test recommendation at normal temperature
        recommended_normal = guard.recommend_optimal_suite(
            available_suites, 
            current_temp_c=50.0,
            target_margin_c=15.0
        )
        assert recommended_normal is not None
        
        # Test recommendation at high temperature (should prefer low-power suite)
        recommended_hot = guard.recommend_optimal_suite(
            available_suites,
            current_temp_c=75.0,
            target_margin_c=10.0
        )
        assert recommended_hot == "cs-mlkem512-aesgcm-mldsa44"  # Should pick lowest power
    
    def test_confidence_calculation(self):
        """Test confidence score calculation based on data quality."""
        guard = ThermalGuard()
        
        base_time = time.time_ns()
        
        # Add stable temperature samples
        for i in range(10):
            sample = TemperatureSample(
                timestamp_ns=base_time + i * int(1e9),
                cpu_temp_c=50.0 + 0.1 * i  # Very stable temperatures
            )
            analysis = guard.update(sample)
        
        # Should have high confidence with stable, regular measurements
        assert analysis.confidence_score > 0.7
        
        # Test with noisy data
        guard_noisy = ThermalGuard()
        import random
        
        for i in range(10):
            sample = TemperatureSample(
                timestamp_ns=base_time + i * int(1e9),
                cpu_temp_c=50.0 + random.uniform(-10, 10)  # Very noisy
            )
            analysis_noisy = guard_noisy.update(sample)
        
        # Should have lower confidence with noisy measurements
        assert analysis_noisy.confidence_score < analysis.confidence_score


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

============================================================

FILE 11/19: scheduler\components\tests\test_unified_scheduler.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\tests\test_unified_scheduler.py
Size: 19,150 bytes
Modified: 2025-10-14 06:28:47
------------------------------------------------------------
#!/usr/bin/env python3
"""Unit tests for unified scheduler orchestrator."""

import pytest
import time
import threading
from unittest.mock import Mock, patch, MagicMock
from src.scheduler.unified_scheduler import (
    UnifiedUAVScheduler, TelemetrySnapshot, DecisionMetrics, SchedulerConfig
)
from src.scheduler.components.battery_predictor import BatteryPredictor
from src.scheduler.components.thermal_guard import ThermalGuard, ThermalState
from src.scheduler.components.security_advisor import SecurityAdvisor, ThreatLevel 
from src.scheduler.components.ipc_bridge import IPCBridge, AlgorithmType


class TestUnifiedUAVScheduler:
    
    @pytest.fixture
    def mock_components(self):
        """Create mock components for testing."""
        battery_mock = Mock(spec=BatteryPredictor)
        thermal_mock = Mock(spec=ThermalGuard)
        security_mock = Mock(spec=SecurityAdvisor)
        ipc_mock = Mock(spec=IPCBridge)
        
        return {
            'battery': battery_mock,
            'thermal': thermal_mock,
            'security': security_mock,
            'ipc': ipc_mock
        }
    
    def test_scheduler_initialization(self, mock_components):
        """Test scheduler initialization with component injection."""
        config = SchedulerConfig(
            decision_interval_ms=100,
            enable_expert_system=True,
            enable_reinforcement_learning=True,
            enable_hybrid_fusion=True
        )
        
        with patch('src.scheduler.unified_scheduler.UnifiedUAVScheduler._initialize_components'):
            scheduler = UnifiedUAVScheduler(
                config=config,
                battery_predictor=mock_components['battery'],
                thermal_guard=mock_components['thermal'],
                security_advisor=mock_components['security'],
                ipc_bridge=mock_components['ipc']
            )
            
            assert scheduler.config == config
            assert scheduler.battery_predictor == mock_components['battery']
            assert scheduler.thermal_guard == mock_components['thermal']
            assert scheduler.security_advisor == mock_components['security']
            assert scheduler.ipc_bridge == mock_components['ipc']
    
    def test_telemetry_processing(self, mock_components):
        """Test telemetry snapshot processing and validation."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock component responses
        mock_components['battery'].update.return_value = Mock(
            soc_percentage=75.0,
            remaining_time_minutes=45.0,
            power_trend_w_per_s=-0.5
        )
        
        mock_components['thermal'].update.return_value = Mock(
            state=ThermalState.NORMAL,
            current_temp_c=55.0,
            thermal_headroom_c=25.0
        )
        
        mock_components['security'].analyze_network_traffic.return_value = Mock(
            threat_level=ThreatLevel.LOW,
            combined_threat_score=0.15
        )
        
        # Process telemetry
        telemetry = TelemetrySnapshot(
            timestamp_ns=time.time_ns(),
            battery_voltage_v=14.8,
            battery_current_a=-2.5,
            cpu_temp_c=55.0,
            ambient_temp_c=25.0,
            network_packet_rate=150.0,
            network_byte_rate=75000.0
        )
        
        processed = scheduler._process_telemetry(telemetry)
        
        assert processed is not None
        assert hasattr(processed, 'battery_analysis')
        assert hasattr(processed, 'thermal_analysis')
        assert hasattr(processed, 'security_analysis')
    
    def test_expert_system_decision_making(self, mock_components):
        """Test expert system decision logic."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Test normal conditions
        normal_analysis = Mock()
        normal_analysis.battery_analysis.soc_percentage = 80.0
        normal_analysis.thermal_analysis.state = ThermalState.NORMAL
        normal_analysis.security_analysis.threat_level = ThreatLevel.LOW
        
        decision_normal = scheduler._expert_system_decision(normal_analysis)
        
        assert decision_normal.recommended_suite in [
            "cs-mlkem768-aesgcm-mldsa65",  # Balanced choice
            "cs-mlkem1024-aesgcm-mldsa87"  # High security choice
        ]
        assert decision_normal.confidence_score > 0.5
        
        # Test critical battery condition
        critical_analysis = Mock()
        critical_analysis.battery_analysis.soc_percentage = 15.0  # Critical
        critical_analysis.thermal_analysis.state = ThermalState.NORMAL
        critical_analysis.security_analysis.threat_level = ThreatLevel.LOW
        
        decision_critical = scheduler._expert_system_decision(critical_analysis)
        
        # Should prefer low-power suite
        assert decision_critical.recommended_suite == "cs-mlkem512-aesgcm-mldsa44"
        assert "battery_critical" in decision_critical.reasoning
    
    def test_reinforcement_learning_integration(self, mock_components):
        """Test reinforcement learning decision integration."""
        with patch('src.scheduler.unified_scheduler.UnifiedUAVScheduler._load_rl_model') as mock_load:
            mock_rl_model = Mock()
            mock_load.return_value = mock_rl_model
            
            scheduler = UnifiedUAVScheduler(
                battery_predictor=mock_components['battery'],
                thermal_guard=mock_components['thermal'],
                security_advisor=mock_components['security'],
                ipc_bridge=mock_components['ipc']
            )
            
            # Mock RL model prediction
            mock_rl_model.predict.return_value = ([1], [0.85])  # Suite index 1, confidence 0.85
            
            analysis = Mock()
            analysis.battery_analysis.soc_percentage = 60.0
            analysis.thermal_analysis.current_temp_c = 65.0
            analysis.security_analysis.combined_threat_score = 0.3
            
            decision_rl = scheduler._reinforcement_learning_decision(analysis)
            
            assert decision_rl.recommended_suite in scheduler.available_suites
            assert decision_rl.confidence_score == 0.85
            assert decision_rl.algorithm_used == AlgorithmType.REINFORCEMENT_LEARNING
    
    def test_hybrid_fusion_decision_making(self, mock_components):
        """Test hybrid fusion of expert system and RL decisions."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock expert system decision
        expert_decision = Mock()
        expert_decision.recommended_suite = "cs-mlkem768-aesgcm-mldsa65"
        expert_decision.confidence_score = 0.7
        expert_decision.algorithm_used = AlgorithmType.EXPERT_SYSTEM
        
        # Mock RL decision
        rl_decision = Mock()
        rl_decision.recommended_suite = "cs-mlkem1024-aesgcm-mldsa87"
        rl_decision.confidence_score = 0.8
        rl_decision.algorithm_used = AlgorithmType.REINFORCEMENT_LEARNING
        
        with patch.object(scheduler, '_expert_system_decision', return_value=expert_decision):
            with patch.object(scheduler, '_reinforcement_learning_decision', return_value=rl_decision):
                
                analysis = Mock()
                fusion_decision = scheduler._hybrid_fusion_decision(analysis)
                
                # Should choose RL decision due to higher confidence
                assert fusion_decision.recommended_suite == "cs-mlkem1024-aesgcm-mldsa87"
                assert fusion_decision.algorithm_used == AlgorithmType.HYBRID_FUSION
                assert fusion_decision.confidence_score > 0.7
    
    def test_graceful_degradation_logic(self, mock_components):
        """Test graceful degradation under resource constraints."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Test thermal degradation
        thermal_critical_analysis = Mock()
        thermal_critical_analysis.battery_analysis.soc_percentage = 50.0
        thermal_critical_analysis.thermal_analysis.state = ThermalState.CRITICAL
        thermal_critical_analysis.thermal_analysis.current_temp_c = 82.0
        thermal_critical_analysis.security_analysis.threat_level = ThreatLevel.LOW
        
        decision_thermal = scheduler._expert_system_decision(thermal_critical_analysis)
        
        # Should degrade to low-power suite
        assert decision_thermal.recommended_suite == "cs-mlkem512-aesgcm-mldsa44"
        assert "thermal_degradation" in decision_thermal.reasoning
        
        # Test battery + thermal combined stress
        combined_stress_analysis = Mock()
        combined_stress_analysis.battery_analysis.soc_percentage = 20.0  # Low battery
        combined_stress_analysis.thermal_analysis.state = ThermalState.ELEVATED
        combined_stress_analysis.security_analysis.threat_level = ThreatLevel.HIGH  # But high threat
        
        decision_combined = scheduler._expert_system_decision(combined_stress_analysis)
        
        # Should balance security vs resource constraints
        assert decision_combined.recommended_suite in [
            "cs-mlkem512-aesgcm-mldsa44",  # Resource priority
            "cs-mlkem768-aesgcm-mldsa65"   # Compromise choice
        ]
    
    def test_real_time_decision_loop(self, mock_components):
        """Test real-time decision loop with timing constraints."""
        config = SchedulerConfig(decision_interval_ms=50)  # Fast loop
        
        scheduler = UnifiedUAVScheduler(
            config=config,
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock telemetry updates
        mock_telemetry_queue = []
        for i in range(5):
            telemetry = TelemetrySnapshot(
                timestamp_ns=time.time_ns() + i * int(50e6),  # 50ms intervals
                battery_voltage_v=14.8 - i * 0.1,
                battery_current_a=-2.0,
                cpu_temp_c=50.0 + i * 2.0,
                network_packet_rate=100.0
            )
            mock_telemetry_queue.append(telemetry)
        
        decisions_made = []
        
        # Mock decision making to capture results
        original_make_decision = scheduler._make_scheduling_decision
        def mock_make_decision(analysis):
            decision = original_make_decision(analysis)
            decisions_made.append((time.time_ns(), decision))
            return decision
        
        scheduler._make_scheduling_decision = mock_make_decision
        
        # Process telemetry in real-time loop simulation
        for telemetry in mock_telemetry_queue:
            start_time = time.time()
            scheduler._process_telemetry(telemetry)
            processing_time = (time.time() - start_time) * 1000  # ms
            
            # Should meet real-time constraints
            assert processing_time < config.decision_interval_ms
    
    def test_algorithm_switching_coordination(self, mock_components):
        """Test coordination of algorithm switching via IPC."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock IPC bridge responses
        mock_components['ipc'].switch_algorithm.return_value = 2.5  # 2.5ms switch time
        
        # Request algorithm switch
        switch_time = scheduler.switch_algorithm(AlgorithmType.REINFORCEMENT_LEARNING)
        
        # Verify IPC bridge was called
        mock_components['ipc'].switch_algorithm.assert_called_once_with(
            target_algorithm=AlgorithmType.REINFORCEMENT_LEARNING,
            priority_ms=pytest.approx(10, abs=5)  # Default priority
        )
        
        assert switch_time == 2.5
    
    def test_performance_monitoring_and_metrics(self, mock_components):
        """Test performance monitoring and metrics collection."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock component responses for metrics
        mock_components['battery'].update.return_value = Mock(soc_percentage=70.0)
        mock_components['thermal'].update.return_value = Mock(state=ThermalState.NORMAL)
        mock_components['security'].analyze_network_traffic.return_value = Mock(
            threat_level=ThreatLevel.LOW
        )
        
        # Process some telemetry to generate metrics
        for i in range(10):
            telemetry = TelemetrySnapshot(
                timestamp_ns=time.time_ns(),
                battery_voltage_v=14.8,
                battery_current_a=-2.0,
                cpu_temp_c=55.0
            )
            scheduler._process_telemetry(telemetry)
        
        metrics = scheduler.get_performance_metrics()
        
        assert "decisions_made" in metrics
        assert "avg_decision_time_ms" in metrics
        assert "algorithm_switches" in metrics
        assert "uptime_seconds" in metrics
        
        assert metrics["decisions_made"] >= 10
        assert metrics["avg_decision_time_ms"] > 0
    
    def test_configuration_hot_reload(self, mock_components):
        """Test hot reloading of scheduler configuration."""
        initial_config = SchedulerConfig(decision_interval_ms=100)
        
        scheduler = UnifiedUAVScheduler(
            config=initial_config,
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Update configuration
        new_config = SchedulerConfig(
            decision_interval_ms=50,  # Faster decisions
            enable_adaptive_thresholds=True
        )
        
        success = scheduler.update_configuration(new_config)
        
        assert success == True
        assert scheduler.config.decision_interval_ms == 50
        assert scheduler.config.enable_adaptive_thresholds == True
    
    def test_emergency_shutdown_procedure(self, mock_components):
        """Test emergency shutdown procedure under critical conditions."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock emergency conditions
        emergency_analysis = Mock()
        emergency_analysis.battery_analysis.soc_percentage = 5.0  # Critical battery
        emergency_analysis.thermal_analysis.state = ThermalState.EMERGENCY
        emergency_analysis.thermal_analysis.emergency_shutdown = True
        emergency_analysis.security_analysis.emergency_mode = True
        
        # Should trigger emergency procedures
        decision = scheduler._expert_system_decision(emergency_analysis)
        
        assert decision.emergency_actions_required == True
        assert "emergency_shutdown" in decision.reasoning
        assert decision.recommended_suite == "cs-mlkem512-aesgcm-mldsa44"  # Minimal power
    
    def test_multi_threaded_operation(self, mock_components):
        """Test scheduler operation under multi-threaded conditions."""
        scheduler = UnifiedUAVScheduler(
            battery_predictor=mock_components['battery'],
            thermal_guard=mock_components['thermal'],
            security_advisor=mock_components['security'],
            ipc_bridge=mock_components['ipc']
        )
        
        # Mock stable component responses
        mock_components['battery'].update.return_value = Mock(soc_percentage=60.0)
        mock_components['thermal'].update.return_value = Mock(state=ThermalState.NORMAL)
        mock_components['security'].analyze_network_traffic.return_value = Mock(
            threat_level=ThreatLevel.LOW
        )
        
        results = []
        errors = []
        
        def worker_thread(thread_id, iterations):
            try:
                for i in range(iterations):
                    telemetry = TelemetrySnapshot(
                        timestamp_ns=time.time_ns(),
                        battery_voltage_v=14.8,
                        battery_current_a=-2.0,
                        cpu_temp_c=55.0 + thread_id  # Slight variation per thread
                    )
                    
                    processed = scheduler._process_telemetry(telemetry)
                    results.append((thread_id, i, processed is not None))
                    
            except Exception as e:
                errors.append((thread_id, str(e)))
        
        # Launch multiple worker threads
        threads = []
        for i in range(3):
            thread = threading.Thread(target=worker_thread, args=(i, 5))
            threads.append(thread)
            thread.start()
        
        # Wait for completion
        for thread in threads:
            thread.join(timeout=10.0)
        
        # Verify thread safety
        assert len(errors) == 0, f"Thread errors: {errors}"
        assert len(results) == 15  # 3 threads × 5 iterations
        successful_operations = [r for r in results if r[2]]
        assert len(successful_operations) == 15


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

============================================================

FILE 12/19: scheduler\components\thermal_guard.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\components\thermal_guard.py
Size: 16,485 bytes
Modified: 2025-10-14 06:28:46
------------------------------------------------------------
#!/usr/bin/env python3
"""Thermal guard and temperature-aware scheduling for UAV companion computers.

This module implements sophisticated thermal management for Raspberry Pi systems:
- Real-time temperature trend analysis with gradient computation
- Critical threshold detection with hysteresis to prevent oscillation  
- Emergency thermal throttling with graceful degradation to lower-power PQC suites
- Predictive thermal modeling to prevent runaway conditions before they occur
"""

from __future__ import annotations

import math
import time
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from collections import deque
from enum import Enum


class ThermalState(Enum):
    """Thermal protection states."""
    NORMAL = "normal"          # < warning threshold
    ELEVATED = "elevated"      # > warning, < critical  
    CRITICAL = "critical"      # > critical threshold
    EMERGENCY = "emergency"    # Rapid temperature rise or > emergency threshold


@dataclass
class TemperatureSample:
    """Single temperature measurement with metadata."""
    timestamp_ns: int
    cpu_temp_c: float
    ambient_temp_c: Optional[float] = None
    gpu_temp_c: Optional[float] = None
    pmic_temp_c: Optional[float] = None  # Power management IC temperature
    
    @property
    def max_temp_c(self) -> float:
        """Maximum temperature across all sensors."""
        temps = [self.cpu_temp_c]
        if self.ambient_temp_c is not None:
            temps.append(self.ambient_temp_c)
        if self.gpu_temp_c is not None:
            temps.append(self.gpu_temp_c)
        if self.pmic_temp_c is not None:
            temps.append(self.pmic_temp_c)
        return max(temps)


@dataclass 
class ThermalAnalysis:
    """Thermal analysis results and recommendations."""
    state: ThermalState
    current_temp_c: float
    trend_c_per_s: float               # Temperature rise rate
    time_to_critical_s: Optional[float] # Predicted time until critical temp
    recommended_action: str             # Action recommendation
    thermal_headroom_c: float          # Distance to critical threshold
    throttling_recommended: bool       # Should system throttle?
    emergency_shutdown: bool           # Should system emergency stop?
    confidence_score: float            # Prediction confidence (0-1)


class ThermalGuard:
    """Temperature-aware thermal protection and scheduling advisor."""
    
    def __init__(
        self,
        warning_temp_c: float = 70.0,      # Start monitoring closely
        critical_temp_c: float = 80.0,     # Begin throttling actions  
        emergency_temp_c: float = 85.0,    # Emergency shutdown threshold
        hysteresis_c: float = 5.0,         # Hysteresis band to prevent oscillation
        trend_window_s: float = 30.0,      # Window for trend analysis
        rapid_rise_threshold_c_per_s: float = 2.0,  # Emergency rise rate
        history_retention_s: float = 600.0, # Keep 10 minutes of history
    ):
        self.warning_temp = warning_temp_c
        self.critical_temp = critical_temp_c  
        self.emergency_temp = emergency_temp_c
        self.hysteresis = hysteresis_c
        self.trend_window_s = trend_window_s
        self.rapid_rise_threshold = rapid_rise_threshold_c_per_s
        self.history_retention_s = history_retention_s
        
        # Temperature history for trend analysis
        self.temp_history: deque[TemperatureSample] = deque(maxlen=2000)
        
        # State tracking
        self.current_state = ThermalState.NORMAL
        self.last_state_change_ns: Optional[int] = None
        self.throttle_start_ns: Optional[int] = None
        
        # Thermal model parameters (simple linear model)
        self.thermal_mass_j_per_c = 10.0    # Thermal mass of system
        self.cooling_rate_w_per_c = 0.5     # Passive cooling effectiveness
    
    def update(self, sample: TemperatureSample) -> ThermalAnalysis:
        """Update thermal model and return analysis with recommendations."""
        
        # Add sample to history and prune old data
        self.temp_history.append(sample)
        self._prune_history(sample.timestamp_ns)
        
        # Calculate temperature trend
        trend_c_per_s = self._calculate_temperature_trend()
        
        # Determine thermal state with hysteresis
        new_state = self._determine_thermal_state(sample.cpu_temp_c, trend_c_per_s)
        
        # Update state tracking
        if new_state != self.current_state:
            self.last_state_change_ns = sample.timestamp_ns
            self.current_state = new_state
        
        # Calculate time to critical temperature
        time_to_critical = self._predict_time_to_critical(sample.cpu_temp_c, trend_c_per_s)
        
        # Generate recommendations
        action, throttling, emergency = self._generate_recommendations(new_state, trend_c_per_s)
        
        # Calculate thermal headroom
        headroom = self.critical_temp - sample.cpu_temp_c
        
        # Confidence score based on trend stability and data quality
        confidence = self._calculate_confidence()
        
        return ThermalAnalysis(
            state=new_state,
            current_temp_c=sample.cpu_temp_c,
            trend_c_per_s=trend_c_per_s,
            time_to_critical_s=time_to_critical,
            recommended_action=action,
            thermal_headroom_c=headroom,
            throttling_recommended=throttling,
            emergency_shutdown=emergency,
            confidence_score=confidence,
        )
    
    def _prune_history(self, current_time_ns: int) -> None:
        """Remove temperature samples older than retention period."""
        cutoff_ns = current_time_ns - int(self.history_retention_s * 1e9)
        while self.temp_history and self.temp_history[0].timestamp_ns < cutoff_ns:
            self.temp_history.popleft()
    
    def _calculate_temperature_trend(self) -> float:
        """Calculate temperature rise rate using linear regression over trend window."""
        if len(self.temp_history) < 3:
            return 0.0
        
        # Get samples within trend window
        latest_time = self.temp_history[-1].timestamp_ns
        cutoff_time = latest_time - int(self.trend_window_s * 1e9)
        
        trend_samples = [s for s in self.temp_history if s.timestamp_ns >= cutoff_time]
        
        if len(trend_samples) < 3:
            return 0.0
        
        # Simple linear regression: y = mx + b, solve for slope m
        n = len(trend_samples)
        sum_t = sum((s.timestamp_ns - trend_samples[0].timestamp_ns) / 1e9 for s in trend_samples)
        sum_temp = sum(s.cpu_temp_c for s in trend_samples)
        sum_t_temp = sum(
            ((s.timestamp_ns - trend_samples[0].timestamp_ns) / 1e9) * s.cpu_temp_c 
            for s in trend_samples
        )
        sum_t_sq = sum(
            ((s.timestamp_ns - trend_samples[0].timestamp_ns) / 1e9) ** 2 
            for s in trend_samples
        )
        
        # Calculate slope (°C/s)
        denominator = n * sum_t_sq - sum_t * sum_t
        if abs(denominator) < 1e-9:
            return 0.0
        
        slope = (n * sum_t_temp - sum_t * sum_temp) / denominator
        return slope
    
    def _determine_thermal_state(self, temp_c: float, trend_c_per_s: float) -> ThermalState:
        """Determine thermal state with hysteresis and trend consideration."""
        
        # Check for emergency rapid temperature rise
        if trend_c_per_s > self.rapid_rise_threshold:
            return ThermalState.EMERGENCY
        
        # Emergency temperature threshold
        if temp_c >= self.emergency_temp:
            return ThermalState.EMERGENCY
        
        # Apply hysteresis based on current state
        if self.current_state == ThermalState.CRITICAL:
            # Need to drop below critical - hysteresis to transition down
            if temp_c < (self.critical_temp - self.hysteresis):
                return ThermalState.ELEVATED if temp_c >= self.warning_temp else ThermalState.NORMAL
            else:
                return ThermalState.CRITICAL
        
        elif self.current_state == ThermalState.ELEVATED:
            # Hysteresis for both up and down transitions
            if temp_c >= self.critical_temp:
                return ThermalState.CRITICAL
            elif temp_c < (self.warning_temp - self.hysteresis):
                return ThermalState.NORMAL
            else:
                return ThermalState.ELEVATED
        
        else:  # NORMAL or EMERGENCY
            # Standard thresholds for upward transitions
            if temp_c >= self.critical_temp:
                return ThermalState.CRITICAL
            elif temp_c >= self.warning_temp:
                return ThermalState.ELEVATED
            else:
                return ThermalState.NORMAL
    
    def _predict_time_to_critical(self, current_temp_c: float, trend_c_per_s: float) -> Optional[float]:
        """Predict time until critical temperature is reached."""
        if trend_c_per_s <= 0:
            return None  # Temperature stable or decreasing
        
        temp_delta = self.critical_temp - current_temp_c
        if temp_delta <= 0:
            return 0.0  # Already at/above critical
        
        # Simple linear extrapolation (conservative)
        time_to_critical = temp_delta / trend_c_per_s
        
        # Cap at reasonable maximum (30 minutes)
        return min(time_to_critical, 1800.0)
    
    def _generate_recommendations(
        self, 
        state: ThermalState, 
        trend_c_per_s: float
    ) -> Tuple[str, bool, bool]:
        """Generate action recommendations based on thermal state."""
        
        if state == ThermalState.EMERGENCY:
            return (
                "EMERGENCY: Immediate shutdown or switch to minimal power suite",
                True,   # throttling_recommended
                True,   # emergency_shutdown  
            )
        
        elif state == ThermalState.CRITICAL:
            if trend_c_per_s > 0.5:  # Still rising
                return (
                    "CRITICAL: Switch to low-power PQC suite immediately", 
                    True, 
                    False
                )
            else:
                return (
                    "CRITICAL: Maintain current low-power configuration",
                    True,
                    False
                )
        
        elif state == ThermalState.ELEVATED:
            if trend_c_per_s > 1.0:  # Rapid rise
                return (
                    "ELEVATED: Preemptively reduce to medium-power suite",
                    True,
                    False
                )
            else:
                return (
                    "ELEVATED: Monitor closely, consider power reduction",
                    False,
                    False
                )
        
        else:  # NORMAL
            return (
                "NORMAL: Full performance available",
                False,
                False
            )
    
    def _calculate_confidence(self) -> float:
        """Calculate confidence in thermal predictions based on data quality."""
        if len(self.temp_history) < 5:
            return 0.3  # Low confidence with insufficient data
        
        # Check temperature measurement stability
        recent_temps = [s.cpu_temp_c for s in list(self.temp_history)[-10:]]
        temp_variance = sum((t - sum(recent_temps)/len(recent_temps))**2 for t in recent_temps) / len(recent_temps)
        temp_stability = max(0.0, 1.0 - temp_variance / 25.0)  # Normalized by 5°C std dev
        
        # Check sampling regularity
        if len(self.temp_history) >= 2:
            intervals = [
                (self.temp_history[i].timestamp_ns - self.temp_history[i-1].timestamp_ns) / 1e9
                for i in range(1, min(len(self.temp_history), 11))
            ]
            avg_interval = sum(intervals) / len(intervals)
            interval_variance = sum((t - avg_interval)**2 for t in intervals) / len(intervals)
            sampling_regularity = max(0.0, 1.0 - interval_variance / (avg_interval**2))
        else:
            sampling_regularity = 0.5
        
        # Combined confidence score
        confidence = (temp_stability * 0.6 + sampling_regularity * 0.4)
        return max(0.1, min(1.0, confidence))
    
    def get_thermal_budget_analysis(self, target_power_increase_w: float) -> Dict[str, any]:
        """Analyze if system can handle additional power load thermally."""
        if not self.temp_history:
            return {"feasible": False, "reason": "no_thermal_data"}
        
        latest_sample = self.temp_history[-1]
        current_analysis = self.update(latest_sample)
        
        # Estimate temperature rise from additional power
        # Rough estimate: 1W additional power = ~2-3°C temperature rise for Pi 4
        estimated_temp_rise_c = target_power_increase_w * 2.5
        projected_temp_c = current_analysis.current_temp_c + estimated_temp_rise_c
        
        # Check thermal headroom
        headroom_after_increase = self.critical_temp - projected_temp_c
        
        feasible = (
            projected_temp_c < self.warning_temp and 
            headroom_after_increase > 5.0 and
            current_analysis.state in {ThermalState.NORMAL, ThermalState.ELEVATED}
        )
        
        return {
            "feasible": feasible,
            "current_temp_c": current_analysis.current_temp_c,
            "projected_temp_c": projected_temp_c,
            "estimated_rise_c": estimated_temp_rise_c,
            "thermal_headroom_c": headroom_after_increase,
            "current_state": current_analysis.state.value,
            "reason": "insufficient_headroom" if not feasible else "feasible",
        }
    
    def get_suite_thermal_mapping(self) -> Dict[str, Dict[str, float]]:
        """Return thermal characteristics for different PQC suites based on observations."""
        # These would ideally be learned from historical data
        # For now, provide reasonable estimates based on computational complexity
        return {
            "cs-mlkem512-aesgcm-mldsa44": {
                "typical_power_w": 2.8,
                "peak_power_w": 4.2,
                "temp_rise_steady_c": 5.0,
                "temp_rise_peak_c": 8.0,
            },
            "cs-mlkem768-aesgcm-mldsa65": {
                "typical_power_w": 3.5,
                "peak_power_w": 5.1,
                "temp_rise_steady_c": 7.0,
                "temp_rise_peak_c": 11.0,
            },
            "cs-mlkem1024-aesgcm-mldsa87": {
                "typical_power_w": 4.8,
                "peak_power_w": 7.2,
                "temp_rise_steady_c": 12.0,
                "temp_rise_peak_c": 18.0,
            },
        }
    
    def recommend_optimal_suite(
        self, 
        available_suites: List[str], 
        current_temp_c: float,
        target_margin_c: float = 10.0
    ) -> Optional[str]:
        """Recommend optimal PQC suite based on current thermal state."""
        thermal_mapping = self.get_suite_thermal_mapping()
        
        # Filter suites that won't cause thermal issues
        viable_suites = []
        for suite in available_suites:
            if suite not in thermal_mapping:
                continue
            
            suite_info = thermal_mapping[suite]
            projected_temp = current_temp_c + suite_info["temp_rise_steady_c"]
            
            if projected_temp < (self.critical_temp - target_margin_c):
                viable_suites.append((suite, projected_temp, suite_info["typical_power_w"]))
        
        if not viable_suites:
            return None
        
        # Sort by projected temperature (ascending) then by power (descending for better security)
        viable_suites.sort(key=lambda x: (x[1], -x[2]))
        
        return viable_suites[0][0]  # Return best option


__all__ = [
    "ThermalState",
    "TemperatureSample", 
    "ThermalAnalysis",
    "ThermalGuard",
]

============================================================

FILE 13/19: scheduler\strategies\__init__.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\strategies\__init__.py
Size: 558 bytes
Modified: 2025-10-14 06:30:52
------------------------------------------------------------
"""Strategy wrappers for expert, RL, and hybrid scheduling.

These adapters provide a thin, stable interface around the existing
implementations under `schedulers/nextgen_*`, so research code can import
from `src.scheduler.strategies` without depending on the internal layout.
"""

from .base import Strategy, StrategyContext
from .expert import ExpertStrategy
from .rl import RlStrategy
from .hybrid import HybridStrategy

__all__ = [
    "Strategy",
    "StrategyContext",
    "ExpertStrategy",
    "RlStrategy",
    "HybridStrategy",
]

============================================================

FILE 14/19: scheduler\strategies\base.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\strategies\base.py
Size: 456 bytes
Modified: 2025-10-14 06:30:52
------------------------------------------------------------
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Optional


@dataclass
class StrategyContext:
    session_id: str
    role: str
    initial_suite: str


class Strategy:
    def warmup(self, ctx: StrategyContext) -> None:  # pragma: no cover - thin adapter
        pass

    def decide(self, features: Dict[str, Any]) -> Optional[Dict[str, Any]]:  # pragma: no cover
        return None

============================================================

FILE 15/19: scheduler\strategies\expert.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\strategies\expert.py
Size: 1,723 bytes
Modified: 2025-10-14 06:30:52
------------------------------------------------------------
from __future__ import annotations

from typing import Any, Dict, Optional
from pathlib import Path
import sys

from .base import Strategy, StrategyContext


class ExpertStrategy(Strategy):
    def __init__(self) -> None:
        # Make top-level 'schedulers' importable when running as a package
        root = Path(__file__).resolve().parents[3]
        root_str = str(root)
        if root_str not in sys.path:
            sys.path.insert(0, root_str)
        try:
            from schedulers.nextgen_expert.strategy import NextGenExpertStrategy  # type: ignore
        except Exception as exc:  # pragma: no cover - adapter remains optional
            self._impl = None
            self._import_error = exc
        else:
            self._impl = NextGenExpertStrategy()
            self._import_error = None

    def warmup(self, ctx: StrategyContext) -> None:
        if self._impl is not None:
            from schedulers.common.state import SchedulerContext  # type: ignore
            self._impl.warmup(SchedulerContext(ctx.session_id, ctx.role, ctx.initial_suite))

    def decide(self, features: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        if self._impl is None:
            return None
        try:
            decision = self._impl.decide(features)  # type: ignore[attr-defined]
        except Exception:
            return None
        if decision is None:
            return None
        # Normalise into a dict
        return {
            "target_suite": getattr(decision, "target_suite", None),
            "ddos_mode": getattr(getattr(decision, "ddos_mode", None), "value", None),
            "notes": getattr(decision, "notes", {}) or {},
        }

============================================================

FILE 16/19: scheduler\strategies\hybrid.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\strategies\hybrid.py
Size: 862 bytes
Modified: 2025-10-14 06:30:53
------------------------------------------------------------
from __future__ import annotations

from typing import Any, Dict, Optional

from .base import Strategy, StrategyContext
from .expert import ExpertStrategy
from .rl import RlStrategy


class HybridStrategy(Strategy):
    def __init__(self) -> None:
        self._expert = ExpertStrategy()
        self._rl = RlStrategy()

    def warmup(self, ctx: StrategyContext) -> None:
        self._expert.warmup(ctx)
        self._rl.warmup(ctx)

    def decide(self, features: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        expert = self._expert.decide(features)
        rl = self._rl.decide(features)
        if rl and expert:
            # Prefer RL if confidence is high, else expert
            rl_conf = float(rl.get("notes", {}).get("confidence", 0.0))
            return rl if rl_conf >= 0.75 else expert
        return rl or expert

============================================================

FILE 17/19: scheduler\strategies\rl.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\strategies\rl.py
Size: 1,582 bytes
Modified: 2025-10-14 06:30:53
------------------------------------------------------------
from __future__ import annotations

from typing import Any, Dict, Optional
from pathlib import Path
import sys

from .base import Strategy, StrategyContext


class RlStrategy(Strategy):
    def __init__(self) -> None:
        root = Path(__file__).resolve().parents[3]
        root_str = str(root)
        if root_str not in sys.path:
            sys.path.insert(0, root_str)
        try:
            from schedulers.nextgen_rl.strategy import NextGenRlStrategy  # type: ignore
        except Exception as exc:  # pragma: no cover - optional
            self._impl = None
            self._import_error = exc
        else:
            self._impl = NextGenRlStrategy()
            self._import_error = None

    def warmup(self, ctx: StrategyContext) -> None:
        if self._impl is not None:
            from schedulers.common.state import SchedulerContext  # type: ignore
            self._impl.warmup(SchedulerContext(ctx.session_id, ctx.role, ctx.initial_suite))

    def decide(self, features: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        if self._impl is None:
            return None
        try:
            decision = self._impl.decide(features)  # type: ignore[attr-defined]
        except Exception:
            return None
        if decision is None:
            return None
        return {
            "target_suite": getattr(decision, "target_suite", None),
            "ddos_mode": getattr(getattr(decision, "ddos_mode", None), "value", None),
            "notes": getattr(decision, "notes", {}) or {},
        }

============================================================

FILE 18/19: scheduler\unified_scheduler.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\scheduler\unified_scheduler.py
Size: 36,670 bytes
Modified: 2025-10-15 05:52:09
------------------------------------------------------------
#!/usr/bin/env python3
"""
Unified UAV Scheduler - Version 4.0
====================================

Advanced battery-aware, thermal-conscious, security-adaptive scheduler for 
post-quantum cryptographic UAV command and control systems.

Integrates:
- Physics-based battery modeling with Peukert equation
- Thermal runaway protection with predictive modeling  
- Multi-tier DDOS detection (XGBoost + Transformer)
- POSIX IPC for ultra-low-latency algorithm switching
- Graceful degradation with expert policy fallbacks

Hardware: Raspberry Pi 4 + Pixhawk via MAVLink + INA219 power monitoring
Research: Battery and Temperature-Aware Graceful Degradation Schedulers for PQC UAV C&C
Authors: Kamal et al.
"""

from __future__ import annotations

import time
import json
import threading
import logging
from collections import deque
from dataclasses import dataclass, asdict
from typing import Deque, Dict, List, Optional, Any, Callable
from pathlib import Path
from enum import Enum

# Import our components
from .components.battery_predictor import (
    BatteryPredictor, BatteryState, BatteryPrediction, 
    create_default_lipo_spec
)
from .components.thermal_guard import (
    ThermalGuard, TemperatureSample, ThermalAnalysis, ThermalState
)
from .components.security_advisor import (
    SecurityAdvisor,
    NetworkMetrics,
    SecurityPosture,
    ThreatLevel,
    DDOSPrediction,
)
from .components.ipc_bridge import (
    IPCBridge, create_pqc_suite_bridge, create_ddos_model_bridge
)

# Import existing scheduler strategies
import sys
sys.path.append(str(Path(__file__).parents[3]))
from schedulers.common.state import (
    SchedulerContext,
    SchedulerDecision,
    DdosMode,
    SuiteTelemetry,
    TelemetryWindow,
)
from schedulers.nextgen_expert.strategy import NextGenExpertStrategy
from schedulers.nextgen_rl.strategy import NextGenRlStrategy


class SchedulerMode(Enum):
    """Scheduler operation modes."""
    EXPERT_ONLY = "expert"          # Rule-based expert policies
    RL_ONLY = "rl"                  # Pure reinforcement learning
    HYBRID_ADAPTIVE = "hybrid"      # Adaptive expert+RL fusion
    EMERGENCY_SAFE = "emergency"    # Emergency safe mode


@dataclass
class SystemTelemetry:
    """Consolidated system telemetry from all sensors."""
    timestamp_ns: int
    
    # Battery metrics (from INA219)
    battery_voltage_v: float
    battery_current_a: float
    battery_power_w: float
    
    # Thermal metrics (from system sensors)
    cpu_temp_c: float
    
    battery_temp_c: Optional[float] = None
    gpu_temp_c: Optional[float] = None
    ambient_temp_c: Optional[float] = None
    
    # Network performance metrics
    packet_loss_pct: float = 0.0
    rtt_avg_ms: float = 0.0
    rtt_p95_ms: float = 0.0
    throughput_mbps: float = 0.0
    goodput_mbps: float = 0.0
    
    # System performance metrics
    cpu_percent: float = 0.0
    memory_percent: float = 0.0
    cpu_freq_mhz: Optional[float] = None
    
    # Mission context
    altitude_m: Optional[float] = None
    speed_mps: Optional[float] = None
    flight_mode: Optional[str] = None
    # Heartbeat telemetry (from GCS heartbeat summary mapping)
    heartbeat_ok: Optional[bool] = None
    heartbeat_missed_count: Optional[int] = None
    heartbeat_last_ok_step: Optional[int] = None


@dataclass
class SchedulerState:
    """Current scheduler state and decisions."""
    mode: SchedulerMode
    active_suite: str
    active_ddos_tier: str
    battery_soc_percent: float
    thermal_state: ThermalState
    threat_level: ThreatLevel
    last_decision_ns: int
    performance_score: float
    emergency_mode: bool = False


@dataclass 
class SchedulerMetrics:
    """Performance metrics for the scheduler."""
    decisions_per_minute: float
    avg_decision_latency_ms: float
    suite_switches: int
    emergency_activations: int
    battery_warnings: int
    thermal_warnings: int
    ddos_detections: int
    ipc_performance: Dict[str, float]


class UnifiedUAVScheduler:
    """
    Advanced UAV scheduler integrating battery, thermal, and security management.
    
    This is the main orchestrator that coordinates all subsystems to make
    optimal scheduling decisions for post-quantum cryptography in constrained
    UAV environments.
    """
    
    def __init__(
        self,
        battery_capacity_ah: float = 5.0,    # Battery capacity 
        battery_cells: int = 4,              # 4S Li-Po (14.8V nominal)
        log_dir: Path = Path("logging/scheduler"),
        decision_interval_s: float = 2.0,    # Decision cadence
        emergency_battery_pct: float = 15.0, # Emergency battery threshold
        critical_temp_c: float = 80.0,       # Critical temperature
        available_suites: Optional[List[str]] = None,
    ):
        
        # Configuration
        self.decision_interval_s = decision_interval_s
        self.emergency_battery_pct = emergency_battery_pct
        self.log_dir = log_dir
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # Available PQC suites (ordered by performance/security trade-off)
        self.available_suites = available_suites or [
            "cs-mlkem512-aesgcm-mldsa44",    # Low power, fast
            "cs-mlkem768-aesgcm-mldsa65",    # Balanced
            "cs-mlkem1024-aesgcm-mldsa87",   # High security, power hungry
        ]
        
        # Initialize core components
        battery_spec = create_default_lipo_spec(battery_capacity_ah, battery_cells)
        self.battery_predictor = BatteryPredictor(
            battery_spec=battery_spec,
            critical_soc_threshold=emergency_battery_pct,
        )
        
        self.thermal_guard = ThermalGuard(
            critical_temp_c=critical_temp_c,
            emergency_temp_c=critical_temp_c + 5.0,
        )
        
        self.security_advisor = SecurityAdvisor()
        
        # Initialize IPC bridges for fast algorithm switching
        self.pqc_bridge = create_pqc_suite_bridge(self.available_suites)
        self.ddos_bridge = create_ddos_model_bridge()
        
        # Initialize scheduler strategies
        self.expert_scheduler = NextGenExpertStrategy()
        self.rl_scheduler = NextGenRlStrategy()
        
        # State tracking
        self.current_state = SchedulerState(
            mode=SchedulerMode.HYBRID_ADAPTIVE,
            active_suite=self.available_suites[1],  # Start with balanced suite
            active_ddos_tier="lightweight",
            battery_soc_percent=100.0,
            thermal_state=ThermalState.NORMAL,
            threat_level=ThreatLevel.NONE,
            last_decision_ns=time.time_ns(),
            performance_score=1.0,
        )
        
        self.metrics = SchedulerMetrics(
            decisions_per_minute=0.0,
            avg_decision_latency_ms=0.0,
            suite_switches=0,
            emergency_activations=0,
            battery_warnings=0,
            thermal_warnings=0,
            ddos_detections=0,
            ipc_performance={},
        )
        
        # RL telemetry window
        self._rl_snapshots: Deque[SuiteTelemetry] = deque(maxlen=6)
        
        # Threading and control
        self.running = False
        self.scheduler_thread: Optional[threading.Thread] = None
        self.decision_callbacks: List[Callable[[SchedulerDecision], None]] = []
        
        # Logging
        self.logger = self._setup_logging()
        
        # Expert policy context and dwell timers
        now_ns = time.time_ns()
        self._last_battery_prediction: Optional[BatteryPrediction] = None
        self._last_thermal_analysis: Optional[ThermalAnalysis] = None
        self._last_security_posture: Optional[SecurityPosture] = None
        self._last_network_metrics: Optional[NetworkMetrics] = None
        self._last_telemetry: Optional[SystemTelemetry] = None
        self._last_suite_change_ns: int = now_ns
        self._last_ddos_change_ns: int = now_ns
        self._suite_dwell_ns: int = int(8.0 * 1e9)   # 8s dwell for upgrades
        self._ddos_dwell_ns: int = int(6.0 * 1e9)    # 6s dwell before relaxing tiers

        # Initialize scheduler strategies with context
        self.context = SchedulerContext(
            session_id=f"uav_scheduler_{int(time.time())}",
            role="unified_scheduler",
            initial_suite=self.current_state.active_suite,
        )
        
        self.expert_scheduler.warmup(self.context)
        self.rl_scheduler.warmup(self.context)
        
        self.logger.info("UnifiedUAVScheduler initialized", extra={
            "battery_capacity_ah": battery_capacity_ah,
            "battery_cells": battery_cells,
            "available_suites": len(self.available_suites),
            "decision_interval_s": decision_interval_s,
        })
    
    def start(self) -> None:
        """Start the scheduler main loop."""
        if self.running:
            return
        
        self.running = True
        self.scheduler_thread = threading.Thread(
            target=self._scheduler_loop,
            name="UAVScheduler",
            daemon=False
        )
        self.scheduler_thread.start()
        self.logger.info("Scheduler started")
    
    def stop(self) -> None:
        """Stop the scheduler and clean up resources."""
        if not self.running:
            return
        
        self.running = False
        
        if self.scheduler_thread and self.scheduler_thread.is_alive():
            self.scheduler_thread.join(timeout=5.0)
        
        # Clean up IPC resources
        self.pqc_bridge.cleanup()
        self.ddos_bridge.cleanup()
        
        self.logger.info("Scheduler stopped")
    
    def update_telemetry(self, telemetry: SystemTelemetry) -> None:
        """Update scheduler with new telemetry data."""
        
        # Update battery model
        battery_state = BatteryState(
            timestamp_ns=telemetry.timestamp_ns,
            voltage_v=telemetry.battery_voltage_v,
            current_a=telemetry.battery_current_a,
            power_w=telemetry.battery_power_w,
            temperature_c=telemetry.battery_temp_c,
        )
        battery_prediction = self.battery_predictor.update(battery_state)
        
        # Update thermal model
        temp_sample = TemperatureSample(
            timestamp_ns=telemetry.timestamp_ns,
            cpu_temp_c=telemetry.cpu_temp_c,
            gpu_temp_c=telemetry.gpu_temp_c,
            ambient_temp_c=telemetry.ambient_temp_c,
        )
        thermal_analysis = self.thermal_guard.update(temp_sample)
        
        # Update security model
        network_metrics = NetworkMetrics(
            timestamp_ns=telemetry.timestamp_ns,
            packet_loss_pct=telemetry.packet_loss_pct,
            rtt_avg_ms=telemetry.rtt_avg_ms,
            rtt_p95_ms=telemetry.rtt_p95_ms,
            throughput_mbps=telemetry.throughput_mbps,
            goodput_mbps=telemetry.goodput_mbps,
        )
        
        # TODO: Integrate actual ML model predictions here
        lightweight_score = self._calculate_lightweight_ddos_score(network_metrics)
        heavyweight_score = None  # Only compute on-demand
        
        ddos_prediction, security_posture = self.security_advisor.analyze_threat(
            network_metrics, lightweight_score, heavyweight_score
        )
        
        # Persist latest telemetry artifacts for decision logic
        self._last_battery_prediction = battery_prediction
        self._last_thermal_analysis = thermal_analysis
        self._last_security_posture = security_posture
        self._last_network_metrics = network_metrics
        self._last_telemetry = telemetry
        self._record_rl_snapshot(telemetry, battery_prediction, thermal_analysis, network_metrics, ddos_prediction)

        # Update internal state
        self.current_state.battery_soc_percent = battery_prediction.soc_percent
        self.current_state.thermal_state = thermal_analysis.state
        self.current_state.threat_level = ddos_prediction.threat_level
        
        if battery_prediction.critical_warning:
            self.metrics.battery_warnings += 1
        if thermal_analysis.state in {ThermalState.CRITICAL, ThermalState.EMERGENCY}:
            self.metrics.thermal_warnings += 1
        if ddos_prediction.threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
            self.metrics.ddos_detections += 1

        # Check for emergency conditions
        emergency_conditions = [
            battery_prediction.critical_warning,
            thermal_analysis.emergency_shutdown,
            ddos_prediction.threat_level == ThreatLevel.CRITICAL,
        ]
        
        if any(emergency_conditions) and not self.current_state.emergency_mode:
            self._activate_emergency_mode()
        elif not any(emergency_conditions) and self.current_state.emergency_mode:
            self._deactivate_emergency_mode()
        
        # Log telemetry update
        self.logger.debug("Telemetry updated", extra={
            "battery_soc": battery_prediction.soc_percent,
            "thermal_state": thermal_analysis.state.value,
            "threat_level": ddos_prediction.threat_level.value,
            "emergency_mode": self.current_state.emergency_mode,
        })
    
    def _record_rl_snapshot(
        self,
        telemetry: SystemTelemetry,
        battery_prediction: BatteryPrediction,
        thermal_analysis: ThermalAnalysis,
        network_metrics: Optional[NetworkMetrics],
        ddos_prediction: DDOSPrediction,
    ) -> None:
        """Record telemetry snapshot for RL / expert strategies."""
        
        ddos_alert = ddos_prediction.threat_level in {
            ThreatLevel.CONFIRMED,
            ThreatLevel.CRITICAL,
        }

        counters: Dict[str, float] = {
            "thermal_trend_c_per_s": float(thermal_analysis.trend_c_per_s),
            "battery_remaining_s": float(battery_prediction.remaining_time_s),
        }

        snapshot = SuiteTelemetry(
            suite_id=self.current_state.active_suite,
            timestamp_ns=telemetry.timestamp_ns,
            battery_pct=battery_prediction.soc_percent,
            battery_voltage_v=telemetry.battery_voltage_v,
            battery_current_a=telemetry.battery_current_a,
            cpu_percent=telemetry.cpu_percent,
            cpu_temp_c=telemetry.cpu_temp_c,
            power_w=telemetry.battery_power_w,
            throughput_mbps=telemetry.throughput_mbps,
            goodput_mbps=telemetry.goodput_mbps,
            packet_loss_pct=network_metrics.packet_loss_pct if network_metrics else None,
            rtt_ms=network_metrics.rtt_p95_ms if network_metrics else None,
            ddos_alert=ddos_alert,
            counters=counters,
        )

        self._rl_snapshots.append(snapshot)
    
    def _scheduler_loop(self) -> None:
        """Main scheduler decision loop."""
        
        last_decision_time = time.time()
        decision_count = 0
        
        while self.running:
            try:
                loop_start = time.time()
                
                # Make scheduling decision
                decision = self._make_scheduling_decision()
                
                if decision:
                    # Apply decision
                    self._apply_decision(decision)
                    
                    # Notify callbacks
                    for callback in self.decision_callbacks:
                        try:
                            callback(decision)
                        except Exception as e:
                            self.logger.error(f"Decision callback failed: {e}")
                    
                    decision_count += 1
                
                # Update performance metrics
                loop_time = time.time() - loop_start
                self._update_performance_metrics(loop_time, decision_count, last_decision_time)
                
                # Sleep until next decision interval
                sleep_time = max(0.0, self.decision_interval_s - loop_time)
                time.sleep(sleep_time)
                
            except Exception as e:
                self.logger.error(f"Scheduler loop error: {e}", exc_info=True)
                time.sleep(1.0)  # Prevent tight error loop
    
    def _make_scheduling_decision(self) -> Optional[SchedulerDecision]:
        """Make intelligent scheduling decision based on current state."""
        
        if self.current_state.emergency_mode:
            return self._make_emergency_decision()
        
        # Use hybrid decision making based on confidence and conditions
        if self.current_state.mode == SchedulerMode.HYBRID_ADAPTIVE:
            return self._make_hybrid_decision()
        elif self.current_state.mode == SchedulerMode.EXPERT_ONLY:
            return self._make_expert_decision()
        elif self.current_state.mode == SchedulerMode.RL_ONLY:
            return self._make_rl_decision()
        else:
            return self._make_emergency_decision()
    
    def _make_hybrid_decision(self) -> Optional[SchedulerDecision]:
        """Make hybrid decision combining expert rules and RL."""
        
        # Get expert recommendation
        expert_decision = self._make_expert_decision()
        
        # Get RL recommendation  
        rl_decision = self._make_rl_decision()
        
        # Decision fusion logic
        if rl_decision and expert_decision:
            # If both agree, use RL decision (likely higher confidence)
            if rl_decision.target_suite == expert_decision.target_suite:
                return rl_decision
            
            # If they disagree, prefer expert in critical situations
            critical_conditions = [
                self.current_state.battery_soc_percent < 25.0,
                self.current_state.thermal_state in {ThermalState.CRITICAL, ThermalState.EMERGENCY},
                self.current_state.threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL},
            ]
            
            if any(critical_conditions):
                self.logger.info("Critical conditions detected, preferring expert decision")
                return expert_decision
            else:
                # Non-critical: use RL if confidence is high enough
                rl_confidence = float(rl_decision.notes.get("confidence", 0.0))
                if rl_confidence > 0.75:
                    return rl_decision
                else:
                    return expert_decision
        
        # Fallback to whichever is available
        return rl_decision or expert_decision
    
    def _make_expert_decision(self) -> Optional[SchedulerDecision]:
        """Make decision using expert rule-based strategy."""
        if not self.available_suites:
            return None

        # Fallback if we do not have fresh telemetry yet
        if not (
            self._last_battery_prediction and
            self._last_thermal_analysis and
            self._last_telemetry
        ):
            fallback_suite = self.available_suites[min(1, len(self.available_suites) - 1)]
            ddos_mode = DdosMode.LIGHTWEIGHT
            if self.current_state.threat_level in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
                fallback_suite = self.available_suites[-1]
                ddos_mode = DdosMode.HEAVYWEIGHT
            elif self.current_state.battery_soc_percent < 20.0:
                fallback_suite = self.available_suites[0]
            return SchedulerDecision(
                target_suite=fallback_suite,
                ddos_mode=ddos_mode,
                notes={
                    "strategy": "expert",
                    "reason": "telemetry_fallback",
                }
            )

        battery = self._last_battery_prediction
        thermal = self._last_thermal_analysis
        telemetry = self._last_telemetry
        network = self._last_network_metrics
        posture = self._last_security_posture
        threat = self.current_state.threat_level

        suite_order = self.available_suites
        try:
            current_index = suite_order.index(self.current_state.active_suite)
        except ValueError:
            current_index = max(0, min(len(suite_order) - 1, 1))

        max_index_allowed = len(suite_order) - 1
        constraint_reasons: List[str] = []

        def apply_cap(new_cap: int, reason: str) -> None:
            nonlocal max_index_allowed
            capped_value = max(0, min(len(suite_order) - 1, new_cap))
            if capped_value < max_index_allowed:
                max_index_allowed = capped_value
                constraint_reasons.append(reason)

        # Battery bins with dwell-aware caps
        if battery.soc_percent <= 15.0 or battery.remaining_time_s < 300.0:
            battery_bin = "critical"
            apply_cap(0, "battery_critical")
        elif battery.soc_percent <= 30.0:
            battery_bin = "low"
            apply_cap(1, "battery_low")
        elif battery.soc_percent <= 55.0:
            battery_bin = "moderate"
            apply_cap(len(suite_order) - 1 if len(suite_order) <= 2 else 2, "battery_moderate")
        else:
            battery_bin = "high"

        # Thermal guard constraints
        if thermal.state == ThermalState.EMERGENCY:
            apply_cap(0, "thermal_emergency")
        elif thermal.state == ThermalState.CRITICAL:
            apply_cap(0, "thermal_critical")
        elif thermal.state == ThermalState.ELEVATED:
            apply_cap(1, "thermal_elevated")
            if thermal.trend_c_per_s > 0.5 or (
                thermal.time_to_critical_s is not None and thermal.time_to_critical_s < 180.0
            ):
                apply_cap(0, "thermal_trend")

        # CPU utilization guardrails
        cpu_pct = telemetry.cpu_percent
        if cpu_pct >= 90.0:
            apply_cap(0, "cpu_saturated")
        elif cpu_pct >= 80.0:
            apply_cap(1, "cpu_high")

        # Network congestion guardrails
        if network is not None:
            if (
                network.packet_loss_pct > 12.0 or
                network.rtt_p95_ms > 400.0 or
                network.throughput_mbps < 1.5
            ):
                apply_cap(0, "network_congested")
            elif network.packet_loss_pct > 6.0 or network.rtt_p95_ms > 250.0:
                apply_cap(1, "network_degraded")

        # Target suite preference driven by threat posture
        desired_index = 0
        suite_source = "default"

        # If heartbeat indicates follower is missing heartbeats, play safe by
        # preferring the lowest-power suite unless overridden by high threat.
        hb_missed_threshold = 2
        try:
            hb_ok = telemetry.heartbeat_ok
            hb_missed = telemetry.heartbeat_missed_count or 0
        except Exception:
            hb_ok = None
            hb_missed = 0

        if hb_ok is False or (hb_missed and hb_missed >= hb_missed_threshold):
            # If threat is severe, still prefer security; otherwise pick safe
            if threat in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
                desired_index = len(suite_order) - 1
                suite_source = "threat_high_overrides_heartbeat"
            else:
                desired_index = 0
                suite_source = "heartbeat_missing_safe_mode"

        if posture and posture.pqc_suite in suite_order:
            desired_index = suite_order.index(posture.pqc_suite)
            suite_source = "security_posture"
        else:
            if threat in {ThreatLevel.CONFIRMED, ThreatLevel.CRITICAL}:
                desired_index = len(suite_order) - 1
                suite_source = "threat_high"
            elif threat == ThreatLevel.SUSPICIOUS:
                desired_index = min(len(suite_order) - 1, 1)
                suite_source = "threat_suspicious"
            else:
                desired_index = min(len(suite_order) - 1, 1)

        target_index = min(desired_index, max_index_allowed)
        now_ns = time.time_ns()
        dwell_blocked = False

        if target_index > current_index:
            if (now_ns - self._last_suite_change_ns) < self._suite_dwell_ns:
                target_index = current_index
                dwell_blocked = True

        target_suite = suite_order[target_index]

        # Map threat level and posture to DDOS mode with hysteresis
        ddos_mode = DdosMode.LIGHTWEIGHT
        ddos_reason = "threat_map"

        if posture:
            if posture.ddos_detection_tier.value == "heavyweight":
                ddos_mode = DdosMode.HEAVYWEIGHT
            elif threat == ThreatLevel.NONE and not posture.traffic_throttling:
                ddos_mode = DdosMode.DISABLED
            else:
                ddos_mode = DdosMode.LIGHTWEIGHT
            ddos_reason = "security_posture"
        else:
            threat_map = {
                ThreatLevel.NONE: DdosMode.LIGHTWEIGHT,
                ThreatLevel.SUSPICIOUS: DdosMode.LIGHTWEIGHT,
                ThreatLevel.CONFIRMED: DdosMode.HEAVYWEIGHT,
                ThreatLevel.CRITICAL: DdosMode.HEAVYWEIGHT,
            }
            ddos_mode = threat_map.get(threat, DdosMode.LIGHTWEIGHT)

        if network and (
            network.packet_loss_pct > 15.0 or
            network.connection_attempts_per_s and network.connection_attempts_per_s > 50
        ):
            if ddos_mode != DdosMode.HEAVYWEIGHT:
                ddos_mode = DdosMode.HEAVYWEIGHT
                ddos_reason = "network_abuse"

        mode_rank = {
            DdosMode.DISABLED: 0,
            DdosMode.LIGHTWEIGHT: 1,
            DdosMode.HEAVYWEIGHT: 2,
        }
        current_ddos_mode = (
            DdosMode.HEAVYWEIGHT if self.current_state.active_ddos_tier == "heavyweight"
            else DdosMode.DISABLED if self.current_state.active_ddos_tier == "disabled"
            else DdosMode.LIGHTWEIGHT
        )
        ddos_dwell_blocked = False

        if mode_rank[ddos_mode] < mode_rank[current_ddos_mode]:
            if (now_ns - self._last_ddos_change_ns) < self._ddos_dwell_ns:
                ddos_mode = current_ddos_mode
                ddos_dwell_blocked = True

        notes = {
            "strategy": "expert",
            "battery_soc": f"{battery.soc_percent:.1f}",
            "battery_bin": battery_bin,
            "thermal_state": thermal.state.value,
            "cpu_pct": f"{cpu_pct:.1f}",
            "threat_level": threat.value,
            "suite_source": suite_source,
            "ddos_reason": ddos_reason,
        }

        if network:
            notes.update({
                "packet_loss_pct": f"{network.packet_loss_pct:.1f}",
                "rtt_p95_ms": f"{network.rtt_p95_ms:.0f}",
            })

        if constraint_reasons:
            notes["constraints"] = ",".join(constraint_reasons)
        else:
            notes["constraints"] = "none"

        if dwell_blocked:
            notes["suite_dwell_blocked"] = "1"
        if ddos_dwell_blocked:
            notes["ddos_dwell_blocked"] = "1"

        return SchedulerDecision(
            target_suite=target_suite,
            ddos_mode=ddos_mode,
            notes=notes,
        )
    
    def _make_rl_decision(self) -> Optional[SchedulerDecision]:
        """Make decision using reinforcement learning strategy."""
        snapshots = list(self._rl_snapshots)
        if len(snapshots) < 2:
            return None

        window = TelemetryWindow(
            snapshots=snapshots,
            window_start_ns=snapshots[0].timestamp_ns,
            window_end_ns=snapshots[-1].timestamp_ns,
        )

        try:
            decision = self.rl_scheduler.decide(
                context=self.context,
                telemetry=window,
            )
        except Exception as exc:  # pragma: no cover - defensive logging
            self.logger.error("RL decision failed: %s", exc, exc_info=True)
            return None

        if decision is None:
            return None

        notes = dict(decision.notes or {})
        notes.setdefault("strategy", "rl")

        return SchedulerDecision(
            target_suite=decision.target_suite,
            ddos_mode=decision.ddos_mode,
            traffic_rate_mbps=decision.traffic_rate_mbps,
            notes=notes,
        )
    
    def _make_emergency_decision(self) -> SchedulerDecision:
        """Make emergency safe decision."""
        return SchedulerDecision(
            target_suite=self.available_suites[0],  # Lowest power suite
            ddos_mode=DdosMode.DISABLED,            # Minimal processing
            notes={
                "strategy": "emergency",
                "reason": "critical_system_state",
            }
        )
    
    def _apply_decision(self, decision: SchedulerDecision) -> None:
        """Apply scheduling decision to the system."""
        
        decision_start = time.time()
        
        # Switch PQC suite if needed
        if decision.target_suite != self.current_state.active_suite:
            success = self.pqc_bridge.switch_algorithm(decision.target_suite)
            if success:
                self.current_state.active_suite = decision.target_suite
                self.context.initial_suite = decision.target_suite
                self.metrics.suite_switches += 1
                self._last_suite_change_ns = time.time_ns()
                self.logger.info(f"Switched to PQC suite: {decision.target_suite}")
            else:
                self.logger.error(f"Failed to switch to suite: {decision.target_suite}")
        
        # Switch DDOS detection tier if needed
        if decision.ddos_mode == DdosMode.HEAVYWEIGHT:
            ddos_tier = "heavyweight"
            ddos_algorithm = "transformer_heavy"
        elif decision.ddos_mode == DdosMode.LIGHTWEIGHT:
            ddos_tier = "lightweight"
            ddos_algorithm = "xgboost_light"
        else:
            ddos_tier = "disabled"
            ddos_algorithm = "heuristic_fallback"

        if ddos_tier != self.current_state.active_ddos_tier:
            success = True
            if ddos_algorithm:
                success = self.ddos_bridge.switch_algorithm(ddos_algorithm)
            if success:
                self.current_state.active_ddos_tier = ddos_tier
                self._last_ddos_change_ns = time.time_ns()
                self.logger.info(f"Switched to DDOS tier: {ddos_tier}")
        
        # Update state
        self.current_state.last_decision_ns = time.time_ns()
        
        # Log decision
        decision_time_ms = (time.time() - decision_start) * 1000
        self.logger.info("Applied scheduling decision", extra={
            "suite": decision.target_suite,
            "ddos_mode": decision.ddos_mode.value,
            "decision_time_ms": decision_time_ms,
            "notes": decision.notes,
        })
    
    def _activate_emergency_mode(self) -> None:
        """Activate emergency safe mode."""
        self.current_state.emergency_mode = True
        self.current_state.mode = SchedulerMode.EMERGENCY_SAFE
        self.metrics.emergency_activations += 1
        
        self.logger.warning("EMERGENCY MODE ACTIVATED", extra={
            "battery_soc": self.current_state.battery_soc_percent,
            "thermal_state": self.current_state.thermal_state.value,
            "threat_level": self.current_state.threat_level.value,
        })
    
    def _deactivate_emergency_mode(self) -> None:
        """Deactivate emergency mode and return to normal operation."""
        self.current_state.emergency_mode = False
        self.current_state.mode = SchedulerMode.HYBRID_ADAPTIVE
        
        self.logger.info("Emergency mode deactivated - returning to normal operation")
    
    def _calculate_lightweight_ddos_score(self, metrics: NetworkMetrics) -> float:
        """Calculate lightweight DDOS anomaly score using heuristics."""
        # Simple heuristic until real XGBoost integration
        score = 0.0
        
        if metrics.packet_loss_pct > 5.0:
            score += 0.3
        if metrics.rtt_p95_ms > 200.0:
            score += 0.2
        if metrics.throughput_mbps < 2.0:
            score += 0.3
        if metrics.goodput_mbps < metrics.throughput_mbps * 0.8:
            score += 0.2
        
        return min(1.0, score)
    
    def _update_performance_metrics(
        self, 
        loop_time_s: float, 
        decision_count: int, 
        last_decision_time: float
    ) -> None:
        """Update scheduler performance metrics."""
        
        # Decision rate
        time_elapsed = time.time() - last_decision_time
        if time_elapsed > 0:
            self.metrics.decisions_per_minute = (decision_count / time_elapsed) * 60.0
        
        # Average decision latency
        self.metrics.avg_decision_latency_ms = loop_time_s * 1000.0
        
        # IPC performance
        pqc_stats = self.pqc_bridge.get_performance_stats()
        ddos_stats = self.ddos_bridge.get_performance_stats()
        
        self.metrics.ipc_performance = {
            "pqc_avg_switch_ms": pqc_stats.avg_switch_time_ms,
            "pqc_cache_hit_rate": (
                pqc_stats.cache_hits / max(1, pqc_stats.cache_hits + pqc_stats.cache_misses)
            ),
            "ddos_avg_switch_ms": ddos_stats.avg_switch_time_ms,
            "ddos_cache_hit_rate": (
                ddos_stats.cache_hits / max(1, ddos_stats.cache_hits + ddos_stats.cache_misses)
            ),
        }
    
    def _setup_logging(self) -> logging.Logger:
        """Setup structured logging for the scheduler."""
        
        logger = logging.getLogger("UnifiedUAVScheduler")
        logger.setLevel(logging.INFO)
        
        # Create log file with timestamp
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        log_file = self.log_dir / f"scheduler_{timestamp}.log"
        
        # File handler with JSON formatting
        file_handler = logging.FileHandler(log_file)
        file_formatter = logging.Formatter(
            '{"timestamp":"%(asctime)s","level":"%(levelname)s","message":"%(message)s","extra":%(extra)s}'
        )
        
        # Add custom filter to ensure 'extra' field exists
        class ExtraFilter(logging.Filter):
            def filter(self, record):
                if not hasattr(record, 'extra'):
                    record.extra = '{}'
                else:
                    record.extra = json.dumps(getattr(record, 'extra', {}))
                return True
        
        file_handler.addFilter(ExtraFilter())
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
        
        # Console handler for immediate feedback
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s [%(levelname)s] %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
        
        return logger
    
    def register_decision_callback(self, callback: Callable[[SchedulerDecision], None]) -> None:
        """Register callback to be notified of scheduling decisions."""
        self.decision_callbacks.append(callback)
    
    def get_current_state(self) -> SchedulerState:
        """Get current scheduler state."""
        return self.current_state
    
    def get_performance_metrics(self) -> SchedulerMetrics:
        """Get scheduler performance metrics."""
        return self.metrics
    
    def __enter__(self):
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop()


__all__ = [
    "UnifiedUAVScheduler",
    "SystemTelemetry", 
    "SchedulerState",
    "SchedulerMetrics",
    "SchedulerMode",
]

============================================================

FILE 19/19: telemetry\heartbeat.py
============================================================
Full Path: C:\Users\burak\Desktop\research\src\telemetry\heartbeat.py
Size: 4,265 bytes
Modified: 2025-10-14 06:30:53
------------------------------------------------------------
from __future__ import annotations

"""Lightweight UDP heartbeat channel for passive/active DDOS signalling.

Design:
- Pre-encrypted, fixed-size payload blobs are stored on disk (generated offline)
- Sender transmits one blob every interval seconds to a configured host:port
- Receiver validates payloads by constant-time compare against an allowlist
- Stop after N consecutive send failures; expose last status for dataset fusion

This module is intentionally decoupled from core/ transport to avoid any wire
compatibility changes. Integrate from schedulers or tools/ as an auxiliary
channel. Do not log secrets or payload bytes.
"""

import socket
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional


def _load_blobs(path: Path) -> list[bytes]:
    blobs: list[bytes] = []
    if not path.exists():
        return blobs
    for child in sorted(path.glob("*.bin")):
        try:
            data = child.read_bytes()
            if data:
                blobs.append(data)
        except Exception:
            continue
    return blobs


@dataclass
class HeartbeatConfig:
    host: str
    port: int
    interval_s: float = 2.0
    retry_limit: int = 5
    payload_dir: Optional[Path] = None  # Directory containing pre-encrypted .bin files


class HeartbeatSender:
    def __init__(self, cfg: HeartbeatConfig) -> None:
        self.cfg = cfg
        self._blobs = _load_blobs(cfg.payload_dir) if cfg.payload_dir else []
        self._last_ok = False
        self._consecutive_failures = 0
        self._idx = 0

    @property
    def last_ok(self) -> bool:
        return self._last_ok

    @property
    def consecutive_failures(self) -> int:
        return self._consecutive_failures

    def send_once(self) -> bool:
        payload = self._select_payload()
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
                s.settimeout(0.5)
                s.sendto(payload, (self.cfg.host, self.cfg.port))
            self._last_ok = True
            self._consecutive_failures = 0
            return True
        except Exception:
            self._last_ok = False
            self._consecutive_failures += 1
            return False

    def run(self, stop_time: Optional[float] = None) -> None:
        while True:
            if stop_time is not None and time.time() >= stop_time:
                break
            ok = self.send_once()
            if not ok and self._consecutive_failures >= self.cfg.retry_limit:
                break
            time.sleep(max(0.05, self.cfg.interval_s))

    def _select_payload(self) -> bytes:
        if self._blobs:
            blob = self._blobs[self._idx % len(self._blobs)]
            self._idx += 1
            return blob
        # Fallback: zero-filled minimal payload (non-secret)
        return b"\x00" * 16


class HeartbeatReceiver:
    def __init__(self, host: str, port: int, allowlist: Optional[Iterable[bytes]] = None) -> None:
        self.host = host
        self.port = port
        self.allow = tuple(allowlist or ())
        self.last_recv_ts: Optional[float] = None
        self.last_valid: bool = False

    def listen_once(self, timeout_s: float = 0.5) -> bool:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
                s.bind((self.host, self.port))
                s.settimeout(timeout_s)
                data, _addr = s.recvfrom(4096)
        except Exception:
            self.last_valid = False
            return False
        self.last_recv_ts = time.time()
        if not self.allow:
            # If no allowlist provided, accept any non-empty payload
            self.last_valid = bool(data)
            return self.last_valid
        for ref in self.allow:
            # Constant-time compare by length + XOR reduction
            if len(ref) == len(data):
                acc = 0
                for a, b in zip(ref, data):
                    acc |= a ^ b
                if acc == 0:
                    self.last_valid = True
                    return True
        self.last_valid = False
        return False

============================================================

================================================================================
END OF LOG
================================================================================
