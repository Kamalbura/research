PROJECT STRUCTURE AND PYTHON FILES LOG
================================================================================
Root Directory: C:\Users\burak\Desktop\research\tools
Output File: C:\Users\burak\Desktop\research\tools\project_structure_20250929_032127.txt
Generated: 2025-09-29 03:21:27
================================================================================

================================================================================
DIRECTORY TREE STRUCTURE
================================================================================
Root Directory: C:\Users\burak\Desktop\research\tools
Generated: 2025-09-29 03:21:27

├── __pycache__/
│   ├── __init__.cpython-311.pyc (233 bytes)
│   ├── __init__.cpython-313.pyc (222 bytes)
│   ├── auto_test_drone.cpython-313.pyc (4,859 bytes)
│   ├── auto_test_gcs.cpython-313.pyc (3,886 bytes)
│   ├── counter_utils.cpython-311.pyc (9,271 bytes)
│   ├── counter_utils.cpython-313.pyc (8,121 bytes)
│   ├── diag_udp.cpython-313.pyc (12,199 bytes)
│   ├── prepare_matrix_keys.cpython-313.pyc (4,755 bytes)
│   ├── socket_utils.cpython-313.pyc (3,371 bytes)
│   ├── traffic_common.cpython-313.pyc (5,892 bytes)
│   ├── traffic_gcs.cpython-313.pyc (451 bytes)
│   ├── traffic_runner.cpython-313.pyc (8,529 bytes)
│   └── udp_echo.cpython-313.pyc (3,530 bytes)
├── auto/
│   ├── __pycache__/
│   │   ├── drone_follower.cpython-313.pyc (20,592 bytes)
│   │   ├── drone_follower_simple.cpython-313.pyc (8,776 bytes)
│   │   ├── gcs_scheduler.cpython-313.pyc (23,425 bytes)
│   │   ├── gcs_scheduler_quickpass.cpython-313.pyc (13,504 bytes)
│   │   └── gcs_scheduler_simple.cpython-313.pyc (15,429 bytes)
│   ├── drone_follower.py (12,036 bytes)
│   ├── drone_follower_simple.py (4,865 bytes)
│   ├── gcs_scheduler.py (14,222 bytes)
│   ├── gcs_scheduler_quickpass.py (7,891 bytes)
│   └── gcs_scheduler_simple.py (9,391 bytes)
├── captures/
├── manual_4term/
│   ├── __pycache__/
│   │   ├── drone_autopilot_sim.cpython-313.pyc (6,509 bytes)
│   │   ├── drone_tty.cpython-313.pyc (7,352 bytes)
│   │   ├── encrypted_bridge_logger.cpython-313.pyc (7,713 bytes)
│   │   ├── gcs_ground_station_sim.cpython-313.pyc (6,496 bytes)
│   │   ├── gcs_tty.cpython-313.pyc (7,376 bytes)
│   │   ├── launch_manual_test.cpython-311-pytest-8.3.5.pyc (16,348 bytes)
│   │   ├── launch_manual_test.cpython-313-pytest-8.4.2.pyc (15,131 bytes)
│   │   └── launch_manual_test.cpython-313.pyc (14,205 bytes)
│   ├── keys/
│   │   ├── gcs_pub.bin (1,952 bytes)
│   │   └── gcs_sec.bin (4,032 bytes)
│   ├── drone_autopilot_sim.py (3,933 bytes)
│   ├── drone_tty.py (4,213 bytes)
│   ├── encrypted_bridge_logger.py (4,355 bytes)
│   ├── gcs_ground_station_sim.py (3,927 bytes)
│   ├── gcs_tty.py (4,207 bytes)
│   ├── launch_manual_test.py (9,824 bytes)
│   └── README.md (6,886 bytes)
├── netcapture/
│   ├── drone_capture.py (3,434 bytes)
│   └── gcs_capture.py (5,576 bytes)
├── port_profiles/
│   ├── default.ps1 (380 bytes)
│   └── default.sh (395 bytes)
├── wireshark/
│   └── pqc_tunnel.lua (1,267 bytes)
├── __init__.py (69 bytes)
├── aggregate_lan_results.py (4,639 bytes)
├── audit_endpoints.py (5,511 bytes)
├── auto_test_drone.py (3,561 bytes)
├── auto_test_gcs.py (2,549 bytes)
├── bench_cli.py (841 bytes)
├── check_matrix_keys.py (1,373 bytes)
├── check_no_hardcoded_ips.py (2,448 bytes)
├── check_ports.py (3,618 bytes)
├── check_suites.py (1,030 bytes)
├── cleanup_bound_ports.py (2,136 bytes)
├── copy_pubs_to_pi.py (5,456 bytes)
├── counter_utils.py (6,381 bytes)
├── diag_udp.py (8,245 bytes)
├── encrypted_sniffer.py (1,570 bytes)
├── full_comm_check.py (9,657 bytes)
├── generate_env_report.py (5,905 bytes)
├── generate_identity.py (2,266 bytes)
├── markers.py (3,323 bytes)
├── matrix_runner_drone.sh (8,323 bytes)
├── matrix_runner_gcs.ps1 (10,767 bytes)
├── merge_power_csv.py (5,656 bytes)
├── packet_interceptor.py (2,494 bytes)
├── pi_check_env.sh (3,080 bytes)
├── power_hooks.py (208 bytes)
├── prepare_matrix_keys.py (3,043 bytes)
├── print_oqs_info.py (4,200 bytes)
├── project_structure_20250926_023741.txt (85,027 bytes)
├── project_structure_20250929_032127.txt (0 bytes)
├── scaffold_repo.py (17,074 bytes)
├── socket_utils.py (2,295 bytes)
├── traffic_common.py (3,551 bytes)
├── traffic_drone.py (206 bytes)
├── traffic_gcs.py (202 bytes)
├── traffic_runner.py (7,778 bytes)
├── udp_dual_probe.py (5,048 bytes)
├── udp_echo.py (2,558 bytes)
├── udp_echo_server.py (2,488 bytes)
└── udp_forward_log.py (2,796 bytes)


================================================================================
PYTHON FILE CONTENTS
================================================================================

Found 47 Python files:
   1. __init__.py
   2. aggregate_lan_results.py
   3. audit_endpoints.py
   4. auto\drone_follower.py
   5. auto\drone_follower_simple.py
   6. auto\gcs_scheduler.py
   7. auto\gcs_scheduler_quickpass.py
   8. auto\gcs_scheduler_simple.py
   9. auto_test_drone.py
  10. auto_test_gcs.py
  11. bench_cli.py
  12. check_matrix_keys.py
  13. check_no_hardcoded_ips.py
  14. check_ports.py
  15. check_suites.py
  16. cleanup_bound_ports.py
  17. copy_pubs_to_pi.py
  18. counter_utils.py
  19. diag_udp.py
  20. encrypted_sniffer.py
  21. full_comm_check.py
  22. generate_env_report.py
  23. generate_identity.py
  24. manual_4term\drone_autopilot_sim.py
  25. manual_4term\drone_tty.py
  26. manual_4term\encrypted_bridge_logger.py
  27. manual_4term\gcs_ground_station_sim.py
  28. manual_4term\gcs_tty.py
  29. manual_4term\launch_manual_test.py
  30. markers.py
  31. merge_power_csv.py
  32. netcapture\drone_capture.py
  33. netcapture\gcs_capture.py
  34. packet_interceptor.py
  35. power_hooks.py
  36. prepare_matrix_keys.py
  37. print_oqs_info.py
  38. scaffold_repo.py
  39. socket_utils.py
  40. traffic_common.py
  41. traffic_drone.py
  42. traffic_gcs.py
  43. traffic_runner.py
  44. udp_dual_probe.py
  45. udp_echo.py
  46. udp_echo_server.py
  47. udp_forward_log.py

--------------------------------------------------------------------------------

FILE 1/47: __init__.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\__init__.py
Size: 69 bytes
Modified: 2025-09-26 15:16:07
------------------------------------------------------------
"""Helper package for tooling scripts used in automated testing."""

============================================================

FILE 2/47: aggregate_lan_results.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\aggregate_lan_results.py
Size: 4,639 bytes
Modified: 2025-09-27 00:33:54
------------------------------------------------------------
"""Aggregate LAN test artifacts into CSV/JSONL/Markdown summaries.

Usage:
    python -m tools.aggregate_lan_results --results-dir results-20250927-120000
"""

from __future__ import annotations

import argparse
import csv
import json
import re
from pathlib import Path
from typing import Iterable, List, Dict

SUMMARY_FIELDS = [
    "suite",
    "side",
    "ptx_out",
    "ptx_in",
    "enc_out",
    "enc_in",
    "drops",
    "drop_replay",
    "drop_auth",
    "drop_header",
    "drop_session_epoch",
    "drop_other",
]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Aggregate LAN matrix artifacts")
    parser.add_argument(
        "--results-dir",
        required=True,
        help="Path to the results directory (e.g., results-YYYYMMDD-HHMMSS)",
    )
    parser.add_argument(
        "--markdown-name",
        default="SUMMARY.md",
        help="Name of the generated Markdown summary file",
    )
    parser.add_argument(
        "--csv-name",
        default="summary.csv",
        help="Name of the generated CSV file",
    )
    parser.add_argument(
        "--jsonl-name",
        default="summary.jsonl",
        help="Name of the generated JSONL file",
    )
    return parser.parse_args()


def load_counters(path: Path) -> Dict[str, int]:
    try:
        data = json.loads(path.read_text("utf-8"))
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Failed to parse JSON from {path}: {exc}")
    return data.get("counters", {})


def discover_runs(results_dir: Path) -> List[Dict[str, object]]:
    rows: List[Dict[str, object]] = []
    for json_path in results_dir.glob("*_debug_*.json"):
        match = re.search(r"_(cs-[^_]+)\.json$", json_path.name)
        suite = match.group(1) if match else "unknown"
        side = "gcs" if "gcs_" in json_path.name else "drone"
        counters = load_counters(json_path)
        row = {"suite": suite, "side": side}
        for key in SUMMARY_FIELDS:
            if key in ("suite", "side"):
                continue
            row[key] = counters.get(key, 0)
        rows.append(row)
    return rows


def write_jsonl(rows: Iterable[Dict[str, object]], path: Path) -> None:
    with path.open("w", encoding="utf-8") as handle:
        for row in rows:
            handle.write(json.dumps(row) + "\n")


def write_csv(rows: Iterable[Dict[str, object]], path: Path) -> None:
    rows = list(rows)
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=SUMMARY_FIELDS)
        writer.writeheader()
        for row in rows:
            record = {field: row.get(field, "") for field in SUMMARY_FIELDS}
            writer.writerow(record)


def suite_pass(rows: List[Dict[str, object]], suite: str) -> bool:
    gcs = next((row for row in rows if row["suite"] == suite and row["side"] == "gcs"), None)
    drone = next((row for row in rows if row["suite"] == suite and row["side"] == "drone"), None)
    if not gcs or not drone:
        return False
    checks = []
    for entry in (gcs, drone):
        checks.append(entry.get("drops", 0) == 0)
        checks.append(entry.get("enc_in", 0) > 0)
        checks.append(entry.get("enc_out", 0) > 0)
        checks.append(entry.get("ptx_in", 0) > 0)
        checks.append(entry.get("ptx_out", 0) > 0)
    return all(checks)


def write_markdown(rows: List[Dict[str, object]], path: Path) -> None:
    suites = sorted(set(row["suite"] for row in rows))
    lines = ["# PQC Drone↔GCS LAN Matrix — Summary", ""]
    for suite in suites:
        lines.append(f"- {suite}: {'PASS' if suite_pass(rows, suite) else 'FAIL'}")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def main() -> None:
    args = parse_args()
    results_dir = Path(args.results_dir).expanduser().resolve()
    if not results_dir.exists():
        raise SystemExit(f"Results directory {results_dir} does not exist")

    rows = discover_runs(results_dir)
    if not rows:
        raise SystemExit(f"No *_debug_*.json files found in {results_dir}")

    jsonl_path = results_dir / args.jsonl_name
    csv_path = results_dir / args.csv_name
    md_path = results_dir / args.markdown_name

    write_jsonl(rows, jsonl_path)
    write_csv(rows, csv_path)
    write_markdown(rows, md_path)

    print(f"Wrote {jsonl_path}")
    print(f"Wrote {csv_path}")
    print(f"Wrote {md_path}")


if __name__ == "__main__":
    main()

============================================================

FILE 3/47: audit_endpoints.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\audit_endpoints.py
Size: 5,511 bytes
Modified: 2025-09-26 04:19:40
------------------------------------------------------------
#!/usr/bin/env python3
"""Audit repository files for hard-coded network endpoints.

This script scans Python (and optional shell/Lua) files for IPv4 literals
and socket usage that should instead reference core.config.CONFIG.
It emits a JSON report of violations and exits non-zero if any are found.
"""

from __future__ import annotations

import ast
import json
import re
import sys
from pathlib import Path
from typing import Iterable, List

ROOT = Path(__file__).resolve().parents[1]
ALLOW_IPS = {"127.0.0.1", "0.0.0.0", "::1"}
CODE_DIRS = ("core", "tools", "drone", "gcs")
IPV4_RE = re.compile(r"\b\d{1,3}(?:\.\d{1,3}){3}\b")
EXCLUDE_PARTS = {"docs", "logs", "__pycache__"}

Violation = dict[str, object]


def iter_files() -> Iterable[Path]:
    for directory in CODE_DIRS:
        base = ROOT / directory
        if not base.exists():
            continue
        for path in base.rglob("*.py"):
            if any(part in EXCLUDE_PARTS for part in path.parts):
                continue
            yield path


def flag(violations: List[Violation], path: Path, lineno: int, kind: str, detail: str, suggestion: str | None = None) -> None:
    rel = str(path.relative_to(ROOT))
    violations.append(
        {
            "file": rel,
            "line": lineno,
            "kind": kind,
            "detail": detail,
            "suggestion": suggestion or "",
        }
    )


def scan_file(path: Path, violations: List[Violation]) -> None:
    try:
        source = path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return

    # Regex sweep for IPv4 literals
    for lineno, line in enumerate(source.splitlines(), start=1):
        for match in IPV4_RE.finditer(line):
            ip = match.group(0)
            if ip not in ALLOW_IPS:
                flag(
                    violations,
                    path,
                    lineno,
                    "ipv4-literal",
                    f"Found IPv4 literal '{ip}'",
                    "Use CONFIG['GCS_HOST'/'DRONE_HOST'] or accept a parameter",
                )

    # AST analysis for socket invocations with literal endpoints
    try:
        tree = ast.parse(source, filename=str(path))
    except SyntaxError:
        return

    def is_literal_str(node: ast.AST) -> bool:
        return isinstance(node, ast.Constant) and isinstance(node.value, str)

    def is_literal_int(node: ast.AST) -> bool:
        return isinstance(node, ast.Constant) and isinstance(node.value, int)

    class Visitor(ast.NodeVisitor):
        def visit_Call(self, node: ast.Call) -> None:
            attr = getattr(node.func, "attr", None)
            if attr in {"bind", "connect"} and node.args:
                target = node.args[0]
                if isinstance(target, ast.Tuple) and len(target.elts) >= 2:
                    host, port = target.elts[0], target.elts[1]
                    if is_literal_str(host) and IPV4_RE.fullmatch(host.value or "") and host.value not in ALLOW_IPS:
                        flag(
                            violations,
                            path,
                            node.lineno,
                            f"{attr}-literal-host",
                            f"socket.{attr} uses literal host '{host.value}'",
                            "Replace with CONFIG['GCS_HOST'/'DRONE_HOST']",
                        )
                    if is_literal_int(port):
                        flag(
                            violations,
                            path,
                            node.lineno,
                            f"{attr}-literal-port",
                            f"socket.{attr} uses literal port {port.value}",
                            "Use CONFIG[...] for ports or pass via args",
                        )
            elif attr == "sendto" and len(node.args) >= 2:
                destination = node.args[1]
                if isinstance(destination, ast.Tuple) and len(destination.elts) >= 2:
                    host, port = destination.elts[0], destination.elts[1]
                    if is_literal_str(host) and IPV4_RE.fullmatch(host.value or "") and host.value not in ALLOW_IPS:
                        flag(
                            violations,
                            path,
                            node.lineno,
                            "sendto-literal-host",
                            f"socket.sendto uses literal host '{host.value}'",
                            "Replace with CONFIG['GCS_HOST'/'DRONE_HOST']",
                        )
                    if is_literal_int(port):
                        flag(
                            violations,
                            path,
                            node.lineno,
                            "sendto-literal-port",
                            f"socket.sendto uses literal port {port.value}",
                            "Use CONFIG[...] for ports",
                        )
            self.generic_visit(node)

    Visitor().visit(tree)


def main() -> int:
    violations: List[Violation] = []
    for path in iter_files():
        scan_file(path, violations)

    print(json.dumps({"violations": violations}, indent=2))
    if violations:
        print(f"\nFound {len(violations)} endpoint violations.", file=sys.stderr)
        return 2
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 4/47: auto\drone_follower.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_follower.py
Size: 12,036 bytes
Modified: 2025-09-29 02:53:02
------------------------------------------------------------
#!/usr/bin/env python3
"""Drone follower/loopback agent driven entirely by core configuration.

This script launches the drone proxy, exposes the TCP control channel for the
GCS scheduler, and runs the plaintext UDP echo used to validate the encrypted
path. All network endpoints originate from :mod:`core.config`. Test behaviour
can be tuned via optional CLI flags (e.g. to disable perf monitors), but no
network parameters are duplicated here.
"""

from __future__ import annotations

import argparse
import json
import os
import shlex
import signal
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Callable, Optional

from core.config import CONFIG
from core import suites as suites_mod


CONTROL_HOST = CONFIG.get("DRONE_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_BIND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("DRONE_PLAINTEXT_RX", 47004))
APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("DRONE_PLAINTEXT_TX", 47003))

DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

OUTDIR = Path("logs/auto/drone")
MARK_DIR = OUTDIR / "marks"
SECRETS_DIR = Path("secrets/matrix")

PERF_EVENTS = "task-clock,cycles,instructions,cache-misses,context-switches"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def popen(cmd, **kw) -> subprocess.Popen:
    if isinstance(cmd, (list, tuple)):
        display = " ".join(shlex.quote(str(part)) for part in cmd)
    else:
        display = str(cmd)
    print(f"[{ts()}] exec: {display}", flush=True)
    return subprocess.Popen(cmd, **kw)


def killtree(proc: Optional[subprocess.Popen]) -> None:
    if not proc or proc.poll() is not None:
        return
    try:
        proc.terminate()
        proc.wait(timeout=3)
    except Exception:
        try:
            proc.kill()
        except Exception:
            pass


def discover_initial_suite() -> str:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if configured:
        return configured

    suite_map = suites_mod.list_suites()
    if suite_map:
        return sorted(suite_map.keys())[0]

    if SECRETS_DIR.exists():
        for path in sorted(SECRETS_DIR.iterdir()):
            if (path / "gcs_signing.pub").exists():
                return path.name

    return "cs-mlkem768-aesgcm-mldsa65"


def suite_outdir(suite: str) -> Path:
    path = OUTDIR / suite
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_secrets_dir(suite: str) -> Path:
    return SECRETS_DIR / suite


def write_marker(suite: str) -> None:
    MARK_DIR.mkdir(parents=True, exist_ok=True)
    marker = MARK_DIR / f"{int(time.time())}_{suite}.json"
    with open(marker, "w", encoding="utf-8") as handle:
        json.dump({"ts": ts(), "suite": suite}, handle)


def start_drone_proxy(suite: str) -> subprocess.Popen:
    suite_dir = suite_secrets_dir(suite)
    pub = suite_dir / "gcs_signing.pub"
    if not pub.exists():
        print(f"[follower] ERROR: missing {pub}", file=sys.stderr)
        sys.exit(2)

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    suite_path = suite_outdir(suite)
    status = suite_path / "drone_status.json"
    summary = suite_path / "drone_summary.json"
    OUTDIR.mkdir(parents=True, exist_ok=True)
    log_path = OUTDIR / f"drone_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8")

    print(f"[follower] launching drone proxy on suite {suite}", flush=True)
    return popen([
        sys.executable,
        "-m",
        "core.run_proxy",
        "drone",
        "--suite",
        suite,
        "--peer-pubkey-file",
        str(pub),
        "--status-file",
        str(status),
        "--json-out",
        str(summary),
    ], stdout=log_handle, stderr=subprocess.STDOUT, text=True)


class UdpEcho(threading.Thread):
    def __init__(self, bind_host: str, recv_port: int, send_host: str, send_port: int, stop_event: threading.Event):
        super().__init__(daemon=True)
        self.bind_host = bind_host
        self.recv_port = recv_port
        self.send_host = send_host
        self.send_port = send_port
        self.stop_event = stop_event
        self.rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx_sock.bind((self.bind_host, self.recv_port))

    def run(self) -> None:
        print(
            f"[follower] UDP echo up: recv:{self.bind_host}:{self.recv_port} -> send:{self.send_host}:{self.send_port}",
            flush=True,
        )
        self.rx_sock.settimeout(0.5)
        while not self.stop_event.is_set():
            try:
                data, _ = self.rx_sock.recvfrom(65535)
                self.tx_sock.sendto(data, (self.send_host, self.send_port))
            except socket.timeout:
                continue
            except Exception as exc:
                print(f"[follower] UDP echo error: {exc}", flush=True)
        self.rx_sock.close()
        self.tx_sock.close()


class Monitors:
    def __init__(self, enabled: bool):
        self.enabled = enabled
        self.perf: Optional[subprocess.Popen] = None
        self.pidstat: Optional[subprocess.Popen] = None

    def start(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            return
        outdir.mkdir(parents=True, exist_ok=True)
        perf_cmd = f"perf stat -I 1000 -e {PERF_EVENTS} -p {pid} --log-fd 1"
        self.perf = popen(shlex.split(perf_cmd), stdout=open(outdir / f"perf_{suite}.csv", "w"), stderr=subprocess.STDOUT)
        self.pidstat = popen([
            "pidstat",
            "-hlur",
            "-p",
            str(pid),
            "1",
        ], stdout=open(outdir / f"pidstat_{suite}.txt", "w"), stderr=subprocess.STDOUT)

    def rotate(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            write_marker(suite)
            return
        self.stop()
        self.start(pid, outdir, suite)
        write_marker(suite)

    def stop(self) -> None:
        if not self.enabled:
            return
        killtree(self.perf)
        killtree(self.pidstat)
        self.perf = None
        self.pidstat = None


class ControlServer(threading.Thread):
    """Line-delimited JSON control server for the scheduler."""

    def __init__(self, host: str, port: int, state: dict):
        super().__init__(daemon=True)
        self.host = host
        self.port = port
        self.state = state
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.sock.bind((self.host, self.port))
        self.sock.listen(5)

    def run(self) -> None:
        print(f"[follower] control listening on {self.host}:{self.port}", flush=True)
        while not self.state["stop_event"].is_set():
            try:
                self.sock.settimeout(0.5)
                conn, _addr = self.sock.accept()
            except socket.timeout:
                continue
            threading.Thread(target=self.handle, args=(conn,), daemon=True).start()
        self.sock.close()

    def handle(self, conn: socket.socket) -> None:
        try:
            line = conn.makefile().readline()
            request = json.loads(line.strip()) if line else {}
        except Exception:
            request = {}

        try:
            cmd = request.get("cmd")
            if cmd == "ping":
                self._send(conn, {"ok": True, "ts": ts()})
                return
            if cmd == "status":
                proxy = self.state["proxy"]
                running = bool(proxy and proxy.poll() is None)
                self._send(
                    conn,
                    {
                        "ok": True,
                        "suite": self.state["suite"],
                        "proxy_pid": proxy.pid if proxy else None,
                        "running": running,
                        "control_host": self.host,
                        "control_port": self.port,
                        "udp_recv_port": APP_RECV_PORT,
                        "udp_send_port": APP_SEND_PORT,
                        "monitors_enabled": self.state["monitors"].enabled,
                    },
                )
                return
            if cmd == "mark":
                suite = request.get("suite")
                if not suite:
                    self._send(conn, {"ok": False, "error": "missing suite"})
                    return
                proxy = self.state["proxy"]
                if not proxy or proxy.poll() is not None:
                    self._send(conn, {"ok": False, "error": "proxy not running"})
                    return
                self.state["suite"] = suite
                outdir = self.state["suite_outdir"](suite)
                self.state["monitors"].rotate(proxy.pid, outdir, suite)
                self._send(conn, {"ok": True, "marked": suite})
                return
            if cmd == "stop":
                self.state["monitors"].stop()
                self.state["stop_event"].set()
                self._send(conn, {"ok": True, "stopping": True})
                return
            self._send(conn, {"ok": False, "error": "unknown_cmd"})
        finally:
            try:
                conn.close()
            except Exception:
                pass

    @staticmethod
    def _send(conn: socket.socket, obj: dict) -> None:
        conn.sendall((json.dumps(obj) + "\n").encode())


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    MARK_DIR.mkdir(parents=True, exist_ok=True)

    default_suite = discover_initial_suite()

    parser = argparse.ArgumentParser(description="Drone follower driven by core configuration")
    parser.add_argument(
        "--initial-suite",
        default=default_suite,
        help="Initial suite to launch (default: discover from config/secrets)",
    )
    parser.add_argument(
        "--disable-monitors",
        action="store_true",
        help="Disable perf/pidstat monitors",
    )
    args = parser.parse_args()

    initial_suite = args.initial_suite
    stop_event = threading.Event()

    proxy = start_drone_proxy(initial_suite)
    monitors = Monitors(enabled=not args.disable_monitors)
    time.sleep(1)
    if proxy.poll() is None:
        monitors.start(proxy.pid, suite_outdir(initial_suite), initial_suite)

    echo = UdpEcho(APP_BIND_HOST, APP_RECV_PORT, APP_SEND_HOST, APP_SEND_PORT, stop_event)
    echo.start()

    state = {
        "proxy": proxy,
        "suite": initial_suite,
        "suite_outdir": suite_outdir,
        "monitors": monitors,
        "stop_event": stop_event,
    }
    control = ControlServer(CONTROL_HOST, CONTROL_PORT, state)
    control.start()

    try:
        while not stop_event.is_set():
            if proxy.poll() is not None:
                print(f"[follower] proxy exited with {proxy.returncode}", flush=True)
                stop_event.set()
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        stop_event.set()
    finally:
        monitors.stop()
        killtree(proxy)
        try:
            proxy.send_signal(signal.SIGTERM)
        except Exception:
            pass


if __name__ == "__main__":
    main()

============================================================

FILE 5/47: auto\drone_follower_simple.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_follower_simple.py
Size: 4,865 bytes
Modified: 2025-09-29 02:21:38
------------------------------------------------------------
#!/usr/bin/env python3
"""
Drone follower (no args required):
- Starts the drone proxy with the initial suite.
- Runs a UDP echo (recv -> send ports defined in CONFIG).
- Exposes a tiny TCP JSON control API on CONFIG["DRONE_CONTROL_HOST"/"DRONE_CONTROL_PORT"].

All networking parameters are sourced from core.config.CONFIG.
"""

import json, os, socket, threading, subprocess, sys, time, pathlib, signal

from core.config import CONFIG

CONTROL_HOST = CONFIG.get("DRONE_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = CONFIG.get("DRONE_CONTROL_PORT", 48080)

APP_BIND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = CONFIG.get("DRONE_PLAINTEXT_TX", 47003)
APP_RECV_PORT = CONFIG.get("DRONE_PLAINTEXT_RX", 47004)

SECRETS_DIR = "secrets/matrix"
OUTDIR = "logs/auto/drone"
INITIAL_SUITE = CONFIG.get("SIMPLE_INITIAL_SUITE", "cs-mlkem768-aesgcm-mldsa65")

pathlib.Path(OUTDIR).mkdir(parents=True, exist_ok=True)
pathlib.Path(f"{OUTDIR}/marks").mkdir(parents=True, exist_ok=True)

def ts(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def start_drone_proxy(suite: str):
    os.environ["DRONE_HOST"] = CONFIG["DRONE_HOST"]
    os.environ["GCS_HOST"] = CONFIG["GCS_HOST"]
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    pub = f"{SECRETS_DIR}/{suite}/gcs_signing.pub"
    if not os.path.exists(pub):
        print(f"[follower] ERROR: missing {pub}", flush=True)
        sys.exit(2)

    status = f"{OUTDIR}/status.json"
    summary = f"{OUTDIR}/summary.json"
    log = open(f"{OUTDIR}/drone_{time.strftime('%Y%m%d-%H%M%S')}.log","w")
    print(f"[follower] launching drone proxy on suite {suite}", flush=True)
    p = subprocess.Popen([
        sys.executable,"-m","core.run_proxy","drone",
        "--suite", suite, "--peer-pubkey-file", pub,
        "--status-file", status, "--json-out", summary
    ], stdout=log, stderr=subprocess.STDOUT, text=True)
    return p

def udp_echo(stop_evt: threading.Event):
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind((APP_BIND_HOST, APP_RECV_PORT))
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    print(f"[follower] UDP echo up: recv:{APP_BIND_HOST}:{APP_RECV_PORT} -> send:{APP_SEND_HOST}:{APP_SEND_PORT}", flush=True)
    rx.settimeout(0.2)
    while not stop_evt.is_set():
        try:
            data, _ = rx.recvfrom(65535)
            tx.sendto(data, (APP_SEND_HOST, APP_SEND_PORT))
        except socket.timeout:
            pass
    rx.close(); tx.close()
    print("[follower] UDP echo stopped", flush=True)

def control_server(stop_evt: threading.Event):
    srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    srv.bind((CONTROL_HOST, CONTROL_PORT)); srv.listen(8)
    print(f"[follower] control listening on {CONTROL_HOST}:{CONTROL_PORT}", flush=True)
    while not stop_evt.is_set():
        srv.settimeout(0.2)
        try:
            conn, _ = srv.accept()
        except socket.timeout:
            continue
        with conn:
            line = conn.makefile().readline()
            try:
                req = json.loads(line.strip()) if line else {}
            except Exception:
                req = {}
            resp = {"ok": True}
            if req.get("cmd") == "ping":
                resp = {"ok": True, "ts": ts()}
            elif req.get("cmd") == "mark":
                suite = req.get("suite","unknown")
                marker = f"{OUTDIR}/marks/{int(time.time())}_{suite}.json"
                with open(marker,"w") as f:
                    json.dump({"ts":ts(),"suite":suite}, f)
                resp = {"ok": True, "marked": suite}
            elif req.get("cmd") == "stop":
                stop_evt.set()
                resp = {"ok": True, "stopping": True}
            else:
                resp = {"ok": False, "error": "unknown_cmd"}
            conn.sendall((json.dumps(resp)+"\n").encode())
    srv.close()

def main():
    stop_evt = threading.Event()
    # start proxy once, GCS will rekey from there
    proxy = start_drone_proxy(INITIAL_SUITE)

    t_echo = threading.Thread(target=udp_echo, args=(stop_evt,), daemon=True)
    t_ctl  = threading.Thread(target=control_server, args=(stop_evt,), daemon=True)
    t_echo.start(); t_ctl.start()

    try:
        while not stop_evt.is_set():
            time.sleep(0.5)
    except KeyboardInterrupt:
        pass
    stop_evt.set()
    try:
        proxy.send_signal(signal.SIGTERM)
    except Exception:
        pass

if __name__ == "__main__":
    main()

============================================================

FILE 6/47: auto\gcs_scheduler.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler.py
Size: 14,222 bytes
Modified: 2025-09-29 02:59:55
------------------------------------------------------------
#!/usr/bin/env python3
"""GCS scheduler that drives rekeys and traffic using central configuration."""

from __future__ import annotations

import argparse
import csv
import json
import os
import shutil
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Iterable, List, Optional

from core.config import CONFIG
from core import suites as suites_mod


DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("GCS_PLAINTEXT_TX", 47001))
APP_RECV_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("GCS_PLAINTEXT_RX", 47002))

OUTDIR = Path("logs/auto")
SECRETS_DIR = Path("secrets/matrix")
PROXY_STATUS_PATH = OUTDIR / "gcs_proxy_status.json"
PROXY_SUMMARY_PATH = OUTDIR / "gcs_proxy_summary.json"
SUMMARY_CSV = OUTDIR / "summary.csv"
EVENTS_FILENAME = "gcs_events.jsonl"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_outdir(suite: str) -> Path:
    return mkdirp(OUTDIR / suite)


def resolve_suites(requested: Optional[Iterable[str]]) -> List[str]:
    available = suites_mod.list_suites()
    if not available:
        raise RuntimeError("No suites registered in core.suites; cannot proceed")

    if not requested:
        return sorted(available.keys())

    resolved = []
    seen = set()
    for name in requested:
        info = suites_mod.get_suite(name)
        suite_id = info["suite_id"]
        if suite_id not in available:
            raise RuntimeError(f"Suite {name} not present in core registry")
        if suite_id not in seen:
            resolved.append(suite_id)
            seen.add(suite_id)
    return resolved


def preferred_initial_suite(candidates: List[str]) -> Optional[str]:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if not configured:
        return None
    try:
        suite_id = suites_mod.get_suite(configured)["suite_id"]
    except NotImplementedError:
        return None
    return suite_id if suite_id in candidates else None


def ctl_send(obj: dict, timeout: float = 2.0, retries: int = 4, backoff: float = 0.5) -> dict:
    last_exc: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((DRONE_HOST, CONTROL_PORT), timeout=timeout) as sock:
                sock.sendall((json.dumps(obj) + "\n").encode())
                sock.shutdown(socket.SHUT_WR)
                line = sock.makefile().readline()
                return json.loads(line.strip()) if line else {}
        except Exception as exc:
            last_exc = exc
            if attempt < retries:
                time.sleep(backoff * attempt)
                continue
            raise
    if last_exc:
        raise last_exc
    return {}


class UdpTraffic:
    def __init__(
        self,
        send_host: str,
        send_port: int,
        recv_host: str,
        recv_port: int,
        events_path: Path,
        rate_pps: int,
        max_packets: Optional[int] = None,
    ) -> None:
        self.send_addr = (send_host, send_port)
        self.recv_addr = (recv_host, recv_port)
        self.rate_pps = max(rate_pps, 1)
        self.max_packets = max_packets if max_packets and max_packets > 0 else None
        self.stop = threading.Event()
        self.sent = 0
        self.rcvd = 0
        mkdirp(events_path.parent)
        self.events = open(events_path, "w", encoding="utf-8")
        self.tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx.bind(self.recv_addr)
        self.rx.settimeout(0.2)

    def start(self) -> None:
        self.tx_thread = threading.Thread(target=self._sender, daemon=True)
        self.rx_thread = threading.Thread(target=self._receiver, daemon=True)
        self.tx_thread.start()
        self.rx_thread.start()

    def _sender(self) -> None:
        interval = 1.0 / self.rate_pps
        seq = 0
        while not self.stop.is_set():
            payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
            try:
                self.tx.sendto(payload, self.send_addr)
                self.events.write(json.dumps({"event": "send", "seq": seq, "t_send_ns": time.time_ns()}) + "\n")
                self.events.flush()
                self.sent += 1
            except Exception as exc:
                self.events.write(json.dumps({"event": "send_error", "err": str(exc), "ts": ts()}) + "\n")
                self.events.flush()
            if self.max_packets is not None and self.sent >= self.max_packets:
                self.stop.set()
            seq += 1
            time.sleep(interval)

    def _receiver(self) -> None:
        while not self.stop.is_set():
            try:
                data, _ = self.rx.recvfrom(65535)
            except socket.timeout:
                continue
            except Exception as exc:
                self.events.write(json.dumps({"event": "recv_error", "err": str(exc), "ts": ts()}) + "\n")
                self.events.flush()
                continue
            now = time.time_ns()
            seq = int.from_bytes(data[:4], "big") if len(data) >= 4 else -1
            self.events.write(json.dumps({"event": "recv", "seq": seq, "t_recv_ns": now}) + "\n")
            self.events.flush()
            self.rcvd += 1

    def stop_and_close(self) -> None:
        self.stop.set()
        for thread in (self.tx_thread, self.rx_thread):
            if thread.is_alive():
                thread.join(timeout=1.0)
        self.events.close()
        self.tx.close()
        self.rx.close()


def wait_handshake(timeout: float = 20.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        if PROXY_STATUS_PATH.exists():
            try:
                js = json.load(open(PROXY_STATUS_PATH, encoding="utf-8"))
                if js.get("state") in {"running", "completed", "ready"}:
                    return True
            except Exception:
                pass
        time.sleep(0.3)
    return False


def snapshot_proxy_artifacts(suite: str) -> None:
    target_dir = suite_outdir(suite)
    if PROXY_STATUS_PATH.exists():
        shutil.copy(PROXY_STATUS_PATH, target_dir / "gcs_status.json")
    if PROXY_SUMMARY_PATH.exists():
        shutil.copy(PROXY_SUMMARY_PATH, target_dir / "gcs_summary.json")


def start_gcs_proxy(initial_suite: str) -> tuple[subprocess.Popen, Path]:
    key_path = SECRETS_DIR / initial_suite / "gcs_signing.key"
    if not key_path.exists():
        raise FileNotFoundError(f"Missing GCS signing key for suite {initial_suite}: {key_path}")

    mkdirp(OUTDIR)
    log_path = OUTDIR / f"gcs_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8", errors="replace")

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    proc = subprocess.Popen(
        [
            sys.executable,
            "-m",
            "core.run_proxy",
            "gcs",
            "--suite",
            initial_suite,
            "--gcs-secret-file",
            str(key_path),
            "--control-manual",
            "--status-file",
            str(PROXY_STATUS_PATH),
            "--json-out",
            str(PROXY_SUMMARY_PATH),
        ],
        stdin=subprocess.PIPE,
        stdout=log_handle,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    return proc, log_handle


def read_proxy_summary() -> dict:
    if not PROXY_SUMMARY_PATH.exists():
        return {}
    try:
        return json.load(open(PROXY_SUMMARY_PATH, encoding="utf-8"))
    except Exception:
        return {}


def run_suite(
    gcs: subprocess.Popen,
    suite: str,
    is_first: bool,
    duration_s: float,
    rate_pps: int,
    packets_per_suite: Optional[int],
    delay_between_suites: float,
    pass_index: int,
) -> dict:
    if gcs.poll() is not None:
        raise RuntimeError("GCS proxy is not running; cannot continue")

    if is_first:
        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception as exc:
            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)
    else:
        assert gcs.stdin is not None
        print(f"[{ts()}] rekey -> {suite}")
        gcs.stdin.write(suite + "\n")
        gcs.stdin.flush()
        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception as exc:
            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)

    events_path = suite_outdir(suite) / EVENTS_FILENAME
    traffic = UdpTraffic(
        APP_SEND_HOST,
        APP_SEND_PORT,
        APP_RECV_HOST,
        APP_RECV_PORT,
        events_path,
        rate_pps,
        packets_per_suite,
    )
    start_ns = time.time_ns()
    traffic.start()

    timeout = duration_s if duration_s > 0 else None
    if timeout is None:
        traffic.stop.wait()
    else:
        traffic.stop.wait(timeout=timeout)

    traffic.stop_and_close()
    end_ns = time.time_ns()

    snapshot_proxy_artifacts(suite)
    proxy_stats = read_proxy_summary()

    row = {
        "pass": pass_index,
        "suite": suite,
        "duration_s": round((end_ns - start_ns) / 1e9, 3),
        "sent": traffic.sent,
        "rcvd": traffic.rcvd,
        "enc_out": proxy_stats.get("enc_out", 0),
        "enc_in": proxy_stats.get("enc_in", 0),
        "drops": proxy_stats.get("drops", 0),
        "rekeys_ok": proxy_stats.get("rekeys_ok", 0),
        "rekeys_fail": proxy_stats.get("rekeys_fail", 0),
        "start_ns": start_ns,
        "end_ns": end_ns,
    }

    print(
        f"[{ts()}] {suite}: sent={traffic.sent} rcvd={traffic.rcvd} "
        f"enc_out={row['enc_out']} enc_in={row['enc_in']}"
    )

    if delay_between_suites > 0:
        time.sleep(delay_between_suites)

    return row


def write_summary(rows: List[dict]) -> None:
    if not rows:
        return
    mkdirp(OUTDIR)
    with open(SUMMARY_CSV, "w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)
    print(f"[{ts()}] wrote {SUMMARY_CSV}")


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)

    parser = argparse.ArgumentParser(description="GCS automation scheduler (CONFIG-driven)")
    parser.add_argument("--duration", type=float, default=25.0, help="Seconds per suite (0 = until packets are sent)")
    parser.add_argument("--rate", type=int, default=100, help="Packet rate in packets/sec")
    parser.add_argument("--packets-per-suite", type=int, default=0, help="Optional cap on packets per suite")
    parser.add_argument("--passes", type=int, default=1, help="Number of full sweeps across suites")
    parser.add_argument("--delay-between-suites", type=float, default=0.0, help="Seconds to wait between suites")
    parser.add_argument("--suites", nargs="*", help="Optional subset of suites to exercise")
    args = parser.parse_args()

    if args.duration <= 0 and args.packets_per_suite <= 0:
        raise ValueError("Provide --duration > 0 or --packets-per-suite > 0 so runs terminate deterministically")
    if args.rate <= 0:
        raise ValueError("--rate must be a positive integer")
    if args.passes <= 0:
        raise ValueError("--passes must be >= 1")

    suites = resolve_suites(args.suites)
    if not suites:
        raise RuntimeError("No suites selected for execution")

    initial_suite = preferred_initial_suite(suites)
    if initial_suite and suites[0] != initial_suite:
        suites = [initial_suite] + [s for s in suites if s != initial_suite]
        print(f"[{ts()}] reordered suites to start with {initial_suite} (from CONFIG)")

    try:
        ctl_send({"cmd": "ping"})
        print(f"[{ts()}] follower reachable at {DRONE_HOST}:{CONTROL_PORT}")
    except Exception as exc:
        print(f"[WARN] follower ping failed: {exc}", file=sys.stderr)

    gcs_proc, log_handle = start_gcs_proxy(suites[0])

    try:
        ready = wait_handshake(timeout=20.0)
        print(f"[{ts()}] initial handshake ready? {ready}")

        summary_rows: List[dict] = []
        for pass_index in range(args.passes):
            for idx, suite in enumerate(suites):
                row = run_suite(
                    gcs_proc,
                    suite,
                    is_first=(pass_index == 0 and idx == 0),
                    duration_s=args.duration,
                    rate_pps=args.rate,
                    packets_per_suite=(args.packets_per_suite or None),
                    delay_between_suites=args.delay_between_suites,
                    pass_index=pass_index,
                )
                summary_rows.append(row)

        write_summary(summary_rows)

    finally:
        try:
            ctl_send({"cmd": "stop"})
        except Exception:
            pass

        if gcs_proc.stdin:
            try:
                gcs_proc.stdin.write("quit\n")
                gcs_proc.stdin.flush()
            except Exception:
                pass
        try:
            gcs_proc.wait(timeout=5)
        except Exception:
            gcs_proc.kill()

        try:
            log_handle.close()
        except Exception:
            pass


if __name__ == "__main__":
    main()

============================================================

FILE 7/47: auto\gcs_scheduler_quickpass.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler_quickpass.py
Size: 7,891 bytes
Modified: 2025-09-29 01:45:05
------------------------------------------------------------
#!/usr/bin/env python3
"""
Quick-pass scheduler: send-one?wait-echo?next suite.

Minimal, self-contained scheduler intended to run on the GCS host.
It assumes a running drone follower on the Pi exposing a tiny JSON control API
and a running GCS proxy launched with "--control-manual" so rekeys can be
performed by writing suite IDs to the proxy's stdin.

Outputs:
- logs/auto/quickpass_events.jsonl
- logs/auto/quickpass_summary.csv

Usage (example):
  python -m tools.auto.gcs_scheduler_quickpass \
    --gcs 192.168.0.101 --drone 192.168.0.102 \
    --control-port 48080 --app-send-port 47001 --app-recv-port 47002 \
    --passes 1
"""
import argparse
import csv
import json
import os
import pathlib
import socket
import subprocess
import sys
import time

SUITES = [
    "cs-mlkem512-aesgcm-mldsa44","cs-mlkem512-aesgcm-mldsa65","cs-mlkem512-aesgcm-mldsa87",
    "cs-mlkem512-aesgcm-falcon512","cs-mlkem512-aesgcm-falcon1024",
    "cs-mlkem512-aesgcm-sphincs128fsha2","cs-mlkem512-aesgcm-sphincs256fsha2",
    "cs-mlkem768-aesgcm-mldsa44","cs-mlkem768-aesgcm-mldsa65","cs-mlkem768-aesgcm-mldsa87",
    "cs-mlkem768-aesgcm-falcon512","cs-mlkem768-aesgcm-falcon1024",
    "cs-mlkem768-aesgcm-sphincs128fsha2","cs-mlkem768-aesgcm-sphincs256fsha2",
    "cs-mlkem1024-aesgcm-mldsa44","cs-mlkem1024-aesgcm-mldsa65","cs-mlkem1024-aesgcm-mldsa87",
    "cs-mlkem1024-aesgcm-falcon512","cs-mlkem1024-aesgcm-falcon1024",
    "cs-mlkem1024-aesgcm-sphincs128fsha2","cs-mlkem1024-aesgcm-sphincs256fsha2"
]


def ts():
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(p):
    pathlib.Path(p).mkdir(parents=True, exist_ok=True)


# simple control client for drone follower
def ctl(host, port, obj, timeout=3.0):
    with socket.create_connection((host, port), timeout=timeout) as s:
        s.sendall((json.dumps(obj) + "\n").encode())
        s.shutdown(socket.SHUT_WR)
        line = s.makefile().readline()
        return json.loads(line.strip()) if line else {"ok": False, "error": "no reply"}


# send a single UDP packet and wait for an echo
def send_and_wait_echo(send_port: int, recv_port: int, payload: bytes, timeout_s: float):
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx.bind(("0.0.0.0", recv_port))
        rx.settimeout(min(0.2, timeout_s))
        t0 = time.time_ns()
        seq = int.from_bytes(payload[:4], "big") if len(payload) >= 4 else 0
        tx.sendto(payload, ("127.0.0.1", send_port))
        deadline = time.time() + timeout_s
        while time.time() < deadline:
            try:
                data, _ = rx.recvfrom(65535)
                if len(data) >= 4 and int.from_bytes(data[:4], "big") == seq:
                    t1 = time.time_ns()
                    return True, t0, t1, len(data)
            except socket.timeout:
                pass
        return False, t0, None, 0
    finally:
        try:
            tx.close()
        except Exception:
            pass
        try:
            rx.close()
        except Exception:
            pass


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--gcs", required=True)
    ap.add_argument("--drone", required=True)
    ap.add_argument("--control-port", type=int, default=48080)
    ap.add_argument("--app-send-port", type=int, default=47001)
    ap.add_argument("--app-recv-port", type=int, default=47002)
    ap.add_argument("--verify-timeout", type=float, default=5.0)
    ap.add_argument("--passes", type=int, default=1)
    ap.add_argument("--outdir", default="logs/auto")
    ap.add_argument("--secrets-dir", default="secrets/matrix")
    ap.add_argument("--initial-suite", default=None)
    ap.add_argument("--suites", nargs="*", default=SUITES)
    args = ap.parse_args()

    os.environ["DRONE_HOST"] = args.drone
    os.environ["GCS_HOST"] = args.gcs
    os.environ["ENABLE_PACKET_TYPE"] = "1"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1"

    mkdirp(args.outdir)
    evlog = open(f"{args.outdir}/quickpass_events.jsonl", "a", encoding="utf-8")

    def log_event(**row):
        row.setdefault("ts", ts())
        evlog.write(json.dumps(row) + "\n")
        evlog.flush()

    suites = list(args.suites)
    if args.initial_suite and args.initial_suite in suites:
        i = suites.index(args.initial_suite)
        suites = suites[i:] + suites[:i]

    first = suites[0]
    keyfile = f"{args.secrets_dir}/{first}/gcs_signing.key"
    mkdirp(f"{args.outdir}/{first}")
    status_file = f"{args.outdir}/{first}/gcs_status.json"
    summary_file = f"{args.outdir}/{first}/gcs_summary.json"
    gcs_log = open(f"{args.outdir}/gcs_{time.strftime('%Y%m%d-%H%M%S')}.log", "w", encoding="utf-8", errors="replace")

    gcs = subprocess.Popen([
        sys.executable, "-m", "core.run_proxy", "gcs",
        "--suite", first, "--gcs-secret-file", keyfile,
        "--control-manual",
        "--status-file", status_file, "--json-out", summary_file
    ], stdin=subprocess.PIPE, stdout=gcs_log, stderr=subprocess.STDOUT, text=True, bufsize=1)

    # initial ping/mark
    try:
        ctl(args.drone, args.control_port, {"cmd": "ping"})
        ctl(args.drone, args.control_port, {"cmd": "mark", "suite": first})
    except Exception as e:
        log_event(event="control_warn", msg=str(e))

    csv_path = f"{args.outdir}/quickpass_summary.csv"
    have_header = os.path.exists(csv_path)
    csvf = open(csv_path, "a", newline="", encoding="utf-8")
    w = csv.DictWriter(csvf, fieldnames=["pass_idx", "suite", "ok", "attempt_ns", "payload_bytes", "note"])
    if not have_header:
        w.writeheader(); csvf.flush()

    def rekey(to_suite: str):
        try:
            gcs.stdin.write(to_suite + "\n"); gcs.stdin.flush()
        except Exception as e:
            log_event(event="gcs_write_fail", msg=str(e))
        try:
            ctl(args.drone, args.control_port, {"cmd": "mark", "suite": to_suite})
        except Exception as e:
            log_event(event="control_warn", msg=f"mark failed: {e}")

    try:
        for p in range(args.passes):
            for idx, suite in enumerate(suites):
                if p == 0 and idx == 0:
                    current = first
                else:
                    current = suite
                    log_event(event="rekey", to=current, pass_idx=p)
                    rekey(current)

                seq = int(time.time_ns() & 0xFFFFFFFF)
                payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
                ok, t0_ns, t1_ns, nbytes = send_and_wait_echo(args.app_send_port, args.app_recv_port, payload, args.verify_timeout)

                if ok:
                    attempt_ns = t1_ns - t0_ns
                    w.writerow({"pass_idx": p, "suite": current, "ok": True, "attempt_ns": attempt_ns, "payload_bytes": nbytes, "note": "echo"})
                    csvf.flush()
                    log_event(event="echo_ok", suite=current, pass_idx=p, rtt_ns=attempt_ns)
                else:
                    w.writerow({"pass_idx": p, "suite": current, "ok": False, "attempt_ns": "", "payload_bytes": 0, "note": "timeout"})
                    csvf.flush()
                    log_event(event="echo_timeout", suite=current, pass_idx=p)
    finally:
        try:
            ctl(args.drone, args.control_port, {"cmd": "stop"})
        except Exception:
            pass
        try:
            gcs.stdin.write("quit\n"); gcs.stdin.flush()
        except Exception:
            pass
        try:
            gcs.wait(timeout=3)
        except Exception:
            gcs.kill()
        evlog.close(); csvf.close(); gcs_log.close()


if __name__ == "__main__":
    main()

============================================================

FILE 8/47: auto\gcs_scheduler_simple.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler_simple.py
Size: 9,391 bytes
Modified: 2025-09-29 02:27:51
------------------------------------------------------------
#!/usr/bin/env python3
"""
GCS scheduler (interactive by default; --auto runs whole list):
- Starts the GCS proxy in --control-manual with the first suite.
- For each chosen suite: rekey -> send UDP -> wait for echo(s) -> proceed.
- All networking parameters are sourced from core.config.CONFIG.
"""

import os, sys, time, json, csv, pathlib, socket, subprocess

from core.config import CONFIG
from core import suites as suite_registry

SECRETS_DIR = "secrets/matrix"
OUTDIR = "logs/auto"

CONTROL_HOST = CONFIG["DRONE_HOST"]
CONTROL_PORT = CONFIG.get("DRONE_CONTROL_PORT", 48080)

APP_BIND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = CONFIG.get("GCS_PLAINTEXT_TX", 47001)
APP_RECV_PORT = CONFIG.get("GCS_PLAINTEXT_RX", 47002)

VERIFY_TIMEOUT_S = float(CONFIG.get("SIMPLE_VERIFY_TIMEOUT_S", 5.0))
PACKETS_PER_SUITE = max(1, int(CONFIG.get("SIMPLE_PACKETS_PER_SUITE", 1)))
PACKET_DELAY_S = max(0.0, float(CONFIG.get("SIMPLE_PACKET_DELAY_S", 0.0)))
SUITE_DWELL_S = max(0.0, float(CONFIG.get("SIMPLE_SUITE_DWELL_S", 0.0)))
DEFAULT_PASSES = max(1, int(CONFIG.get("SIMPLE_AUTO_PASSES", 1)))

SUITES = sorted(suite_registry.SUITES.keys())
FIRST_SUITE = suite_registry.get_suite(CONFIG.get("SIMPLE_INITIAL_SUITE", SUITES[0]))["suite_id"]

def ts(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
def mkdirp(p): pathlib.Path(p).mkdir(parents=True, exist_ok=True)

def ctl(obj, timeout=3.0):
    with socket.create_connection((CONTROL_HOST, CONTROL_PORT), timeout=timeout) as s:
        s.sendall((json.dumps(obj)+"\n").encode()); s.shutdown(socket.SHUT_WR)
        line = s.makefile().readline()
        return json.loads(line.strip()) if line else {"ok": False, "error": "no reply"}

def send_and_wait_echo(payload: bytes, timeout_s: float):
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind((APP_BIND_HOST, APP_RECV_PORT))
    rx.settimeout(min(0.2, timeout_s))
    t0 = time.time_ns()
    tx.sendto(payload, (APP_SEND_HOST, APP_SEND_PORT))
    deadline = time.time() + timeout_s
    while time.time() < deadline:
        try:
            data, _ = rx.recvfrom(65535)
            t1 = time.time_ns()
            tx.close(); rx.close()
            return True, t0, t1, len(data)
        except socket.timeout:
            pass
    tx.close(); rx.close()
    return False, t0, None, 0

def start_gcs_proxy(first_suite: str):
    os.environ["DRONE_HOST"] = CONFIG["DRONE_HOST"]
    os.environ["GCS_HOST"] = CONFIG["GCS_HOST"]
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    keyfile = f"{SECRETS_DIR}/{first_suite}/gcs_signing.key"
    status = f"{OUTDIR}/{first_suite}/gcs_status.json"
    summary = f"{OUTDIR}/{first_suite}/gcs_summary.json"
    mkdirp(f"{OUTDIR}/{first_suite}")
    log = open(f"{OUTDIR}/gcs_{time.strftime('%Y%m%d-%H%M%S')}.log","w", encoding="utf-8", errors="replace")
    print(f"[scheduler] launching GCS proxy on suite {first_suite}")
    p = subprocess.Popen([
        sys.executable,"-m","core.run_proxy","gcs",
        "--suite", first_suite, "--gcs-secret-file", keyfile,
        "--control-manual","--status-file", status, "--json-out", summary
    ], stdin=subprocess.PIPE, stdout=log, stderr=subprocess.STDOUT, text=True, bufsize=1)
    return p

def rekey(gcs_proc, suite: str):
    try:
        gcs_proc.stdin.write(suite + "\n"); gcs_proc.stdin.flush()
    except Exception as e:
        print(f"[scheduler] ERROR writing to proxy stdin: {e}", flush=True)
    try:
        ctl({"cmd":"mark","suite": suite})
    except Exception:
        pass

def run_one(gcs_proc, suite: str, writer, csv_file):
    print(f"[scheduler] ? {suite}")
    # If the proxy died, restart it
    try:
        if gcs_proc is None or (hasattr(gcs_proc, 'poll') and gcs_proc.poll() is not None):
            print('[scheduler] GCS proxy not running; restarting...')
            try:
                gcs_proc = start_gcs_proxy(suite)
                # give proxy a short moment to warm up
                time.sleep(0.5)
            except Exception as e:
                print(f"[scheduler] failed to restart proxy: {e}")
                return gcs_proc

    except Exception:
        # Defensive: if any introspection fails, proceed to attempt rekey and catch errors
        pass

    rekey(gcs_proc, suite)
    attempts = []
    for attempt_idx in range(PACKETS_PER_SUITE):
        seq = (attempt_idx + 1) & 0xFFFFFFFF
        payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
        ok, t0, t1, n = send_and_wait_echo(payload, VERIFY_TIMEOUT_S)
        attempts.append((ok, t0, t1, n))
        if ok:
            print(f"[scheduler]   packet {attempt_idx+1}/{PACKETS_PER_SUITE} OK")
        else:
            print(f"[scheduler]   packet {attempt_idx+1}/{PACKETS_PER_SUITE} TIMEOUT")
        if PACKET_DELAY_S > 0 and attempt_idx < PACKETS_PER_SUITE - 1:
            time.sleep(PACKET_DELAY_S)

    successes = sum(1 for ok, *_ in attempts if ok)
    best_rtt = min((t1 - t0) for ok, t0, t1, _ in attempts if ok) if successes else ""
    last_bytes = next((n for ok, _, _, n in reversed(attempts) if ok), 0)
    note = "" if successes == PACKETS_PER_SUITE else "timeout"

    writer.writerow({
        "ts": ts(),
        "suite": suite,
        "packets": PACKETS_PER_SUITE,
        "success_packets": successes,
        "ok": successes == PACKETS_PER_SUITE,
        "best_rtt_ns": best_rtt,
        "bytes": last_bytes,
        "note": note,
    })
    csv_file.flush()

    if SUITE_DWELL_S > 0:
        time.sleep(SUITE_DWELL_S)
    return gcs_proc

def interactive_loop(gcs_proc):
    print("\nMANUAL MODE. Commands:")
    print("  list                - show suites")
    print("  next                - advance to the next suite in the list")
    print("  all                 - run full quick-pass across all suites once")
    print("  <suite-id>          - switch to a specific suite and test once")
    print("  quit                - exit\n")

    idx = 0
    csvp = f"{OUTDIR}/quickpass_summary.csv"
    have = os.path.exists(csvp)
    with open(csvp, "a", newline="") as f:
        w = csv.DictWriter(
            f,
            fieldnames=[
                "ts",
                "suite",
                "packets",
                "success_packets",
                "ok",
                "best_rtt_ns",
                "bytes",
                "note",
            ],
        )
        if not have: w.writeheader()
        while True:
            cmd = input("rekey> ").strip()
            if cmd == "quit": break
            if cmd == "list":
                for s in SUITES: print("  ", s)
                continue
            if cmd == "next":
                suite = SUITES[idx % len(SUITES)]; idx += 1
                gcs_proc = run_one(gcs_proc, suite, w, f)
                continue
            if cmd == "all":
                for suite in SUITES:
                    gcs_proc = run_one(gcs_proc, suite, w, f)
                print("[scheduler] full sweep done")
                continue
            # treat as suite-id
            try:
                target_suite = suite_registry.get_suite(cmd)["suite_id"]
            except NotImplementedError:
                print("Unknown command or suite. Type 'list'.")
                continue
            gcs_proc = run_one(gcs_proc, target_suite, w, f)
    return gcs_proc

def auto_sweep(gcs_proc, passes=DEFAULT_PASSES):
    csvp = f"{OUTDIR}/quickpass_summary.csv"
    have = os.path.exists(csvp)
    with open(csvp, "a", newline="") as f:
        w = csv.DictWriter(
            f,
            fieldnames=[
                "ts",
                "suite",
                "packets",
                "success_packets",
                "ok",
                "best_rtt_ns",
                "bytes",
                "note",
            ],
        )
        if not have: w.writeheader()
        for _ in range(passes):
            for suite in SUITES:
                gcs_proc = run_one(gcs_proc, suite, w, f)
    print("[scheduler] auto sweep complete")
    return gcs_proc

def main():
    pathlib.Path(OUTDIR).mkdir(parents=True, exist_ok=True)
    try:
        ctl({"cmd":"ping"})
        print(f"[scheduler] follower reachable at {CONTROL_HOST}:{CONTROL_PORT}")
    except Exception as e:
        print(f"[scheduler] WARNING follower not reachable: {e}")

    gcs = start_gcs_proxy(FIRST_SUITE)
    try:
        mode = "manual"
        if len(sys.argv) > 1 and sys.argv[1] == "--auto":
            mode = "auto"
        if mode == "manual":
            gcs = interactive_loop(gcs)
        else:
            gcs = auto_sweep(gcs, passes=DEFAULT_PASSES)
    finally:
        try: gcs.stdin.write("quit\n"); gcs.stdin.flush()
        except Exception: pass
        try: gcs.wait(timeout=2)
        except Exception: gcs.kill()
        try: ctl({"cmd":"stop"})
        except Exception: pass

if __name__ == "__main__":
    main()

============================================================

FILE 9/47: auto_test_drone.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto_test_drone.py
Size: 3,561 bytes
Modified: 2025-09-28 19:12:42
------------------------------------------------------------
#!/usr/bin/env python3
"""Drone-side runner for automated matrix tests.

Usage: python tools/auto_test_drone.py --gcs-host 100.101.93.23 --gcs-port 47010

Behavior:
- Connect to GCS control TCP port, wait for JSON command.
- Command will include suite, count, udp_dest [host,port].
- Send 'count' UDP messages to udp_dest; for each message include a sequence number and timestamp.
- Listen for replies on the same UDP socket and compute RTT per message.
- Send results JSON back to GCS over the TCP control connection.
"""
from __future__ import annotations

import argparse
import json
import socket
import struct
import time
import sys
from pathlib import Path
from typing import Tuple

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
_REPO = _HERE.parent.parent
if str(_REPO) not in sys.path:
    sys.path.insert(0, str(_REPO))

from tools.socket_utils import open_udp_socket, close_socket


def now_ms() -> float:
    return time.time() * 1000.0


def run_test(control_sock: socket.socket, cmd: dict):
    udp_host, udp_port = cmd.get('udp_dest', ['127.0.0.1', 47001])
    count = int(cmd.get('count', 8))
    suite = cmd.get('suite', 'unknown')

    print(f'Running test: suite={suite} count={count} -> {udp_host}:{udp_port}')

    # Use an ephemeral bound UDP socket so replies are received reliably and
    # the socket is registered with our cleanup helper.
    sock = open_udp_socket('0.0.0.0', 0, timeout=2.0)

    results = []
    for i in range(count):
        payload = json.dumps({'seq': i, 'ts': now_ms(), 'suite': suite}).encode('utf-8')
        send_t = now_ms()
        try:
            sock.sendto(payload, (udp_host, int(udp_port)))
        except Exception as e:
            results.append({'seq': i, 'error': f'send-fail: {e}'})
            continue

        try:
            data, addr = sock.recvfrom(8192)
            recv_t = now_ms()
            # Expect the peer to echo back or the proxy to return something
            results.append({'seq': i, 'rtt_ms': (recv_t - send_t), 'reply_len': len(data)})
        except socket.timeout:
            results.append({'seq': i, 'error': 'timeout'})

        # small pacing
        time.sleep(0.05)

    try:
        # send results back over control socket
        out = {'suite': suite, 'count': count, 'results': results}
        control_sock.sendall(json.dumps(out).encode('utf-8') + b'\n')
        print('Sent results back to GCS control')
    finally:
        try:
            close_socket(sock)
        except Exception:
            pass


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--gcs-host', required=True)
    p.add_argument('--gcs-port', type=int, default=47010)
    p.add_argument('--local-bind', default='0.0.0.0')
    args = p.parse_args()

    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        print(f'Connecting to GCS control {args.gcs_host}:{args.gcs_port}...')
        s.connect((args.gcs_host, args.gcs_port))
        # read a line
        data = b''
        while True:
            chunk = s.recv(4096)
            if not chunk:
                print('Control connection closed')
                return
            data += chunk
            if b'\n' in data:
                break
        line, _ = data.split(b'\n', 1)
        cmd = json.loads(line.decode('utf-8'))
        print('Received command:', cmd)
        run_test(s, cmd)


if __name__ == '__main__':
    main()

============================================================

FILE 10/47: auto_test_gcs.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto_test_gcs.py
Size: 2,549 bytes
Modified: 2025-09-28 19:12:42
------------------------------------------------------------
#!/usr/bin/env python3
"""GCS-side controller for automated matrix tests.

Usage: python tools/auto_test_gcs.py --listen-port 47010

Protocol (simple):
- GCS listens on TCP control port.
- Drone connects and awaits a JSON command from GCS: {"suite":"<suite>", "count":N, "udp_dest": [host,port]}
- Drone performs N UDP messages to udp_dest and replies over the TCP control channel with results JSON.
"""
from __future__ import annotations

import argparse
import json
import socket
import time
import sys
from pathlib import Path
from typing import Tuple

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
_REPO = _HERE.parent.parent
if str(_REPO) not in sys.path:
    sys.path.insert(0, str(_REPO))


def handle_client(conn: socket.socket, addr: Tuple[str,int], args):
    print(f'Client connected: {addr}')
    # For demo: pick a suite and count
    cmd = {"suite": args.suite, "count": args.count, "udp_dest": [args.udp_host, args.udp_port]}
    raw = json.dumps(cmd).encode('utf-8') + b'\n'
    conn.sendall(raw)
    print('Sent command:', cmd)

    # Wait for a line-terminated JSON result
    data = b''
    while True:
        chunk = conn.recv(4096)
        if not chunk:
            print('Connection closed by client')
            return
        data += chunk
        if b'\n' in data:
            break
    line, _ = data.split(b'\n', 1)
    try:
        res = json.loads(line.decode('utf-8'))
    except Exception as e:
        print('Failed to parse result JSON:', e)
        return
    print('Result from drone:')
    print(json.dumps(res, indent=2))


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--listen-port', type=int, default=47010)
    p.add_argument('--suite', default='cs-mlkem512-aesgcm-mldsa44')
    p.add_argument('--count', type=int, default=8)
    p.add_argument('--udp-host', default='192.168.0.101', help='UDP destination host (proxy plaintext endpoint)')
    p.add_argument('--udp-port', type=int, default=47001, help='UDP destination port')
    args = p.parse_args()

    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        s.bind(('0.0.0.0', args.listen_port))
        s.listen(1)
        print(f'Listening for drone control on port {args.listen_port}...')
        conn, addr = s.accept()
        with conn:
            handle_client(conn, addr, args)


if __name__ == '__main__':
    main()

============================================================

FILE 11/47: bench_cli.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\bench_cli.py
Size: 841 bytes
Modified: 2025-09-25 00:18:03
------------------------------------------------------------
import os, time, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.aead import Sender, Receiver, AeadIds
from core.suites import header_ids_for_suite
from core.config import CONFIG
def main():
    suite = {"kem_name":"ML-KEM-768","sig_name":"ML-DSA-65","aead":"AES-256-GCM","kdf":"HKDF-SHA256","kem_param":768,"sig_param":65}
    ids = AeadIds(*header_ids_for_suite(suite))
    key = os.urandom(32); sid = os.urandom(8)
    s = Sender(CONFIG["WIRE_VERSION"], ids, sid, 0, key)
    r = Receiver(CONFIG["WIRE_VERSION"], ids, sid, 0, key, CONFIG["REPLAY_WINDOW"])
    t0=time.perf_counter(); n=2000
    for _ in range(n):
        w = s.encrypt(b"x"*64)
        _ = r.decrypt(w)
    dt=time.perf_counter()-t0
    print({"pps": int(n/dt), "lat_us_per_pkt": int(dt/n*1e6)})
if __name__=="__main__": main()

============================================================

FILE 12/47: check_matrix_keys.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_matrix_keys.py
Size: 1,373 bytes
Modified: 2025-09-28 03:39:33
------------------------------------------------------------
#!/usr/bin/env python3
"""Check per-suite signing key/pub presence under secrets/matrix and print JSON.

Usage: python tools/check_matrix_keys.py
Outputs JSON to stdout: { suite: { has_key: bool, has_pub: bool, key_size: int|null, pub_size: int|null, pub_sha256: str|null } }
"""
from __future__ import annotations

import hashlib
import json
import pathlib
import sys

from core.suites import list_suites


def sha256_hex(path: pathlib.Path) -> str:
    h = hashlib.sha256()
    with path.open('rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            h.update(chunk)
    return h.hexdigest()


def main() -> int:
    suites = list_suites()
    root = pathlib.Path('secrets') / 'matrix'
    out = {}
    for suite in suites.keys():
        d = root / suite
        key = d / 'gcs_signing.key'
        pub = d / 'gcs_signing.pub'
        rec = {
            'has_key': key.exists(),
            'has_pub': pub.exists(),
            'key_size': key.stat().st_size if key.exists() else None,
            'pub_size': pub.stat().st_size if pub.exists() else None,
            'pub_sha256': sha256_hex(pub) if pub.exists() else None,
        }
        out[suite] = rec

    json.dump(out, sys.stdout, indent=2, sort_keys=True)
    print()
    return 0


if __name__ == '__main__':
    raise SystemExit(main())

============================================================

FILE 13/47: check_no_hardcoded_ips.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_no_hardcoded_ips.py
Size: 2,448 bytes
Modified: 2025-09-26 14:12:14
------------------------------------------------------------
"""Static check to ensure IPs/ports are sourced from core.config."""
from __future__ import annotations

import re
import sys
from pathlib import Path
from typing import Iterable, List, Tuple

REPO_ROOT = Path(__file__).resolve().parents[1]
TARGET_SUFFIXES = {".py", ".ps1", ".sh"}
ALLOW_DIRS = {".git", "__pycache__", "venv", "env"}
SKIP_PREFIXES = {
    REPO_ROOT / "core" / "config.py",
}
SKIP_DIRS = {REPO_ROOT / "tests" / "fixtures"}

IP_PATTERN = re.compile(r"\b(?:\d{1,3}\.){3}\d{1,3}\b")
PORT_PATTERN = re.compile(r"socket\.(?:bind|connect|sendto)\([^\n\#]*?(\d{4,5})")
ALLOWED_IPS = {"0.0.0.0", "127.0.0.1", "::1"}
ALLOWED_PORTS = {"0", "53"}


def iter_files() -> Iterable[Path]:
    for path in REPO_ROOT.rglob("*"):
        if not path.is_file():
            continue
        if path.suffix not in TARGET_SUFFIXES:
            continue
        if any(part in ALLOW_DIRS for part in path.parts):
            continue
        if any(path.is_relative_to(skip) for skip in SKIP_DIRS):
            continue
        yield path


def find_violations(path: Path) -> Tuple[List[str], List[str]]:
    if path in SKIP_PREFIXES:
        return [], []
    text = path.read_text(encoding="utf-8", errors="ignore")
    ips = []
    for match in IP_PATTERN.finditer(text):
        ip = match.group(0)
        if ip in ALLOWED_IPS:
            continue
        ips.append(f"{path}:{match.start()} -> {ip}")
    ports = []
    for match in PORT_PATTERN.finditer(text):
        port = match.group(1)
        if port in ALLOWED_PORTS:
            continue
        ports.append(f"{path}:{match.start()} -> {port}")
    return ips, ports


def main() -> int:
    ip_violations: List[str] = []
    port_violations: List[str] = []

    for path in iter_files():
        ips, ports = find_violations(path)
        ip_violations.extend(ips)
        port_violations.extend(ports)

    if ip_violations or port_violations:
        if ip_violations:
            print("IP literal violations detected:")
            for item in ip_violations:
                print(f"  {item}")
        if port_violations:
            print("Port literal violations detected:")
            for item in port_violations:
                print(f"  {item}")
        return 1

    print("No hard-coded IPs or forbidden port literals detected.")
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 14/47: check_ports.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_ports.py
Size: 3,618 bytes
Modified: 2025-09-25 15:53:08
------------------------------------------------------------
# tools/check_ports.py
"""
A utility to check if the network ports required by the PQC proxy
are available on localhost. Supports both default and manual_4term port profiles.
"""
import argparse
import os
import socket
import sys

# Add the project root to the Python path to allow importing the 'core' module
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

try:
    from core.config import CONFIG as BASE_CONFIG
except ImportError:
    print("❌ Error: Could not import CONFIG from core/config.py.")
    print("   Please run this script from the project's root directory.")
    sys.exit(1)

# Manual 4-terminal testing port configuration
MANUAL_4TERM_CONFIG = {
    "TCP_HANDSHAKE_PORT": 45800,
    "UDP_DRONE_RX": 45801,
    "UDP_GCS_RX": 45802,
    "DRONE_PLAINTEXT_TX": 45803,
    "DRONE_PLAINTEXT_RX": 45804,
    "GCS_PLAINTEXT_TX": 45805,
    "GCS_PLAINTEXT_RX": 45806,
    "WIRE_VERSION": 1,
}

def check_bind(addr: str, proto: str, port: int) -> bool:
    """Attempts to bind to a port to check its availability. Returns True if available."""
    socket_type = socket.SOCK_STREAM if proto == "TCP" else socket.SOCK_DGRAM
    with socket.socket(socket.AF_INET, socket_type) as s:
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        try:
            s.bind((addr, port))
            return True
        except OSError:
            return False

def main():
    parser = argparse.ArgumentParser(description="Check PQC proxy port availability")
    parser.add_argument("--profile", choices=["default", "manual4term"], default="default",
                        help="Which port profile to check (default: default)")
    parser.add_argument("--include-app-ports", action="store_true",
                        help="Also check the app listener ports (Plaintext RX)")
    args = parser.parse_args()

    # Select configuration based on profile
    config = dict(BASE_CONFIG) if args.profile == "default" else MANUAL_4TERM_CONFIG

    print(f"--- Checking ports on 127.0.0.1 for profile: {args.profile} ---")

    # Define ports to check with their bind addresses
    port_checks = [
        ("TCP", config["TCP_HANDSHAKE_PORT"], "GCS Handshake Listener", "0.0.0.0"),
        ("UDP", config["UDP_DRONE_RX"],       "Drone Encrypted Ingress", "0.0.0.0"),
        ("UDP", config["UDP_GCS_RX"],         "GCS Encrypted Ingress",   "0.0.0.0"),
        ("UDP", config["DRONE_PLAINTEXT_TX"], "Drone Plaintext Ingress", "127.0.0.1"),
        ("UDP", config["GCS_PLAINTEXT_TX"],   "GCS Plaintext Ingress",   "127.0.0.1"),
    ]
    
    if args.include_app_ports:
        port_checks += [
            ("UDP", config["DRONE_PLAINTEXT_RX"], "Drone Plaintext RX (app listener)", "127.0.0.1"),
            ("UDP", config["GCS_PLAINTEXT_RX"],   "GCS Plaintext RX (app listener)",   "127.0.0.1"),
        ]

    all_available = True
    for proto, port, label, addr in port_checks:
        is_available = check_bind(addr, proto, port)
        if is_available:
            status = "✅ Available"
        else:
            status = "❌ IN USE"
            all_available = False
            
        print(f"{proto:4} {port:<5} {label:<40} {addr:<9} : {status}")

    print("-" * 70)
    
    if all_available:
        print("✅ All required ports are available.")
        sys.exit(0)
    else:
        print("❌ One or more required ports are in use. Please close the conflicting application.")
        sys.exit(1)

if __name__ == "__main__":
    main()

============================================================

FILE 15/47: check_suites.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_suites.py
Size: 1,030 bytes
Modified: 2025-09-28 01:02:44
------------------------------------------------------------
from core.suites import list_suites

wanted = [
    "cs-mlkem512-aesgcm-mldsa44",
    "cs-mlkem512-aesgcm-mldsa65",
    "cs-mlkem512-aesgcm-mldsa87",
    "cs-mlkem512-aesgcm-falcon512",
    "cs-mlkem512-aesgcm-falcon1024",
    "cs-mlkem512-aesgcm-sphincs128fsha2",
    "cs-mlkem512-aesgcm-sphincs256fsha2",
    "cs-mlkem768-aesgcm-mldsa44",
    "cs-mlkem768-aesgcm-mldsa65",
    "cs-mlkem768-aesgcm-mldsa87",
    "cs-mlkem768-aesgcm-falcon512",
    "cs-mlkem768-aesgcm-falcon1024",
    "cs-mlkem768-aesgcm-sphincs128fsha2",
    "cs-mlkem768-aesgcm-sphincs256fsha2",
    "cs-mlkem1024-aesgcm-mldsa44",
    "cs-mlkem1024-aesgcm-mldsa65",
    "cs-mlkem1024-aesgcm-mldsa87",
    "cs-mlkem1024-aesgcm-falcon512",
    "cs-mlkem1024-aesgcm-falcon1024",
    "cs-mlkem1024-aesgcm-sphincs128fsha2",
    "cs-mlkem1024-aesgcm-sphincs256fsha2",
]

available = set(list_suites().keys())
missing = [s for s in wanted if s not in available]
print('missing:', missing)
print('total registry suites:', len(available))

============================================================

FILE 16/47: cleanup_bound_ports.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\cleanup_bound_ports.py
Size: 2,136 bytes
Modified: 2025-09-28 19:05:13
------------------------------------------------------------
"""Utility to inspect and optionally free known test ports on Windows.

Usage (Windows):
  python tools/cleanup_bound_ports.py --ports 46000 46011 47001 --kill

This script is intentionally conservative: it will list processes bound to the
given ports and only attempt to terminate them if --kill is provided.
"""
from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path

# Ensure repo root is on sys.path when executed from tools/ directory
_HERE = Path(__file__).resolve()
_REPO = _HERE.parent.parent
if str(_REPO) not in sys.path:
    sys.path.insert(0, str(_REPO))


def _get_pid_for_port(port: int) -> int | None:
    # Uses netstat -ano and finds the PID for lines containing :port
    try:
        out = subprocess.check_output(['netstat', '-ano'], shell=True, text=True)
    except subprocess.CalledProcessError:
        return None

    for line in out.splitlines():
        if f':{port} ' in line or f':{port}\r' in line:
            parts = line.split()
            if parts:
                try:
                    pid = int(parts[-1])
                    return pid
                except Exception:
                    continue
    return None


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--ports', type=int, nargs='+', required=True)
    p.add_argument('--kill', action='store_true', help='Terminate processes owning the ports')
    args = p.parse_args()

    for port in args.ports:
        pid = _get_pid_for_port(port)
        if pid is None:
            print(f'Port {port}: free')
            continue
        print(f'Port {port}: PID {pid}')
        if args.kill:
            try:
                subprocess.check_call(['taskkill', '/PID', str(pid), '/F'], shell=True)
                print(f'  Killed PID {pid}')
            except subprocess.CalledProcessError as e:
                print(f'  Failed to kill PID {pid}: {e}')


if __name__ == '__main__':
    if sys.platform != 'win32':
        print('This cleanup helper is primarily intended for Windows hosts.')
    main()

============================================================

FILE 17/47: copy_pubs_to_pi.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\copy_pubs_to_pi.py
Size: 5,456 bytes
Modified: 2025-09-28 04:11:29
------------------------------------------------------------
#!/usr/bin/env python3
"""Copy gcs_signing.pub files under secrets/matrix to a remote Pi and verify sha256.

Usage:
  python tools/copy_pubs_to_pi.py --pi dev@100.101.93.23

The script will:
 - Find all secrets/matrix/*/gcs_signing.pub
 - For each one, ensure the remote directory exists (ssh user@host mkdir -p ...)
 - Copy the file with scp
 - Run sha256sum on remote and compare to local
 - Print a concise per-suite result
"""
from __future__ import annotations

import argparse
import hashlib
import os
import pathlib
import shlex
import subprocess
import sys


def sha256_hex(path: pathlib.Path) -> str:
    h = hashlib.sha256()
    with path.open('rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            h.update(chunk)
    return h.hexdigest()


def run(cmd: list[str], check: bool = False) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)


def main() -> int:
    p = argparse.ArgumentParser()
    p.add_argument('--pi', required=True, help='Remote user@host for the Pi (e.g. dev@100.101.93.23)')
    p.add_argument('--remote-root', default='/home/dev/research', help='Remote repo root on the Pi')
    p.add_argument('--use-sudo', action='store_true', help='Use sudo on the remote side to create dirs and move files (scp to /tmp then sudo mv)')
    p.add_argument('--dry-run', action='store_true')
    args = p.parse_args()

    root = pathlib.Path('secrets') / 'matrix'
    if not root.exists():
        print('No secrets/matrix directory found in cwd', os.getcwd(), file=sys.stderr)
        return 2

    pubs = list(sorted(root.glob('*/gcs_signing.pub')))
    if not pubs:
        print('No gcs_signing.pub files found under secrets/matrix')
        return 0

    summary = []

    for pub in pubs:
        suite = pub.parent.name
        local_hex = sha256_hex(pub)
        remote_dir = f"{args.remote_root.rstrip('/')}/secrets/matrix/{suite}"
        remote_path = f"{remote_dir}/gcs_signing.pub"

        print(f'[{suite}] local: {pub} ({pub.stat().st_size} bytes) sha256={local_hex}')

        if args.dry_run:
            summary.append((suite, 'dry-run'))
            continue

        # Ensure remote dir exists. If using sudo, create with sudo (may require password).
        if args.use_sudo:
            mkdir_cmd = ['ssh', args.pi, 'sudo', 'mkdir', '-p', shlex.quote(remote_dir)]
        else:
            mkdir_cmd = ['ssh', args.pi, 'mkdir', '-p', shlex.quote(remote_dir)]
        rc = run(mkdir_cmd)
        if rc.returncode != 0:
            print(f'[{suite}] ERROR making remote dir: {rc.stderr.strip()}')
            summary.append((suite, 'mkdir-fail'))
            continue

        # Copy via scp. If use_sudo is set, copy to /tmp then sudo-move into place.
        if args.use_sudo:
            remote_tmp = f"/tmp/{suite}_gcs_signing.pub"
            scp_cmd = ['scp', str(pub), f"{args.pi}:{remote_tmp}"]
            rc = run(scp_cmd)
            if rc.returncode != 0:
                print(f'[{suite}] ERROR scp to /tmp: {rc.stderr.strip()}')
                summary.append((suite, 'scp-fail'))
                continue

            # Move into place with sudo and set ownership to remote user
            # extract username from user@host
            if '@' in args.pi:
                remote_user = args.pi.split('@', 1)[0]
            else:
                remote_user = None

            if remote_user:
                mv_cmd = ['ssh', args.pi, 'sudo', 'mv', shlex.quote(remote_tmp), shlex.quote(remote_path), '&&', 'sudo', 'chown', f"{remote_user}:{remote_user}", shlex.quote(remote_path)]
            else:
                mv_cmd = ['ssh', args.pi, 'sudo', 'mv', shlex.quote(remote_tmp), shlex.quote(remote_path)]

            rc = run(mv_cmd)
            if rc.returncode != 0:
                print(f'[{suite}] ERROR sudo-move: {rc.stderr.strip() or rc.stdout.strip()}')
                summary.append((suite, 'sudo-move-fail'))
                continue
        else:
            scp_cmd = ['scp', str(pub), f"{args.pi}:{remote_path}"]
            rc = run(scp_cmd)
            if rc.returncode != 0:
                print(f'[{suite}] ERROR scp: {rc.stderr.strip()}')
                summary.append((suite, 'scp-fail'))
                continue

        # Compute remote sha256
        sha_cmd = ['ssh', args.pi, 'sha256sum', shlex.quote(remote_path)]
        rc = run(sha_cmd)
        if rc.returncode != 0:
            print(f'[{suite}] ERROR remote sha256: {rc.stderr.strip()}')
            summary.append((suite, 'remote-sha-fail'))
            continue

        remote_out = rc.stdout.strip().split()[0]
        if remote_out == local_hex:
            print(f'[{suite}] OK (sha256 matched)')
            summary.append((suite, 'ok'))
        else:
            print(f'[{suite}] MISMATCH local={local_hex} remote={remote_out}')
            summary.append((suite, 'mismatch'))

    # Print summary
    print('\nSummary:')
    counts = {}
    for _, s in summary:
        counts[s] = counts.get(s, 0) + 1
    for k, v in counts.items():
        print(f'  {k}: {v}')

    # exit 0 if all ok or dry-run, else non-zero
    bad = [s for _, s in summary if s not in ('ok', 'dry-run')]
    return 0 if not bad else 3


if __name__ == '__main__':
    raise SystemExit(main())

============================================================

FILE 18/47: counter_utils.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\counter_utils.py
Size: 6,381 bytes
Modified: 2025-09-26 18:45:57
------------------------------------------------------------
"""Utility helpers for reading proxy and traffic counter artifacts.

These helpers keep the orchestration scripts decoupled from the exact JSON
structure emitted by the proxies and traffic generators.
"""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional


@dataclass(frozen=True)
class ProxyCounters:
    """Parsed counters emitted by ``core.run_proxy``.

    Attributes
    ----------
    role:
        ``"gcs"`` or ``"drone"`` as recorded in the JSON payload.
    suite:
        Canonical suite identifier associated with the run.
    counters:
        Raw counter dictionary from the JSON payload.
    ts_stop_ns:
        Optional timestamp (nanoseconds) indicating when the proxy shut down.
    path:
        Filesystem location from which the payload was loaded.
    """

    role: str
    suite: str
    counters: Dict[str, Any]
    ts_stop_ns: Optional[int] = None
    path: Optional[Path] = None

    @property
    def rekeys_ok(self) -> int:
        """Return the number of successful rekeys recorded by the proxy."""

        return int(self.counters.get("rekeys_ok", 0))

    @property
    def rekeys_fail(self) -> int:
        """Return the number of failed rekeys recorded by the proxy."""

        return int(self.counters.get("rekeys_fail", 0))

    @property
    def last_rekey_suite(self) -> Optional[str]:
        """Return the last suite identifier applied during rekey, if any."""

        last_suite = self.counters.get("last_rekey_suite")
        if isinstance(last_suite, str) and last_suite:
            return last_suite
        return None

    def ensure_rekey(self, expected_suite: str) -> None:
        """Validate that at least one rekey succeeded to ``expected_suite``.

        Raises
        ------
        ValueError
            If no successful rekey occurred or the final suite does not match
            ``expected_suite``.
        """

        if self.rekeys_ok < 1:
            raise ValueError(
                f"Proxy {self.role} reported no successful rekeys (path={self.path})"
            )
        final_suite = self.last_rekey_suite
        if final_suite != expected_suite:
            raise ValueError(
                f"Proxy {self.role} last_rekey_suite={final_suite!r} does not match "
                f"expected {expected_suite!r}"
            )


@dataclass(frozen=True)
class TrafficSummary:
    """Counters emitted by ``tools/traffic_*.py``."""

    role: str
    peer_role: Optional[str]
    sent_total: int
    recv_total: int
    tx_bytes_total: int
    rx_bytes_total: int
    first_send_ts: Optional[str]
    last_send_ts: Optional[str]
    first_recv_ts: Optional[str]
    last_recv_ts: Optional[str]
    out_of_order: int
    unique_senders: int
    path: Optional[Path] = None


def _load_json(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Counter file not found: {path}")
    try:
        import json

        return json.loads(path.read_text(encoding="utf-8"))
    except Exception as exc:  # pragma: no cover - defensive logging only
        raise ValueError(f"Failed to parse JSON from {path}: {exc}") from exc


def load_proxy_counters(path: Path | str) -> ProxyCounters:
    """Load proxy counters JSON from ``path``.

    Parameters
    ----------
    path:
        Filesystem path to the JSON payload created by ``--json-out``.

    Returns
    -------
    ProxyCounters
        Dataclass encapsulating the parsed counters.
    """

    target = Path(path)
    payload = _load_json(target)

    role = payload.get("role")
    suite = payload.get("suite")
    counters = payload.get("counters")

    if not isinstance(role, str) or not isinstance(suite, str) or not isinstance(counters, dict):
        raise ValueError(f"Invalid proxy counters JSON schema in {target}")

    ts_stop_ns = payload.get("ts_stop_ns")
    if ts_stop_ns is not None:
        try:
            ts_stop_ns = int(ts_stop_ns)
        except (TypeError, ValueError):
            ts_stop_ns = None

    return ProxyCounters(
        role=role,
        suite=suite,
        counters=counters,
        ts_stop_ns=ts_stop_ns,
        path=target,
    )


def load_traffic_summary(path: Path | str) -> TrafficSummary:
    """Load traffic generator summary JSON.

    Parameters
    ----------
    path:
        Path to the file created via ``--summary``.
    """

    target = Path(path)
    payload = _load_json(target)

    role = payload.get("role")
    peer_role = payload.get("peer_role")

    required_int_fields = {
        "sent_total": int,
        "recv_total": int,
        "tx_bytes_total": int,
        "rx_bytes_total": int,
        "out_of_order": int,
    }

    counters: Dict[str, int] = {}
    for field, field_type in required_int_fields.items():
        value = payload.get(field)
        if not isinstance(value, field_type):
            raise ValueError(f"Summary field {field} missing or wrong type in {target}")
        counters[field] = int(value)

    unique_senders_raw = payload.get("unique_senders")
    unique_senders = int(unique_senders_raw) if unique_senders_raw is not None else 0

    if not isinstance(role, str):
        raise ValueError(f"Summary missing role field in {target}")

    return TrafficSummary(
        role=role,
        peer_role=peer_role if isinstance(peer_role, str) else None,
        sent_total=counters["sent_total"],
        recv_total=counters["recv_total"],
        tx_bytes_total=counters["tx_bytes_total"],
        rx_bytes_total=counters["rx_bytes_total"],
        first_send_ts=_opt_str(payload.get("first_send_ts")),
        last_send_ts=_opt_str(payload.get("last_send_ts")),
        first_recv_ts=_opt_str(payload.get("first_recv_ts")),
        last_recv_ts=_opt_str(payload.get("last_recv_ts")),
        out_of_order=counters["out_of_order"],
        unique_senders=unique_senders,
        path=target,
    )


def _opt_str(value: Any) -> Optional[str]:
    return value if isinstance(value, str) and value else None


__all__ = [
    "ProxyCounters",
    "TrafficSummary",
    "load_proxy_counters",
    "load_traffic_summary",
]

============================================================

FILE 19/47: diag_udp.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\diag_udp.py
Size: 8,245 bytes
Modified: 2025-09-26 03:26:42
------------------------------------------------------------
import socket
import threading
import time
import argparse
import sys
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
# Prefer the ancestor that contains a 'core' directory
for parent in (_HERE.parent.parent, _HERE.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        # Best-effort; fall through
        pass

from core.config import CONFIG  # Defines hosts and all plaintext/handshake ports

def _sendto(sock: socket.socket, host: str, port: int, text: str) -> None:
    sock.sendto(text.encode('utf-8'), (host, port))


def run_udp_test(role, local_ip, remote_ip, local_rx_port, remote_tx_port):
    """
    Sets up a UDP listener and sender to test direct plaintext communication.
    :param role: "GCS" or "DRONE"
    :param local_ip: The IP address this machine should bind its receiver to (usually "0.0.0.0")
    :param remote_ip: The IP address of the remote machine to send messages to
    :param local_rx_port: The port this machine listens on
    :param remote_tx_port: The port the remote machine is listening on (which we send to)
    """
    print(f"\n--- {role} Plaintext UDP Test ---")
    print(f"  Listening on: {local_ip}:{local_rx_port}")
    print(f"  Sending to:   {remote_ip}:{remote_tx_port}")
    print(f"  Type a message and press Enter to send. Ctrl+C to exit.")

    # Setup receiver socket
    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx_sock.bind((local_ip, local_rx_port))
    rx_sock.setblocking(False) # Non-blocking for concurrent read/write

    # Setup sender socket
    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    # Thread for receiving messages
    def receiver():
        while True:
            try:
                data, addr = rx_sock.recvfrom(65535)
                msg = data.decode('utf-8', errors='ignore').strip()
                print(f"\n[{time.strftime('%H:%M:%S')}] Received from {addr[0]}:{addr[1]}: {msg}")
                print(f"Type message: ", end='', flush=True) # Prompt again after receiving
            except BlockingIOError:
                time.sleep(0.01) # Small delay to prevent busy-waiting
            except Exception as e:
                print(f"Error in receiver: {e}")
                break

    # Start receiver thread
    receiver_thread = threading.Thread(target=receiver, daemon=True)
    receiver_thread.start()

    # Main thread for sending messages
    try:
        while True:
            message = input(f"Type message: ")
            if message.lower() == 'exit':
                break
            tx_sock.sendto(message.encode('utf-8'), (remote_ip, remote_tx_port))
    except KeyboardInterrupt:
        print("\nExiting...")
    finally:
        rx_sock.close()
        tx_sock.close()


def run_auto(role: str, *, verbose: bool = False, delay: float = 0.05) -> int:
    """Automatic cross-direction UDP smoke test using CONFIG hosts/ports.

    Flow:
      - Drone listens on DRONE_PLAINTEXT_RX; GCS listens on GCS_PLAINTEXT_RX.
      - Drone sends trigger "HELLO_FROM_DRONE" to GCS_PLAINTEXT_RX.
      - GCS replies "HELLO_FROM_GCS" to DRONE_PLAINTEXT_RX.
      - Each side then sends 5 numbered messages to the other's RX port.
      - Returns 0 on success; non-zero on failure.
    """

    gcs_host = CONFIG.get("GCS_HOST", "127.0.0.1")
    drone_host = CONFIG.get("DRONE_HOST", "127.0.0.1")
    gcs_rx = int(CONFIG["GCS_PLAINTEXT_RX"])  # local RX for GCS
    drone_rx = int(CONFIG["DRONE_PLAINTEXT_RX"])  # local RX for Drone

    # Sockets
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    if role == "gcs":
        rx.bind(("0.0.0.0", gcs_rx))
        peer_host, peer_port = drone_host, drone_rx
    else:
        rx.bind(("0.0.0.0", drone_rx))
        peer_host, peer_port = gcs_host, gcs_rx

    rx.setblocking(False)

    received = []
    stop = False

    def recv_loop():
        nonlocal stop
        while not stop:
            try:
                data, addr = rx.recvfrom(65535)
            except BlockingIOError:
                time.sleep(0.01)
                continue
            except Exception as e:
                if verbose:
                    print(f"recv error: {e}")
                break
            received.append((time.time(), addr, data))
            if verbose:
                print(f"RX {addr}: {data[:64]!r}")

    t = threading.Thread(target=recv_loop, daemon=True)
    t.start()

    try:
        if role == "drone":
            _sendto(tx, gcs_host, gcs_rx, "HELLO_FROM_DRONE")
        # Wait briefly for trigger; then GCS replies
        deadline = time.time() + 2.0
        replied = False
        while time.time() < deadline:
            if any(b"HELLO_FROM_DRONE" in it[2] for it in received) and role == "gcs":
                _sendto(tx, drone_host, drone_rx, "HELLO_FROM_GCS")
                replied = True
                break
            if any(b"HELLO_FROM_GCS" in it[2] for it in received) and role == "drone":
                replied = True
                break
            time.sleep(0.01)

        if not replied:
            print("Timeout waiting for trigger exchange")
            return 2

        # Now fire 5 numbered messages from both sides
        for i in range(1, 6):
            if role == "gcs":
                _sendto(tx, drone_host, drone_rx, f"GCS_MSG_{i}")
            else:
                _sendto(tx, gcs_host, gcs_rx, f"DRONE_MSG_{i}")
            time.sleep(delay)

        # Allow receive
        time.sleep(0.5)

        # Basic assertions
        rx_texts = [pkt[2].decode("utf-8", errors="ignore") for pkt in received]
        if role == "gcs":
            ok = any("HELLO_FROM_DRONE" in s for s in rx_texts) and sum(1 for s in rx_texts if s.startswith("DRONE_MSG_")) >= 1
        else:
            ok = any("HELLO_FROM_GCS" in s for s in rx_texts) and sum(1 for s in rx_texts if s.startswith("GCS_MSG_")) >= 1
        print(f"Auto test {'PASSED' if ok else 'FAILED'}; received {len(received)} datagrams")
        return 0 if ok else 1
    finally:
        stop = True
        t.join(timeout=0.2)
        try:
            rx.close()
            tx.close()
        except Exception:
            pass

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Test direct UDP plaintext communication between GCS and Drone.")
    parser.add_argument("--role", choices=["gcs", "drone"], required=True, help="Specify if this is the 'gcs' or 'drone' side.")
    parser.add_argument("--local_ip", default="0.0.0.0", help="Local IP to bind the receiver socket to.")
    parser.add_argument("--remote_gcs_ip", help="IP of the GCS machine (required for drone role).")
    parser.add_argument("--remote_drone_ip", help="IP of the Drone machine (required for gcs role).")
    parser.add_argument("--auto", action="store_true", help="Run automatic cross-direction smoke test using CONFIG hosts/ports.")
    args = parser.parse_args()

    if args.auto:
        rc = run_auto(args.role)
        raise SystemExit(rc)

    if args.role == "gcs":
        if not args.remote_drone_ip:
            parser.error("--remote_drone_ip is required for 'gcs' role.")
        run_udp_test(
            role="GCS",
            local_ip=args.local_ip,
            remote_ip=args.remote_drone_ip,
            local_rx_port=CONFIG["GCS_PLAINTEXT_RX"],
            remote_tx_port=CONFIG["DRONE_PLAINTEXT_RX"]
        )
    elif args.role == "drone":
        if not args.remote_gcs_ip:
            parser.error("--remote_gcs_ip is required for 'drone' role.")
        run_udp_test(
            role="DRONE",
            local_ip=args.local_ip,
            remote_ip=args.remote_gcs_ip,
            local_rx_port=CONFIG["DRONE_PLAINTEXT_RX"],
            remote_tx_port=CONFIG["GCS_PLAINTEXT_RX"]
        )

============================================================

FILE 20/47: encrypted_sniffer.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\encrypted_sniffer.py
Size: 1,570 bytes
Modified: 2025-09-25 16:20:53
------------------------------------------------------------
# tools/encrypted_sniffer.py
"""
A simple UDP sniffer to verify that encrypted packets are being sent
by the proxies. Listens on a specified port and prints details of
any received datagrams.
"""
import socket
import sys
import time

def main():
    if len(sys.argv) != 2:
        print(f"Usage: python {sys.argv[0]} <port_to_listen_on>")
        sys.exit(1)

    try:
        listen_port = int(sys.argv[1])
    except ValueError:
        print(f"Error: Invalid port '{sys.argv[1]}'. Please provide a number.")
        sys.exit(1)

    print(f"--- 🕵️ Encrypted Packet Sniffer ---")
    print(f"Listening for UDP packets on 0.0.0.0:{listen_port}...")
    print("Press Ctrl+C to stop.")

    count = 0
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.bind(('0.0.0.0', listen_port))
            while True:
                data, addr = s.recvfrom(2048)
                count += 1
                timestamp = time.strftime("%H:%M:%S")
                print(
                    f"[{timestamp}] Packet #{count}: Received {len(data)} bytes from {addr[0]}:{addr[1]}"
                    f" | Data (hex): {data[:16].hex()}..."
                )
    except OSError as e:
        print(f"\n❌ Error binding to port {listen_port}: {e}")
        print("   Is another application already using this port?")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nSniffer stopped. Received a total of {count} packets.")
        sys.exit(0)

if __name__ == "__main__":
    main()

============================================================

FILE 21/47: full_comm_check.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\full_comm_check.py
Size: 9,657 bytes
Modified: 2025-09-25 00:18:03
------------------------------------------------------------
from __future__ import annotations
import json, os, socket, threading, time, sys
from types import ModuleType

# --------- helpers ---------
def _free_udp_port() -> int:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.bind(("127.0.0.1", 0))
    port = s.getsockname()[1]
    s.close()
    return port

def _clone_config_with_ports(base_cfg: dict) -> dict:
    cfg = dict(base_cfg)
    # Make everything local loopback and unique per run
    cfg["DRONE_HOST"] = "127.0.0.1"
    cfg["GCS_HOST"] = "127.0.0.1"

    # Plaintext app ports (4 distinct)
    cfg["DRONE_PLAINTEXT_TX"] = _free_udp_port()
    cfg["DRONE_PLAINTEXT_RX"] = _free_udp_port()
    while cfg["DRONE_PLAINTEXT_RX"] == cfg["DRONE_PLAINTEXT_TX"]:
        cfg["DRONE_PLAINTEXT_RX"] = _free_udp_port()

    cfg["GCS_PLAINTEXT_TX"] = _free_udp_port()
    cfg["GCS_PLAINTEXT_RX"] = _free_udp_port()
    while cfg["GCS_PLAINTEXT_RX"] == cfg["GCS_PLAINTEXT_TX"]:
        cfg["GCS_PLAINTEXT_RX"] = _free_udp_port()

    # Encrypted RX ports (must be distinct)
    cfg["DRONE_ENCRYPTED_RX"] = _free_udp_port()
    cfg["GCS_ENCRYPTED_RX"] = _free_udp_port()
    while cfg["GCS_ENCRYPTED_RX"] == cfg["DRONE_ENCRYPTED_RX"]:
        cfg["GCS_ENCRYPTED_RX"] = _free_udp_port()

    # Handshake TCP port
    cfg["TCP_HANDSHAKE_PORT"] = max(5800, _free_udp_port())
    return cfg

# --------- step 1: pytest ---------
def run_pytests() -> dict:
    try:
        import pytest  # type: ignore
    except Exception as e:
        return {"status": "ERROR", "detail": f"pytest import failed: {e}"}
    # Run full test suite quietly
    code = pytest.main(["-q"])
    return {"status": "OK" if code == 0 else "FAIL", "exit_code": code}

# --------- step 2: loopback smoke ---------
def smoke_loopback() -> dict:
    try:
        from core.async_proxy import run_proxy
        from oqs.oqs import Signature
    except Exception as e:
        return {"status": "ERROR", "detail": f"cannot import required modules: {e}"}

    # Load baseline config
    try:
        from core.config import CONFIG, load_config, validate_config  # type: ignore
        base_cfg = CONFIG
        # If load_config/validate_config exist, run a quick check
        try:
            tmp = load_config(os.environ) if callable(load_config) else None  # type: ignore
            if callable(validate_config):  # type: ignore
                validate_config(base_cfg)  # type: ignore
        except Exception:
            pass
    except Exception:
        # Fallback: try project_config re-export
        try:
            from core.project_config import CONFIG  # type: ignore
            base_cfg = CONFIG
        except Exception as e2:
            return {"status": "ERROR", "detail": f"cannot load config: {e2}"}

    cfg = _clone_config_with_ports(base_cfg)
    
    # Generate REAL cryptographic keys for testing - SECURITY CRITICAL
    try:
        suite_dict = {"kem_name":"ML-KEM-768","kem_param":768,"sig_name":"ML-DSA-65","sig_param":65,"aead":"AES-256-GCM","kdf":"HKDF-SHA256","nist_level":3}
        sig = Signature(suite_dict["sig_name"])
        gcs_sig_public = sig.generate_keypair()
    except Exception as e:
        return {"status": "ERROR", "detail": f"failed to generate keys: {e}"}

    # Storage for proxy results and errors
    gcs_err = {"error": None}
    drn_err = {"error": None}

    def gcs_thread():
        try:
            run_proxy(
                role="gcs",
                suite=suite_dict,
                cfg=cfg,
                gcs_sig_secret=sig,  # Real signature object - SECURITY CRITICAL
                gcs_sig_public=None,
                stop_after_seconds=2.0,
            )
        except Exception as e:
            gcs_err["error"] = repr(e)

    def drone_thread():
        try:
            time.sleep(0.2)  # let GCS bind first
            run_proxy(
                role="drone",
                suite=suite_dict,
                cfg=cfg,
                gcs_sig_secret=None,
                gcs_sig_public=gcs_sig_public,  # Real public key - SECURITY CRITICAL
                stop_after_seconds=2.0,
            )
        except Exception as e:
            drn_err["error"] = repr(e)

    # Start receivers (apps side)
    received_at_gcs = {"data": None}
    received_at_drone = {"data": None}

    def recv_gcs():
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as r:
                r.bind(("127.0.0.1", cfg["GCS_PLAINTEXT_RX"]))
                r.settimeout(2.0)
                data, _ = r.recvfrom(2048)
                received_at_gcs["data"] = data
        except Exception:
            pass

    def recv_drone():
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as r:
                r.bind(("127.0.0.1", cfg["DRONE_PLAINTEXT_RX"]))
                r.settimeout(2.0)
                data, _ = r.recvfrom(2048)
                received_at_drone["data"] = data
        except Exception:
            pass

    tg = threading.Thread(target=gcs_thread, daemon=True)
    td = threading.Thread(target=drone_thread, daemon=True)
    rg = threading.Thread(target=recv_gcs, daemon=True)
    rd = threading.Thread(target=recv_drone, daemon=True)

    rg.start(); rd.start()
    tg.start(); td.start()

    time.sleep(0.7)  # allow handshake

    # Send both directions via plaintext TX
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.sendto(b"Hello from drone", ("127.0.0.1", cfg["DRONE_PLAINTEXT_TX"]))
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.sendto(b"Hello from GCS", ("127.0.0.1", cfg["GCS_PLAINTEXT_TX"]))
    except Exception as e:
        return {"status": "ERROR", "detail": f"send failed: {e}"}

    rg.join(timeout=2.5); rd.join(timeout=2.5)
    tg.join(timeout=3.0);  td.join(timeout=3.0)

    if gcs_err["error"] or drn_err["error"]:
        return {"status": "FAIL", "detail": {"gcs": gcs_err["error"], "drone": drn_err["error"]}}

    ok = (received_at_gcs["data"] == b"Hello from drone" and
          received_at_drone["data"] == b"Hello from GCS")
    return {"status": "OK" if ok else "FAIL",
            "detail": {
                "gcs_rx": received_at_gcs["data"],
                "drone_rx": received_at_drone["data"],
                "ports": {
                    "DRONE_TX": cfg["DRONE_PLAINTEXT_TX"],
                    "DRONE_RX": cfg["DRONE_PLAINTEXT_RX"],
                    "GCS_TX": cfg["GCS_PLAINTEXT_TX"],
                    "GCS_RX": cfg["GCS_PLAINTEXT_RX"],
                    "ENC_DRONE": cfg["DRONE_ENCRYPTED_RX"],
                    "ENC_GCS": cfg["GCS_ENCRYPTED_RX"],
                    "HS_TCP": cfg["TCP_HANDSHAKE_PORT"],
                }
            }}

# --------- step 3: config checks ---------
def config_checks() -> dict:
    out = {}
    try:
        from core.config import CONFIG, load_config, validate_config  # type: ignore
    except Exception as e:
        return {"status": "UNKNOWN", "detail": f"no load/validate available: {e}"}

    # Base validate
    try:
        validate_config(CONFIG)  # type: ignore
        out["base_validate"] = "OK"
    except Exception as e:
        out["base_validate"] = f"FAIL: {e}"

    # Env override smoke
    try:
        env = os.environ.copy()
        env["DRONE_HOST"] = "127.0.0.1"
        env["GCS_HOST"] = "127.0.0.1"
        env["DRONE_PLAINTEXT_TX"] = "14650"
        env["DRONE_PLAINTEXT_RX"] = "14651"
        env["GCS_PLAINTEXT_TX"] = "15652"
        env["GCS_PLAINTEXT_RX"] = "15653"
        env["DRONE_ENCRYPTED_RX"] = "6810"
        env["GCS_ENCRYPTED_RX"] = "6811"
        cfg2 = load_config(env)  # type: ignore
        validate_config(cfg2)  # type: ignore
        out["env_override"] = "OK"
    except Exception as e:
        out["env_override"] = f"FAIL: {e}"

    # Port dedupe failure
    try:
        bad = dict(CONFIG)
        bad["DRONE_PLAINTEXT_RX"] = bad["DRONE_PLAINTEXT_TX"]
        validate_config(bad)  # type: ignore
        out["dedupe_check"] = "FAIL: expected ValueError"
    except Exception:
        out["dedupe_check"] = "OK"

    status = ("OK" if all(v == "OK" for v in out.values()) else "FAIL")
    out["status"] = status
    return out

# --------- step 4: wrapper import check ---------
def wrapper_imports() -> dict:
    import importlib, pathlib
    results = {"drone": {}, "gcs": {}}
    base = pathlib.Path(__file__).resolve().parents[1]

    for side in ("drone", "gcs"):
        wdir = base / side / "wrappers"
        if not wdir.exists():
            results[side]["status"] = "UNKNOWN: wrappers dir missing"
            continue
        for f in sorted(wdir.glob("*.py")):
            modname = f"{side}.wrappers.{f.stem}"
            try:
                m: ModuleType = importlib.import_module(modname)  # noqa
                results[side][f.name] = "IMPORTED"
            except Exception as e:
                results[side][f.name] = f"IMPORT_FAIL: {e}"
        results[side]["status"] = "OK" if all(v=="IMPORTED" for k,v in results[side].items() if k.endswith(".py")) else "FAIL"
    return results

# --------- main ---------
def main():
    report = {}
    report["pytest"] = run_pytests()
    report["smoke"] = smoke_loopback()
    report["config"] = config_checks()
    report["wrappers"] = wrapper_imports()
    print(json.dumps(report, indent=2, default=str))

if __name__ == "__main__":
    main()

============================================================

FILE 22/47: generate_env_report.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\generate_env_report.py
Size: 5,905 bytes
Modified: 2025-09-28 04:17:09
------------------------------------------------------------
#!/usr/bin/env python3
"""Generate a short environment report for PQC tests.

Produces a markdown report containing:
- conda list (if available)
- Python executable and version
- oqs / liboqs import info and supported/enabled mechanisms (best-effort)
- Audit of secrets/matrix: count of suites, per-suite pub/key presence and pub sha256

Usage: python tools/generate_env_report.py --out docs/env_report.md
"""
from __future__ import annotations

import argparse
import hashlib
import importlib
import json
import os
import pathlib
import platform
import shutil
import subprocess
import sys
import textwrap
from typing import List


def run_cmd(cmd: List[str]) -> str:
    try:
        p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, check=False)
        return p.stdout
    except Exception as e:
        return f'ERROR running {cmd}: {e}'


def sha256_hex(path: pathlib.Path) -> str:
    h = hashlib.sha256()
    with path.open('rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            h.update(chunk)
    return h.hexdigest()


def probe_oqs() -> dict:
    info = {}
    info['python_executable'] = sys.executable
    info['python_version'] = platform.python_version()
    # conda env name if present
    info['conda_prefix'] = os.environ.get('CONDA_PREFIX')

    # attempt to import oqs and liboqs
    try:
        oqs = importlib.import_module('oqs')
        info['oqs_file'] = getattr(oqs, '__file__', None)
        info['oqs_dir'] = getattr(oqs, '__path__', None)
        # Try common helper functions
        for fn in ('get_supported_kem_mechanisms', 'get_supported_sig_mechanisms', 'get_enabled_kem_mechanisms', 'get_enabled_sig_mechanisms'):
            f = getattr(oqs, fn, None)
            if callable(f):
                try:
                    items = f()
                    info[fn] = list(items)
                except Exception as e:
                    info[fn] = f'ERROR calling {fn}: {e}'
            else:
                info[fn] = None
    except Exception as e:
        info['oqs_import_error'] = repr(e)

    try:
        liboqs = importlib.import_module('liboqs')
        info['liboqs_file'] = getattr(liboqs, '__file__', None)
    except Exception as e:
        info['liboqs_import_error'] = repr(e)

    return info


def audit_secrets_matrix(root: pathlib.Path) -> dict:
    out = {}
    if not root.exists():
        out['error'] = f'{root} does not exist'
        return out
    pubs = list(sorted(root.glob('*/gcs_signing.pub')))
    out['pub_count'] = len(pubs)
    suites = []
    for pub in pubs:
        suite = pub.parent.name
        key_path = pub.parent / 'gcs_signing.key'
        pub_sha = sha256_hex(pub)
        suites.append({'suite': suite, 'pub': str(pub), 'pub_size': pub.stat().st_size, 'pub_sha256': pub_sha, 'has_key': key_path.exists(), 'key_path': str(key_path) if key_path.exists() else None})
    out['suites'] = suites
    return out


def render_markdown(info: dict, secrets: dict, conda_list_text: str) -> str:
    lines = []
    lines.append('# Environment report')
    lines.append('')
    lines.append('## Python / Conda')
    lines.append('')
    lines.append(f"- Python executable: `{info.get('python_executable')}`")
    lines.append(f"- Python version: `{info.get('python_version')}`")
    lines.append(f"- CONDA_PREFIX: `{info.get('conda_prefix')}`")
    lines.append('')
    lines.append('### Conda packages (conda list)')
    lines.append('')
    lines.append('```')
    lines.append(conda_list_text.strip())
    lines.append('```')
    lines.append('')
    lines.append('## oqs / liboqs info')
    lines.append('')
    if 'oqs_import_error' in info:
        lines.append(f"- oqs import error: {info['oqs_import_error']}")
    else:
        lines.append(f"- oqs module file: `{info.get('oqs_file')}`")
        for fn in ('get_supported_sig_mechanisms', 'get_enabled_sig_mechanisms', 'get_supported_kem_mechanisms', 'get_enabled_kem_mechanisms'):
            val = info.get(fn)
            if val is None:
                lines.append(f"- {fn}: MISSING")
            elif isinstance(val, str) and val.startswith('ERROR'):
                lines.append(f"- {fn}: {val}")
            else:
                lines.append(f"- {fn}: {len(val)} items (showing up to 10): {val[:10]}")
    if 'liboqs_import_error' in info:
        lines.append(f"- liboqs import error: {info['liboqs_import_error']}")
    else:
        lines.append(f"- liboqs module file: `{info.get('liboqs_file')}`")

    lines.append('')
    lines.append('## secrets/matrix audit')
    lines.append('')
    lines.append(f"- pub files found: {secrets.get('pub_count',0)}")
    lines.append('')
    lines.append('| suite | pub_size | pub_sha256 | has_key |')
    lines.append('|---|---:|---|---:|')
    for s in secrets.get('suites', []):
        lines.append(f"| {s['suite']} | {s['pub_size']} | `{s['pub_sha256']}` | {s['has_key']} |")

    lines.append('')
    lines.append('Generated by `tools/generate_env_report.py`')
    return '\n'.join(lines)


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--out', '--out-file', dest='out', default='docs/env_report.md')
    args = p.parse_args()

    # Get conda list if available
    conda_text = run_cmd(['conda', 'list']) if shutil.which('conda') else run_cmd([sys.executable, '-m', 'pip', 'freeze'])

    info = probe_oqs()
    secrets = audit_secrets_matrix(pathlib.Path('secrets') / 'matrix')
    md = render_markdown(info, secrets, conda_text)

    out_path = pathlib.Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(md, encoding='utf-8')
    print(f'Wrote report to {out_path}')


if __name__ == '__main__':
    raise SystemExit(main())

============================================================

FILE 23/47: generate_identity.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\generate_identity.py
Size: 2,266 bytes
Modified: 2025-09-25 08:18:20
------------------------------------------------------------
#!/usr/bin/env python3
"""Generate and persist a post-quantum GCS identity (signature keypair).

Usage:
  python tools/generate_identity.py --suite cs-kyber768-aesgcm-dilithium3 --out-dir keys

Outputs:
  <out-dir>/gcs_sig_public.bin
  <out-dir>/gcs_sig_secret.bin

Security:
  - Secret key file is written with 0o600 permissions where supported.
  - Fails fast on any error; never substitutes random bytes.
"""
import argparse, os, sys, stat
from pathlib import Path
from oqs.oqs import Signature
from core.suites import get_suite


def write_file(path: Path, data: bytes, secret: bool = False):
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(data)
    if secret:
        try:
            path.chmod(stat.S_IRUSR | stat.S_IWUSR)
        except Exception:
            pass  # best effort on non-POSIX


def main():
    ap = argparse.ArgumentParser(description="Generate PQC signature identity keypair")
    ap.add_argument("--suite", required=True, help="Suite ID (must correspond to desired signature algorithm)")
    ap.add_argument("--out-dir", default="identity", help="Output directory for key files")
    args = ap.parse_args()

    try:
        suite = get_suite(args.suite)
    except Exception as e:
        print(f"Error: unknown suite '{args.suite}': {e}")
        sys.exit(2)

    sig_alg = suite["sig_name"]
    try:
        sig = Signature(sig_alg)
        pub = sig.generate_keypair()
        secret = sig.export_secret_key()
    except Exception as e:
        print(f"Failed to generate signature keypair for {sig_alg}: {e}")
        sys.exit(1)

    out_dir = Path(args.out_dir).resolve()
    write_file(out_dir / "gcs_sig_public.bin", pub, secret=False)
    write_file(out_dir / "gcs_sig_secret.bin", secret, secret=True)

    print("Generated PQC signature identity:")
    print(f"  Signature algorithm : {sig_alg}")
    print(f"  Public key (hex)    : {pub.hex()}")
    print(f"  Public key file     : {out_dir / 'gcs_sig_public.bin'}")
    print(f"  Secret key file     : {out_dir / 'gcs_sig_secret.bin'} (mode 600 if supported)")
    print("\nDistribute the public key to drone nodes; keep the secret key private.")

if __name__ == "__main__":
    main()

============================================================

FILE 24/47: manual_4term\drone_autopilot_sim.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\drone_autopilot_sim.py
Size: 3,933 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Drone-side simulator for manual quad-terminal tests.

Generates telemetry frames towards the drone proxy and prints any
commands received from the GCS proxy.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from typing import List

_TELEMETRY_FRAMES: List[str] = [
    "TELEM:POS:37.7749,-122.4194,ALT=120",
    "TELEM:ATT:ROLL=1.2,PITCH=-0.3,YAW=90",
    "TELEM:VEL:N=5.1,E=0.4,D=-0.2",
    "TELEM:BAT:V=23.9,I=12.3,SOC=87",
]

_BUFFER_SIZE = 2048


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Simulate a drone autopilot connected to the proxy")
    parser.add_argument("--send-port", type=int, required=True, help="Port where drone proxy listens for plaintext telemetry")
    parser.add_argument("--recv-port", type=int, required=True, help="Port where drone proxy delivers decrypted commands")
    parser.add_argument("--host", default="127.0.0.1", help="Loopback host for both directions (default: %(default)s)")
    parser.add_argument("--interval", type=float, default=1.5, help="Seconds between telemetry frames (default: %(default)s)")
    parser.add_argument("--loop", action="store_true", help="Loop telemetry frames forever (default: stop after one pass)")
    return parser.parse_args()


def telemetry_loop(sock: socket.socket, host: str, port: int, interval: float, loop: bool, shutdown: threading.Event) -> None:
    print(f"[DRONE] Sending telemetry to {host}:{port}")
    while not shutdown.is_set():
        for frame in _TELEMETRY_FRAMES:
            try:
                payload = frame.encode("utf-8")
                sock.sendto(payload, (host, port))
                timestamp = time.strftime("%H:%M:%S")
                print(f"[DRONE] {timestamp} -> {frame}")
            except OSError as exc:
                print(f"[DRONE] Send error: {exc}")
                shutdown.set()
                break
            if shutdown.wait(interval):
                break
        if not loop:
            break
    print("[DRONE] Telemetry loop stopped")


def command_loop(sock: socket.socket, shutdown: threading.Event) -> None:
    print("[DRONE] Listening for decrypted commands...")
    sock.settimeout(0.5)
    while not shutdown.is_set():
        try:
            data, addr = sock.recvfrom(_BUFFER_SIZE)
        except socket.timeout:
            continue
        except OSError as exc:
            if not shutdown.is_set():
                print(f"[DRONE] Receive error: {exc}")
            break
        timestamp = time.strftime("%H:%M:%S")
        try:
            text = data.decode("utf-8", errors="replace")
        except Exception:
            text = data.hex()
        print(f"[DRONE] {timestamp} <- {text} (from {addr[0]}:{addr[1]})")
    print("[DRONE] Command listener stopped")


def main() -> None:
    args = parse_args()

    shutdown = threading.Event()

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as send_sock, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as recv_sock:
        recv_sock.bind(("0.0.0.0", args.recv_port))

        sender = threading.Thread(target=telemetry_loop, args=(send_sock, args.host, args.send_port, args.interval, args.loop, shutdown), daemon=True)
        receiver = threading.Thread(target=command_loop, args=(recv_sock, shutdown), daemon=True)

        sender.start()
        receiver.start()

        print("[DRONE] Autopilot simulator running. Press Ctrl+C to exit.")
        try:
            while sender.is_alive() or receiver.is_alive():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\n[DRONE] Interrupt received, shutting down")
            shutdown.set()
            sender.join(timeout=1.0)
            receiver.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 25/47: manual_4term\drone_tty.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\drone_tty.py
Size: 4,213 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""Minimal interactive CLI for Drone plaintext tunnel."""

from __future__ import annotations

import argparse
import os
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_ROOT = Path(__file__).resolve().parents[2]
_ROOT_STR = str(_ROOT)
if _ROOT_STR not in sys.path:
    sys.path.insert(0, _ROOT_STR)

from core.config import CONFIG

MAX_PAYLOAD = 4096


def ensure_newline(payload: bytes) -> bytes:
    if payload.endswith(b"\n"):
        return payload
    return payload + b"\n"


def truncate_payload(payload: bytes) -> bytes:
    if len(payload) <= MAX_PAYLOAD:
        return payload
    trimmed = payload[:MAX_PAYLOAD]
    if trimmed[-1:] != b"\n":
        trimmed = trimmed[:-1] + b"\n"
    return trimmed


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Interactive Drone plaintext console")
    parser.add_argument(
        "--host",
        default="127.0.0.1",
        help="Destination host for plaintext telemetry (defaults to local proxy)",
    )
    parser.add_argument("--tx-port", type=int, default=CONFIG["DRONE_PLAINTEXT_TX"], help="Port to send telemetry lines")
    parser.add_argument("--rx-port", type=int, default=CONFIG["DRONE_PLAINTEXT_RX"], help="Port receiving command lines")
    parser.add_argument("--expect", type=int, default=0, help="Exit automatically after receiving N lines")
    parser.add_argument("--verbose", action="store_true", help="Enable debug output to stderr")
    return parser


def main() -> None:
    args = build_parser().parse_args()

    done = threading.Event()
    recv_count = 0
    recv_lock = threading.Lock()

    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx_sock.bind(("0.0.0.0", args.rx_port))
    except OSError as exc:
        sys.stderr.write(
            f"Failed to bind local RX port {args.rx_port}. Is another console or app already using it? ({exc})\n"
        )
        rx_sock.close()
        sys.exit(1)
    rx_sock.settimeout(0.1)

    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    sys.stderr.write(
        f"[Drone TTY] Sending to {args.host}:{args.tx_port} | Listening on 0.0.0.0:{args.rx_port}\n"
    )
    sys.stderr.flush()

    def debug(msg: str) -> None:
        if args.verbose:
            sys.stderr.write(msg + "\n")
            sys.stderr.flush()

    def reader() -> None:
        nonlocal recv_count
        while not done.is_set():
            try:
                data, _ = rx_sock.recvfrom(65535)
            except socket.timeout:
                continue
            except OSError:
                break
            if not data:
                continue
            trimmed = data[:MAX_PAYLOAD]
            text = trimmed.decode("utf-8", errors="replace")
            if not text.endswith("\n"):
                text += "\n"
            sys.stdout.write(text)
            sys.stdout.flush()
            if args.expect:
                with recv_lock:
                    recv_count += 1
                    if recv_count >= args.expect:
                        done.set()
                        os._exit(0)
        try:
            rx_sock.close()
        except OSError:
            pass

    thread = threading.Thread(target=reader, daemon=True)
    thread.start()

    try:
        for line in sys.stdin:
            if done.is_set():
                break
            encoded = ensure_newline(line.encode("utf-8", errors="replace"))
            encoded = truncate_payload(encoded)
            try:
                tx_sock.sendto(encoded, (args.host, args.tx_port))
            except OSError as exc:
                debug(f"sendto failed: {exc}; retrying in 0.5s")
                time.sleep(0.5)
                continue
    except KeyboardInterrupt:
        pass
    finally:
        done.set()
        try:
            tx_sock.close()
        except OSError:
            pass
        thread.join(timeout=0.2)


if __name__ == "__main__":
    main()

============================================================

FILE 26/47: manual_4term\encrypted_bridge_logger.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\encrypted_bridge_logger.py
Size: 4,355 bytes
Modified: 2025-09-25 19:32:10
------------------------------------------------------------
"""Encrypted UDP bridge logger for manual 4-terminal testing.

Listens on two UDP ports (drone->GCS and GCS->drone), forwards the
packets to their true destinations, and prints concise metadata so you
can verify encrypted traffic is flowing in both directions.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from dataclasses import dataclass
from typing import Tuple

_LOG_BYTES_DEFAULT = 32
_BUFFER_SIZE = 2048


@dataclass
class BridgeConfig:
    listen_addr: Tuple[str, int]
    forward_addr: Tuple[str, int]
    label: str


def _format_bytes(data: bytes, limit: int) -> str:
    clipped = data[:limit]
    hex_preview = clipped.hex()
    if len(data) > limit:
        return f"{hex_preview}... ({len(data)} bytes)"
    return f"{hex_preview} ({len(data)} bytes)"


def _bridge_loop(cfg: BridgeConfig, log_bytes: int, shutdown: threading.Event) -> None:
    packet_count = 0
    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as listener, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as forwarder:
        listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        listener.bind(cfg.listen_addr)
        listener.settimeout(0.5)

        print(f"[{cfg.label}] Listening on {cfg.listen_addr[0]}:{cfg.listen_addr[1]} -> forwarding to {cfg.forward_addr[0]}:{cfg.forward_addr[1]}")
        while not shutdown.is_set():
            try:
                data, addr = listener.recvfrom(_BUFFER_SIZE)
            except socket.timeout:
                continue
            except OSError as exc:
                if not shutdown.is_set():
                    print(f"[{cfg.label}] Socket error: {exc}")
                break

            packet_count += 1
            timestamp = time.strftime("%H:%M:%S")
            preview = _format_bytes(data, log_bytes)
            print(f"[{cfg.label}] {timestamp} #{packet_count} from {addr[0]}:{addr[1]} -> {preview}")

            try:
                forwarder.sendto(data, cfg.forward_addr)
            except OSError as exc:
                print(f"[{cfg.label}] Forward error: {exc}")
                break

        print(f"[{cfg.label}] Shutdown (processed {packet_count} packets)")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Log encrypted packets while forwarding between proxies")
    parser.add_argument("--d2g-listen", type=int, required=True, help="Port to bind for Drone -> GCS traffic")
    parser.add_argument("--d2g-forward", required=True, help="host:port to forward Drone -> GCS packets")
    parser.add_argument("--g2d-listen", type=int, required=True, help="Port to bind for GCS -> Drone traffic")
    parser.add_argument("--g2d-forward", required=True, help="host:port to forward GCS -> Drone packets")
    parser.add_argument("--log-bytes", type=int, default=_LOG_BYTES_DEFAULT, help="Number of ciphertext bytes to preview (default: %(default)s)")
    return parser.parse_args()


def _parse_host_port(value: str) -> Tuple[str, int]:
    if ":" not in value:
        raise ValueError(f"Expected host:port, got '{value}'")
    host, port_str = value.rsplit(":", 1)
    return host, int(port_str)


def main() -> None:
    args = parse_args()

    try:
        d2g_forward = _parse_host_port(args.d2g_forward)
        g2d_forward = _parse_host_port(args.g2d_forward)
    except ValueError as exc:
        print(f"Argument error: {exc}")
        sys.exit(1)

    shutdown = threading.Event()
    bridges = [
        BridgeConfig(("0.0.0.0", args.d2g_listen), d2g_forward, "Drone->GCS"),
        BridgeConfig(("0.0.0.0", args.g2d_listen), g2d_forward, "GCS->Drone"),
    ]

    threads = [threading.Thread(target=_bridge_loop, args=(cfg, args.log_bytes, shutdown), daemon=True) for cfg in bridges]

    print("Starting encrypted bridge logger. Press Ctrl+C to stop.")
    for thread in threads:
        thread.start()

    try:
        while any(thread.is_alive() for thread in threads):
            time.sleep(0.5)
    except KeyboardInterrupt:
        print("\nInterrupt received, shutting down...")
        shutdown.set()
        for thread in threads:
            thread.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 27/47: manual_4term\gcs_ground_station_sim.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\gcs_ground_station_sim.py
Size: 3,927 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Minimal GCS ground-station simulator for manual quad-terminal tests.

Sends a rotating set of high-level commands to the GCS proxy plaintext
port and prints any telemetry frames returned from the drone proxy via
GCS_PLAINTEXT_RX.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from typing import List

_DEFAULT_COMMANDS: List[str] = [
    "CMD_ARM",
    "CMD_TAKEOFF_ALT_30",
    "CMD_SET_HEADING_090",
    "CMD_LOITER_HOLD",
    "CMD_RTL",
]

_BUFFER_SIZE = 2048


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Simulate a GCS app talking to the proxy")
    parser.add_argument("--send-port", type=int, required=True, help="Port where GCS proxy listens for plaintext commands")
    parser.add_argument("--recv-port", type=int, required=True, help="Port where GCS proxy delivers decrypted telemetry")
    parser.add_argument("--host", default="127.0.0.1", help="Loopback host for both directions (default: %(default)s)")
    parser.add_argument("--interval", type=float, default=2.0, help="Seconds between commands (default: %(default)s)")
    parser.add_argument("--loop", action="store_true", help="Loop command list forever (default: stop after one pass)")
    return parser.parse_args()


def command_loop(sock: socket.socket, host: str, port: int, interval: float, loop: bool, shutdown: threading.Event) -> None:
    print(f"[GCS] Sending plaintext commands to {host}:{port}")
    while not shutdown.is_set():
        for command in _DEFAULT_COMMANDS:
            try:
                payload = command.encode("utf-8")
                sock.sendto(payload, (host, port))
                timestamp = time.strftime("%H:%M:%S")
                print(f"[GCS] {timestamp} -> {command}")
            except OSError as exc:
                print(f"[GCS] Send error: {exc}")
                shutdown.set()
                break
            if shutdown.wait(interval):
                break
        if not loop:
            break
    print("[GCS] Command loop stopped")


def telemetry_loop(sock: socket.socket, shutdown: threading.Event) -> None:
    print("[GCS] Listening for decrypted telemetry...")
    sock.settimeout(0.5)
    while not shutdown.is_set():
        try:
            data, addr = sock.recvfrom(_BUFFER_SIZE)
        except socket.timeout:
            continue
        except OSError as exc:
            if not shutdown.is_set():
                print(f"[GCS] Receive error: {exc}")
            break
        timestamp = time.strftime("%H:%M:%S")
        try:
            text = data.decode("utf-8", errors="replace")
        except Exception:
            text = data.hex()
        print(f"[GCS] {timestamp} <- {text} (from {addr[0]}:{addr[1]})")
    print("[GCS] Telemetry listener stopped")


def main() -> None:
    args = parse_args()

    shutdown = threading.Event()

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as send_sock, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as recv_sock:
        recv_sock.bind(("0.0.0.0", args.recv_port))

        sender = threading.Thread(target=command_loop, args=(send_sock, args.host, args.send_port, args.interval, args.loop, shutdown), daemon=True)
        receiver = threading.Thread(target=telemetry_loop, args=(recv_sock, shutdown), daemon=True)

        sender.start()
        receiver.start()

        print("[GCS] Ground-station simulator running. Press Ctrl+C to exit.")
        try:
            while sender.is_alive() or receiver.is_alive():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\n[GCS] Interrupt received, shutting down")
            shutdown.set()
            sender.join(timeout=1.0)
            receiver.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 28/47: manual_4term\gcs_tty.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\gcs_tty.py
Size: 4,207 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""Minimal interactive CLI for GCS plaintext tunnel."""

from __future__ import annotations

import argparse
import os
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_ROOT = Path(__file__).resolve().parents[2]
_ROOT_STR = str(_ROOT)
if _ROOT_STR not in sys.path:
    sys.path.insert(0, _ROOT_STR)

from core.config import CONFIG

MAX_PAYLOAD = 4096


def ensure_newline(payload: bytes) -> bytes:
    if payload.endswith(b"\n"):
        return payload
    return payload + b"\n"


def truncate_payload(payload: bytes) -> bytes:
    if len(payload) <= MAX_PAYLOAD:
        return payload
    trimmed = payload[:MAX_PAYLOAD]
    if trimmed[-1:] != b"\n":
        trimmed = trimmed[:-1] + b"\n"
    return trimmed


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Interactive GCS plaintext console")
    parser.add_argument(
        "--host",
        default="127.0.0.1",
        help="Destination host for plaintext commands (defaults to local proxy)",
    )
    parser.add_argument("--tx-port", type=int, default=CONFIG["GCS_PLAINTEXT_TX"], help="Port to send plaintext commands")
    parser.add_argument("--rx-port", type=int, default=CONFIG["GCS_PLAINTEXT_RX"], help="Port receiving telemetry lines")
    parser.add_argument("--expect", type=int, default=0, help="Exit automatically after receiving N lines")
    parser.add_argument("--verbose", action="store_true", help="Enable debug output to stderr")
    return parser


def main() -> None:
    args = build_parser().parse_args()

    done = threading.Event()
    recv_count = 0
    recv_lock = threading.Lock()

    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx_sock.bind(("0.0.0.0", args.rx_port))
    except OSError as exc:
        sys.stderr.write(
            f"Failed to bind local RX port {args.rx_port}. Is another console or app already using it? ({exc})\n"
        )
        rx_sock.close()
        sys.exit(1)
    rx_sock.settimeout(0.1)

    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    sys.stderr.write(
        f"[GCS TTY] Sending to {args.host}:{args.tx_port} | Listening on 0.0.0.0:{args.rx_port}\n"
    )
    sys.stderr.flush()

    def debug(msg: str) -> None:
        if args.verbose:
            sys.stderr.write(msg + "\n")
            sys.stderr.flush()

    def reader() -> None:
        nonlocal recv_count
        while not done.is_set():
            try:
                data, _ = rx_sock.recvfrom(65535)
            except socket.timeout:
                continue
            except OSError:
                break
            if not data:
                continue
            trimmed = data[:MAX_PAYLOAD]
            text = trimmed.decode("utf-8", errors="replace")
            if not text.endswith("\n"):
                text += "\n"
            sys.stdout.write(text)
            sys.stdout.flush()
            if args.expect:
                with recv_lock:
                    recv_count += 1
                    if recv_count >= args.expect:
                        done.set()
                        os._exit(0)
        try:
            rx_sock.close()
        except OSError:
            pass

    thread = threading.Thread(target=reader, daemon=True)
    thread.start()

    try:
        for line in sys.stdin:
            if done.is_set():
                break
            encoded = ensure_newline(line.encode("utf-8", errors="replace"))
            encoded = truncate_payload(encoded)
            try:
                tx_sock.sendto(encoded, (args.host, args.tx_port))
            except OSError as exc:
                debug(f"sendto failed: {exc}; retrying in 0.5s")
                time.sleep(0.5)
                continue
    except KeyboardInterrupt:
        pass
    finally:
        done.set()
        try:
            tx_sock.close()
        except OSError:
            pass
        thread.join(timeout=0.2)


if __name__ == "__main__":
    main()

============================================================

FILE 29/47: manual_4term\launch_manual_test.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\launch_manual_test.py
Size: 9,824 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Launch a four-terminal manual end-to-end test for the PQC proxy.

Processes spawned:
  1. GCS proxy (core.run_proxy gcs)
  2. Drone proxy (core.run_proxy drone)
  3. GCS ground-station simulator (commands -> proxy, telemetry <- proxy)
  4. Drone autopilot simulator (telemetry -> proxy, commands <- proxy)

Optional fifth process:
  - Encrypted bridge logger that sits between the proxies and prints
    ciphertext metadata while forwarding packets in both directions.
"""
from __future__ import annotations

import argparse
import os
import signal
import subprocess
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

REPO_ROOT = Path(__file__).resolve().parents[2]
MANUAL_DIR = Path(__file__).resolve().parent
DEFAULT_SECRETS = REPO_ROOT / "secrets"

PORTS = {
    "TCP_HANDSHAKE": 46000,
    "GCS_ENCRYPTED_BIND": 46011,
    "DRONE_ENCRYPTED_BIND": 46012,
    "INTERCEPT_D2G_LISTEN": 46001,
    "INTERCEPT_G2D_LISTEN": 46002,
    "GCS_PLAINTEXT_TX": 47001,
    "GCS_PLAINTEXT_RX": 47002,
    "DRONE_PLAINTEXT_TX": 47003,
    "DRONE_PLAINTEXT_RX": 47004,
}

_BUFFERED_TEXT = bool(os.name != "nt")  # On Windows CREATE_NEW_CONSOLE forbids capturing


@dataclass
class ProcessSpec:
    label: str
    command: List[str]
    env: Dict[str, str]
    new_window: bool


@dataclass
class ProcessHandle:
    spec: ProcessSpec
    process: subprocess.Popen
    pump_thread: Optional[threading.Thread]


def _ensure_identity(suite: str, secrets_dir: Path) -> None:
    secret_path = secrets_dir / "gcs_signing.key"
    public_path = secrets_dir / "gcs_signing.pub"
    if secret_path.exists() and public_path.exists():
        return

    print(f"[setup] Generating GCS signing identity in {secrets_dir}")
    secrets_dir.mkdir(parents=True, exist_ok=True)
    cmd = [sys.executable, "-m", "core.run_proxy", "init-identity", "--suite", suite, "--output-dir", str(secrets_dir)]
    result = subprocess.run(cmd, cwd=REPO_ROOT)
    if result.returncode != 0:
        raise RuntimeError("Failed to initialise GCS signing identity")


def _stream_output(label: str, proc: subprocess.Popen) -> None:
    assert proc.stdout is not None
    for line in proc.stdout:
        print(f"[{label}] {line.rstrip()}" )
    proc.stdout.close()


def _launch_process(spec: ProcessSpec, cwd: Path) -> ProcessHandle:
    creationflags = 0
    stdout = None
    stderr = None

    if spec.new_window and os.name == "nt":
        creationflags = subprocess.CREATE_NEW_CONSOLE  # type: ignore[attr-defined]
    elif spec.new_window:
        print(f"[warn] '--new-windows' requested but not supported on this platform. Running inline instead for {spec.label}.")

    if not spec.new_window:
        stdout = subprocess.PIPE
        stderr = subprocess.STDOUT

    proc = subprocess.Popen(
        spec.command,
        cwd=cwd,
        env=spec.env,
        stdout=stdout,
        stderr=stderr,
        text=True,
        bufsize=1,
    )

    pump_thread: Optional[threading.Thread] = None
    if stdout is not None and proc.stdout is not None:
        pump_thread = threading.Thread(target=_stream_output, args=(spec.label, proc), daemon=True)
        pump_thread.start()

    return ProcessHandle(spec, proc, pump_thread)


def _build_env(overrides: Dict[str, int]) -> Dict[str, str]:
    env = os.environ.copy()
    for key, value in overrides.items():
        env[key] = str(value)
    return env


def _build_specs(args: argparse.Namespace, secrets_dir: Path) -> List[ProcessSpec]:
    secret_path = secrets_dir / "gcs_signing.key"
    public_path = secrets_dir / "gcs_signing.pub"

    # Base overrides shared by both proxies
    base_overrides = {
        "TCP_HANDSHAKE_PORT": PORTS["TCP_HANDSHAKE"],
        "DRONE_HOST": "127.0.0.1",
        "GCS_HOST": "127.0.0.1",
    }

    if args.with_intercept:
        drone_peer_port = PORTS["INTERCEPT_D2G_LISTEN"]
        gcs_peer_port = PORTS["INTERCEPT_G2D_LISTEN"]
    else:
        drone_peer_port = PORTS["GCS_ENCRYPTED_BIND"]
        gcs_peer_port = PORTS["DRONE_ENCRYPTED_BIND"]

    gcs_env = _build_env({
        **base_overrides,
        "UDP_GCS_RX": PORTS["GCS_ENCRYPTED_BIND"],
        "UDP_DRONE_RX": gcs_peer_port,
        "GCS_PLAINTEXT_TX": PORTS["GCS_PLAINTEXT_TX"],
        "GCS_PLAINTEXT_RX": PORTS["GCS_PLAINTEXT_RX"],
    })

    drone_env = _build_env({
        **base_overrides,
        "UDP_DRONE_RX": PORTS["DRONE_ENCRYPTED_BIND"],
        "UDP_GCS_RX": drone_peer_port,
        "DRONE_PLAINTEXT_TX": PORTS["DRONE_PLAINTEXT_TX"],
        "DRONE_PLAINTEXT_RX": PORTS["DRONE_PLAINTEXT_RX"],
    })

    specs: List[ProcessSpec] = []

    gcs_cmd = [sys.executable, "-m", "core.run_proxy", "gcs", "--suite", args.suite]
    if secret_path != DEFAULT_SECRETS / "gcs_signing.key":
        gcs_cmd += ["--gcs-secret-file", str(secret_path)]
    specs.append(ProcessSpec("GCS", gcs_cmd, gcs_env, args.new_windows))

    drone_cmd = [
        sys.executable,
        "-m",
        "core.run_proxy",
        "drone",
        "--suite",
        args.suite,
        "--peer-pubkey-file",
        str(public_path),
    ]
    specs.append(ProcessSpec("DRONE", drone_cmd, drone_env, args.new_windows))

    gcs_sim_cmd = [
        sys.executable,
        str(MANUAL_DIR / "gcs_ground_station_sim.py"),
        "--send-port",
        str(PORTS["GCS_PLAINTEXT_TX"]),
        "--recv-port",
        str(PORTS["GCS_PLAINTEXT_RX"]),
        "--loop",
    ]
    specs.append(ProcessSpec("GCS-SIM", gcs_sim_cmd, os.environ.copy(), args.new_windows))

    drone_sim_cmd = [
        sys.executable,
        str(MANUAL_DIR / "drone_autopilot_sim.py"),
        "--send-port",
        str(PORTS["DRONE_PLAINTEXT_TX"]),
        "--recv-port",
        str(PORTS["DRONE_PLAINTEXT_RX"]),
        "--loop",
    ]
    specs.append(ProcessSpec("DRONE-SIM", drone_sim_cmd, os.environ.copy(), args.new_windows))

    if args.with_intercept:
        bridge_cmd = [
            sys.executable,
            str(MANUAL_DIR / "encrypted_bridge_logger.py"),
            "--d2g-listen",
            str(PORTS["INTERCEPT_D2G_LISTEN"]),
            "--d2g-forward",
            f"127.0.0.1:{PORTS['GCS_ENCRYPTED_BIND']}",
            "--g2d-listen",
            str(PORTS["INTERCEPT_G2D_LISTEN"]),
            "--g2d-forward",
            f"127.0.0.1:{PORTS['DRONE_ENCRYPTED_BIND']}",
        ]
        specs.append(ProcessSpec("BRIDGE", bridge_cmd, os.environ.copy(), args.new_windows))

    return specs


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Launch a manual four-terminal PQC proxy test")
    parser.add_argument("--suite", default="cs-kyber768-aesgcm-dilithium3", help="Cryptographic suite for both proxies (default: %(default)s)")
    parser.add_argument("--secrets-dir", default=str(DEFAULT_SECRETS), help="Directory containing GCS keypair (default: %(default)s)")
    parser.add_argument("--no-auto-init", action="store_true", help="Do not auto-generate GCS keys if missing")
    parser.add_argument("--with-intercept", action="store_true", help="Launch the encrypted bridge logger between proxies")
    parser.add_argument("--new-windows", action="store_true", help="Attempt to open each process in a new console window (Windows only)")
    return parser.parse_args()


def print_banner(args: argparse.Namespace) -> None:
    print("Manual PQC proxy test launcher")
    print("Repository root:", REPO_ROOT)
    print("Suite:", args.suite)
    print("Secrets directory:", args.secrets_dir)
    print("Intercept enabled:" if args.with_intercept else "Intercept disabled", args.with_intercept)
    print("Ports in use:")
    for key, value in PORTS.items():
        print(f"  {key:<24} {value}")
    print()
    print("Press Ctrl+C in this window to stop all managed processes.")


def main() -> None:
    args = parse_args()
    secrets_dir = Path(args.secrets_dir).resolve()

    if not args.no_auto_init:
        _ensure_identity(args.suite, secrets_dir)

    print_banner(args)

    specs = _build_specs(args, secrets_dir)
    handles: List[ProcessHandle] = []

    try:
        for spec in specs:
            handle = _launch_process(spec, REPO_ROOT)
            handles.append(handle)
            print(f"[launch] Started {spec.label} (PID {handle.process.pid})")

        while True:
            for handle in list(handles):
                code = handle.process.poll()
                if code is not None:
                    print(f"[exit] {handle.spec.label} exited with code {code}")
                    handles.remove(handle)
            if not handles:
                print("[launcher] All processes exited. Stopping launcher.")
                break
            time.sleep(0.5)

    except KeyboardInterrupt:
        print("\n[launcher] Interrupt received, terminating child processes...")
    finally:
        for handle in handles:
            if handle.process.poll() is None:
                try:
                    if os.name == "nt" and hasattr(signal, "CTRL_BREAK_EVENT"):
                        handle.process.send_signal(signal.CTRL_BREAK_EVENT)
                        time.sleep(0.3)
                    handle.process.terminate()
                except Exception:
                    pass
        time.sleep(0.5)
        for handle in handles:
            if handle.process.poll() is None:
                try:
                    handle.process.kill()
                except Exception:
                    pass


if __name__ == "__main__":
    main()

============================================================

FILE 30/47: markers.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\markers.py
Size: 3,323 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""Marker sink implementations for external power instrumentation.

Used by benchmark harnesses to emit precise START/END markers that align with
external power meters or logging systems.
"""

from __future__ import annotations

from typing import Protocol
import socket


class MarkerSink(Protocol):
    """Protocol for marker sinks used to signal run boundaries."""

    def start(self, run_id: str, t_wall_ns: int) -> None:
        """Emit a run start marker."""

    def end(self, run_id: str, t_wall_ns: int) -> None:
        """Emit a run end marker."""

    def close(self) -> None:  # pragma: no cover - optional hook
        """Optional resource cleanup."""


class NullMarker:
    """Marker sink that discards all events."""

    def start(self, run_id: str, t_wall_ns: int) -> None:  # pragma: no cover - trivial
        return

    def end(self, run_id: str, t_wall_ns: int) -> None:  # pragma: no cover - trivial
        return

    def close(self) -> None:  # pragma: no cover - trivial
        return


class FileMarker:
    """Append START/END markers to a text file."""

    def __init__(self, path: str) -> None:
        self.path = path

    def _write(self, tag: str, run_id: str, t_wall_ns: int) -> None:
        with open(self.path, "a", encoding="utf-8") as handle:
            handle.write(f"{tag} {run_id} {t_wall_ns}\n")

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._write("START", run_id, t_wall_ns)

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._write("END", run_id, t_wall_ns)

    def close(self) -> None:  # pragma: no cover - nothing persistent
        return


class SerialMarker:
    """Write markers to a serial port.

    Requires ``pyserial`` to be installed in the environment.
    """

    def __init__(self, port: str, baud: int = 115_200) -> None:
        import serial  # type: ignore

        self._serial = serial.Serial(port=port, baudrate=baud, timeout=1)

    def _send(self, payload: str) -> None:
        self._serial.write(f"{payload}\n".encode("ascii"))
        self._serial.flush()

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"START {run_id} {t_wall_ns}")

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"END {run_id} {t_wall_ns}")

    def close(self) -> None:
        try:
            self._serial.close()
        except Exception:  # pragma: no cover - best effort cleanup
            pass


class UdpMarker:
    """Send markers over UDP to a remote host."""

    def __init__(self, host_port: str) -> None:
        host, port_str = host_port.split(":", 1)
        self.addr = (host, int(port_str))
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    def _send(self, payload: str) -> None:
        self.sock.sendto(payload.encode("ascii"), self.addr)

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"START {run_id} {t_wall_ns}")

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"END {run_id} {t_wall_ns}")

    def close(self) -> None:
        try:
            self.sock.close()
        except Exception:  # pragma: no cover - best effort cleanup
            pass

============================================================

FILE 31/47: merge_power_csv.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\merge_power_csv.py
Size: 5,656 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""Merge external power meter CSV output with benchmark manifests.

For each manifest.json produced by the benchmark runner, slice the power-meter
CSV to the START/END timestamps and compute aggregate energy statistics.
"""

from __future__ import annotations

import argparse
import csv
import json
import math
from pathlib import Path
from typing import Dict, Iterable, List, Optional


def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(description="Merge benchmark manifests with external power meter CSV data")
+    parser.add_argument("--manifest-dir", required=True, help="Directory containing manifest.json files")
+    parser.add_argument("--meter-csv", required=True, help="Power meter CSV file containing timestamped power samples")
+    parser.add_argument("--time-col", default="timestamp_ns", help="Column name for sample timestamps (nanoseconds)")
+    parser.add_argument("--power-col", default="power_w", help="Column name for power samples (watts)")
+    parser.add_argument("--out", default="benchmarks/out/merged.csv", help="Output CSV path with merged statistics")
+    return parser.parse_args()
+
+
+def load_meter_samples(csv_path: Path, time_col: str, power_col: str) -> List[Dict[str, float]]:
+    rows: List[Dict[str, float]] = []
+    with csv_path.open(newline="", encoding="utf-8") as handle:
+        reader = csv.DictReader(handle)
+        if time_col not in reader.fieldnames or power_col not in reader.fieldnames:
+            raise SystemExit(f"Required columns '{time_col}' and/or '{power_col}' missing from meter CSV")
+        for row in reader:
+            try:
+                t_ns = int(row[time_col])
+                p_w = float(row[power_col])
+            except (TypeError, ValueError) as exc:
+                raise SystemExit(f"Invalid meter row: {row}") from exc
+            rows.append({"t_ns": t_ns, "p_w": p_w})
+    if not rows:
+        print("Warning: meter CSV contained no samples")
+    return rows
+
+
+def slice_samples(samples: Iterable[Dict[str, float]], start_ns: int, end_ns: int) -> List[float]:
+    return [sample["p_w"] for sample in samples if start_ns <= sample["t_ns"] < end_ns]
+
+
+def compute_stats(samples: List[float], start_ns: int, end_ns: int) -> Dict[str, Optional[float]]:
+    duration_s = (end_ns - start_ns) / 1e9
+    if not samples:
+        return {
+            "samples": 0,
+            "avg_w": None,
+            "p95_w": None,
+            "max_w": None,
+            "joules": None,
+            "dur_s": duration_s,
+        }
+
+    sorted_samples = sorted(samples)
+    avg = sum(sorted_samples) / len(sorted_samples)
+    max_val = sorted_samples[-1]
+    p95_index = max(0, min(len(sorted_samples) - 1, math.floor(0.95 * (len(sorted_samples) - 1))))
+    p95_val = sorted_samples[p95_index]
+    joules = avg * duration_s
+    return {
+        "samples": len(sorted_samples),
+        "avg_w": avg,
+        "p95_w": p95_val,
+        "max_w": max_val,
+        "joules": joules,
+        "dur_s": duration_s,
+    }
+
+
+def collect_manifests(manifest_dir: Path) -> List[Dict[str, object]]:
+    manifests = []
+    for manifest_path in manifest_dir.rglob("manifest.json"):
+        data = json.loads(manifest_path.read_text(encoding="utf-8"))
+        data["_manifest_path"] = manifest_path
+        manifests.append(data)
+    if not manifests:
+        raise SystemExit(f"No manifest.json files found under {manifest_dir}")
+    manifests.sort(key=lambda entry: (entry.get("start_wall_ns", 0), entry.get("run_id", "")))
+    return manifests
+
+
+def merge(args: argparse.Namespace) -> None:
+    meter_samples = load_meter_samples(Path(args.meter_csv), args.time_col, args.power_col)
+    manifests = collect_manifests(Path(args.manifest_dir))
+
+    output_rows: List[Dict[str, object]] = []
+    for manifest in manifests:
+        start_ns = int(manifest["start_wall_ns"])
+        end_ns = int(manifest["end_wall_ns"])
+        sliced = slice_samples(meter_samples, start_ns, end_ns)
+        stats = compute_stats(sliced, start_ns, end_ns)
+        row: Dict[str, object] = {
+            "run_id": manifest.get("run_id"),
+            "suite": manifest.get("suite"),
+            "kem": manifest.get("kem"),
+            "sig": manifest.get("sig"),
+            "aead": manifest.get("aead"),
+            "repeat_idx": manifest.get("repeat_idx"),
+            "duration_s": manifest.get("duration_s"),
+            "start_wall_ns": start_ns,
+            "end_wall_ns": end_ns,
+            "manifest_path": str(manifest.get("_manifest_path")),
+            **stats,
+        }
+        output_rows.append(row)
+
+    out_path = Path(args.out)
+    out_path.parent.mkdir(parents=True, exist_ok=True)
+    fieldnames = [
+        "run_id",
+        "suite",
+        "kem",
+        "sig",
+        "aead",
+        "repeat_idx",
+        "duration_s",
+        "start_wall_ns",
+        "end_wall_ns",
+        "samples",
+        "avg_w",
+        "p95_w",
+        "max_w",
+        "joules",
+        "dur_s",
+        "manifest_path",
+    ]
+
+    with out_path.open("w", newline="", encoding="utf-8") as handle:
+        writer = csv.DictWriter(handle, fieldnames=fieldnames)
+        writer.writeheader()
+        for row in output_rows:
+            writer.writerow(row)
+    print(f"Merged {len(output_rows)} manifest entries into {out_path}")
+
+
+def main() -> None:
+    args = parse_args()
+    merge(args)
+
+
+if __name__ == "__main__":
+    main()

============================================================

FILE 32/47: netcapture\drone_capture.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\netcapture\drone_capture.py
Size: 3,434 bytes
Modified: 2025-09-26 09:46:35
------------------------------------------------------------
#!/usr/bin/env python3
"""Linux-oriented capture helper for the drone host (Raspberry Pi).

Usage::

    python tools/netcapture/drone_capture.py --iface wlan0 --duration 30 --out captures/drone

The script shells out to ``tcpdump`` (ubiquitous on Linux) and applies
BPF filters for the PQC handshake TCP port and encrypted UDP ports defined in
``core.config.CONFIG``.  The resulting ``.pcap`` can be inspected with Wireshark
on any workstation.
"""

from __future__ import annotations

import argparse
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Iterable

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG

HANDSHAKE_PORT = int(CONFIG["TCP_HANDSHAKE_PORT"])
ENCRYPTED_PORTS = [int(CONFIG["UDP_GCS_RX"]), int(CONFIG["UDP_DRONE_RX"])]


class CaptureError(RuntimeError):
    pass


def ensure_linux() -> None:
    if sys.platform.startswith("win"):
        raise SystemExit("drone_capture.py is intended for Linux hosts only")


def tcpdump_available() -> bool:
    return shutil.which("tcpdump") is not None


def build_filter() -> str:
    ports = {HANDSHAKE_PORT, *ENCRYPTED_PORTS}
    clauses = []
    for port in sorted(ports):
        clauses.append(f"port {port}")
    return " or ".join(clauses)


def run_tcpdump(iface: str, pcap_path: Path, duration: int) -> None:
    if not tcpdump_available():
        raise CaptureError("tcpdump not found in PATH; install it (sudo apt install tcpdump)")

    bpf = build_filter()
    cmd: Iterable[str] = (
        "tcpdump",
        "-i",
        iface,
        "-w",
        str(pcap_path),
        "-G",
        str(duration),
        "-W",
        "1",
        "-n",
        bpf,
    )
    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    if proc.returncode != 0:
        raise CaptureError(f"tcpdump failed ({proc.returncode})\n{proc.stdout}")


def main() -> None:
    ensure_linux()

    ap = argparse.ArgumentParser(description="Capture handshake/encrypted traffic on the drone host")
    ap.add_argument("--iface", required=True, help="Network interface to capture (e.g., wlan0, eth0)")
    ap.add_argument("--duration", type=int, default=20, help="Capture duration in seconds (default: 20)")
    ap.add_argument(
        "--out",
        type=Path,
        default=Path("captures/drone.pcap"),
        help="Output pcap path (default: captures/drone.pcap)",
    )
    args = ap.parse_args()

    args.out.parent.mkdir(parents=True, exist_ok=True)

    try:
        run_tcpdump(args.iface, args.out, args.duration)
    except CaptureError as exc:
        print(f"\n❌ Capture failed: {exc}\n", file=sys.stderr)
        raise SystemExit(2) from exc

    print("\n✅ Capture complete:")
    print(f"  • {args.out}")
    print("\nTip: start this capture, then launch the proxy. Stop the proxy when you have enough packets, or rerun the capture for another segment.")


if __name__ == "__main__":
    main()

============================================================

FILE 33/47: netcapture\gcs_capture.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\netcapture\gcs_capture.py
Size: 5,576 bytes
Modified: 2025-09-26 09:59:28
------------------------------------------------------------
#!/usr/bin/env python3
r"""Windows-oriented capture helper for the GCS host.

Usage examples
--------------
Collect a 30s capture of handshake + encrypted ports into ``captures\gcs``::

    python tools/netcapture/gcs_capture.py --duration 30 --out captures/gcs

The script prefers ``pktmon`` (ships with Windows 10 2004+) and falls back to
``netsh trace``.  It tries to add filters for the PQC handshake and encrypted
UDP ports defined in ``core.config.CONFIG`` so the traces stay focused.

Outputs
-------
* ``<out>.etl``        Raw ETW capture (always produced)
* ``<out>.pcapng``     Packet capture (when ``pktmon`` is available)
* ``<out>.log``        Text summary (when ``pktmon`` is available)

Prerequisites
-------------
* Run from an elevated PowerShell / Command Prompt (admin rights).
* ``pktmon`` or ``netsh`` must be available in ``PATH`` (Windows built-ins).
"""

from __future__ import annotations

import argparse
import shutil
import subprocess
import sys
import tempfile
import time
from pathlib import Path
from typing import Iterable

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG

HANDSHAKE_PORT = int(CONFIG["TCP_HANDSHAKE_PORT"])
ENCRYPTED_PORTS = [int(CONFIG["UDP_GCS_RX"]), int(CONFIG["UDP_DRONE_RX"])]


class CaptureError(RuntimeError):
    pass


def run(cmd: Iterable[str], *, check: bool = True) -> subprocess.CompletedProcess[str]:
    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    if check and proc.returncode != 0:
        raise CaptureError(f"Command failed ({proc.returncode}): {' '.join(cmd)}\n{proc.stdout}")
    return proc


def ensure_windows() -> None:
    if sys.platform != "win32":
        raise SystemExit("gcs_capture.py is intended for Windows hosts only")


def pktmon_available() -> bool:
    return shutil.which("pktmon") is not None


def netsh_available() -> bool:
    return shutil.which("netsh") is not None


def build_default_output(out_base: Path) -> tuple[Path, Path, Path]:
    etl = out_base.with_suffix(".etl")
    pcap = out_base.with_suffix(".pcapng")
    log = out_base.with_suffix(".log")
    return etl, pcap, log


def run_pktmon(out_base: Path, duration: int) -> list[Path]:
    etl, pcap, log = build_default_output(out_base)

    # Reset previous state to keep output predictable
    run(["pktmon", "stop"], check=False)
    run(["pktmon", "reset"], check=False)

    # Apply lightweight port filters so we only capture the PQC traffic
    filter_ports = sorted({HANDSHAKE_PORT, *ENCRYPTED_PORTS})
    for port in filter_ports:
        run(["pktmon", "filter", "add", "--port", str(port)])

    run(["pktmon", "start", "--etw", "--capture"])
    time.sleep(duration)
    run(["pktmon", "stop"])

    temp_etl = Path("PktMon.etl")
    if temp_etl.exists():
        temp_etl.replace(etl)
    else:
        raise CaptureError("pktmon did not produce PktMon.etl")

    run(["pktmon", "format", str(etl), "-o", str(pcap)])
    run(["pktmon", "format", str(etl), "-o", str(log), "--text"])

    run(["pktmon", "reset"], check=False)
    return [etl, pcap, log]


def run_netsh(out_base: Path, duration: int) -> list[Path]:
    if not netsh_available():
        raise CaptureError("Neither pktmon nor netsh is available; cannot capture")

    etl, _, _ = build_default_output(out_base)
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp = Path(tmpdir) / "trace"
        run(
            [
                "netsh",
                "trace",
                "start",
                "capture=yes",
                "tracefile=" + str(tmp),
                "report=no",
                "maxsize=512",
            ]
        )
        time.sleep(duration)
        run(["netsh", "trace", "stop"])
        raw = tmp.with_suffix(".etl")
        if raw.exists():
            raw.replace(etl)
        else:
            raise CaptureError("netsh trace did not produce an .etl file")
    return [etl]


def main() -> None:
    ensure_windows()

    ap = argparse.ArgumentParser(description="Capture handshake/encrypted traffic on the GCS host")
    ap.add_argument("--duration", type=int, default=20, help="Capture duration in seconds (default: 20)")
    ap.add_argument(
        "--out",
        type=Path,
        default=Path("captures/gcs_capture"),
        help="Output file base name (extensions added automatically)",
    )
    args = ap.parse_args()

    args.out.parent.mkdir(parents=True, exist_ok=True)

    try:
        if pktmon_available():
            produced = run_pktmon(args.out, args.duration)
        else:
            produced = run_netsh(args.out, args.duration)
    except CaptureError as exc:
        print(f"\n❌ Capture failed: {exc}\n", file=sys.stderr)
        raise SystemExit(2) from exc

    print("\n✅ Capture complete. Generated files:")
    for path in produced:
        print(f"  • {path}")
    print(
        "\nTip: start this capture, then launch the proxy. Stop the proxy and re-run the capture if you need multiple segments."
    )


if __name__ == "__main__":
    main()

============================================================

FILE 34/47: packet_interceptor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\packet_interceptor.py
Size: 2,494 bytes
Modified: 2025-09-25 16:20:53
------------------------------------------------------------
# tools/packet_interceptor.py
"""
A packet interceptor that sits between proxy components to monitor encrypted traffic.
This acts as a transparent UDP forwarder that logs all packets passing through.
"""
import socket
import sys
import time
import threading

def main():
    if len(sys.argv) != 4:
        print(f"Usage: python {sys.argv[0]} <listen_port> <forward_to_host> <forward_to_port>")
        print("Example: python packet_interceptor.py 45899 127.0.0.1 45801")
        print("  This listens on 45899 and forwards everything to 127.0.0.1:45801")
        sys.exit(1)

    try:
        listen_port = int(sys.argv[1])
        forward_host = sys.argv[2]
        forward_port = int(sys.argv[3])
    except ValueError as e:
        print(f"Error: Invalid arguments: {e}")
        sys.exit(1)

    print(f"--- 🔍 Packet Interceptor ---")
    print(f"Listening on 0.0.0.0:{listen_port}")
    print(f"Forwarding all traffic to {forward_host}:{forward_port}")
    print("Press Ctrl+C to stop.")
    print()

    packet_count = 0

    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as listener:
            listener.bind(('0.0.0.0', listen_port))
            
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as forwarder:
                while True:
                    data, addr = listener.recvfrom(2048)
                    packet_count += 1
                    timestamp = time.strftime("%H:%M:%S")
                    
                    print(f"[{timestamp}] INTERCEPTED Packet #{packet_count}:")
                    print(f"  From: {addr[0]}:{addr[1]}")
                    print(f"  Size: {len(data)} bytes")
                    print(f"  Data (hex): {data[:32].hex()}...")
                    print(f"  Forwarding to {forward_host}:{forward_port}")
                    
                    # Forward the packet
                    try:
                        forwarder.sendto(data, (forward_host, forward_port))
                        print(f"  ✅ Forwarded successfully")
                    except Exception as e:
                        print(f"  ❌ Forward failed: {e}")
                    print()

    except OSError as e:
        print(f"\n❌ Error binding to port {listen_port}: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nInterceptor stopped. Processed {packet_count} packets.")
        sys.exit(0)

if __name__ == "__main__":
    main()

============================================================

FILE 35/47: power_hooks.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\power_hooks.py
Size: 208 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
# Placeholder for energy measurements; intentionally empty to avoid fake data.
class PowerHook:
    def __enter__(self): return self
    def __exit__(self, *exc): return False
    def sample(self): return {}

============================================================

FILE 36/47: prepare_matrix_keys.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\prepare_matrix_keys.py
Size: 3,043 bytes
Modified: 2025-09-26 19:54:12
------------------------------------------------------------
#!/usr/bin/env python3
"""Generate per-suite signing identities for matrix tests.

Creates `gcs_signing.key`/`gcs_signing.pub` pairs under
`secrets/matrix/<safe_suite>/` so both the GCS and drone proxies can
reuse deterministic file locations during automated matrix runs.
"""
from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path

from core.suites import list_suites

REPO_ROOT = Path(__file__).resolve().parents[1]


def safe_suite_name(name: str) -> str:
    return "".join(ch if ch.isalnum() or ch in ("-", "_") else "_" for ch in name)


def ensure_identity(suite: str, out_root: Path, *, force: bool = False) -> None:
    safe = safe_suite_name(suite)
    suite_dir = out_root / safe
    secret_path = suite_dir / "gcs_signing.key"
    public_path = suite_dir / "gcs_signing.pub"

    if not force and secret_path.exists() and public_path.exists():
        print(f"[keys] Reusing existing signing identity for {suite} ({suite_dir})")
        return

    print(f"[keys] Generating signing identity for {suite} -> {suite_dir}")
    suite_dir.mkdir(parents=True, exist_ok=True)

    cmd = [
        sys.executable,
        "-m",
        "core.run_proxy",
        "init-identity",
        "--suite",
        suite,
        "--output-dir",
        str(suite_dir),
    ]
    result = subprocess.run(cmd, cwd=REPO_ROOT)
    if result.returncode != 0:
        raise SystemExit(f"Failed to generate signing identity for {suite}")

    if not secret_path.exists() or not public_path.exists():
        raise SystemExit(f"Generated signing identity for {suite} is missing files in {suite_dir}")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Prepare signing identities for matrix tests")
    parser.add_argument(
        "--suite",
        action="append",
        help="Suite ID to generate (may be provided multiple times). Defaults to all registered suites.",
    )
    parser.add_argument(
        "--out-root",
        default=str(REPO_ROOT / "secrets" / "matrix"),
        help="Output directory for matrix key material (default: secrets/matrix)",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Regenerate identities even if files already exist",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    if args.suite:
        suites = list(dict.fromkeys(args.suite))
    else:
        suites = list(list_suites().keys())

    out_root = Path(args.out_root).expanduser()
    if not out_root.is_absolute():
        out_root = (REPO_ROOT / out_root).resolve()
    else:
        out_root.mkdir(parents=True, exist_ok=True)

    out_root.mkdir(parents=True, exist_ok=True)

    for suite in suites:
        ensure_identity(suite, out_root, force=args.force)

    print(f"[keys] Complete. Generated {len(suites)} suites in {out_root}")


if __name__ == "__main__":
    main()

============================================================

FILE 37/47: print_oqs_info.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\print_oqs_info.py
Size: 4,200 bytes
Modified: 2025-09-28 04:17:08
------------------------------------------------------------
#!/usr/bin/env python3
"""Robust debug info about oqs/python and native liboqs availability.

This probes both the top-level `oqs` package and the `oqs.oqs` binding
submodule, tries several API-name variants (different capitalizations),
and prints any discovered classes and mechanism lists. Run inside your
`gcs-env` to see what the runtime exposes.
"""
import importlib
import sys
import traceback


def try_import(name):
    try:
        m = importlib.import_module(name)
        return True, m
    except Exception as e:
        return False, e


def probe_functions(mod, logical_name, variants):
    """Try variants on mod and return the first callable found and its name."""
    for var in variants:
        fn = getattr(mod, var, None)
        if callable(fn):
            return var, fn
    return None, None


def print_mech_list(fn):
    try:
        res = fn()
        try:
            size = len(res)
        except Exception:
            size = 'unknown'
        print(f"  -> {size} items")
        try:
            # show a short sample
            sample = list(res)[:10]
            print('   ', sample)
        except Exception:
            print('   (unable to list sample)')
    except Exception as e:
        print('  ERROR calling function:', e)
        traceback.print_exc()


def main():
    print('Python executable:', sys.executable)

    # Try several import points: oqs.oqs (binding) preferred, then oqs
    ok_binding, oqs_binding = try_import('oqs.oqs')
    ok_pkg, oqs_pkg = try_import('oqs')

    if not ok_binding and not ok_pkg:
        print('Could not import oqs or oqs.oqs:', oqs_pkg)
        return 2

    # Choose module to probe: binding wins if present
    oqs_mod = oqs_binding if ok_binding else oqs_pkg
    print('Probing module:', getattr(oqs_mod, '__name__', repr(oqs_mod)))
    print('Module file:', getattr(oqs_mod, '__file__', '<built-in or namespace>'))

    # Look for common classes used by the codebase
    for cls_name in ('Signature', 'KeyEncapsulation'):
        obj = getattr(oqs_mod, cls_name, None)
        print(f"\nClass {cls_name}:", 'FOUND' if obj is not None else 'MISSING')

    # Logical API names and their common variants (case differences)
    api_variants = {
        'get_enabled_kem_mechanisms': ['get_enabled_kem_mechanisms', 'get_enabled_KEM_mechanisms', 'get_enabled_KEM_mechanism', 'get_enabled_kem_mechanisms'],
        'get_enabled_sig_mechanisms': ['get_enabled_sig_mechanisms', 'get_enabled_sig_mechanism', 'get_enabled_SIG_mechanisms', 'get_enabled_sig_mechanisms'],
        'get_supported_kem_mechanisms': ['get_supported_kem_mechanisms', 'get_supported_KEM_mechanisms', 'get_supported_kem_mechanism'],
        'get_supported_sig_mechanisms': ['get_supported_sig_mechanisms', 'get_supported_SIG_mechanisms', 'get_supported_sig_mechanism'],
    }

    for logical, variants in api_variants.items():
        print('\nChecking logical API:', logical)
        name, fn = probe_functions(oqs_mod, logical, variants)
        if name is None:
            print('  NO matching function found on module; trying package-level fallback (if different)')
            # If we probed oqs.oqs, also try top-level package if available
            if oqs_mod is not oqs_pkg and ok_pkg:
                name, fn = probe_functions(oqs_pkg, logical, variants)
        if name is None:
            print('  MISSING API (no variant found)')
        else:
            print(f'  Found function name: {name}')
            print_mech_list(fn)

    # Try to import native module 'liboqs' if present
    ok_native, lib = try_import('liboqs')
    print('\nNative liboqs import:', 'OK' if ok_native else f'FAIL: {lib}')
    if ok_native:
        print('liboqs module file:', getattr(lib, '__file__', '<unknown>'))

    # Also dump a short dir() to help diagnose odd packaging
    try:
        print('\nShort dir() of probed module:')
        names = [n for n in dir(oqs_mod) if not n.startswith('_')][:80]
        print(' ', names)
    except Exception:
        pass

    return 0


if __name__ == '__main__':
    raise SystemExit(main())

============================================================

FILE 38/47: scaffold_repo.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\scaffold_repo.py
Size: 17,074 bytes
Modified: 2025-09-24 15:32:18
------------------------------------------------------------
# tools/scaffold_repo.py
# Create planned folders/files that aren't in the current tree.
# Safe by default: won't overwrite unless --force is given.

import argparse, os, sys, stat, textwrap
from pathlib import Path
ROOT = Path(__file__).resolve().parents[1]

def write(path: Path, content: str, force=False):
    path.parent.mkdir(parents=True, exist_ok=True)
    if path.exists() and not force:
        print(f"skip  (exists) {path}")
        return False
    path.write_text(textwrap.dedent(content).lstrip(), encoding="utf-8", newline="\n")
    print(f"write {path}")
    return True

def make_executable(path: Path):
    try:
        path.chmod(path.stat().st_mode | stat.S_IEXEC)
    except Exception:
        pass  # windows ok

def main(force=False):
    wrote = 0

    # ---------- core additions ----------
    wrote += write(ROOT / "core" / "project_config.py", """
        # Thin shim so planned path 'project_config.py' exists without breaking tests.
        # Source of truth remains core/config.py
        from .config import CONFIG
        __all__ = ["CONFIG"]
    """, force)

    wrote += write(ROOT / "core" / "logging_utils.py", """
        import json, logging, sys, time
        from typing import Any, Dict

        class JsonFormatter(logging.Formatter):
            def format(self, record: logging.LogRecord) -> str:
                payload = {
                    "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(record.created)),
                    "level": record.levelname,
                    "name": record.name,
                    "msg": record.getMessage(),
                }
                if record.exc_info:
                    payload["exc_info"] = self.formatException(record.exc_info)
                # Allow extra fields via record.__dict__ (filtered)
                for k, v in record.__dict__.items():
                    if k not in ("msg", "args", "exc_info", "exc_text", "stack_info", "stack_level", "created",
                                 "msecs", "relativeCreated", "levelno", "levelname", "pathname", "filename",
                                 "module", "lineno", "funcName", "thread", "threadName", "processName", "process"):
                        try:
                            json.dumps({k: v})
                            payload[k] = v
                        except Exception:
                            payload[k] = str(v)
                return json.dumps(payload)

        def get_logger(name: str = "pqc") -> logging.Logger:
            logger = logging.getLogger(name)
            if logger.handlers:
                return logger
            logger.setLevel(logging.INFO)
            h = logging.StreamHandler(sys.stdout)
            h.setFormatter(JsonFormatter())
            logger.addHandler(h)
            logger.propagate = False
            return logger

        # Very small metrics hook (no deps)
        class Counter:
            def __init__(self): self.value = 0
            def inc(self, n: int = 1): self.value += n

        class Gauge:
            def __init__(self): self.value = 0
            def set(self, v: float): self.value = v

        class Metrics:
            def __init__(self):
                self.counters = {}
                self.gauges = {}
            def counter(self, name: str) -> Counter:
                self.counters.setdefault(name, Counter()); return self.counters[name]
            def gauge(self, name: str) -> Gauge:
                self.gauges.setdefault(name, Gauge()); return self.gauges[name]

        METRICS = Metrics()
    """, force)

    # ---------- wrappers (no-arg launchers) ----------
    WRAPPER_MAP = {
        # drone
        "drone/wrappers/drone_kyber_512.py":        "cs-kyber512-aesgcm-dilithium2",
        "drone/wrappers/drone_kyber_768.py":        "cs-kyber768-aesgcm-dilithium3",
        "drone/wrappers/drone_kyber_1024.py":       "cs-kyber1024-aesgcm-dilithium5",
        "drone/wrappers/drone_dilithium2.py":       "cs-kyber512-aesgcm-dilithium2",
        "drone/wrappers/drone_dilithium3.py":       "cs-kyber768-aesgcm-dilithium3",
        "drone/wrappers/drone_dilithium5.py":       "cs-kyber1024-aesgcm-dilithium5",
        "drone/wrappers/drone_falcon512.py":        "cs-kyber768-aesgcm-falcon512",
        "drone/wrappers/drone_falcon1024.py":       "cs-kyber1024-aesgcm-falcon1024",
        "drone/wrappers/drone_sphincs_sha2_128f.py":"cs-kyber512-aesgcm-sphincs128f_sha2",
        "drone/wrappers/drone_sphincs_sha2_256f.py":"cs-kyber1024-aesgcm-sphincs256f_sha2",
        # gcs
        "gcs/wrappers/gcs_kyber_512.py":            "cs-kyber512-aesgcm-dilithium2",
        "gcs/wrappers/gcs_kyber_768.py":            "cs-kyber768-aesgcm-dilithium3",
        "gcs/wrappers/gcs_kyber_1024.py":           "cs-kyber1024-aesgcm-dilithium5",
        "gcs/wrappers/gcs_dilithium2.py":           "cs-kyber512-aesgcm-dilithium2",
        "gcs/wrappers/gcs_dilithium3.py":           "cs-kyber768-aesgcm-dilithium3",
        "gcs/wrappers/gcs_dilithium5.py":           "cs-kyber1024-aesgcm-dilithium5",
        "gcs/wrappers/gcs_falcon512.py":            "cs-kyber768-aesgcm-falcon512",
        "gcs/wrappers/gcs_falcon1024.py":           "cs-kyber1024-aesgcm-falcon1024",
        "gcs/wrappers/gcs_sphincs_sha2_128f.py":    "cs-kyber512-aesgcm-sphincs128f_sha2",
        "gcs/wrappers/gcs_sphincs_sha2_256f.py":    "cs-kyber1024-aesgcm-sphincs256f_sha2",
    }
    WRAPPER_TMPL = """
        from core.runner import start
        ROLE="{role}"; SUITE_ID="{suite}"
        if __name__ == "__main__":
            start(ROLE, SUITE_ID)
    """
    for rel, suite in WRAPPER_MAP.items():
        role = "drone" if rel.startswith("drone/") else "gcs"
        wrote += write(ROOT / rel, WRAPPER_TMPL.format(role=role, suite=suite), force)

    # ---------- scripts (bash + ps1) ----------
    wrote += write(ROOT / "drone" / "scripts" / "start_suite.sh", """
        #!/usr/bin/env bash
        set -euo pipefail
        suite="${1:-cs-kyber768-aesgcm-dilithium3}"
        case "$suite" in
          cs-kyber512-aesgcm-dilithium2)  py="drone/wrappers/drone_kyber_512.py";;
          cs-kyber768-aesgcm-dilithium3)  py="drone/wrappers/drone_kyber_768.py";;
          cs-kyber1024-aesgcm-dilithium5) py="drone/wrappers/drone_kyber_1024.py";;
          cs-kyber768-aesgcm-falcon512)   py="drone/wrappers/drone_falcon512.py";;
          cs-kyber1024-aesgcm-falcon1024) py="drone/wrappers/drone_falcon1024.py";;
          cs-kyber512-aesgcm-sphincs128f_sha2) py="drone/wrappers/drone_sphincs_sha2_128f.py";;
          cs-kyber1024-aesgcm-sphincs256f_sha2) py="drone/wrappers/drone_sphincs_sha2_256f.py";;
          *) echo "Unknown suite: $suite"; exit 2;;
        esac
        exec python "$py"
    """, force)
    make_executable(ROOT / "drone" / "scripts" / "start_suite.sh")

    wrote += write(ROOT / "gcs" / "scripts" / "start_suite.sh", """
        #!/usr/bin/env bash
        set -euo pipefail
        suite="${1:-cs-kyber768-aesgcm-dilithium3}"
        case "$suite" in
          cs-kyber512-aesgcm-dilithium2)  py="gcs/wrappers/gcs_kyber_512.py";;
          cs-kyber768-aesgcm-dilithium3)  py="gcs/wrappers/gcs_kyber_768.py";;
          cs-kyber1024-aesgcm-dilithium5) py="gcs/wrappers/gcs_kyber_1024.py";;
          cs-kyber768-aesgcm-falcon512)   py="gcs/wrappers/gcs_falcon512.py";;
          cs-kyber1024-aesgcm-falcon1024) py="gcs/wrappers/gcs_falcon1024.py";;
          cs-kyber512-aesgcm-sphincs128f_sha2) py="gcs/wrappers/gcs_sphincs_sha2_128f.py";;
          cs-kyber1024-aesgcm-sphincs256f_sha2) py="gcs/wrappers/gcs_sphincs_sha2_256f.py";;
          *) echo "Unknown suite: $suite"; exit 2;;
        esac
        exec python "$py"
    """, force)
    make_executable(ROOT / "gcs" / "scripts" / "start_suite.sh")

    wrote += write(ROOT / "drone" / "scripts" / "start_suite.ps1", r"""
        param([string]$suite = "cs-kyber768-aesgcm-dilithium3")
        $map = @{
          "cs-kyber512-aesgcm-dilithium2"      = "drone/wrappers/drone_kyber_512.py"
          "cs-kyber768-aesgcm-dilithium3"      = "drone/wrappers/drone_kyber_768.py"
          "cs-kyber1024-aesgcm-dilithium5"     = "drone/wrappers/drone_kyber_1024.py"
          "cs-kyber768-aesgcm-falcon512"       = "drone/wrappers/drone_falcon512.py"
          "cs-kyber1024-aesgcm-falcon1024"     = "drone/wrappers/drone_falcon1024.py"
          "cs-kyber512-aesgcm-sphincs128f_sha2"= "drone/wrappers/drone_sphincs_sha2_128f.py"
          "cs-kyber1024-aesgcm-sphincs256f_sha2"= "drone/wrappers/drone_sphincs_sha2_256f.py"
        }
        if (-not $map.ContainsKey($suite)) { Write-Error "Unknown suite $suite"; exit 2 }
        python $map[$suite]
    """, force)

    wrote += write(ROOT / "gcs" / "scripts" / "start_suite.ps1", r"""
        param([string]$suite = "cs-kyber768-aesgcm-dilithium3")
        $map = @{
          "cs-kyber512-aesgcm-dilithium2"      = "gcs/wrappers/gcs_kyber_512.py"
          "cs-kyber768-aesgcm-dilithium3"      = "gcs/wrappers/gcs_kyber_768.py"
          "cs-kyber1024-aesgcm-dilithium5"     = "gcs/wrappers/gcs_kyber_1024.py"
          "cs-kyber768-aesgcm-falcon512"       = "gcs/wrappers/gcs_falcon512.py"
          "cs-kyber1024-aesgcm-falcon1024"     = "gcs/wrappers/gcs_falcon1024.py"
          "cs-kyber512-aesgcm-sphincs128f_sha2"= "gcs/wrappers/gcs_sphincs_sha2_128f.py"
          "cs-kyber1024-aesgcm-sphincs256f_sha2"= "gcs/wrappers/gcs_sphincs_sha2_256f.py"
        }
        if (-not $map.ContainsKey($suite)) { Write-Error "Unknown suite $suite"; exit 2 }
        python $map[$suite]
    """, force)

    wrote += write(ROOT / "drone" / "scripts" / "env_check.py", """
        import sys
        status = {}
        try:
            import cryptography
            status["cryptography"] = cryptography.__version__
        except Exception as e:
            status["cryptography"] = f"ERROR: {e}"
        try:
            import oqs.oqs as oqs
            status["oqs-python"] = oqs.oqs_version()
        except Exception as e:
            status["oqs-python"] = f"ERROR: {e}"
        print(status); sys.exit(0 if all("ERROR" not in v for v in status.values()) else 1)
    """, force)
    wrote += write(ROOT / "gcs" / "scripts" / "env_check.py", (ROOT / "drone" / "scripts" / "env_check.py").read_text() if (ROOT / "drone" / "scripts" / "env_check.py").exists() else """
        # same as drone/scripts/env_check.py
    """, force)

    # ---------- ddos stubs ----------
    wrote += write(ROOT / "ddos" / "features.py", """
        def extract_features(pkt_batch):
            raise NotImplementedError("DDoS pipeline is out of scope right now.")
    """, force)
    wrote += write(ROOT / "ddos" / "xgb_stage1.py", """
        def score(features):
            raise NotImplementedError("DDoS stage-1 XGBoost not implemented in this phase.")
    """, force)
    wrote += write(ROOT / "ddos" / "tst_stage2.py", """
        def confirm(features):
            raise NotImplementedError("DDoS stage-2 TST not implemented in this phase.")
    """, force)
    wrote += write(ROOT / "ddos" / "mitigations.py", """
        def apply(action):
            raise NotImplementedError("DDoS mitigations controlled by RL/ops; not implemented yet.")
    """, force)

    # ---------- rl stubs ----------
    wrote += write(ROOT / "rl" / "linucb.py", """
        class LinUCB:
            def __init__(self, *_, **__): raise NotImplementedError("RL is out of scope right now.")
    """, force)
    wrote += write(ROOT / "rl" / "agent_runtime.py", """
        def main(): raise NotImplementedError("RL runtime not implemented in this phase.")
        if __name__ == "__main__": main()
    """, force)
    wrote += write(ROOT / "rl" / "safety.py", """
        def guard(action, mission): raise NotImplementedError("RL safety shield not implemented in this phase.")
    """, force)

    # ---------- tools ----------
    wrote += write(ROOT / "tools" / "bench_cli.py", """
        import os, time
        from core.aead import Sender, Receiver
        from core.suites import header_ids_for_suite, AeadIds
        from core.config import CONFIG
        import os as _os
        def main():
            suite = {"kem_name":"ML-KEM-768","sig_name":"ML-DSA-65","aead":"AES-256-GCM","kdf":"HKDF-SHA256","kem_param":768,"sig_param":65}
            ids = AeadIds(*header_ids_for_suite(suite))
            key = os.urandom(32); sid = os.urandom(8)
            s = Sender(CONFIG["WIRE_VERSION"], ids, sid, 0, key)
            r = Receiver(CONFIG["WIRE_VERSION"], ids, sid, 0, key, CONFIG["REPLAY_WINDOW"])
            t0=time.perf_counter(); n=2000
            for _ in range(n):
                w = s.encrypt(b"x"*64)
                _ = r.decrypt(w)
            dt=time.perf_counter()-t0
            print({"pps": int(n/dt), "lat_us_per_pkt": int(dt/n*1e6)})
        if __name__=="__main__": main()
    """, force)
    wrote += write(ROOT / "tools" / "power_hooks.py", """
        # Placeholder for energy measurements; intentionally empty to avoid fake data.
        class PowerHook:
            def __enter__(self): return self
            def __exit__(self, *exc): return False
            def sample(self): return {}
    """, force)
    wrote += write(ROOT / "tools" / "wireshark" / "pqc_tunnel.lua", """
        -- Minimal skeleton dissector (header-only) for dev convenience.
        local p = Proto("pqctun","PQC Tunnel")
        local f_version = ProtoField.uint8("pqctun.version","version", base.DEC)
        local f_kem_id  = ProtoField.uint8("pqctun.kem_id","kem_id", base.DEC)
        local f_kem_prm = ProtoField.uint8("pqctun.kem_param","kem_param", base.DEC)
        local f_sig_id  = ProtoField.uint8("pqctun.sig_id","sig_id", base.DEC)
        local f_sig_prm = ProtoField.uint8("pqctun.sig_param","sig_param", base.DEC)
        local f_sid     = ProtoField.bytes("pqctun.session_id","session_id")
        local f_seq     = ProtoField.uint64("pqctun.seq","seq", base.DEC)
        local f_epoch   = ProtoField.uint8("pqctun.epoch","epoch", base.DEC)
        p.fields = {f_version,f_kem_id,f_kem_prm,f_sig_id,f_sig_prm,f_sid,f_seq,f_epoch}
        function p.dissector(buf,pkt,tree)
          if buf:len() < 1+1+1+1+1+8+8+1 then return end
          local t = tree:add(p, buf(0))
          local o=0
          t:add(f_version, buf(o,1)); o=o+1
          t:add(f_kem_id,  buf(o,1)); o=o+1
          t:add(f_kem_prm, buf(o,1)); o=o+1
          t:add(f_sig_id,  buf(o,1)); o=o+1
          t:add(f_sig_prm, buf(o,1)); o=o+1
          t:add(f_sid,     buf(o,8)); o=o+8
          t:add(f_seq,     buf(o,8)); o=o+8
          t:add(f_epoch,   buf(o,1)); o=o+1
        end
        local udp_table = DissectorTable.get("udp.port")
        -- you can: udp_table:add(5810, p) etc.
    """, force)

    # ---------- benchmarks ----------
    wrote += write(ROOT / "benchmarks" / "matrix.yaml", """
        defaults:
          payloads: [64,256,512,1024]
          suites:
            - cs-kyber768-aesgcm-dilithium3
            - cs-kyber512-aesgcm-dilithium2
            - cs-kyber1024-aesgcm-dilithium5
    """, force)
    wrote += write(ROOT / "benchmarks" / "run_matrix.py", """
        def main():
            raise NotImplementedError("Bench harness will be added later; keeping repo honest.")
        if __name__=="__main__": main()
    """, force)

    # ---------- tests: add placeholder for loss/dup/oom (skipped) ----------
    wrote += write(ROOT / "tests" / "test_loss_dup_oom.py", """
        import pytest
        @pytest.mark.skip(reason="Placeholder; to be implemented when netem/backpressure harness is added.")
        def test_loss_dup_oom():
            pass
    """, force)

    # ---------- docs placeholder folder ----------
    wrote += write(ROOT / "docs" / "README.md", """
        This folder will host consolidated Markdown docs migrated from the top-level .txt design notes.
        Keep core/ as the single source of truth for crypto & transport; update docs when the wire changes.
    """, force)

    # ---------- environment.yml skeleton (optional) ----------
    wrote += write(ROOT / "environment.yml", """
        name: pqc-env
        channels: [conda-forge, defaults]
        dependencies:
          - python>=3.10
          - pip
          - pip:
              - cryptography>=41
              - oqs-python
              - pytest
    """, force)

    print(f"\nDone. Created/updated ~{wrote} files.")
    print("Launch examples:\n  python gcs/wrappers/gcs_kyber_768.py\n  python drone/wrappers/drone_kyber_768.py")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--force", action="store_true", help="overwrite existing files")
    args = ap.parse_args()
    sys.exit(main(force=args.force) or 0)

============================================================

FILE 39/47: socket_utils.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\socket_utils.py
Size: 2,295 bytes
Modified: 2025-09-28 18:56:22
------------------------------------------------------------
"""Small socket helpers to ensure sockets are closed on process exit or signals.

Provides open_udp_socket(...) which registers the socket for atexit and signal-driven
cleanup. Designed to be low-risk and dependency-free.
"""
from __future__ import annotations

import atexit
import signal
import socket
from typing import List, Optional

# Global registry of sockets to close on exit
_REG_SOCKS: List[socket.socket] = []


def _close_registered() -> None:
    # Close all sockets that are still open
    for s in list(_REG_SOCKS):
        try:
            s.close()
        except Exception:
            pass
    _REG_SOCKS.clear()


# Register atexit cleanup and signal handlers (best-effort)
atexit.register(_close_registered)


def _signal_handler(signum, frame):
    # Best-effort: close sockets and continue shutdown
    _close_registered()


# Install handlers for common signals where available
try:
    signal.signal(signal.SIGINT, _signal_handler)
except Exception:
    pass

try:
    if hasattr(signal, 'SIGTERM'):
        signal.signal(signal.SIGTERM, _signal_handler)
except Exception:
    pass


def open_udp_socket(host: str, port: int, timeout: Optional[float] = None, reuseaddr: bool = True) -> socket.socket:
    """Create, bind and return a UDP socket and register it for cleanup.

    The returned socket is ready to use. Close it with close_socket(sock) when
    you no longer need it to avoid relying on atexit cleanup.
    """
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        if reuseaddr:
            try:
                s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            except Exception:
                pass
        s.bind((host, port))
        if timeout is not None:
            s.settimeout(timeout)
        _REG_SOCKS.append(s)
        return s
    except Exception:
        try:
            s.close()
        except Exception:
            pass
        raise


def close_socket(s: socket.socket) -> None:
    """Close socket and unregister it from the cleanup list."""
    try:
        if s in _REG_SOCKS:
            _REG_SOCKS.remove(s)
    except Exception:
        pass
    try:
        s.close()
    except Exception:
        pass

============================================================

FILE 40/47: traffic_common.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_common.py
Size: 3,551 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""Shared helpers for traffic generators that exercise the plaintext sides of the PQC proxy."""
from __future__ import annotations

import json
import os
import selectors
import socket
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Callable, Dict, Literal, Tuple

from core.config import CONFIG

Role = Literal["gcs", "drone"]


def _timestamp() -> str:
    """Return an ISO-8601 timestamp with UTC timezone."""
    return datetime.now(timezone.utc).isoformat()


def load_ports_and_hosts(role: Role) -> Dict[str, object]:
    """Return resolved host/port information for the given role.

    All values originate from ``core.config.CONFIG`` after environment overrides
    have been applied. The returned dictionary contains:

    ``local_listen_ip`` – interface to bind UDP receivers (default ``0.0.0.0``).
    ``tx_addr`` – tuple of (host, port) for sending plaintext to the local proxy.
    ``rx_bind`` – tuple for binding the UDP receive socket.
    ``peer_role`` – the opposite role string.
    """

    role_upper = role.upper()
    peer_role = "drone" if role == "gcs" else "gcs"

    host_key_tx = f"{role_upper}_PLAINTEXT_HOST"
    host_key_rx = host_key_tx
    tx_port_key = f"{role_upper}_PLAINTEXT_TX"
    rx_port_key = f"{role_upper}_PLAINTEXT_RX"

    tx_host = CONFIG[host_key_tx]
    rx_host = CONFIG[host_key_rx]
    tx_port = CONFIG[tx_port_key]
    rx_port = CONFIG[rx_port_key]

    return {
        "local_listen_ip": os.environ.get("PQC_TRAFFIC_LISTEN_IP", "0.0.0.0"),
        "tx_addr": (tx_host, tx_port),
        "rx_bind": (os.environ.get("PQC_TRAFFIC_BIND_HOST", rx_host), rx_port),
        "peer_role": peer_role,
        "role_host": tx_host,
    }


def open_udp_socket(rx_bind: Tuple[str, int]) -> socket.socket:
    """Create a non-blocking UDP socket bound to ``rx_bind``."""
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    except OSError:
        pass  # Not supported on all platforms (e.g., Windows prior to 10)
    sock.bind(rx_bind)
    sock.setblocking(False)
    return sock


def ndjson_logger(path: Path) -> Tuple[Callable[[Dict[str, object]], None], Callable[[], None]]:
    """Return a simple NDJSON logger factory returning (log_fn, close_fn)."""
    path.parent.mkdir(parents=True, exist_ok=True)
    fp = path.open("a", encoding="utf-8")

    def log(event: Dict[str, object]) -> None:
        payload = {"ts": _timestamp(), **event}
        fp.write(json.dumps(payload, separators=(",", ":")) + "\n")
        fp.flush()

    def close() -> None:
        fp.flush()
        os.fsync(fp.fileno())
        fp.close()

    return log, close


class TokenBucket:
    """Simple token bucket rate limiter."""

    def __init__(self, rate_per_sec: float) -> None:
        self.rate = max(rate_per_sec, 0.0)
        self.tokens = 0.0
        self.last = time.monotonic()

    def consume(self, now: float) -> bool:
        if self.rate <= 0:
            return True
        self.tokens = min(self.rate, self.tokens + (now - self.last) * self.rate)
        self.last = now
        if self.tokens >= 1.0:
            self.tokens -= 1.0
            return True
        return False


def configured_selector(sock: socket.socket) -> selectors.BaseSelector:
    sel = selectors.DefaultSelector()
    sel.register(sock, selectors.EVENT_READ)
    return sel


============================================================

FILE 41/47: traffic_drone.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_drone.py
Size: 206 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""CLI entry point for the drone traffic generator."""
from __future__ import annotations

import sys

from tools.traffic_runner import run


if __name__ == "__main__":
    sys.exit(run("drone"))

============================================================

FILE 42/47: traffic_gcs.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_gcs.py
Size: 202 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""CLI entry point for the GCS traffic generator."""
from __future__ import annotations

import sys

from tools.traffic_runner import run


if __name__ == "__main__":
    sys.exit(run("gcs"))

============================================================

FILE 43/47: traffic_runner.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_runner.py
Size: 7,778 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""Shared runner for automated plaintext traffic generators."""
from __future__ import annotations

import argparse
import json
import socket
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Optional

from tools.traffic_common import (
    TokenBucket,
    configured_selector,
    load_ports_and_hosts,
    ndjson_logger,
    open_udp_socket,
)


def iso_now() -> str:
    return datetime.now(timezone.utc).isoformat()


def _build_parser(role: str) -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog=f"traffic_{role}",
        description="Generate UDP plaintext traffic for the PQC proxy.",
    )
    parser.add_argument("--count", type=int, default=200, help="Total messages to send (default: 200)")
    parser.add_argument("--rate", type=float, default=50.0, help="Maximum send rate in packets/sec (default: 50)")
    parser.add_argument(
        "--duration",
        type=float,
        default=None,
        help="Optional duration cap in seconds. When omitted, exits after sending all messages and an idle grace period.",
    )
    parser.add_argument("--out", type=Path, default=None, help="Path for NDJSON event log")
    parser.add_argument("--summary", type=Path, default=None, help="Path for JSON summary output")
    parser.add_argument("--peer-hint", type=str, default=None, help="Annotate payloads with expected peer role")
    parser.add_argument(
        "--payload-bytes",
        type=int,
        default=0,
        help="Optional number of '.' bytes appended to each payload for throughput testing.",
    )
    return parser


def _default_paths(role: str) -> Dict[str, Path]:
    ts = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H-%M-%SZ")
    logs_dir = Path("logs")
    return {
        "out": logs_dir / f"{role}_traffic_{ts}.jsonl",
        "summary": logs_dir / f"{role}_traffic_summary_{ts}.json",
    }


def run(role: str, argv: Optional[list[str]] = None) -> int:
    parser = _build_parser(role)
    args = parser.parse_args(argv)

    defaults = _default_paths(role)
    out_path: Path = args.out or defaults["out"]
    summary_path: Path = args.summary or defaults["summary"]

    settings = load_ports_and_hosts(role)  # type: ignore[arg-type]
    rx_host, rx_port = settings["rx_bind"]  # type: ignore[index]
    rx_sock = open_udp_socket((rx_host, rx_port))
    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    selector = configured_selector(rx_sock)
    bucket = TokenBucket(args.rate)

    log_event, close_log = ndjson_logger(out_path)

    payload_pad = b"." * max(args.payload_bytes, 0)

    start = time.monotonic()
    deadline = start + args.duration if args.duration else None
    last_activity = start
    idle_grace = 1.0

    counters: Dict[str, Optional[object]] = {
        "role": role,
        "peer_role": settings["peer_role"],
        "sent_total": 0,
        "recv_total": 0,
        "first_send_ts": None,
        "last_send_ts": None,
        "first_recv_ts": None,
        "last_recv_ts": None,
        "out_of_order": 0,
        "unique_senders": 0,
        "rx_bytes_total": 0,
        "tx_bytes_total": 0,
    }

    expected_seq: Dict[str, int] = {}
    unique_senders = set()

    seq = 0
    send_done = False

    tx_addr = settings["tx_addr"]  # type: ignore[assignment]

    try:
        while True:
            now = time.monotonic()
            if deadline and now >= deadline:
                break

            if not send_done:
                if seq >= args.count:
                    send_done = True
                else:
                    if bucket.consume(now):
                        seq += 1
                        payload = {
                            "role": role,
                            "seq": seq,
                            "t_send_ns": time.monotonic_ns(),
                        }
                        if args.peer_hint:
                            payload["peer_hint"] = args.peer_hint
                        packet = json.dumps(payload, separators=(",", ":")).encode("utf-8") + payload_pad
                        sent_bytes = tx_sock.sendto(packet, tx_addr)
                        counters["sent_total"] = int(counters["sent_total"]) + 1  # type: ignore[arg-type]
                        counters["tx_bytes_total"] = int(counters["tx_bytes_total"]) + sent_bytes  # type: ignore[arg-type]
                        iso_ts = iso_now()
                        counters["last_send_ts"] = iso_ts
                        if counters["first_send_ts"] is None:
                            counters["first_send_ts"] = iso_ts
                        log_event({"event": "send", "seq": seq, "bytes": sent_bytes})
                        last_activity = now

            timeout = 0.05
            if deadline:
                timeout = max(0.0, min(timeout, deadline - now))

            events = selector.select(timeout)
            if events:
                for _key, _mask in events:
                    try:
                        data, addr = rx_sock.recvfrom(4096)
                    except BlockingIOError:
                        continue
                    now = time.monotonic()
                    last_activity = now
                    counters["recv_total"] = int(counters["recv_total"]) + 1  # type: ignore[arg-type]
                    counters["rx_bytes_total"] = int(counters["rx_bytes_total"]) + len(data)  # type: ignore[arg-type]
                    iso_ts = iso_now()
                    counters["last_recv_ts"] = iso_ts
                    if counters["first_recv_ts"] is None:
                        counters["first_recv_ts"] = iso_ts

                    sender_label = f"{addr[0]}:{addr[1]}"
                    try:
                        message = json.loads(data.decode("utf-8"))
                        sender_label = message.get("role", sender_label)
                        seq_val = message.get("seq")
                        if isinstance(seq_val, int):
                            expected = expected_seq.get(sender_label)
                            if expected is None:
                                expected_seq[sender_label] = seq_val + 1
                            else:
                                if seq_val != expected:
                                    counters["out_of_order"] = int(counters["out_of_order"]) + abs(seq_val - expected)  # type: ignore[arg-type]
                                expected_seq[sender_label] = seq_val + 1
                    except (ValueError, UnicodeDecodeError):
                        message = None

                    unique_senders.add(sender_label)
                    log_payload: Dict[str, object] = {
                        "event": "recv",
                        "bytes": len(data),
                        "from": f"{addr[0]}:{addr[1]}",
                        "sender": sender_label,
                    }
                    if isinstance(message, dict) and "seq" in message:
                        log_payload["seq"] = message["seq"]
                    log_event(log_payload)

            if send_done and not events and not deadline:
                if now - last_activity >= idle_grace:
                    break
    except KeyboardInterrupt:
        pass
    finally:
        selector.close()
        rx_sock.close()
        tx_sock.close()
        close_log()

    counters["unique_senders"] = len(unique_senders)

    summary_path.parent.mkdir(parents=True, exist_ok=True)
    summary_path.write_text(json.dumps(counters, indent=2), encoding="utf-8")
    return 0

============================================================

FILE 44/47: udp_dual_probe.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_dual_probe.py
Size: 5,048 bytes
Modified: 2025-09-26 10:15:21
------------------------------------------------------------
#!/usr/bin/env python3
"""Bi-directional UDP probe to verify ports and paths end-to-end.

Run this on both hosts (GCS and Drone) at the same time. It will:
- Bind a local RX port and print every packet received (with source IP:port).
- Periodically send numbered messages to the peer's RX port.
- Log exactly which local ephemeral source port each message leaves from.

Defaults are taken from core.config.CONFIG for the encrypted path (UDP_GCS_RX/UDP_DRONE_RX)
so you can prove the tunnel ports themselves are reachable. You can target plaintext
ports as well with --mode plaintext.

Examples:
  # GCS side (listens on UDP_GCS_RX, sends to DRONE_HOST:UDP_DRONE_RX)
  python tools/udp_dual_probe.py --role gcs --mode encrypted

  # Drone side (listens on UDP_DRONE_RX, sends to GCS_HOST:UDP_GCS_RX)
  python tools/udp_dual_probe.py --role drone --mode encrypted

Stop with Ctrl+C.
"""

from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            p = str(parent)
            if p not in sys.path:
                sys.path.insert(0, p)
            break
    except Exception:
        pass

from core.config import CONFIG


def build_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="Bi-directional UDP probe")
    ap.add_argument("--role", choices=["gcs", "drone"], required=True)
    ap.add_argument("--mode", choices=["encrypted", "plaintext"], default="encrypted")
    ap.add_argument("--interval", type=float, default=1.0, help="Seconds between sends")
    ap.add_argument("--count", type=int, default=10, help="Messages to send before exit (0 = infinite)")
    return ap.parse_args()


essential = {
    "gcs": {
        "encrypted_rx": int(CONFIG["UDP_GCS_RX"]),
        "plaintext_tx": int(CONFIG["GCS_PLAINTEXT_TX"]),
        "plaintext_rx": int(CONFIG["GCS_PLAINTEXT_RX"]),
        "peer_host": CONFIG["DRONE_HOST"],
        "peer_encrypted_rx": int(CONFIG["UDP_DRONE_RX"]),
    },
    "drone": {
        "encrypted_rx": int(CONFIG["UDP_DRONE_RX"]),
        "plaintext_tx": int(CONFIG["DRONE_PLAINTEXT_TX"]),
        "plaintext_rx": int(CONFIG["DRONE_PLAINTEXT_RX"]),
        "peer_host": CONFIG["GCS_HOST"],
        "peer_encrypted_rx": int(CONFIG["UDP_GCS_RX"]),
    },
}


def run_probe(role: str, mode: str, interval: float, count: int) -> None:
    cfg = essential[role]

    if mode == "encrypted":
        local_rx_port = cfg["encrypted_rx"]
        peer_host = cfg["peer_host"]
        peer_rx_port = cfg["peer_encrypted_rx"]
        label = "ENC"
    else:
        # plaintext runs on loopback only for each host
        local_rx_port = cfg["plaintext_rx"]
        peer_host = "127.0.0.1"
        peer_rx_port = cfg["plaintext_tx"]
        label = "PTX"

    print(f"[{role.upper()}][{label}] RX bind on 0.0.0.0:{local_rx_port}")
    print(f"[{role.upper()}][{label}] Will send to {peer_host}:{peer_rx_port}")

    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind(("0.0.0.0", local_rx_port))
    rx.settimeout(0.2)

    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    # For visibility, bind tx to an ephemeral port so we know the source
    tx.bind(("0.0.0.0", 0))

    stop = threading.Event()

    def receiver() -> None:
        while not stop.is_set():
            try:
                data, addr = rx.recvfrom(2048)
            except socket.timeout:
                continue
            except OSError:
                break
            ts = time.strftime("%H:%M:%S")
            print(f"[{role.upper()}][{label}][{ts}] RX {len(data)}B from {addr[0]}:{addr[1]} :: {data[:64]!r}")

    t = threading.Thread(target=receiver, daemon=True)
    t.start()

    try:
        i = 0
        while count == 0 or i < count:
            i += 1
            ts = time.strftime("%H:%M:%S")
            try:
                # Print the local source address/port before sending
                src_host, src_port = tx.getsockname()
                payload = f"{label}_MSG_{i}@{ts}".encode()
                tx.sendto(payload, (peer_host, peer_rx_port))
                print(f"[{role.upper()}][{label}][{ts}] TX {len(payload)}B from {src_host}:{src_port} -> {peer_host}:{peer_rx_port}")
            except Exception as exc:
                print(f"[{role.upper()}][{label}] TX error: {exc}")
                break
            time.sleep(interval)
    except KeyboardInterrupt:
        pass
    finally:
        stop.set()
        t.join(timeout=0.3)
        try:
            rx.close()
            tx.close()
        except OSError:
            pass


if __name__ == "__main__":
    args = build_args()
    run_probe(args.role, args.mode, args.interval, args.count)

============================================================

FILE 45/47: udp_echo.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_echo.py
Size: 2,558 bytes
Modified: 2025-09-28 19:05:13
------------------------------------------------------------
#!/usr/bin/env python3
"""Simple UDP echo server for local testing.

Usage: python tools/udp_echo.py --host 127.0.0.1 --port 47001
"""
import argparse
import signal
import socket
import threading
import time
import sys
from pathlib import Path

# Ensure repository root is on sys.path when executed directly so
# imports like 'from tools.socket_utils import ...' succeed.
_HERE = Path(__file__).resolve()
_REPO = _HERE.parent.parent
if str(_REPO) not in sys.path:
    sys.path.insert(0, str(_REPO))

from tools.socket_utils import open_udp_socket, close_socket


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--host', default='192.168.0.101')
    p.add_argument('--port', type=int, default=47001)
    p.add_argument('--timeout', type=float, default=1.0,
                   help='socket recv timeout in seconds (used for responsive shutdown)')
    args = p.parse_args()

    stop_event = threading.Event()

    def _handle_signal(signum, frame):
        print(f'received signal {signum}, shutting down...')
        stop_event.set()

    # install signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, _handle_signal)
    try:
        signal.signal(signal.SIGTERM, _handle_signal)
    except AttributeError:
        # SIGTERM may not exist on some platforms (e.g., Windows old py versions)
        pass

    s = None
    try:
        s = open_udp_socket(args.host, args.port, timeout=args.timeout)
        print(f'UDP echo server listening on {args.host}:{args.port} (timeout={args.timeout}s)')

        while not stop_event.is_set():
            try:
                data, addr = s.recvfrom(65536)
            except socket.timeout:
                # loop again, checking stop_event so Ctrl-C is responsive
                continue
            except OSError:
                # socket closed from another thread or during shutdown
                break

            # echo back exactly what we received
            try:
                s.sendto(data, addr)
            except OSError:
                # peer gone or socket closed, ignore and continue
                continue

    except Exception as exc:
        print(f'udp_echo encountered error: {exc}')
    finally:
        if s is not None:
            try:
                close_socket(s)
            except Exception:
                pass
        # give a moment for prints to flush
        time.sleep(0.05)
        print('udp_echo exiting')


if __name__ == '__main__':
    main()

============================================================

FILE 46/47: udp_echo_server.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_echo_server.py
Size: 2,488 bytes
Modified: 2025-09-26 09:59:28
------------------------------------------------------------
#!/usr/bin/env python3
r"""Simple UDP echo server to test network connectivity.

This replaces the complex pktmon capture with a basic UDP listener that
will tell us definitively if packets are reaching the Windows machine.
"""

from __future__ import annotations

import argparse
import socket
import sys
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG


def main() -> None:
    parser = argparse.ArgumentParser(description="UDP Echo Server for Firewall Testing")
    parser.add_argument("--port", type=int, default=CONFIG["UDP_GCS_RX"], help="UDP port to listen on")
    parser.add_argument("--host", default="0.0.0.0", help="Host IP to bind to")
    parser.add_argument("--timeout", type=int, default=30, help="Timeout in seconds")
    args = parser.parse_args()

    print(f"--- UDP Echo Server ---")
    print(f"🚀 Listening for UDP packets on {args.host}:{args.port} for {args.timeout} seconds...")
    print(f"Send a packet from the Pi with: echo 'TEST' | nc -u -w1 <GCS_IP> {args.port}")

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
        try:
            s.bind((args.host, args.port))
            s.settimeout(args.timeout)
            
            while True:
                try:
                    data, addr = s.recvfrom(2048)
                    timestamp = time.strftime("%H:%M:%S")
                    print(f"\n✅ [{timestamp}] Received '{data.decode()}' from {addr[0]}:{addr[1]}")
                    
                    # Echo back
                    s.sendto(b"ECHO:" + data, addr)
                    print(f"🚀 Echoed back to sender")
                except socket.timeout:
                    print("\n⏰ Timeout reached. No packets received.")
                    break
                except KeyboardInterrupt:
                    print("\n🛑 Stopped by user.")
                    break

        except Exception as e:
            print(f"\n❌ FAILED: {e}")
            return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 47/47: udp_forward_log.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_forward_log.py
Size: 2,796 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""UDP forwarder that logs PQC header metadata while keeping traffic flowing."""

from __future__ import annotations

import argparse
import socket
import struct
import time

HEADER_STRUCT = "!BBBBB8sQB"
HEADER_LEN = struct.calcsize(HEADER_STRUCT)


def parse_header(data: bytes):
    if len(data) < HEADER_LEN:
        return None
    try:
        version, kem_id, kem_param, sig_id, sig_param, session_id, seq, epoch = struct.unpack(
            HEADER_STRUCT, data[:HEADER_LEN]
        )
        return {
            "version": version,
            "kem": (kem_id, kem_param),
            "sig": (sig_id, sig_param),
            "session_id": session_id.hex(),
            "seq": seq,
            "epoch": epoch,
        }
    except Exception:
        return None


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="UDP forwarder with PQC header logging")
    parser.add_argument("--listen", required=True, help="host:port to bind (e.g., 0.0.0.0:46012)")
    parser.add_argument("--forward", required=True, help="host:port to forward to (e.g., 127.0.0.1:56012)")
    parser.add_argument("--label", default="tap", help="Log label for output prefix")
    return parser


def parse_host_port(value: str) -> tuple[str, int]:
    host, port_str = value.rsplit(":", 1)
    return host, int(port_str)


def main() -> None:
    args = build_parser().parse_args()
    listen_host, listen_port = parse_host_port(args.listen)
    forward_host, forward_port = parse_host_port(args.forward)

    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    try:
        rx.bind((listen_host, listen_port))
        print(f"[{args.label}] listening on {listen_host}:{listen_port} -> forwarding to {forward_host}:{forward_port}")

        while True:
            data, addr = rx.recvfrom(65535)
            meta = parse_header(data)
            ts = time.strftime("%H:%M:%S")
            if meta:
                print(
                    f"[{ts}][{args.label}] {len(data)}B from {addr[0]}:{addr[1]} "
                    f"hdr={{'version': {meta['version']}, 'kem': {meta['kem']}, 'sig': {meta['sig']}, "
                    f"'session_id': '{meta['session_id']}', 'seq': {meta['seq']}, 'epoch': {meta['epoch']}}}"
                )
            else:
                print(
                    f"[{ts}][{args.label}] {len(data)}B from {addr[0]}:{addr[1]} hdr=? first16={data[:16].hex()}"
                )
            tx.sendto(data, (forward_host, forward_port))
    except KeyboardInterrupt:
        pass
    finally:
        rx.close()
        tx.close()


if __name__ == "__main__":
    main()

============================================================

================================================================================
END OF LOG
================================================================================
