PROJECT STRUCTURE AND PYTHON FILES LOG
================================================================================
Root Directory: C:\Users\burak\Desktop\research\tools\auto
Output File: C:\Users\burak\Desktop\research\tools\auto\project_structure_20251005_040330.txt
Generated: 2025-10-05 04:03:30
================================================================================

================================================================================
DIRECTORY TREE STRUCTURE
================================================================================
Root Directory: C:\Users\burak\Desktop\research\tools\auto
Generated: 2025-10-05 04:03:30

├── __pycache__/
│   ├── drone_follower.cpython-313.pyc (70,395 bytes)
│   ├── drone_follower_simple.cpython-313.pyc (8,744 bytes)
│   ├── drone_scheduler.cpython-313.pyc (62,246 bytes)
│   ├── gcs_follower.cpython-313.pyc (37,461 bytes)
│   ├── gcs_scheduler.cpython-313.pyc (65,112 bytes)
│   ├── gcs_scheduler_quickpass.cpython-313.pyc (13,480 bytes)
│   └── gcs_scheduler_simple.cpython-313.pyc (15,352 bytes)
├── consolidate_json_logs.py (3,339 bytes)
├── drone_follower copy.py (12,270 bytes)
├── drone_follower.py (53,188 bytes)
├── drone_follower_simple.py (4,865 bytes)
├── drone_scheduler.py (42,605 bytes)
├── gcs_follower.py (24,003 bytes)
├── gcs_scheduler copy.py (16,757 bytes)
├── gcs_scheduler.py (46,297 bytes)
├── gcs_scheduler_quickpass.py (7,899 bytes)
├── gcs_scheduler_simple.py (9,391 bytes)
└── project_structure_20251005_040330.txt (0 bytes)


================================================================================
PYTHON FILE CONTENTS
================================================================================

Found 10 Python files:
   1. consolidate_json_logs.py
   2. drone_follower copy.py
   3. drone_follower.py
   4. drone_follower_simple.py
   5. drone_scheduler.py
   6. gcs_follower.py
   7. gcs_scheduler copy.py
   8. gcs_scheduler.py
   9. gcs_scheduler_quickpass.py
  10. gcs_scheduler_simple.py

--------------------------------------------------------------------------------

FILE 1/10: consolidate_json_logs.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\consolidate_json_logs.py
Size: 3,339 bytes
Modified: 2025-09-29 15:47:53
------------------------------------------------------------
#!/usr/bin/env python3
"""
Consolidate JSON logs into a single text file.

Usage:
    python consolidate_json_logs.py <root_dir> <output_file>

Example:
    python tools/auto/consolidate_json_logs.py logs/auto/drone consolidated_drone_logs.txt

The script walks `root_dir` recursively, finds files ending in `.json` (case-insensitive), and writes a single
text file with entries like:

---
Folder: <relative/folder/path>
File: <filename.json>
Size: 1234 bytes
Modified: 2025-09-29 09:00:00

<pretty-printed JSON or raw content>
---

If a file is not valid JSON, the raw file contents are included (with non-UTF8 bytes replaced).
"""

from __future__ import annotations
import sys
import json
from pathlib import Path
from datetime import datetime


def consolidate(root: Path, out_file: Path, skip_dirs: set[str] | None = None):
    if skip_dirs is None:
        skip_dirs = set()

    json_files = []
    for p in sorted(root.rglob('*.json')):
        # skip files in hidden dirs or in skip_dirs
        if any(part.startswith('.') for part in p.parts):
            continue
        if any(part in skip_dirs for part in p.parts):
            continue
        json_files.append(p)

    if not json_files:
        print(f"No JSON files found under {root}")
        return

    with out_file.open('w', encoding='utf-8') as out:
        out.write(f"Consolidated JSON logs from: {root}\n")
        out.write(f"Generated: {datetime.now().isoformat()}\n")
        out.write('=' * 80 + '\n\n')

        for i, p in enumerate(json_files, 1):
            rel_folder = p.parent.relative_to(root)
            out.write('-' * 60 + '\n')
            out.write(f"Entry {i}/{len(json_files)}\n")
            out.write(f"Folder: {rel_folder}\n")
            out.write(f"File: {p.name}\n")
            try:
                st = p.stat()
                out.write(f"Size: {st.st_size} bytes\n")
                out.write(f"Modified: {datetime.fromtimestamp(st.st_mtime).isoformat()}\n")
            except Exception as e:
                out.write(f"[Error getting file stat: {e}]\n")

            out.write('\n')
            try:
                raw = p.read_bytes()
                try:
                    text = raw.decode('utf-8')
                except Exception:
                    text = raw.decode('utf-8', errors='replace')

                # Try to parse JSON and pretty-print
                try:
                    obj = json.loads(text)
                    pretty = json.dumps(obj, indent=2, ensure_ascii=False)
                    out.write(pretty + '\n')
                except Exception:
                    out.write(text + '\n')

            except Exception as e:
                out.write(f"[Error reading file: {e}]\n")

            out.write('\n')

    print(f"Wrote consolidated log to: {out_file}")


def main(argv: list[str]):
    if len(argv) < 3:
        print("Usage: consolidate_json_logs.py <root_dir> <output_file>")
        return
    root = Path(argv[1]).resolve()
    out = Path(argv[2]).resolve()
    if not root.exists() or not root.is_dir():
        print(f"Error: root dir {root} does not exist or is not a directory")
        return

    consolidate(root, out)


if __name__ == '__main__':
    main(sys.argv)

============================================================

FILE 2/10: drone_follower copy.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_follower copy.py
Size: 12,270 bytes
Modified: 2025-09-29 10:04:11
------------------------------------------------------------
#!/usr/bin/env python3
"""Drone follower/loopback agent driven entirely by core configuration.

This script launches the drone proxy, exposes the TCP control channel for the
GCS scheduler, and runs the plaintext UDP echo used to validate the encrypted
path. All network endpoints originate from :mod:`core.config`. Test behaviour
can be tuned via optional CLI flags (e.g. to disable perf monitors), but no
network parameters are duplicated here.
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path
# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import json
import os
import shlex
import signal
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Callable, Optional

from core.config import CONFIG
from core import suites as suites_mod


CONTROL_HOST = CONFIG.get("DRONE_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_BIND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("DRONE_PLAINTEXT_RX", 47004))
APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("DRONE_PLAINTEXT_TX", 47003))

DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

OUTDIR = Path("logs/auto/drone")
MARK_DIR = OUTDIR / "marks"
SECRETS_DIR = Path("secrets/matrix")

PERF_EVENTS = "task-clock,cycles,instructions,cache-misses,context-switches"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def popen(cmd, **kw) -> subprocess.Popen:
    if isinstance(cmd, (list, tuple)):
        display = " ".join(shlex.quote(str(part)) for part in cmd)
    else:
        display = str(cmd)
    print(f"[{ts()}] exec: {display}", flush=True)
    return subprocess.Popen(cmd, **kw)


def killtree(proc: Optional[subprocess.Popen]) -> None:
    if not proc or proc.poll() is not None:
        return
    try:
        proc.terminate()
        proc.wait(timeout=3)
    except Exception:
        try:
            proc.kill()
        except Exception:
            pass


def discover_initial_suite() -> str:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if configured:
        return configured

    suite_map = suites_mod.list_suites()
    if suite_map:
        return sorted(suite_map.keys())[0]

    if SECRETS_DIR.exists():
        for path in sorted(SECRETS_DIR.iterdir()):
            if (path / "gcs_signing.pub").exists():
                return path.name

    return "cs-mlkem768-aesgcm-mldsa65"


def suite_outdir(suite: str) -> Path:
    path = OUTDIR / suite
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_secrets_dir(suite: str) -> Path:
    return SECRETS_DIR / suite


def write_marker(suite: str) -> None:
    MARK_DIR.mkdir(parents=True, exist_ok=True)
    marker = MARK_DIR / f"{int(time.time())}_{suite}.json"
    with open(marker, "w", encoding="utf-8") as handle:
        json.dump({"ts": ts(), "suite": suite}, handle)


def start_drone_proxy(suite: str) -> subprocess.Popen:
    suite_dir = suite_secrets_dir(suite)
    pub = suite_dir / "gcs_signing.pub"
    if not pub.exists():
        print(f"[follower] ERROR: missing {pub}", file=sys.stderr)
        sys.exit(2)

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    suite_path = suite_outdir(suite)
    status = suite_path / "drone_status.json"
    summary = suite_path / "drone_summary.json"
    OUTDIR.mkdir(parents=True, exist_ok=True)
    log_path = OUTDIR / f"drone_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8")

    print(f"[follower] launching drone proxy on suite {suite}", flush=True)
    return popen([
        sys.executable,
        "-m",
        "core.run_proxy",
        "drone",
        "--suite",
        suite,
        "--peer-pubkey-file",
        str(pub),
        "--status-file",
        str(status),
        "--json-out",
        str(summary),
    ], stdout=log_handle, stderr=subprocess.STDOUT, text=True)


class UdpEcho(threading.Thread):
    def __init__(self, bind_host: str, recv_port: int, send_host: str, send_port: int, stop_event: threading.Event):
        super().__init__(daemon=True)
        self.bind_host = bind_host
        self.recv_port = recv_port
        self.send_host = send_host
        self.send_port = send_port
        self.stop_event = stop_event
        self.rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx_sock.bind((self.bind_host, self.recv_port))

    def run(self) -> None:
        print(
            f"[follower] UDP echo up: recv:{self.bind_host}:{self.recv_port} -> send:{self.send_host}:{self.send_port}",
            flush=True,
        )
        self.rx_sock.settimeout(0.5)
        while not self.stop_event.is_set():
            try:
                data, _ = self.rx_sock.recvfrom(65535)
                self.tx_sock.sendto(data, (self.send_host, self.send_port))
            except socket.timeout:
                continue
            except Exception as exc:
                print(f"[follower] UDP echo error: {exc}", flush=True)
        self.rx_sock.close()
        self.tx_sock.close()


class Monitors:
    def __init__(self, enabled: bool):
        self.enabled = enabled
        self.perf: Optional[subprocess.Popen] = None
        self.pidstat: Optional[subprocess.Popen] = None

    def start(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            return
        outdir.mkdir(parents=True, exist_ok=True)
        perf_cmd = f"perf stat -I 1000 -e {PERF_EVENTS} -p {pid} --log-fd 1"
        self.perf = popen(shlex.split(perf_cmd), stdout=open(outdir / f"perf_{suite}.csv", "w"), stderr=subprocess.STDOUT)
        self.pidstat = popen([
            "pidstat",
            "-hlur",
            "-p",
            str(pid),
            "1",
        ], stdout=open(outdir / f"pidstat_{suite}.txt", "w"), stderr=subprocess.STDOUT)

    def rotate(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            write_marker(suite)
            return
        self.stop()
        self.start(pid, outdir, suite)
        write_marker(suite)

    def stop(self) -> None:
        if not self.enabled:
            return
        killtree(self.perf)
        killtree(self.pidstat)
        self.perf = None
        self.pidstat = None


class ControlServer(threading.Thread):
    """Line-delimited JSON control server for the scheduler."""

    def __init__(self, host: str, port: int, state: dict):
        super().__init__(daemon=True)
        self.host = host
        self.port = port
        self.state = state
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.sock.bind((self.host, self.port))
        self.sock.listen(5)

    def run(self) -> None:
        print(f"[follower] control listening on {self.host}:{self.port}", flush=True)
        while not self.state["stop_event"].is_set():
            try:
                self.sock.settimeout(0.5)
                conn, _addr = self.sock.accept()
            except socket.timeout:
                continue
            threading.Thread(target=self.handle, args=(conn,), daemon=True).start()
        self.sock.close()

    def handle(self, conn: socket.socket) -> None:
        try:
            line = conn.makefile().readline()
            request = json.loads(line.strip()) if line else {}
        except Exception:
            request = {}

        try:
            cmd = request.get("cmd")
            if cmd == "ping":
                self._send(conn, {"ok": True, "ts": ts()})
                return
            if cmd == "status":
                proxy = self.state["proxy"]
                running = bool(proxy and proxy.poll() is None)
                self._send(
                    conn,
                    {
                        "ok": True,
                        "suite": self.state["suite"],
                        "proxy_pid": proxy.pid if proxy else None,
                        "running": running,
                        "control_host": self.host,
                        "control_port": self.port,
                        "udp_recv_port": APP_RECV_PORT,
                        "udp_send_port": APP_SEND_PORT,
                        "monitors_enabled": self.state["monitors"].enabled,
                    },
                )
                return
            if cmd == "mark":
                suite = request.get("suite")
                if not suite:
                    self._send(conn, {"ok": False, "error": "missing suite"})
                    return
                proxy = self.state["proxy"]
                if not proxy or proxy.poll() is not None:
                    self._send(conn, {"ok": False, "error": "proxy not running"})
                    return
                self.state["suite"] = suite
                outdir = self.state["suite_outdir"](suite)
                self.state["monitors"].rotate(proxy.pid, outdir, suite)
                self._send(conn, {"ok": True, "marked": suite})
                return
            if cmd == "stop":
                self.state["monitors"].stop()
                self.state["stop_event"].set()
                self._send(conn, {"ok": True, "stopping": True})
                return
            self._send(conn, {"ok": False, "error": "unknown_cmd"})
        finally:
            try:
                conn.close()
            except Exception:
                pass

    @staticmethod
    def _send(conn: socket.socket, obj: dict) -> None:
        conn.sendall((json.dumps(obj) + "\n").encode())


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    MARK_DIR.mkdir(parents=True, exist_ok=True)

    default_suite = discover_initial_suite()

    parser = argparse.ArgumentParser(description="Drone follower driven by core configuration")
    parser.add_argument(
        "--initial-suite",
        default=default_suite,
        help="Initial suite to launch (default: discover from config/secrets)",
    )
    parser.add_argument(
        "--disable-monitors",
        action="store_true",
        help="Disable perf/pidstat monitors",
    )
    args = parser.parse_args()

    initial_suite = args.initial_suite
    stop_event = threading.Event()

    proxy = start_drone_proxy(initial_suite)
    monitors = Monitors(enabled=not args.disable_monitors)
    time.sleep(1)
    if proxy.poll() is None:
        monitors.start(proxy.pid, suite_outdir(initial_suite), initial_suite)

    echo = UdpEcho(APP_BIND_HOST, APP_RECV_PORT, APP_SEND_HOST, APP_SEND_PORT, stop_event)
    echo.start()

    state = {
        "proxy": proxy,
        "suite": initial_suite,
        "suite_outdir": suite_outdir,
        "monitors": monitors,
        "stop_event": stop_event,
    }
    control = ControlServer(CONTROL_HOST, CONTROL_PORT, state)
    control.start()

    try:
        while not stop_event.is_set():
            if proxy.poll() is not None:
                print(f"[follower] proxy exited with {proxy.returncode}", flush=True)
                stop_event.set()
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        stop_event.set()
    finally:
        monitors.stop()
        killtree(proxy)
        try:
            proxy.send_signal(signal.SIGTERM)
        except Exception:
            pass


if __name__ == "__main__":
    main()

============================================================

FILE 3/10: drone_follower.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_follower.py
Size: 53,188 bytes
Modified: 2025-10-05 02:04:56
------------------------------------------------------------
#!/usr/bin/env python3
"""Drone follower/loopback agent driven entirely by core configuration.

This script launches the drone proxy, exposes the TCP control channel for the
GCS scheduler, and runs the plaintext UDP echo used to validate the encrypted
path. All network endpoints originate from :mod:`core.config`. Test behaviour
can be tuned via optional CLI flags (e.g. to disable perf monitors), but no
network parameters are duplicated here.
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path
# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import csv
import json
import os
import shlex
import signal
import socket
import struct
import subprocess
import threading
import time
import queue
from typing import Optional
def optimize_cpu_performance(target_khz: int = 1800000) -> None:
    governors = list(Path("/sys/devices/system/cpu").glob("cpu[0-9]*/cpufreq"))
    for governor_dir in governors:
        gov = governor_dir / "scaling_governor"
        min_freq = governor_dir / "scaling_min_freq"
        max_freq = governor_dir / "scaling_max_freq"
        try:
            if gov.exists():
                gov.write_text("performance\n", encoding="utf-8")
            if min_freq.exists():
                min_freq.write_text(f"{target_khz}\n", encoding="utf-8")
            if max_freq.exists():
                current_max = int(max_freq.read_text().strip())
                if current_max < target_khz:
                    max_freq.write_text(f"{target_khz}\n", encoding="utf-8")
        except PermissionError:
            print("[follower] insufficient permissions to adjust CPU governor")
        except Exception as exc:
            print(f"[follower] governor tuning failed: {exc}")


import psutil

from core.config import CONFIG
from core import suites as suites_mod
from core.power_monitor import (
    PowerMonitor,
    PowerMonitorUnavailable,
    PowerSummary,
    create_power_monitor,
)


CONTROL_HOST = CONFIG.get("DRONE_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_BIND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("DRONE_PLAINTEXT_RX", 47004))
APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("DRONE_PLAINTEXT_TX", 47003))

DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

TELEMETRY_DEFAULT_HOST = (
    CONFIG.get("DRONE_TELEMETRY_HOST")
    or CONFIG.get("GCS_HOST")
    or "127.0.0.1"
)
TELEMETRY_DEFAULT_PORT = int(
    CONFIG.get("DRONE_TELEMETRY_PORT")
    or CONFIG.get("GCS_TELEMETRY_PORT")
    or 52080
)

OUTDIR = Path("logs/auto/drone")
MARK_DIR = OUTDIR / "marks"
SECRETS_DIR = Path("secrets/matrix")

DEFAULT_MONITOR_BASE = Path(
    CONFIG.get("DRONE_MONITOR_OUTPUT_BASE")
    or os.getenv("DRONE_MONITOR_OUTPUT_BASE", "/home/dev/research/output/drone")
)
LOG_INTERVAL_MS = 100

PERF_EVENTS = "task-clock,cycles,instructions,cache-misses,branch-misses,context-switches,branches"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


class TelemetryPublisher:
    """Best-effort telemetry pipe from the drone follower to the GCS scheduler."""

    def __init__(self, host: str, port: int, session_id: str) -> None:
        self.host = host
        self.port = port
        self.session_id = session_id
        self.queue: "queue.Queue[dict]" = queue.Queue(maxsize=5000)
        self.stop_event = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=True)
        self.sock: Optional[socket.socket] = None
        self.writer = None

    def start(self) -> None:
        self.thread.start()

    def publish(self, kind: str, payload: dict) -> None:
        if self.stop_event.is_set():
            return
        message = {"session_id": self.session_id, "kind": kind, **payload}
        try:
            self.queue.put_nowait(message)
        except queue.Full:
            # Drop oldest by removing one item to make space, then enqueue.
            try:
                self.queue.get_nowait()
            except queue.Empty:
                pass
            try:
                self.queue.put_nowait(message)
            except queue.Full:
                pass

    def stop(self) -> None:
        self.stop_event.set()
        if self.thread.is_alive():
            self.thread.join(timeout=2.0)
        self._close_socket()

    def _close_socket(self) -> None:
        if self.writer is not None:
            try:
                self.writer.close()
            except Exception:
                pass
            self.writer = None
        if self.sock is not None:
            try:
                self.sock.close()
            except Exception:
                pass
            self.sock = None

    def _ensure_connection(self) -> bool:
        if self.sock is not None and self.writer is not None:
            return True
        try:
            sock = socket.create_connection((self.host, self.port), timeout=3.0)
            self.sock = sock
            self.writer = sock.makefile("w", encoding="utf-8", buffering=1)
            hello = {
                "session_id": self.session_id,
                "kind": "telemetry_hello",
                "timestamp_ns": time.time_ns(),
            }
            self.writer.write(json.dumps(hello) + "\n")
            self.writer.flush()
            return True
        except Exception as exc:
            print(f"[follower] telemetry connect failed: {exc}")
            self._close_socket()
            return False

    def _run(self) -> None:
        backoff = 1.0
        while not self.stop_event.is_set():
            if not self._ensure_connection():
                time.sleep(min(backoff, 5.0))
                backoff = min(backoff * 1.5, 5.0)
                continue
            backoff = 1.0
            try:
                item = self.queue.get(timeout=0.5)
            except queue.Empty:
                continue
            try:
                if self.writer is None:
                    continue
                if "timestamp_ns" not in item:
                    item["timestamp_ns"] = time.time_ns()
                self.writer.write(json.dumps(item) + "\n")
                self.writer.flush()
            except Exception as exc:
                print(f"[follower] telemetry send failed: {exc}")
                self._close_socket()


def _summary_to_dict(summary: PowerSummary, *, suite: str, session_id: str) -> dict:
    return {
        "timestamp_ns": summary.end_ns,
        "suite": suite,
        "label": summary.label,
        "session_id": session_id,
        "duration_s": summary.duration_s,
        "samples": summary.samples,
        "avg_current_a": summary.avg_current_a,
        "avg_voltage_v": summary.avg_voltage_v,
        "avg_power_w": summary.avg_power_w,
        "energy_j": summary.energy_j,
        "sample_rate_hz": summary.sample_rate_hz,
        "csv_path": summary.csv_path,
        "start_ns": summary.start_ns,
        "end_ns": summary.end_ns,
    }


class PowerCaptureManager:
    """Coordinates power captures for control commands."""

    def __init__(
        self,
        output_dir: Path,
        session_id: str,
        telemetry: Optional[TelemetryPublisher],
    ) -> None:
        self.telemetry = telemetry
        self.session_id = session_id
        self.lock = threading.Lock()
        self._thread: Optional[threading.Thread] = None
        self._last_summary: Optional[dict] = None
        self._last_error: Optional[str] = None
        self._pending_suite: Optional[str] = None
        self.monitor: Optional[PowerMonitor] = None

        def _parse_int_env(name: str, default: int) -> int:
            raw = os.getenv(name)
            if not raw:
                return default
            try:
                return int(raw)
            except ValueError:
                print(f"[follower] invalid {name}={raw!r}, using {default}")
                return default

        def _parse_float_env(name: str, default: float) -> float:
            raw = os.getenv(name)
            if not raw:
                return default
            try:
                return float(raw)
            except ValueError:
                print(f"[follower] invalid {name}={raw!r}, using {default}")
                return default

        def _parse_float_optional(name: str) -> Optional[float]:
            raw = os.getenv(name)
            if raw is None or raw == "":
                return None
            try:
                return float(raw)
            except ValueError:
                print(f"[follower] invalid {name}={raw!r}, ignoring")
                return None

        backend = os.getenv("DRONE_POWER_BACKEND", "auto")
        sample_hz = _parse_int_env("DRONE_POWER_SAMPLE_HZ", 1000)
        shunt_ohm = _parse_float_env("DRONE_POWER_SHUNT_OHM", 0.1)
        sign_mode = os.getenv("DRONE_POWER_SIGN_MODE", "auto")
        hwmon_path = os.getenv("DRONE_POWER_HWMON_PATH")
        hwmon_name_hint = os.getenv("DRONE_POWER_HWMON_NAME")
        voltage_file = os.getenv("DRONE_POWER_VOLTAGE_FILE")
        current_file = os.getenv("DRONE_POWER_CURRENT_FILE")
        power_file = os.getenv("DRONE_POWER_POWER_FILE")
        voltage_scale = _parse_float_optional("DRONE_POWER_VOLTAGE_SCALE")
        current_scale = _parse_float_optional("DRONE_POWER_CURRENT_SCALE")
        power_scale = _parse_float_optional("DRONE_POWER_POWER_SCALE")

        try:
            self.monitor = create_power_monitor(
                output_dir,
                backend=backend,
                sample_hz=sample_hz,
                shunt_ohm=shunt_ohm,
                sign_mode=sign_mode,
                hwmon_path=hwmon_path,
                hwmon_name_hint=hwmon_name_hint,
                voltage_file=voltage_file,
                current_file=current_file,
                power_file=power_file,
                voltage_scale=voltage_scale,
                current_scale=current_scale,
                power_scale=power_scale,
            )
            self.available = True
        except PowerMonitorUnavailable as exc:
            self.monitor = None
            self.available = False
            self._last_error = str(exc)
            print(f"[follower] power monitor disabled: {exc}")
        except ValueError as exc:
            self.monitor = None
            self.available = False
            self._last_error = str(exc)
            print(f"[follower] power monitor configuration invalid: {exc}")

    def start_capture(self, suite: str, duration_s: float, start_ns: Optional[int]) -> tuple[bool, Optional[str]]:
        if not self.available or self.monitor is None:
            return False, self._last_error or "power_monitor_unavailable"
        if duration_s <= 0:
            return False, "invalid_duration"
        with self.lock:
            if self._thread and self._thread.is_alive():
                return False, "busy"
            self._last_error = None
            self._pending_suite = suite

            def worker() -> None:
                try:
                    summary = self.monitor.capture(label=suite, duration_s=duration_s, start_ns=start_ns)
                    summary_dict = _summary_to_dict(summary, suite=suite, session_id=self.session_id)
                    summary_json_path = Path(summary.csv_path).with_suffix(".json")
                    try:
                        summary_json_path.write_text(json.dumps(summary_dict, indent=2), encoding="utf-8")
                        summary_dict["summary_json_path"] = str(summary_json_path)
                    except Exception as exc_json:
                        print(f"[follower] power summary write failed: {exc_json}")
                    with self.lock:
                        self._last_summary = summary_dict
                        self._pending_suite = None
                    if self.telemetry:
                        self.telemetry.publish("power_summary", dict(summary_dict))
                except Exception as exc:  # pragma: no cover - depends on hardware
                    with self.lock:
                        self._last_error = str(exc)
                        self._pending_suite = None
                    print(f"[follower] power capture failed: {exc}")
                    if self.telemetry:
                        self.telemetry.publish(
                            "power_summary_error",
                            {
                                "timestamp_ns": time.time_ns(),
                                "suite": suite,
                                "error": str(exc),
                            },
                        )
                finally:
                    with self.lock:
                        self._thread = None

            self._thread = threading.Thread(target=worker, daemon=True)
            self._thread.start()
        return True, None

    def status(self) -> dict:
        with self.lock:
            busy = bool(self._thread and self._thread.is_alive())
            summary = dict(self._last_summary) if self._last_summary else None
            error = self._last_error
            pending_suite = self._pending_suite
        return {
            "available": self.available,
            "busy": busy,
            "last_summary": summary,
            "error": error,
            "pending_suite": pending_suite,
        }



def popen(cmd, **kw) -> subprocess.Popen:
    if isinstance(cmd, (list, tuple)):
        display = " ".join(shlex.quote(str(part)) for part in cmd)
    else:
        display = str(cmd)
    print(f"[{ts()}] exec: {display}", flush=True)
    return subprocess.Popen(cmd, **kw)


def killtree(proc: Optional[subprocess.Popen]) -> None:
    if not proc or proc.poll() is not None:
        return
    try:
        proc.terminate()
        proc.wait(timeout=3)
    except Exception:
        try:
            proc.kill()
        except Exception:
            pass


def discover_initial_suite() -> str:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if configured:
        return configured

    suite_map = suites_mod.list_suites()
    if suite_map:
        return sorted(suite_map.keys())[0]

    if SECRETS_DIR.exists():
        for path in sorted(SECRETS_DIR.iterdir()):
            if (path / "gcs_signing.pub").exists():
                return path.name

    return "cs-mlkem768-aesgcm-mldsa65"


def suite_outdir(suite: str) -> Path:
    path = OUTDIR / suite
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_secrets_dir(suite: str) -> Path:
    return SECRETS_DIR / suite


def write_marker(suite: str) -> None:
    MARK_DIR.mkdir(parents=True, exist_ok=True)
    marker = MARK_DIR / f"{int(time.time())}_{suite}.json"
    with open(marker, "w", encoding="utf-8") as handle:
        json.dump({"ts": ts(), "suite": suite}, handle)


def start_drone_proxy(suite: str) -> subprocess.Popen:
    suite_dir = suite_secrets_dir(suite)
    pub = suite_dir / "gcs_signing.pub"
    if not pub.exists():
        print(f"[follower] ERROR: missing {pub}", file=sys.stderr)
        sys.exit(2)

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    suite_path = suite_outdir(suite)
    status = suite_path / "drone_status.json"
    summary = suite_path / "drone_summary.json"
    OUTDIR.mkdir(parents=True, exist_ok=True)
    log_path = OUTDIR / f"drone_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8")

    print(f"[follower] launching drone proxy on suite {suite}", flush=True)
    return popen([
        sys.executable,
        "-m",
        "core.run_proxy",
        "drone",
        "--suite",
        suite,
        "--peer-pubkey-file",
        str(pub),
        "--status-file",
        str(status),
        "--json-out",
        str(summary),
    ], stdout=log_handle, stderr=subprocess.STDOUT, text=True)


class HighSpeedMonitor(threading.Thread):
    def __init__(
        self,
        output_dir: Path,
        session_id: str,
        publisher: Optional[TelemetryPublisher],
    ):
        super().__init__(daemon=True)
        self.output_dir = output_dir
        self.session_id = session_id
        self.stop_event = threading.Event()
        self.current_suite = "unknown"
        self.proxy_pid: Optional[int] = None
        self.rekey_start_ns: Optional[int] = None
        self.csv_handle: Optional[object] = None
        self.csv_writer: Optional[csv.writer] = None
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.csv_path = self.output_dir / f"system_monitoring_{session_id}.csv"
        self.publisher = publisher

    def attach_proxy(self, pid: int) -> None:
        self.proxy_pid = pid

    def start_rekey(self, old_suite: str, new_suite: str) -> None:
        self.current_suite = new_suite
        self.rekey_start_ns = time.time_ns()
        print(f"[monitor] rekey transition {old_suite} -> {new_suite}")
        if self.publisher:
            self.publisher.publish(
                "rekey_transition_start",
                {
                    "timestamp_ns": self.rekey_start_ns,
                    "old_suite": old_suite,
                    "new_suite": new_suite,
                },
            )

    def end_rekey(self) -> None:
        if self.rekey_start_ns is None:
            return
        duration_ms = (time.time_ns() - self.rekey_start_ns) / 1_000_000
        print(f"[monitor] rekey completed in {duration_ms:.2f} ms")
        if self.publisher:
            self.publisher.publish(
                "rekey_transition_end",
                {
                    "timestamp_ns": time.time_ns(),
                    "suite": self.current_suite,
                    "duration_ms": duration_ms,
                },
            )
        self.rekey_start_ns = None

    def run(self) -> None:
        self.csv_handle = open(self.csv_path, "w", newline="", encoding="utf-8")
        self.csv_writer = csv.writer(self.csv_handle)
        self.csv_writer.writerow(
            [
                "timestamp_iso",
                "timestamp_ns",
                "suite",
                "proxy_pid",
                "cpu_percent",
                "cpu_freq_mhz",
                "cpu_temp_c",
                "mem_used_mb",
                "mem_percent",
                "rekey_duration_ms",
            ]
        )
        interval = LOG_INTERVAL_MS / 1000.0
        while not self.stop_event.is_set():
            start = time.time()
            self._sample()
            elapsed = time.time() - start
            sleep_for = max(0.0, interval - elapsed)
            if sleep_for:
                time.sleep(sleep_for)

    def _sample(self) -> None:
        timestamp_ns = time.time_ns()
        timestamp_iso = time.strftime("%Y-%m-%d %H:%M:%S.%f", time.gmtime(timestamp_ns / 1e9))[:-3]
        cpu_percent = psutil.cpu_percent(interval=None)
        try:
            with open("/sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq", "r", encoding="utf-8") as handle:
                cpu_freq_mhz = int(handle.read().strip()) / 1000.0
        except Exception:
            cpu_freq_mhz = 0.0
        cpu_temp_c = 0.0
        try:
            result = subprocess.run(["vcgencmd", "measure_temp"], capture_output=True, text=True)
            if result.returncode == 0 and "=" in result.stdout:
                cpu_temp_c = float(result.stdout.split("=")[1].split("'" )[0])
        except Exception:
            pass
        mem = psutil.virtual_memory()
        rekey_ms = ""
        if self.rekey_start_ns is not None:
            rekey_ms = f"{(timestamp_ns - self.rekey_start_ns) / 1_000_000:.2f}"
        if self.csv_writer is None:
            return
        self.csv_writer.writerow(
            [
                timestamp_iso,
                str(timestamp_ns),
                self.current_suite,
                self.proxy_pid or "",
                f"{cpu_percent:.1f}",
                f"{cpu_freq_mhz:.1f}",
                f"{cpu_temp_c:.1f}",
                f"{mem.used / (1024 * 1024):.1f}",
                f"{mem.percent:.1f}",
                rekey_ms,
            ]
        )
        self.csv_handle.flush()
        if self.publisher:
            sample = {
                "timestamp_ns": timestamp_ns,
                "timestamp_iso": timestamp_iso,
                "suite": self.current_suite,
                "proxy_pid": self.proxy_pid,
                "cpu_percent": cpu_percent,
                "cpu_freq_mhz": cpu_freq_mhz,
                "cpu_temp_c": cpu_temp_c,
                "mem_used_mb": mem.used / (1024 * 1024),
                "mem_percent": mem.percent,
            }
            if self.rekey_start_ns is not None:
                sample["rekey_elapsed_ms"] = (timestamp_ns - self.rekey_start_ns) / 1_000_000
            self.publisher.publish("system_sample", sample)

    def stop(self) -> None:
        self.stop_event.set()
        if self.is_alive():
            self.join(timeout=2.0)
        if self.csv_handle:
            self.csv_handle.close()


class UdpEcho(threading.Thread):
    def __init__(
        self,
        bind_host: str,
        recv_port: int,
        send_host: str,
        send_port: int,
        stop_event: threading.Event,
        monitor: Optional[HighSpeedMonitor],
        session_dir: Path,
        publisher: Optional[TelemetryPublisher],
    ):
        super().__init__(daemon=True)
        self.bind_host = bind_host
        self.recv_port = recv_port
        self.send_host = send_host
        self.send_port = send_port
        self.stop_event = stop_event
        self.monitor = monitor
        self.session_dir = session_dir
        self.publisher = publisher
        self.rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            sndbuf = int(os.getenv("DRONE_SOCK_SNDBUF", str(16 << 20)))
            rcvbuf = int(os.getenv("DRONE_SOCK_RCVBUF", str(16 << 20)))
            self.rx_sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, rcvbuf)
            self.tx_sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, sndbuf)
        except Exception:
            pass
        self.rx_sock.bind((self.bind_host, self.recv_port))
        self.packet_log_path = self.session_dir / "packet_timing.csv"
        self.packet_log_handle: Optional[object] = None
        self.packet_writer: Optional[csv.writer] = None
        self.samples = 0

    def run(self) -> None:
        print(
            f"[follower] UDP echo up: recv:{self.bind_host}:{self.recv_port} -> send:{self.send_host}:{self.send_port}",
            flush=True,
        )
        self.packet_log_handle = open(self.packet_log_path, "w", newline="", encoding="utf-8")
        self.packet_writer = csv.writer(self.packet_log_handle)
        self.packet_writer.writerow([
            "recv_timestamp_ns",
            "send_timestamp_ns",
            "processing_ns",
            "processing_ms",
            "sequence",
        ])
        self.rx_sock.settimeout(0.001)
        while not self.stop_event.is_set():
            try:
                data, _ = self.rx_sock.recvfrom(65535)
                recv_ns = time.time_ns()
                enhanced = self._annotate_packet(data, recv_ns)
                send_ns = time.time_ns()
                self.tx_sock.sendto(enhanced, (self.send_host, self.send_port))
                self._record_packet(data, recv_ns, send_ns)
            except socket.timeout:
                continue
            except Exception as exc:
                print(f"[follower] UDP echo error: {exc}", flush=True)
        self.rx_sock.close()
        self.tx_sock.close()
        if self.packet_log_handle:
            self.packet_log_handle.close()

    def _annotate_packet(self, data: bytes, recv_ns: int) -> bytes:
        if len(data) >= 20:
            return data[:-8] + recv_ns.to_bytes(8, "big")
        return data + recv_ns.to_bytes(8, "big")

    def _record_packet(self, data: bytes, recv_ns: int, send_ns: int) -> None:
        if self.packet_writer is None or len(data) < 4:
            return
        try:
            seq, = struct.unpack("!I", data[:4])
        except struct.error:
            return
        processing_ns = send_ns - recv_ns
        if seq % 100 == 0:
            self.packet_writer.writerow([
                recv_ns,
                send_ns,
                processing_ns,
                f"{processing_ns / 1_000_000:.6f}",
                seq,
            ])
            # Always flush to prevent data loss on crashes
            if self.packet_log_handle:
                self.packet_log_handle.flush()
            if self.publisher:
                suite = self.monitor.current_suite if self.monitor else "unknown"
                self.publisher.publish(
                    "udp_echo_sample",
                    {
                        "recv_timestamp_ns": recv_ns,
                        "send_timestamp_ns": send_ns,
                        "processing_ns": processing_ns,
                        "sequence": seq,
                        "suite": suite,
                    },
                )



class Monitors:
    """Structured performance/telemetry collectors for the drone proxy."""

    PERF_FIELDS = [
        "ts_unix_ns",
        "t_offset_ms",
        "instructions",
        "cycles",
        "cache-misses",
        "branch-misses",
        "task-clock",
        "context-switches",
        "branches",
    ]

    def __init__(self, enabled: bool, telemetry: Optional[TelemetryPublisher]):
        self.enabled = enabled
        self.telemetry = telemetry
        self.perf: Optional[subprocess.Popen] = None
        self.pidstat: Optional[subprocess.Popen] = None
        self.perf_thread: Optional[threading.Thread] = None
        self.perf_stop = threading.Event()
        self.perf_csv_handle: Optional[object] = None
        self.perf_writer: Optional[csv.DictWriter] = None
        self.perf_start_ns = 0
        self.current_suite = "unknown"

        self.psutil_thread: Optional[threading.Thread] = None
        self.psutil_stop = threading.Event()
        self.psutil_csv_handle: Optional[object] = None
        self.psutil_writer: Optional[csv.DictWriter] = None
        self.psutil_proc: Optional[psutil.Process] = None

        self.temp_thread: Optional[threading.Thread] = None
        self.temp_stop = threading.Event()
        self.temp_csv_handle: Optional[object] = None
        self.temp_writer: Optional[csv.DictWriter] = None

    def start(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            return
        outdir.mkdir(parents=True, exist_ok=True)
        self.current_suite = suite

        # Structured perf samples
        perf_cmd = [
            "perf",
            "stat",
            "-I",
            "1000",
            "-x",
            ",",
            "-e",
            PERF_EVENTS,
            "-p",
            str(pid),
            "--log-fd",
            "1",
        ]
        perf_path = outdir / f"perf_samples_{suite}.csv"
        self.perf_csv_handle = open(perf_path, "w", newline="", encoding="utf-8")
        self.perf_writer = csv.DictWriter(self.perf_csv_handle, fieldnames=self.PERF_FIELDS)
        self.perf_writer.writeheader()
        self.perf_start_ns = time.time_ns()

        self.perf = popen(
            perf_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )
        self.perf_stop.clear()
        self.perf_thread = threading.Thread(
            target=self._consume_perf,
            args=(self.perf.stdout,),
            daemon=True,
        )
        self.perf_thread.start()

        # pidstat baseline dump for parity with legacy tooling
        self.pidstat = popen(
            ["pidstat", "-hlur", "-p", str(pid), "1"],
            stdout=open(outdir / f"pidstat_{suite}.txt", "w"),
            stderr=subprocess.STDOUT,
        )

        # psutil metrics (CPU%, RSS, threads)
        self.psutil_proc = psutil.Process(pid)
        self.psutil_proc.cpu_percent(interval=None)
        psutil_path = outdir / f"psutil_proc_{suite}.csv"
        self.psutil_csv_handle = open(psutil_path, "w", newline="", encoding="utf-8")
        self.psutil_writer = csv.DictWriter(
            self.psutil_csv_handle,
            fieldnames=["ts_unix_ns", "cpu_percent", "rss_bytes", "num_threads"],
        )
        self.psutil_writer.writeheader()
        self.psutil_stop.clear()
        self.psutil_thread = threading.Thread(target=self._psutil_loop, daemon=True)
        self.psutil_thread.start()

        # Temperature / frequency / throttled flags
        temp_path = outdir / f"sys_telemetry_{suite}.csv"
        self.temp_csv_handle = open(temp_path, "w", newline="", encoding="utf-8")
        self.temp_writer = csv.DictWriter(
            self.temp_csv_handle,
            fieldnames=["ts_unix_ns", "temp_c", "freq_hz", "throttled_hex"],
        )
        self.temp_writer.writeheader()
        self.temp_stop.clear()
        self.temp_thread = threading.Thread(target=self._telemetry_loop, daemon=True)
        self.temp_thread.start()

        if self.telemetry:
            self.telemetry.publish(
                "monitors_started",
                {
                    "timestamp_ns": time.time_ns(),
                    "suite": suite,
                    "proxy_pid": pid,
                },
            )

    def _consume_perf(self, stream) -> None:
        if not self.perf_writer:
            return
        current_ms = None
        row = None
        try:
            for line in iter(stream.readline, ""):
                if self.perf_stop.is_set():
                    break
                parts = [part.strip() for part in line.strip().split(",")]
                if len(parts) < 4:
                    continue
                try:
                    offset_ms = float(parts[0])
                except ValueError:
                    continue
                event = parts[3]
                if event.startswith("#"):
                    continue
                try:
                    value = int(parts[1].replace(",", ""))
                except Exception:
                    value = ""

                if current_ms is None or abs(offset_ms - current_ms) >= 0.5:
                    if row:
                        self.perf_writer.writerow(row)
                        self.perf_csv_handle.flush()
                    current_ms = offset_ms
                    row = {field: "" for field in self.PERF_FIELDS}
                    row["t_offset_ms"] = f"{offset_ms:.0f}"
                    row["ts_unix_ns"] = str(self.perf_start_ns + int(offset_ms * 1_000_000))

                key_map = {
                    "instructions": "instructions",
                    "cycles": "cycles",
                    "cache-misses": "cache-misses",
                    "branch-misses": "branch-misses",
                    "task-clock": "task-clock",
                    "context-switches": "context-switches",
                    "branches": "branches",
                }
                column = key_map.get(event)
                if row is not None and column:
                    row[column] = value

            if row:
                self.perf_writer.writerow(row)
                self.perf_csv_handle.flush()
                if self.telemetry:
                    sample = {k: row.get(k, "") for k in self.PERF_FIELDS}
                    sample["suite"] = self.current_suite
                    self.telemetry.publish("perf_sample", sample)
        finally:
            try:
                stream.close()
            except Exception:
                pass

    def _psutil_loop(self) -> None:
        while not self.psutil_stop.is_set():
            try:
                assert self.psutil_writer is not None
                ts_now = time.time_ns()
                cpu_percent = self.psutil_proc.cpu_percent(interval=None)  # type: ignore[arg-type]
                rss_bytes = self.psutil_proc.memory_info().rss  # type: ignore[union-attr]
                num_threads = self.psutil_proc.num_threads()  # type: ignore[union-attr]
                self.psutil_writer.writerow({
                    "ts_unix_ns": ts_now,
                    "cpu_percent": cpu_percent,
                    "rss_bytes": rss_bytes,
                    "num_threads": num_threads,
                })
                self.psutil_csv_handle.flush()
                if self.telemetry:
                    self.telemetry.publish(
                        "psutil_sample",
                        {
                            "timestamp_ns": ts_now,
                            "suite": self.current_suite,
                            "cpu_percent": cpu_percent,
                            "rss_bytes": rss_bytes,
                            "num_threads": num_threads,
                        },
                    )
            except Exception:
                pass
            time.sleep(1.0)
            try:
                self.psutil_proc.cpu_percent(interval=None)  # type: ignore[arg-type]
            except Exception:
                pass

    def _telemetry_loop(self) -> None:
        while not self.temp_stop.is_set():
            payload = {
                "ts_unix_ns": time.time_ns(),
                "temp_c": None,
                "freq_hz": None,
                "throttled_hex": "",
            }
            try:
                out = subprocess.check_output(["vcgencmd", "measure_temp"]).decode(errors="ignore")
                payload["temp_c"] = float(out.split("=")[1].split("'")[0])
            except Exception:
                pass
            try:
                freq_path = Path("/sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq")
                if freq_path.exists():
                    payload["freq_hz"] = int(freq_path.read_text().strip()) * 1000
                else:
                    out = subprocess.check_output(["vcgencmd", "measure_clock", "arm"]).decode(errors="ignore")
                    payload["freq_hz"] = int(out.split("=")[1].strip())
            except Exception:
                pass
            try:
                out = subprocess.check_output(["vcgencmd", "get_throttled"]).decode(errors="ignore")
                payload["throttled_hex"] = out.strip().split("=")[1]
            except Exception:
                pass
            try:
                assert self.temp_writer is not None
                self.temp_writer.writerow(payload)
                self.temp_csv_handle.flush()
                if self.telemetry:
                    payload = dict(payload)
                    payload["suite"] = self.current_suite
                    self.telemetry.publish("thermal_sample", payload)
            except Exception:
                pass
            time.sleep(1.0)

    def rotate(self, pid: int, outdir: Path, suite: str) -> None:
        if not self.enabled:
            write_marker(suite)
            return
        self.stop()
        self.start(pid, outdir, suite)
        write_marker(suite)

    def stop(self) -> None:
        if not self.enabled:
            return

        self.perf_stop.set()
        if self.perf_thread:
            self.perf_thread.join(timeout=1.0)
        if self.perf:
            killtree(self.perf)
            self.perf = None
        if self.perf_csv_handle:
            try:
                self.perf_csv_handle.close()
            except Exception:
                pass
            self.perf_csv_handle = None

        killtree(self.pidstat)
        self.pidstat = None

        self.psutil_stop.set()
        if self.psutil_thread:
            self.psutil_thread.join(timeout=1.0)
            self.psutil_thread = None
        if self.psutil_csv_handle:
            try:
                self.psutil_csv_handle.close()
            except Exception:
                pass
            self.psutil_csv_handle = None

        self.temp_stop.set()
        if self.temp_thread:
            self.temp_thread.join(timeout=1.0)
            self.temp_thread = None
        if self.temp_csv_handle:
            try:
                self.temp_csv_handle.close()
            except Exception:
                pass
            self.temp_csv_handle = None

        if self.telemetry:
            self.telemetry.publish(
                "monitors_stopped",
                {
                    "timestamp_ns": time.time_ns(),
                    "suite": self.current_suite,
                },
            )


class ControlServer(threading.Thread):
    """Line-delimited JSON control server for the scheduler."""

    def __init__(self, host: str, port: int, state: dict):
        super().__init__(daemon=True)
        self.host = host
        self.port = port
        self.state = state
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.sock.bind((self.host, self.port))
        self.sock.listen(5)

    def run(self) -> None:
        print(f"[follower] control listening on {self.host}:{self.port}", flush=True)
        while not self.state["stop_event"].is_set():
            try:
                self.sock.settimeout(0.5)
                conn, _addr = self.sock.accept()
            except socket.timeout:
                continue
            threading.Thread(target=self.handle, args=(conn,), daemon=True).start()
        self.sock.close()

    def handle(self, conn: socket.socket) -> None:
        try:
            line = conn.makefile().readline()
            request = json.loads(line.strip()) if line else {}
        except Exception:
            request = {}

        try:
            cmd = request.get("cmd")
            if cmd == "ping":
                self._send(conn, {"ok": True, "ts": ts()})
                return
            if cmd == "timesync":
                t1 = int(request.get("t1_ns", 0))
                t2 = time.time_ns()
                t3 = time.time_ns()
                self._send(conn, {"ok": True, "t1_ns": t1, "t2_ns": t2, "t3_ns": t3})
                return
            if cmd == "status":
                with self.state.get("lock", threading.Lock()):
                    proxy = self.state["proxy"]
                    suite = self.state["suite"]
                    monitors_enabled = self.state["monitors"].enabled
                    running = bool(proxy and proxy.poll() is None)
                    proxy_pid = proxy.pid if proxy else None
                telemetry: Optional[TelemetryPublisher] = self.state.get("telemetry")
                self._send(
                    conn,
                    {
                        "ok": True,
                        "suite": suite,
                        "proxy_pid": proxy_pid,
                        "running": running,
                        "control_host": self.host,
                        "control_port": self.port,
                        "udp_recv_port": APP_RECV_PORT,
                        "udp_send_port": APP_SEND_PORT,
                        "monitors_enabled": monitors_enabled,
                    },
                )
                if telemetry:
                    telemetry.publish(
                        "status_reply",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": self.state["suite"],
                            "running": running,
                        },
                    )
                return
            if cmd == "mark":
                suite = request.get("suite")
                if not suite:
                    self._send(conn, {"ok": False, "error": "missing suite"})
                    return
                proxy = self.state["proxy"]
                if not proxy or proxy.poll() is not None:
                    self._send(conn, {"ok": False, "error": "proxy not running"})
                    return
                old_suite = self.state.get("suite")
                self.state["prev_suite"] = old_suite
                self.state["pending_suite"] = suite
                self.state["suite"] = suite
                outdir = self.state["suite_outdir"](suite)
                self.state["monitors"].rotate(proxy.pid, outdir, suite)
                monitor = self.state.get("high_speed_monitor")
                if monitor and old_suite != suite:
                    monitor.start_rekey(old_suite or "unknown", suite)
                self._send(conn, {"ok": True, "marked": suite})
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "mark",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                            "prev_suite": old_suite,
                        },
                    )
                return
            if cmd == "rekey_complete":
                status_value = str(request.get("status", "ok"))
                monitor = self.state.get("high_speed_monitor")
                proxy = self.state.get("proxy")
                if status_value.lower() != "ok":
                    previous = self.state.get("prev_suite")
                    pending = self.state.get("pending_suite")
                    if previous is not None and pending and previous != pending:
                        print(f"[follower] rekey to {pending} reported {status_value}; reverting to {previous}", flush=True)
                    if previous is not None and previous != self.state.get("suite"):
                        self.state["suite"] = previous
                        if proxy and proxy.poll() is None:
                            outdir = self.state["suite_outdir"](previous)
                            self.state["monitors"].rotate(proxy.pid, outdir, previous)
                    if monitor and previous:
                        monitor.current_suite = previous
                else:
                    pending_suite = self.state.get("pending_suite")
                    if pending_suite:
                        self.state["suite"] = pending_suite
                if monitor:
                    monitor.end_rekey()
                self.state.pop("pending_suite", None)
                self.state.pop("prev_suite", None)
                self._send(conn, {"ok": True})
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "rekey_complete",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": self.state.get("suite"),
                            "status": status_value,
                        },
                    )
                return
            if cmd == "schedule_mark":
                suite = request.get("suite")
                t0_ns = int(request.get("t0_ns", 0))
                if not suite or not t0_ns:
                    self._send(conn, {"ok": False, "error": "missing suite or t0_ns"})
                    return

                def _do_mark() -> None:
                    delay = max(0.0, (t0_ns - time.time_ns()) / 1e9)
                    if delay:
                        time.sleep(delay)
                    current_suite = self.state.get("suite")
                    proxy = self.state["proxy"]
                    self.state["prev_suite"] = current_suite
                    self.state["pending_suite"] = suite
                    if proxy and proxy.poll() is None:
                        outdir = self.state["suite_outdir"](suite)
                        self.state["monitors"].rotate(proxy.pid, outdir, suite)
                    else:
                        write_marker(suite)
                    self.state["suite"] = suite
                    monitor = self.state.get("high_speed_monitor")
                    if monitor and current_suite != suite:
                        monitor.start_rekey(current_suite or "unknown", suite)

                threading.Thread(target=_do_mark, daemon=True).start()
                self._send(conn, {"ok": True, "scheduled": suite, "t0_ns": t0_ns})
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "schedule_mark",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                            "t0_ns": t0_ns,
                        },
                    )
                return
            if cmd == "power_capture":
                manager = self.state.get("power_manager")
                if not isinstance(manager, PowerCaptureManager):
                    self._send(conn, {"ok": False, "error": "power_monitor_unavailable"})
                    return
                duration_s = request.get("duration_s")
                suite = request.get("suite") or self.state.get("suite") or "unknown"
                try:
                    duration_val = float(duration_s)
                except (TypeError, ValueError):
                    self._send(conn, {"ok": False, "error": "invalid_duration"})
                    return
                start_ns = request.get("start_ns")
                try:
                    start_ns_val = int(start_ns) if start_ns is not None else None
                except (TypeError, ValueError):
                    start_ns_val = None
                ok, error = manager.start_capture(suite, duration_val, start_ns_val)
                if ok:
                    self._send(
                        conn,
                        {
                            "ok": True,
                            "scheduled": True,
                            "suite": suite,
                            "duration_s": duration_val,
                            "start_ns": start_ns_val,
                        },
                    )
                    telemetry = self.state.get("telemetry")
                    if telemetry:
                        telemetry.publish(
                            "power_capture_request",
                            {
                                "timestamp_ns": time.time_ns(),
                                "suite": suite,
                                "duration_s": duration_val,
                                "start_ns": start_ns_val,
                            },
                        )
                else:
                    self._send(conn, {"ok": False, "error": error or "power_capture_failed"})
                return
            if cmd == "power_status":
                manager = self.state.get("power_manager")
                if not isinstance(manager, PowerCaptureManager):
                    self._send(conn, {"ok": False, "error": "power_monitor_unavailable"})
                    return
                status = manager.status()
                self._send(conn, {"ok": True, **status})
                return
            if cmd == "stop":
                self.state["monitors"].stop()
                self.state["stop_event"].set()
                self._send(conn, {"ok": True, "stopping": True})
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "stop",
                        {"timestamp_ns": time.time_ns()},
                    )
                return
            self._send(conn, {"ok": False, "error": "unknown_cmd"})
        finally:
            try:
                conn.close()
            except Exception:
                pass

    @staticmethod
    def _send(conn: socket.socket, obj: dict) -> None:
        conn.sendall((json.dumps(obj) + "\n").encode())


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    MARK_DIR.mkdir(parents=True, exist_ok=True)

    default_suite = discover_initial_suite()

    parser = argparse.ArgumentParser(description="Drone follower driven by core configuration")
    parser.add_argument(
        "--initial-suite",
        default=default_suite,
        help="Initial suite to launch (default: discover from config/secrets)",
    )
    parser.add_argument(
        "--disable-monitors",
        action="store_true",
        help="Disable perf/pidstat monitors",
    )
    parser.add_argument(
        "--session-id",
        help="Session identifier for monitoring output",
    )
    parser.add_argument(
        "--no-cpu-optimization",
        action="store_true",
        help="Skip CPU governor adjustments",
    )
    parser.add_argument(
        "--telemetry-host",
        default=TELEMETRY_DEFAULT_HOST,
        help="GCS telemetry collector host (default: config GCS_HOST)",
    )
    parser.add_argument(
        "--telemetry-port",
        type=int,
        default=TELEMETRY_DEFAULT_PORT,
        help="Telemetry collector TCP port (default: 52080)",
    )
    args = parser.parse_args()

    initial_suite = args.initial_suite
    session_id = args.session_id or f"session_{int(time.time())}"
    stop_event = threading.Event()

    monitor_base = DEFAULT_MONITOR_BASE.expanduser().resolve()
    session_dir = monitor_base / session_id
    session_dir.mkdir(parents=True, exist_ok=True)
    print(f"[follower] monitor output -> {session_dir}")

    telemetry = TelemetryPublisher(args.telemetry_host, args.telemetry_port, session_id)
    telemetry.start()

    if not args.no_cpu_optimization:
        optimize_cpu_performance()

    power_dir = session_dir / "power"
    power_manager = PowerCaptureManager(power_dir, session_id, telemetry)

    high_speed_monitor = HighSpeedMonitor(session_dir, session_id, telemetry)
    high_speed_monitor.start()

    proxy = start_drone_proxy(initial_suite)
    monitors = Monitors(enabled=not args.disable_monitors, telemetry=telemetry)
    time.sleep(1)
    if proxy.poll() is None:
        monitors.start(proxy.pid, suite_outdir(initial_suite), initial_suite)
        high_speed_monitor.attach_proxy(proxy.pid)
        high_speed_monitor.current_suite = initial_suite

    echo = UdpEcho(
        APP_BIND_HOST,
        APP_RECV_PORT,
        APP_SEND_HOST,
        APP_SEND_PORT,
        stop_event,
        high_speed_monitor,
        session_dir,
        telemetry,
    )
    echo.start()

    state = {
        "proxy": proxy,
        "suite": initial_suite,
        "suite_outdir": suite_outdir,
        "monitors": monitors,
        "stop_event": stop_event,
        "high_speed_monitor": high_speed_monitor,
        "telemetry": telemetry,
        "prev_suite": None,
        "pending_suite": None,
        "power_manager": power_manager,
    }
    control = ControlServer(CONTROL_HOST, CONTROL_PORT, state)
    control.start()

    try:
        while not stop_event.is_set():
            if proxy.poll() is not None:
                print(f"[follower] proxy exited with {proxy.returncode}", flush=True)
                stop_event.set()
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        stop_event.set()
    finally:
        monitors.stop()
        high_speed_monitor.stop()
        killtree(proxy)
        try:
            proxy.send_signal(signal.SIGTERM)
        except Exception:
            pass
        telemetry.stop()


if __name__ == "__main__":
    main()

============================================================

FILE 4/10: drone_follower_simple.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_follower_simple.py
Size: 4,865 bytes
Modified: 2025-09-29 03:50:07
------------------------------------------------------------
#!/usr/bin/env python3
"""
Drone follower (no args required):
- Starts the drone proxy with the initial suite.
- Runs a UDP echo (recv -> send ports defined in CONFIG).
- Exposes a tiny TCP JSON control API on CONFIG["DRONE_CONTROL_HOST"/"DRONE_CONTROL_PORT"].

All networking parameters are sourced from core.config.CONFIG.
"""

import json, os, socket, threading, subprocess, sys, time, pathlib, signal

from core.config import CONFIG

CONTROL_HOST = CONFIG.get("DRONE_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = CONFIG.get("DRONE_CONTROL_PORT", 48080)

APP_BIND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = CONFIG.get("DRONE_PLAINTEXT_TX", 47003)
APP_RECV_PORT = CONFIG.get("DRONE_PLAINTEXT_RX", 47004)

SECRETS_DIR = "secrets/matrix"
OUTDIR = "logs/auto/drone"
INITIAL_SUITE = CONFIG.get("SIMPLE_INITIAL_SUITE", "cs-mlkem768-aesgcm-mldsa65")

pathlib.Path(OUTDIR).mkdir(parents=True, exist_ok=True)
pathlib.Path(f"{OUTDIR}/marks").mkdir(parents=True, exist_ok=True)

def ts(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def start_drone_proxy(suite: str):
    os.environ["DRONE_HOST"] = CONFIG["DRONE_HOST"]
    os.environ["GCS_HOST"] = CONFIG["GCS_HOST"]
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    pub = f"{SECRETS_DIR}/{suite}/gcs_signing.pub"
    if not os.path.exists(pub):
        print(f"[follower] ERROR: missing {pub}", flush=True)
        sys.exit(2)

    status = f"{OUTDIR}/status.json"
    summary = f"{OUTDIR}/summary.json"
    log = open(f"{OUTDIR}/drone_{time.strftime('%Y%m%d-%H%M%S')}.log","w")
    print(f"[follower] launching drone proxy on suite {suite}", flush=True)
    p = subprocess.Popen([
        sys.executable,"-m","core.run_proxy","drone",
        "--suite", suite, "--peer-pubkey-file", pub,
        "--status-file", status, "--json-out", summary
    ], stdout=log, stderr=subprocess.STDOUT, text=True)
    return p

def udp_echo(stop_evt: threading.Event):
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind((APP_BIND_HOST, APP_RECV_PORT))
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    print(f"[follower] UDP echo up: recv:{APP_BIND_HOST}:{APP_RECV_PORT} -> send:{APP_SEND_HOST}:{APP_SEND_PORT}", flush=True)
    rx.settimeout(0.2)
    while not stop_evt.is_set():
        try:
            data, _ = rx.recvfrom(65535)
            tx.sendto(data, (APP_SEND_HOST, APP_SEND_PORT))
        except socket.timeout:
            pass
    rx.close(); tx.close()
    print("[follower] UDP echo stopped", flush=True)

def control_server(stop_evt: threading.Event):
    srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    srv.bind((CONTROL_HOST, CONTROL_PORT)); srv.listen(8)
    print(f"[follower] control listening on {CONTROL_HOST}:{CONTROL_PORT}", flush=True)
    while not stop_evt.is_set():
        srv.settimeout(0.2)
        try:
            conn, _ = srv.accept()
        except socket.timeout:
            continue
        with conn:
            line = conn.makefile().readline()
            try:
                req = json.loads(line.strip()) if line else {}
            except Exception:
                req = {}
            resp = {"ok": True}
            if req.get("cmd") == "ping":
                resp = {"ok": True, "ts": ts()}
            elif req.get("cmd") == "mark":
                suite = req.get("suite","unknown")
                marker = f"{OUTDIR}/marks/{int(time.time())}_{suite}.json"
                with open(marker,"w") as f:
                    json.dump({"ts":ts(),"suite":suite}, f)
                resp = {"ok": True, "marked": suite}
            elif req.get("cmd") == "stop":
                stop_evt.set()
                resp = {"ok": True, "stopping": True}
            else:
                resp = {"ok": False, "error": "unknown_cmd"}
            conn.sendall((json.dumps(resp)+"\n").encode())
    srv.close()

def main():
    stop_evt = threading.Event()
    # start proxy once, GCS will rekey from there
    proxy = start_drone_proxy(INITIAL_SUITE)

    t_echo = threading.Thread(target=udp_echo, args=(stop_evt,), daemon=True)
    t_ctl  = threading.Thread(target=control_server, args=(stop_evt,), daemon=True)
    t_echo.start(); t_ctl.start()

    try:
        while not stop_evt.is_set():
            time.sleep(0.5)
    except KeyboardInterrupt:
        pass
    stop_evt.set()
    try:
        proxy.send_signal(signal.SIGTERM)
    except Exception:
        pass

if __name__ == "__main__":
    main()

============================================================

FILE 5/10: drone_scheduler.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\drone_scheduler.py
Size: 42,605 bytes
Modified: 2025-10-03 19:11:10
------------------------------------------------------------
#!/usr/bin/env python3
"""Drone-side scheduler that controls the GCS follower."""

from __future__ import annotations

import argparse
import csv
import json
import os
import shlex
import shutil
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Set

import psutil

try:
    from openpyxl import Workbook
except ImportError:  # pragma: no cover
    Workbook = None

# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from core import suites as suites_mod
from core.config import CONFIG


DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

CONTROL_HOST = CONFIG.get("GCS_CONTROL_HOST") or GCS_HOST
CONTROL_PORT = int(CONFIG.get("GCS_CONTROL_PORT", CONFIG.get("DRONE_CONTROL_PORT", 48080)))

APP_SEND_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("DRONE_PLAINTEXT_TX", 47003))
APP_RECV_HOST = CONFIG.get("DRONE_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("DRONE_PLAINTEXT_RX", 47004))

OUTDIR = Path("logs/auto/drone_scheduler")
SUITES_OUTDIR = OUTDIR / "suites"
SECRETS_DIR = Path("secrets/matrix")

PROXY_STATUS_PATH = OUTDIR / "drone_status.json"
PROXY_SUMMARY_PATH = OUTDIR / "drone_summary.json"
SUMMARY_CSV = OUTDIR / "summary.csv"
EVENTS_FILENAME = "scheduler_events.jsonl"

TELEMETRY_BIND_HOST = CONFIG.get("DRONE_TELEMETRY_BIND", "0.0.0.0")
TELEMETRY_PORT = int(
    CONFIG.get("DRONE_TELEMETRY_PORT")
    or CONFIG.get("GCS_TELEMETRY_PORT")
    or 52080
)

COMBINED_OUTPUT_DIR = Path(
    CONFIG.get("DRONE_COMBINED_OUTPUT_BASE")
    or os.getenv("DRONE_COMBINED_OUTPUT_BASE", "output/drone")
)


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def suite_outdir(suite: str) -> Path:
    target = SUITES_OUTDIR / suite
    mkdirp(target)
    return target


PERF_EVENTS = "task-clock,cycles,instructions,cache-misses,branch-misses,context-switches,branches"


def popen(cmd, **kw) -> subprocess.Popen:
    if isinstance(cmd, (list, tuple)):
        display = " ".join(shlex.quote(str(part)) for part in cmd)
    else:
        display = str(cmd)
    print(f"[{ts()}] exec: {display}", flush=True)
    return subprocess.Popen(cmd, **kw)


def killtree(proc: Optional[subprocess.Popen]) -> None:
    if not proc or proc.poll() is not None:
        return
    try:
        proc.terminate()
        proc.wait(timeout=3)
    except Exception:
        try:
            proc.kill()
        except Exception:
            pass


class Monitors:
    PERF_FIELDS = [
        "ts_unix_ns",
        "t_offset_ms",
        "instructions",
        "cycles",
        "cache-misses",
        "branch-misses",
        "task-clock",
        "context-switches",
        "branches",
    ]

    def __init__(self, enabled: bool) -> None:
        self.enabled = enabled
        self.perf: Optional[subprocess.Popen] = None
        self.pidstat: Optional[subprocess.Popen] = None
        self.perf_thread: Optional[threading.Thread] = None
        self.perf_stop = threading.Event()
        self.perf_csv_handle = None
        self.perf_writer: Optional[csv.DictWriter] = None
        self.perf_start_ns = 0
        self.current_suite = "unknown"

        self.psutil_thread: Optional[threading.Thread] = None
        self.psutil_stop = threading.Event()
        self.psutil_csv_handle = None
        self.psutil_writer: Optional[csv.DictWriter] = None
        self.psutil_proc: Optional[psutil.Process] = None

        self.temp_thread: Optional[threading.Thread] = None
        self.temp_stop = threading.Event()
        self.temp_csv_handle = None
        self.temp_writer: Optional[csv.DictWriter] = None

    def start(self, pid: int, suite: str) -> None:
        if not self.enabled or pid <= 0:
            return
        self.stop()
        outdir = suite_outdir(suite)
        self.current_suite = suite
        self._start_perf(pid, suite, outdir)
        self._start_pidstat(pid, suite, outdir)
        self._start_psutil(pid, suite, outdir)
        self._start_sysmon(suite, outdir)

    def rotate(self, pid: int, suite: str) -> None:
        self.start(pid, suite)

    def stop(self) -> None:
        if not self.enabled:
            return

        self.perf_stop.set()
        if self.perf_thread and self.perf_thread.is_alive():
            self.perf_thread.join(timeout=1.0)
        self.perf_thread = None
        if self.perf:
            killtree(self.perf)
            self.perf = None
        if self.perf_csv_handle:
            try:
                self.perf_csv_handle.close()
            except Exception:
                pass
            self.perf_csv_handle = None
        self.perf_writer = None

        killtree(self.pidstat)
        self.pidstat = None

        self.psutil_stop.set()
        if self.psutil_thread and self.psutil_thread.is_alive():
            self.psutil_thread.join(timeout=1.0)
        self.psutil_thread = None
        if self.psutil_csv_handle:
            try:
                self.psutil_csv_handle.close()
            except Exception:
                pass
            self.psutil_csv_handle = None
        self.psutil_writer = None
        self.psutil_proc = None

        self.temp_stop.set()
        if self.temp_thread and self.temp_thread.is_alive():
            self.temp_thread.join(timeout=1.0)
        self.temp_thread = None
        if self.temp_csv_handle:
            try:
                self.temp_csv_handle.close()
            except Exception:
                pass
            self.temp_csv_handle = None
        self.temp_writer = None

    def _start_perf(self, pid: int, suite: str, outdir: Path) -> None:
        perf_cmd = [
            "perf",
            "stat",
            "-I",
            "1000",
            "-x",
            ",",
            "-e",
            PERF_EVENTS,
            "-p",
            str(pid),
            "--log-fd",
            "1",
        ]
        perf_path = outdir / f"perf_samples_{suite}.csv"
        try:
            self.perf_csv_handle = open(perf_path, "w", newline="", encoding="utf-8")
            self.perf_writer = csv.DictWriter(self.perf_csv_handle, fieldnames=self.PERF_FIELDS)
            self.perf_writer.writeheader()
            self.perf_start_ns = time.time_ns()
            self.perf_stop.clear()
            self.perf = popen(
                perf_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )
            if self.perf.stdout:
                self.perf_thread = threading.Thread(
                    target=self._consume_perf,
                    args=(self.perf.stdout,),
                    daemon=True,
                )
                self.perf_thread.start()
        except FileNotFoundError:
            print("[WARN] perf not available; skipping counter capture", file=sys.stderr)
            self._cleanup_perf_handles()
        except Exception as exc:
            print(f"[WARN] perf start failed: {exc}", file=sys.stderr)
            self._cleanup_perf_handles()

    def _cleanup_perf_handles(self) -> None:
        if self.perf:
            killtree(self.perf)
            self.perf = None
        if self.perf_csv_handle:
            try:
                self.perf_csv_handle.close()
            except Exception:
                pass
            self.perf_csv_handle = None
        self.perf_writer = None

    def _start_pidstat(self, pid: int, suite: str, outdir: Path) -> None:
        try:
            log_handle = open(outdir / f"pidstat_{suite}.txt", "w", encoding="utf-8")
        except Exception as exc:
            print(f"[WARN] pidstat log open failed: {exc}", file=sys.stderr)
            return
        try:
            self.pidstat = popen(
                ["pidstat", "-hlur", "-p", str(pid), "1"],
                stdout=log_handle,
                stderr=subprocess.STDOUT,
            )
        except FileNotFoundError:
            print("[WARN] pidstat not available; skipping", file=sys.stderr)
            try:
                log_handle.close()
            except Exception:
                pass
            self.pidstat = None
        except Exception as exc:
            print(f"[WARN] pidstat start failed: {exc}", file=sys.stderr)
            try:
                log_handle.close()
            except Exception:
                pass
            self.pidstat = None

    def _start_psutil(self, pid: int, suite: str, outdir: Path) -> None:
        try:
            self.psutil_proc = psutil.Process(pid)
            self.psutil_proc.cpu_percent(interval=None)
        except Exception as exc:
            print(f"[WARN] psutil cannot attach to pid {pid}: {exc}", file=sys.stderr)
            self.psutil_proc = None
            return
        psutil_path = outdir / f"psutil_proc_{suite}.csv"
        try:
            self.psutil_csv_handle = open(psutil_path, "w", newline="", encoding="utf-8")
        except Exception as exc:
            print(f"[WARN] psutil log open failed: {exc}", file=sys.stderr)
            self.psutil_proc = None
            return
        self.psutil_writer = csv.DictWriter(
            self.psutil_csv_handle,
            fieldnames=["ts_unix_ns", "cpu_percent", "rss_bytes", "num_threads"],
        )
        self.psutil_writer.writeheader()
        self.psutil_stop.clear()
        self.psutil_thread = threading.Thread(target=self._psutil_loop, daemon=True)
        self.psutil_thread.start()

    def _start_sysmon(self, suite: str, outdir: Path) -> None:
        temp_path = outdir / f"sys_telemetry_{suite}.csv"
        try:
            self.temp_csv_handle = open(temp_path, "w", newline="", encoding="utf-8")
        except Exception as exc:
            print(f"[WARN] thermal log open failed: {exc}", file=sys.stderr)
            self.temp_csv_handle = None
            return
        self.temp_writer = csv.DictWriter(
            self.temp_csv_handle,
            fieldnames=["ts_unix_ns", "temp_c", "freq_hz", "throttled_hex"],
        )
        self.temp_writer.writeheader()
        self.temp_stop.clear()
        self.temp_thread = threading.Thread(target=self._sysmon_loop, daemon=True)
        self.temp_thread.start()

    def _consume_perf(self, stream) -> None:
        if self.perf_writer is None:
            return
        current_ms: Optional[float] = None
        row = None
        try:
            for line in iter(stream.readline, ""):
                if self.perf_stop.is_set():
                    break
                parts = [part.strip() for part in line.strip().split(",")]
                if len(parts) < 4:
                    continue
                try:
                    offset_ms = float(parts[0])
                except ValueError:
                    continue
                event = parts[3]
                if event.startswith("#"):
                    continue
                try:
                    value = parts[1].replace(",", "")
                    int(value)
                except Exception:
                    value = parts[1]
                if current_ms is None or abs(offset_ms - current_ms) >= 0.5:
                    if row and self.perf_writer and self.perf_csv_handle:
                        self.perf_writer.writerow(row)
                        self.perf_csv_handle.flush()
                    current_ms = offset_ms
                    row = {field: "" for field in self.PERF_FIELDS}
                    row["t_offset_ms"] = f"{offset_ms:.0f}"
                    row["ts_unix_ns"] = str(self.perf_start_ns + int(offset_ms * 1_000_000))
                key_map = {
                    "instructions": "instructions",
                    "cycles": "cycles",
                    "cache-misses": "cache-misses",
                    "branch-misses": "branch-misses",
                    "task-clock": "task-clock",
                    "context-switches": "context-switches",
                    "branches": "branches",
                }
                if row is not None:
                    column = key_map.get(event)
                    if column:
                        row[column] = value
            if row and self.perf_writer and self.perf_csv_handle:
                self.perf_writer.writerow(row)
                self.perf_csv_handle.flush()
        finally:
            try:
                stream.close()
            except Exception:
                pass

    def _psutil_loop(self) -> None:
        while not self.psutil_stop.is_set():
            proc = self.psutil_proc
            writer = self.psutil_writer
            handle = self.psutil_csv_handle
            if proc is None or writer is None or handle is None:
                break
            try:
                ts_now = time.time_ns()
                cpu_percent = proc.cpu_percent(interval=None)
                rss_bytes = proc.memory_info().rss
                num_threads = proc.num_threads()
                writer.writerow(
                    {
                        "ts_unix_ns": ts_now,
                        "cpu_percent": cpu_percent,
                        "rss_bytes": rss_bytes,
                        "num_threads": num_threads,
                    }
                )
                handle.flush()
            except Exception:
                break
            time.sleep(1.0)

    def _sysmon_loop(self) -> None:
        while not self.temp_stop.is_set():
            writer = self.temp_writer
            handle = self.temp_csv_handle
            if writer is None or handle is None:
                break
            payload = {
                "ts_unix_ns": time.time_ns(),
                "temp_c": None,
                "freq_hz": None,
                "throttled_hex": "",
            }
            try:
                out = subprocess.check_output(["vcgencmd", "measure_temp"]).decode(errors="ignore")
                payload["temp_c"] = float(out.split("=")[1].split("'")[0])
            except Exception:
                pass
            try:
                freq_path = Path("/sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq")
                if freq_path.exists():
                    payload["freq_hz"] = int(freq_path.read_text().strip()) * 1000
                else:
                    out = subprocess.check_output(["vcgencmd", "measure_clock", "arm"]).decode(errors="ignore")
                    payload["freq_hz"] = int(out.split("=")[1].strip())
            except Exception:
                pass
            try:
                out = subprocess.check_output(["vcgencmd", "get_throttled"]).decode(errors="ignore")
                payload["throttled_hex"] = out.strip().split("=")[1]
            except Exception:
                pass
            try:
                writer.writerow(payload)
                handle.flush()
            except Exception:
                pass
            time.sleep(1.0)


def resolve_suites(requested: Optional[Iterable[str]]) -> List[str]:
    available = list(suites_mod.list_suites())
    if not available:
        raise RuntimeError("No suites registered in core.suites; cannot proceed")
    if not requested:
        return available
    resolved: List[str] = []
    seen: Set[str] = set()
    for name in requested:
        info = suites_mod.get_suite(name)
        suite_id = info["suite_id"]
        if suite_id not in available:
            raise RuntimeError(f"Suite {name} not present in core registry")
        if suite_id not in seen:
            resolved.append(suite_id)
            seen.add(suite_id)
    return resolved


def preferred_initial_suite(candidates: List[str]) -> Optional[str]:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if not configured:
        return None
    try:
        suite_id = suites_mod.get_suite(configured)["suite_id"]
    except NotImplementedError:
        return None
    return suite_id if suite_id in candidates else None


def ctl_send(obj: dict, timeout: float = 2.0, retries: int = 4, backoff: float = 0.5) -> dict:
    last_exc: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((CONTROL_HOST, CONTROL_PORT), timeout=timeout) as sock:
                sock.sendall((json.dumps(obj) + "\n").encode())
                sock.shutdown(socket.SHUT_WR)
                line = sock.makefile().readline()
                return json.loads(line.strip()) if line else {}
        except Exception as exc:
            last_exc = exc
            if attempt < retries:
                time.sleep(backoff * attempt)
                continue
            raise
    if last_exc:
        raise last_exc
    return {}


class Blaster:
    """Local UDP traffic generator with RTT sampling."""

    def __init__(
        self,
        send_host: str,
        send_port: int,
        recv_host: str,
        recv_port: int,
        events_path: Path,
        payload_bytes: int,
        sample_every: int,
    ) -> None:
        self.send_addr = (send_host, send_port)
        self.recv_addr = (recv_host, recv_port)
        self.payload_bytes = max(12, int(payload_bytes))
        self.sample_every = max(0, int(sample_every))
        self.tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx.bind(self.recv_addr)
        self.rx.settimeout(0.001)
        try:
            sndbuf = int(os.getenv("DRONE_SOCK_SNDBUF", str(1 << 20)))
            rcvbuf = int(os.getenv("DRONE_SOCK_RCVBUF", str(1 << 20)))
            self.tx.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, sndbuf)
            self.rx.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, rcvbuf)
        except Exception:
            pass
        mkdirp(events_path.parent)
        self.events = open(events_path, "w", encoding="utf-8")
        self.sent = 0
        self.rcvd = 0
        self.sent_bytes = 0
        self.rcvd_bytes = 0
        self.rtt_sum_ns = 0
        self.rtt_samples = 0
        self.rtt_max_ns = 0
        self.rtt_min_ns: Optional[int] = None
        self.pending: Dict[int, int] = {}

    def _log_event(self, payload: dict) -> None:
        self.events.write(json.dumps(payload) + "\n")

    def _maybe_log(self, kind: str, seq: int, t_ns: int) -> None:
        if self.sample_every == 0:
            return
        if kind == "send":
            if seq % self.sample_every:
                return
        else:
            if self.rcvd % self.sample_every:
                return
        self._log_event({"event": kind, "seq": seq, "t_ns": t_ns})

    def run(self, duration_s: float, rate_pps: int) -> None:
        stop_at = time.time() + max(0.0, duration_s)
        payload_pad = b"\x00" * (self.payload_bytes - 12)
        interval = 0.0 if rate_pps <= 0 else 1.0 / max(1, rate_pps)
        stop_event = threading.Event()
        rx_thread = threading.Thread(target=self._rx_loop, args=(stop_event,), daemon=True)
        rx_thread.start()
        seq = 0
        burst = 32 if interval == 0.0 else 1
        while time.time() < stop_at:
            sends_this_loop = burst
            while sends_this_loop > 0:
                if time.time() >= stop_at:
                    break
                t_send = time.time_ns()
                packet = seq.to_bytes(4, "big") + int(t_send).to_bytes(8, "big") + payload_pad
                try:
                    self.tx.sendto(packet, self.send_addr)
                    if self.sample_every == 0 or (self.sample_every and seq % self.sample_every == 0):
                        self.pending[seq] = int(t_send)
                    self.sent += 1
                    self.sent_bytes += len(packet)
                    self._maybe_log("send", seq, int(t_send))
                except Exception as exc:
                    self._log_event({"event": "send_error", "err": str(exc), "ts": ts()})
                seq += 1
                sends_this_loop -= 1
            if interval > 0.0:
                time.sleep(interval)
            elif (seq & 0x3FFF) == 0:
                time.sleep(0)
        tail_deadline = time.time() + 0.25
        while time.time() < tail_deadline:
            if not self._rx_once():
                time.sleep(0)
        stop_event.set()
        rx_thread.join(timeout=0.2)
        try:
            self.events.flush()
        except Exception:
            pass
        self.events.close()
        self.tx.close()
        self.rx.close()

    def _rx_loop(self, stop_event: threading.Event) -> None:
        while not stop_event.is_set():
            progressed = False
            for _ in range(32):
                if self._rx_once():
                    progressed = True
                else:
                    break
            if not progressed:
                time.sleep(0)

    def _rx_once(self) -> bool:
        try:
            data, _ = self.rx.recvfrom(65535)
        except socket.timeout:
            return False
        except Exception:
            return False
        t_recv = time.time_ns()
        self.rcvd += 1
        self.rcvd_bytes += len(data)
        if len(data) >= 12:
            seq = int.from_bytes(data[:4], "big")
            t_send = self.pending.pop(seq, None)
            if t_send is not None:
                rtt = t_recv - t_send
                self.rtt_sum_ns += rtt
                self.rtt_samples += 1
                if rtt > self.rtt_max_ns:
                    self.rtt_max_ns = rtt
                if self.rtt_min_ns is None or rtt < self.rtt_min_ns:
                    self.rtt_min_ns = rtt
                self._maybe_log("recv", seq, int(t_recv))
        return True


def read_json(path: Path) -> dict:
    try:
        with open(path, encoding="utf-8") as handle:
            return json.load(handle)
    except Exception:
        return {}


def read_local_proxy_status() -> dict:
    data = read_json(PROXY_STATUS_PATH)
    if data:
        return data
    return read_json(PROXY_SUMMARY_PATH)


def read_local_proxy_counters() -> dict:
    status = read_local_proxy_status()
    if isinstance(status, dict):
        counters = status.get("counters")
        if isinstance(counters, dict) and counters:
            return counters
        if any(key in status for key in ("enc_out", "enc_in", "rekeys_ok", "rekeys_fail")):
            return status
    return {}


def snapshot_local_proxy_artifacts(suite: str) -> None:
    target = suite_outdir(suite)
    try:
        if PROXY_STATUS_PATH.exists():
            shutil.copy(PROXY_STATUS_PATH, target / "drone_status.json")
        if PROXY_SUMMARY_PATH.exists():
            shutil.copy(PROXY_SUMMARY_PATH, target / "drone_summary.json")
    except Exception:
        pass


def start_drone_proxy(suite: str) -> tuple[subprocess.Popen, object]:
    suite_dir = SECRETS_DIR / suite
    pub = suite_dir / "gcs_signing.pub"
    if not pub.exists():
        raise FileNotFoundError(f"Missing GCS signing public key for suite {suite}: {pub}")

    OUTDIR.mkdir(parents=True, exist_ok=True)
    log_path = OUTDIR / f"drone_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8", errors="replace")

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    proc = subprocess.Popen(
        [
            sys.executable,
            "-m",
            "core.run_proxy",
            "drone",
            "--suite",
            suite,
            "--peer-pubkey-file",
            str(pub),
            "--status-file",
            str(PROXY_STATUS_PATH),
            "--json-out",
            str(PROXY_SUMMARY_PATH),
        ],
        stdout=log_handle,
        stderr=subprocess.STDOUT,
        text=True,
    )
    return proc, log_handle


def wait_handshake(timeout: float = 20.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        status = read_local_proxy_status()
        state = status.get("state") if isinstance(status, dict) else None
        if state in {"running", "completed", "ready", "handshake_ok"}:
            return True
        time.sleep(0.3)
    return False


def read_remote_status() -> dict:
    status = ctl_send({"cmd": "status"}, timeout=1.5, retries=2)
    return status if isinstance(status, dict) else {}


def read_remote_counters() -> dict:
    status = read_remote_status()
    counters = status.get("counters") if isinstance(status, dict) else None
    return counters if isinstance(counters, dict) else {}


def wait_remote_active_suite(target: str, timeout: float = 10.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        status = read_remote_status()
        if status.get("suite") == target:
            return True
        time.sleep(0.2)
    return False


def wait_remote_rekey(target_suite: str, baseline: Dict[str, object], timeout: float = 20.0) -> str:
    start = time.time()
    baseline_ok = int(baseline.get("rekeys_ok", 0) or 0)
    baseline_fail = int(baseline.get("rekeys_fail", 0) or 0)
    while time.time() - start < timeout:
        status = read_remote_status()
        counters = status.get("counters") if isinstance(status, dict) else {}
        if not isinstance(counters, dict):
            time.sleep(0.4)
            continue
        rekeys_ok = int(counters.get("rekeys_ok", 0) or 0)
        rekeys_fail = int(counters.get("rekeys_fail", 0) or 0)
        last_suite = counters.get("last_rekey_suite") or status.get("suite") or ""
        if rekeys_fail > baseline_fail:
            return "fail"
        if rekeys_ok > baseline_ok and (not last_suite or last_suite == target_suite):
            return "ok"
        time.sleep(0.4)
    return "timeout"


def activate_suite(
    suite: str,
    is_first: bool,
    monitors: Monitors,
    drone_proc: Optional[subprocess.Popen],
) -> float:
    def _rotate_local() -> None:
        if drone_proc and drone_proc.poll() is None:
            monitors.rotate(drone_proc.pid, suite)

    if is_first:
        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception:
            pass
        try:
            ctl_send({"cmd": "rekey_complete", "suite": suite, "status": "ok"})
        except Exception:
            pass
        wait_remote_active_suite(suite, timeout=5.0)
        _rotate_local()
        return 0.0

    baseline = read_remote_counters()
    start_ns = time.time_ns()
    try:
        ctl_send({"cmd": "mark", "suite": suite})
    except Exception:
        pass

    rekey_status = "timeout"
    try:
        ctl_send({"cmd": "rekey", "suite": suite}, timeout=2.0)
        rekey_status = wait_remote_rekey(suite, baseline, timeout=15.0)
    except Exception as exc:
        rekey_status = f"error:{exc}"[:32]
    finally:
        try:
            ctl_send({"cmd": "rekey_complete", "suite": suite, "status": rekey_status})
        except Exception:
            pass
    wait_remote_active_suite(suite, timeout=5.0)
    _rotate_local()
    return (time.time_ns() - start_ns) / 1_000_000


def run_suite(
    suite: str,
    is_first: bool,
    duration_s: float,
    payload_bytes: int,
    event_sample: int,
    pass_index: int,
    pre_gap: float,
    rate_pps: int,
    monitors: Monitors,
    drone_proc: Optional[subprocess.Popen],
) -> dict:
    rekey_ms = activate_suite(suite, is_first, monitors, drone_proc)

    events_path = suite_outdir(suite) / EVENTS_FILENAME
    start_mark_ns = time.time_ns() + int(max(pre_gap, 0.0) * 1e9) + int(0.150 * 1e9)
    try:
        ctl_send({"cmd": "schedule_mark", "suite": suite, "t0_ns": start_mark_ns})
    except Exception:
        pass

    print(
        f"[{ts()}] >>> START suite={suite} pass={pass_index} duration={duration_s:.1f}s rate={rate_pps}pps",
        flush=True,
    )
    if pre_gap > 0:
        time.sleep(pre_gap)

    blaster = Blaster(
        APP_SEND_HOST,
        APP_SEND_PORT,
        APP_RECV_HOST,
        APP_RECV_PORT,
        events_path,
        payload_bytes=payload_bytes,
        sample_every=event_sample,
    )
    start_perf_ns = time.perf_counter_ns()
    blaster.run(duration_s=duration_s, rate_pps=rate_pps)
    end_perf_ns = time.perf_counter_ns()

    remote_counters = read_remote_counters()
    local_counters = read_local_proxy_counters()
    snapshot_local_proxy_artifacts(suite)

    elapsed_s = max(1e-9, (end_perf_ns - start_perf_ns) / 1e9)
    pps = blaster.sent / elapsed_s
    throughput_mbps = (blaster.rcvd_bytes * 8) / (elapsed_s * 1_000_000)
    avg_rtt_ms = (blaster.rtt_sum_ns // max(1, blaster.rtt_samples)) / 1_000_000
    max_rtt_ms = blaster.rtt_max_ns / 1_000_000
    loss_pct = 0.0
    if blaster.sent:
        loss_pct = max(0.0, (blaster.sent - blaster.rcvd) * 100.0 / blaster.sent)

    row = {
        "pass": pass_index,
        "suite": suite,
        "duration_s": round(elapsed_s, 3),
        "sent": blaster.sent,
        "rcvd": blaster.rcvd,
        "pps": round(pps, 1),
        "throughput_mbps": round(throughput_mbps, 3),
        "rtt_avg_ms": round(avg_rtt_ms, 3),
        "rtt_max_ms": round(max_rtt_ms, 3),
        "rtt_samples": blaster.rtt_samples,
        "loss_pct": round(loss_pct, 3),
        "rekey_ms": round(rekey_ms, 3),
        "remote_enc_out": remote_counters.get("enc_out", 0),
        "remote_enc_in": remote_counters.get("enc_in", 0),
        "remote_rekeys_ok": remote_counters.get("rekeys_ok", 0),
        "remote_rekeys_fail": remote_counters.get("rekeys_fail", 0),
        "local_enc_out": local_counters.get("enc_out", 0),
        "local_enc_in": local_counters.get("enc_in", 0),
    }
    print(
        f"[{ts()}] <<< STOP suite={suite} sent={blaster.sent} rcvd={blaster.rcvd} loss={row['loss_pct']:.2f}% "
        f"thr={row['throughput_mbps']:.2f}Mb/s rtt_avg={row['rtt_avg_ms']:.3f}ms",
        flush=True,
    )
    return row


def write_summary(rows: List[dict]) -> None:
    if not rows:
        return
    mkdirp(OUTDIR)
    with open(SUMMARY_CSV, "w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)
    print(f"[{ts()}] wrote {SUMMARY_CSV}")


class TelemetryCollector:
    def __init__(self, host: str, port: int) -> None:
        self.host = host
        self.port = port
        self.stop_event = threading.Event()
        self.server: Optional[socket.socket] = None
        self.accept_thread: Optional[threading.Thread] = None
        self.client_threads: List[threading.Thread] = []
        self.samples: List[dict] = []
        self.lock = threading.Lock()
        self.enabled = True

    def start(self) -> None:
        try:
            srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            srv.bind((self.host, self.port))
            srv.listen(8)
            srv.settimeout(0.5)
            self.server = srv
            self.accept_thread = threading.Thread(target=self._accept_loop, daemon=True)
            self.accept_thread.start()
            print(f"[{ts()}] telemetry collector on {self.host}:{self.port}")
        except Exception as exc:
            print(f"[WARN] telemetry collector disabled: {exc}")
            self.enabled = False
            if self.server:
                try:
                    self.server.close()
                except Exception:
                    pass
            self.server = None

    def _accept_loop(self) -> None:
        assert self.server is not None
        while not self.stop_event.is_set():
            try:
                conn, addr = self.server.accept()
            except socket.timeout:
                continue
            except OSError:
                break
            except Exception as exc:
                if not self.stop_event.is_set():
                    print(f"[WARN] telemetry accept error: {exc}")
                continue
            thread = threading.Thread(target=self._client_loop, args=(conn, addr), daemon=True)
            thread.start()
            self.client_threads.append(thread)

    def _client_loop(self, conn: socket.socket, addr) -> None:
        peer = f"{addr[0]}:{addr[1]}"
        try:
            conn.settimeout(1.0)
            with conn, conn.makefile("r", encoding="utf-8") as reader:
                for line in reader:
                    if self.stop_event.is_set():
                        break
                    data = line.strip()
                    if not data:
                        continue
                    try:
                        payload = json.loads(data)
                    except json.JSONDecodeError:
                        continue
                    payload.setdefault("collector_ts_ns", time.time_ns())
                    payload.setdefault("source", "gcs-follower")
                    payload.setdefault("peer", peer)
                    with self.lock:
                        self.samples.append(payload)
        except Exception:
            pass

    def snapshot(self) -> List[dict]:
        with self.lock:
            return list(self.samples)

    def stop(self) -> None:
        self.stop_event.set()
        if self.server:
            try:
                self.server.close()
            except Exception:
                pass
        if self.accept_thread and self.accept_thread.is_alive():
            self.accept_thread.join(timeout=1.5)
        for thread in self.client_threads:
            if thread.is_alive():
                thread.join(timeout=1.0)


def export_combined_excel(
    session_id: str,
    summary_rows: List[dict],
    telemetry_samples: List[dict],
) -> Optional[Path]:
    if Workbook is None:
        print("[WARN] openpyxl not available; skipping workbook export")
        return None
    workbook = Workbook()
    info_sheet = workbook.active
    info_sheet.title = "run_info"
    info_sheet.append(["generated_utc", ts()])
    info_sheet.append(["session_id", session_id])

    if summary_rows:
        sheet = workbook.create_sheet("summary")
        headers = list(summary_rows[0].keys())
        sheet.append(headers)
        for row in summary_rows:
            sheet.append([row.get(header, "") for header in headers])

    if telemetry_samples:
        sheet = workbook.create_sheet("telemetry")
        headers: List[str] = []
        for sample in telemetry_samples:
            for key in sample.keys():
                if key not in headers:
                    headers.append(key)
        sheet.append(headers)
        for sample in telemetry_samples:
            sheet.append([sample.get(key, "") for key in headers])

    COMBINED_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    target_path = COMBINED_OUTPUT_DIR / f"{session_id}_combined.xlsx"
    workbook.save(target_path)
    return target_path


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    SUITES_OUTDIR.mkdir(parents=True, exist_ok=True)

    parser = argparse.ArgumentParser(description="Drone scheduler controlling the GCS follower")
    parser.add_argument(
        "--traffic",
        choices=["blast"],
        default="blast",
        help="Traffic pattern (only blast supported)",
    )
    parser.add_argument(
        "--pre-gap",
        type=float,
        default=1.0,
        help="Seconds to wait after (re)key before sending",
    )
    parser.add_argument(
        "--inter-gap",
        type=float,
        default=15.0,
        help="Seconds to wait between suites",
    )
    parser.add_argument(
        "--duration",
        type=float,
        default=45.0,
        help="Active send window per suite",
    )
    parser.add_argument(
        "--rate",
        type=int,
        default=0,
        help="Packets/sec for blast; 0 = as fast as possible",
    )
    parser.add_argument(
        "--payload-bytes",
        type=int,
        default=256,
        help="UDP payload size in bytes",
    )
    parser.add_argument(
        "--event-sample",
        type=int,
        default=100,
        help="Log every Nth send/recv event (0 = disable)",
    )
    parser.add_argument(
        "--passes",
        type=int,
        default=1,
        help="Number of full sweeps across suites",
    )
    parser.add_argument("--suites", nargs="*", help="Optional subset of suites to exercise")
    parser.add_argument("--session-id", help="Identifier for output artifacts")
    parser.add_argument(
        "--no-local-proxy",
        action="store_true",
        help="Skip launching the local drone proxy (assumes external process)",
    )
    parser.add_argument(
        "--no-monitors",
        action="store_true",
        help="Disable perf/pidstat/psutil capture for the local drone proxy",
    )
    args = parser.parse_args()

    if args.duration <= 0:
        raise ValueError("--duration must be positive")
    if args.pre_gap < 0:
        raise ValueError("--pre-gap must be >= 0")
    if args.inter_gap < 0:
        raise ValueError("--inter-gap must be >= 0")
    if args.rate < 0:
        raise ValueError("--rate must be >= 0")
    if args.passes <= 0:
        raise ValueError("--passes must be >= 1")

    suites = resolve_suites(args.suites)
    if not suites:
        raise RuntimeError("No suites selected for execution")

    session_id = args.session_id or f"session_{int(time.time())}"

    initial_suite = preferred_initial_suite(suites)
    if initial_suite and suites[0] != initial_suite:
        suites = [initial_suite] + [s for s in suites if s != initial_suite]
        print(f"[{ts()}] reordered suites to start with {initial_suite}")

    telemetry_collector = TelemetryCollector(TELEMETRY_BIND_HOST, TELEMETRY_PORT)
    telemetry_collector.start()

    monitors = Monitors(enabled=not args.no_monitors and not args.no_local_proxy)

    drone_proc: Optional[subprocess.Popen] = None
    drone_log = None

    try:
        if not args.no_local_proxy:
            drone_proc, drone_log = start_drone_proxy(suites[0])
            time.sleep(1.0)
            if drone_proc.poll() is not None:
                raise RuntimeError(f"drone proxy exited with {drone_proc.returncode}")

        reachable = False
        for attempt in range(6):
            try:
                resp = ctl_send({"cmd": "ping"}, timeout=1.0, retries=1)
                if resp.get("ok"):
                    reachable = True
                    break
            except Exception:
                pass
            time.sleep(0.5)
        if reachable:
            print(f"[{ts()}] follower reachable at {CONTROL_HOST}:{CONTROL_PORT}")
        else:
            print(f"[WARN] follower not reachable at {CONTROL_HOST}:{CONTROL_PORT}")

        if not wait_handshake(timeout=20.0):
            print(f"[WARN] local handshake not confirmed for {suites[0]}")

        summary_rows: List[dict] = []

        for pass_index in range(args.passes):
            for idx, suite in enumerate(suites):
                row = run_suite(
                    suite,
                    is_first=(pass_index == 0 and idx == 0),
                    duration_s=args.duration,
                    payload_bytes=args.payload_bytes,
                    event_sample=args.event_sample,
                    pass_index=pass_index,
                    pre_gap=args.pre_gap,
                        rate_pps=args.rate,
                        monitors=monitors,
                        drone_proc=drone_proc,
                )
                summary_rows.append(row)
                is_last_suite = idx == len(suites) - 1
                is_last_pass = pass_index == args.passes - 1
                if args.inter_gap > 0 and not (is_last_suite and is_last_pass):
                    time.sleep(args.inter_gap)

        write_summary(summary_rows)
        telemetry_samples: List[dict] = []
        if telemetry_collector.enabled:
            telemetry_samples = telemetry_collector.snapshot()
            telemetry_path = OUTDIR / f"telemetry_{session_id}.jsonl"
            with open(telemetry_path, "w", encoding="utf-8") as handle:
                for sample in telemetry_samples:
                    handle.write(json.dumps(sample) + "\n")
            print(f"[{ts()}] wrote {telemetry_path}")

        combined_path = export_combined_excel(session_id, summary_rows, telemetry_samples)
        if combined_path:
            print(f"[{ts()}] combined workbook written to {combined_path}")

    finally:
        try:
            ctl_send({"cmd": "stop"}, timeout=1.0, retries=1)
        except Exception:
            pass

        monitors.stop()

        telemetry_collector.stop()

        if drone_proc:
            try:
                drone_proc.terminate()
                drone_proc.wait(timeout=5)
            except Exception:
                try:
                    drone_proc.kill()
                except Exception:
                    pass
        if drone_log:
            try:
                drone_log.close()
            except Exception:
                pass


if __name__ == "__main__":
    main()

============================================================

FILE 6/10: gcs_follower.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_follower.py
Size: 24,003 bytes
Modified: 2025-10-03 15:09:23
------------------------------------------------------------
#!/usr/bin/env python3
"""GCS follower that exposes the control channel for a drone-side scheduler."""

from __future__ import annotations

import argparse
import json
import os
import queue
import signal
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Dict, Optional

# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from core import suites as suites_mod
from core.config import CONFIG


DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

CONTROL_HOST = CONFIG.get("GCS_CONTROL_HOST", "0.0.0.0")
CONTROL_PORT = int(CONFIG.get("GCS_CONTROL_PORT", CONFIG.get("DRONE_CONTROL_PORT", 48080)))

APP_BIND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("GCS_PLAINTEXT_RX", 47002))
APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("GCS_PLAINTEXT_TX", 47001))

TELEMETRY_DEFAULT_HOST = (
    CONFIG.get("DRONE_TELEMETRY_HOST")
    or CONFIG.get("DRONE_HOST")
    or "127.0.0.1"
)
TELEMETRY_DEFAULT_PORT = int(
    CONFIG.get("DRONE_TELEMETRY_PORT")
    or CONFIG.get("GCS_TELEMETRY_PORT")
    or 52080
)

OUTDIR = Path("logs/auto/gcs_follower")
MARK_DIR = OUTDIR / "marks"
SECRETS_DIR = Path("secrets/matrix")

PROXY_STATUS_PATH = OUTDIR / "gcs_status.json"
PROXY_SUMMARY_PATH = OUTDIR / "gcs_summary.json"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


class TelemetryPublisher:
    """Best-effort telemetry transport towards the drone scheduler."""

    def __init__(self, host: str, port: int, session_id: str) -> None:
        self.host = host
        self.port = port
        self.session_id = session_id
        self.queue: "queue.Queue[dict]" = queue.Queue(maxsize=5000)
        self.stop_event = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=True)
        self.sock: Optional[socket.socket] = None
        self.writer = None

    def start(self) -> None:
        self.thread.start()

    def publish(self, kind: str, payload: Dict[str, object]) -> None:
        if self.stop_event.is_set():
            return
        message = {"session_id": self.session_id, "kind": kind, **payload}
        try:
            self.queue.put_nowait(message)
        except queue.Full:
            try:
                self.queue.get_nowait()
            except queue.Empty:
                pass
            try:
                self.queue.put_nowait(message)
            except queue.Full:
                pass

    def stop(self) -> None:
        self.stop_event.set()
        if self.thread.is_alive():
            self.thread.join(timeout=2.0)
        self._close_socket()

    def _close_socket(self) -> None:
        if self.writer is not None:
            try:
                self.writer.close()
            except Exception:
                pass
            self.writer = None
        if self.sock is not None:
            try:
                self.sock.close()
            except Exception:
                pass
            self.sock = None

    def _ensure_connection(self) -> bool:
        if self.sock is not None and self.writer is not None:
            return True
        try:
            sock = socket.create_connection((self.host, self.port), timeout=3.0)
            self.sock = sock
            self.writer = sock.makefile("w", encoding="utf-8", buffering=1)
            hello = {
                "session_id": self.session_id,
                "kind": "telemetry_hello",
                "timestamp_ns": time.time_ns(),
                "source": "gcs-follower",
            }
            self.writer.write(json.dumps(hello) + "\n")
            self.writer.flush()
            return True
        except Exception:
            self._close_socket()
            return False

    def _run(self) -> None:
        backoff = 1.0
        while not self.stop_event.is_set():
            if not self._ensure_connection():
                time.sleep(min(backoff, 5.0))
                backoff = min(backoff * 1.5, 5.0)
                continue
            backoff = 1.0
            try:
                item = self.queue.get(timeout=0.5)
            except queue.Empty:
                continue
            try:
                if self.writer is None:
                    continue
                if "timestamp_ns" not in item:
                    item["timestamp_ns"] = time.time_ns()
                self.writer.write(json.dumps(item) + "\n")
                self.writer.flush()
            except Exception:
                self._close_socket()


def popen(cmd, **kw) -> subprocess.Popen:
    if isinstance(cmd, (list, tuple)):
        display = " ".join(str(part) for part in cmd)
    else:
        display = str(cmd)
    print(f"[{ts()}] exec: {display}", flush=True)
    return subprocess.Popen(cmd, **kw)


def killtree(proc: Optional[subprocess.Popen]) -> None:
    if not proc or proc.poll() is not None:
        return
    try:
        proc.terminate()
        proc.wait(timeout=3)
    except Exception:
        try:
            proc.kill()
        except Exception:
            pass


def discover_initial_suite() -> str:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if configured:
        return configured
    suite_map = suites_mod.list_suites()
    if suite_map:
        first = sorted(suite_map.keys())[0]
        return suites_mod.get_suite(first)["suite_id"]
    if SECRETS_DIR.exists():
        for path in sorted(SECRETS_DIR.iterdir()):
            if (path / "gcs_signing.key").exists():
                return path.name
    return "cs-mlkem768-aesgcm-mldsa65"


def suite_outdir(suite: str) -> Path:
    path = OUTDIR / "suites" / suite
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_secrets_dir(suite: str) -> Path:
    return SECRETS_DIR / suite


def write_marker(suite: str) -> None:
    MARK_DIR.mkdir(parents=True, exist_ok=True)
    marker = MARK_DIR / f"{int(time.time())}_{suite}.json"
    with open(marker, "w", encoding="utf-8") as handle:
        json.dump({"ts": ts(), "suite": suite}, handle)


def read_json(path: Path) -> dict:
    try:
        with open(path, encoding="utf-8") as handle:
            return json.load(handle)
    except Exception:
        return {}


def read_proxy_counters() -> dict:
    data = read_json(PROXY_STATUS_PATH)
    counters = data.get("counters") if isinstance(data, dict) else None
    if isinstance(counters, dict) and counters:
        return counters
    summary = read_json(PROXY_SUMMARY_PATH)
    if isinstance(summary, dict):
        summary_counters = summary.get("counters")
        if isinstance(summary_counters, dict) and summary_counters:
            return summary_counters
        if any(key in summary for key in ("enc_out", "enc_in", "rekeys_ok", "rekeys_fail")):
            return summary
    return {}


def read_proxy_status() -> dict:
    data = read_json(PROXY_STATUS_PATH)
    if isinstance(data, dict) and data:
        return data
    return read_json(PROXY_SUMMARY_PATH)


def start_gcs_proxy(suite: str) -> tuple[subprocess.Popen, object]:
    key_path = suite_secrets_dir(suite) / "gcs_signing.key"
    if not key_path.exists():
        raise FileNotFoundError(f"Missing GCS signing key for suite {suite}: {key_path}")

    OUTDIR.mkdir(parents=True, exist_ok=True)
    log_path = OUTDIR / f"gcs_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8", errors="replace")

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    proc = popen(
        [
            sys.executable,
            "-m",
            "core.run_proxy",
            "gcs",
            "--suite",
            suite,
            "--gcs-secret-file",
            str(key_path),
            "--control-manual",
            "--status-file",
            str(PROXY_STATUS_PATH),
            "--json-out",
            str(PROXY_SUMMARY_PATH),
        ],
        stdin=subprocess.PIPE,
        stdout=log_handle,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    if proc.stdin is None:
        raise RuntimeError("GCS proxy did not expose stdin for manual control")
    return proc, log_handle


class UdpEcho(threading.Thread):
    def __init__(
        self,
        bind_host: str,
        recv_port: int,
        send_host: str,
        send_port: int,
        stop_event: threading.Event,
        publisher: Optional[TelemetryPublisher],
    ) -> None:
        super().__init__(daemon=True)
        self.bind_host = bind_host
        self.recv_port = recv_port
        self.send_host = send_host
        self.send_port = send_port
        self.stop_event = stop_event
        self.publisher = publisher
        self.rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            sndbuf = int(os.getenv("GCS_SOCK_SNDBUF", str(8 << 20)))
            rcvbuf = int(os.getenv("GCS_SOCK_RCVBUF", str(8 << 20)))
            self.rx_sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, rcvbuf)
            self.tx_sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, sndbuf)
        except Exception:
            pass
        self.rx_sock.bind((self.bind_host, self.recv_port))

    def run(self) -> None:
        print(
            f"[gcs-follower] UDP echo listening {self.bind_host}:{self.recv_port} -> {self.send_host}:{self.send_port}",
            flush=True,
        )
        self.rx_sock.settimeout(0.001)
        while not self.stop_event.is_set():
            try:
                data, addr = self.rx_sock.recvfrom(65535)
                recv_ns = time.time_ns()
                annotated = self._annotate_packet(data, recv_ns)
                self.tx_sock.sendto(annotated, (self.send_host, self.send_port))
                if self.publisher:
                    self.publisher.publish(
                        "udp_echo",
                        {
                            "recv_timestamp_ns": recv_ns,
                            "payload_len": len(data),
                            "peer": f"{addr[0]}:{addr[1]}",
                        },
                    )
            except socket.timeout:
                continue
            except Exception as exc:
                print(f"[gcs-follower] UDP echo error: {exc}", flush=True)
        self.rx_sock.close()
        self.tx_sock.close()

    @staticmethod
    def _annotate_packet(data: bytes, recv_ns: int) -> bytes:
        if len(data) >= 20:
            return data[:-8] + recv_ns.to_bytes(8, "big")
        return data + recv_ns.to_bytes(8, "big")


class ControlServer(threading.Thread):
    def __init__(self, host: str, port: int, state: dict, lock: threading.RLock):
        super().__init__(daemon=True)
        self.host = host
        self.port = port
        self.state = state
        self.lock = lock
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.sock.bind((self.host, self.port))
        self.sock.listen(5)

    def run(self) -> None:
        print(f"[gcs-follower] control listening on {self.host}:{self.port}", flush=True)
        while not self.state["stop_event"].is_set():
            try:
                self.sock.settimeout(0.5)
                conn, _addr = self.sock.accept()
            except socket.timeout:
                continue
            threading.Thread(target=self.handle, args=(conn,), daemon=True).start()
        self.sock.close()

    def handle(self, conn: socket.socket) -> None:
        try:
            line = conn.makefile().readline()
            request = json.loads(line.strip()) if line else {}
        except Exception:
            request = {}
        try:
            cmd = request.get("cmd")
            if cmd == "ping":
                self._send(conn, {"ok": True, "ts": ts()})
                return
            if cmd == "timesync":
                t1 = int(request.get("t1_ns", 0))
                t2 = time.time_ns()
                t3 = time.time_ns()
                self._send(conn, {"ok": True, "t1_ns": t1, "t2_ns": t2, "t3_ns": t3})
                return
            if cmd == "status":
                with self.lock:
                    proxy: Optional[subprocess.Popen] = self.state.get("proxy")
                    running = bool(proxy and proxy.poll() is None)
                    suite = self.state.get("suite")
                    pending = self.state.get("pending_suite")
                counters = read_proxy_counters()
                status = read_proxy_status()
                self._send(
                    conn,
                    {
                        "ok": True,
                        "suite": suite,
                        "pending_suite": pending,
                        "running": running,
                        "counters": counters,
                        "status": status,
                    },
                )
                telemetry: Optional[TelemetryPublisher] = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "status_reply",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                            "running": running,
                        },
                    )
                return
            if cmd == "mark":
                suite = request.get("suite")
                if not suite:
                    self._send(conn, {"ok": False, "error": "missing suite"})
                    return
                with self.lock:
                    current = self.state.get("suite")
                    self.state["prev_suite"] = current
                    self.state["pending_suite"] = suite
                    self.state["suite"] = suite
                write_marker(suite)
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "mark",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                            "prev_suite": current,
                        },
                    )
                self._send(conn, {"ok": True, "marked": suite})
                return
            if cmd == "rekey":
                suite = request.get("suite")
                if not suite:
                    self._send(conn, {"ok": False, "error": "missing suite"})
                    return
                with self.lock:
                    proxy: Optional[subprocess.Popen] = self.state.get("proxy")
                    stdin = self.state.get("proxy_stdin")
                if not proxy or proxy.poll() is not None or stdin is None:
                    self._send(conn, {"ok": False, "error": "proxy_not_running"})
                    return
                try:
                    stdin.write(suite + "\n")
                    stdin.flush()
                except Exception as exc:
                    self._send(conn, {"ok": False, "error": f"stdin_write_failed: {exc}"})
                    return
                with self.lock:
                    self.state["pending_suite"] = suite
                    self.state["last_rekey_started_ns"] = time.time_ns()
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish(
                        "rekey_initiated",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                        },
                    )
                self._send(conn, {"ok": True, "suite": suite})
                return
            if cmd == "rekey_complete":
                status_value = str(request.get("status", "ok"))
                suite = request.get("suite")
                telemetry = self.state.get("telemetry")
                with self.lock:
                    if status_value.lower() == "ok" and suite:
                        self.state["suite"] = suite
                    self.state.pop("pending_suite", None)
                if telemetry:
                    telemetry.publish(
                        "rekey_complete",
                        {
                            "timestamp_ns": time.time_ns(),
                            "suite": suite,
                            "status": status_value,
                        },
                    )
                self._send(conn, {"ok": True})
                return
            if cmd == "schedule_mark":
                suite = request.get("suite")
                t0_ns = int(request.get("t0_ns", 0))
                if not suite or not t0_ns:
                    self._send(conn, {"ok": False, "error": "missing suite or t0_ns"})
                    return

                def _do_mark() -> None:
                    delay = max(0.0, (t0_ns - time.time_ns()) / 1e9)
                    if delay:
                        time.sleep(delay)
                    with self.lock:
                        current = self.state.get("suite")
                        self.state["prev_suite"] = current
                        self.state["pending_suite"] = suite
                        self.state["suite"] = suite
                    write_marker(suite)
                    telemetry_inner = self.state.get("telemetry")
                    if telemetry_inner:
                        telemetry_inner.publish(
                            "scheduled_mark",
                            {
                                "timestamp_ns": time.time_ns(),
                                "suite": suite,
                                "prev_suite": current,
                            },
                        )

                threading.Thread(target=_do_mark, daemon=True).start()
                self._send(conn, {"ok": True, "scheduled": suite, "t0_ns": t0_ns})
                return
            if cmd == "stop":
                self.state["stop_event"].set()
                telemetry = self.state.get("telemetry")
                if telemetry:
                    telemetry.publish("stop", {"timestamp_ns": time.time_ns()})
                self._send(conn, {"ok": True, "stopping": True})
                return
            self._send(conn, {"ok": False, "error": "unknown_cmd"})
        finally:
            try:
                conn.close()
            except Exception:
                pass

    @staticmethod
    def _send(conn: socket.socket, obj: dict) -> None:
        conn.sendall((json.dumps(obj) + "\n").encode())


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    MARK_DIR.mkdir(parents=True, exist_ok=True)

    default_suite = discover_initial_suite()

    parser = argparse.ArgumentParser(description="GCS follower driven by core configuration")
    parser.add_argument(
        "--initial-suite",
        default=default_suite,
        help="Initial suite to launch (default: discover from config/secrets)",
    )
    parser.add_argument(
        "--session-id",
        help="Session identifier for telemetry",
    )
    parser.add_argument(
        "--telemetry-host",
        default=TELEMETRY_DEFAULT_HOST,
        help="Telemetry collector host (default: drone host)",
    )
    parser.add_argument(
        "--telemetry-port",
        type=int,
        default=TELEMETRY_DEFAULT_PORT,
        help="Telemetry collector TCP port",
    )
    parser.add_argument(
        "--disable-telemetry",
        action="store_true",
        help="Disable telemetry publisher",
    )
    parser.add_argument(
        "--disable-echo",
        action="store_true",
        help="Disable UDP echo service",
    )
    args = parser.parse_args()

    initial_suite = args.initial_suite
    session_id = args.session_id or f"session_{int(time.time())}"
    stop_event = threading.Event()

    telemetry: Optional[TelemetryPublisher] = None
    if not args.disable_telemetry:
        telemetry = TelemetryPublisher(args.telemetry_host, args.telemetry_port, session_id)
        telemetry.start()

    proxy = None
    log_handle = None
    echo_thread: Optional[UdpEcho] = None
    control_thread: Optional[ControlServer] = None

    try:
        proxy, log_handle = start_gcs_proxy(initial_suite)
        if proxy.poll() is not None:
            raise RuntimeError(f"gcs proxy exited immediately with {proxy.returncode}")

        if not args.disable_telemetry and telemetry:
            telemetry.publish(
                "proxy_started",
                {
                    "timestamp_ns": time.time_ns(),
                    "suite": initial_suite,
                    "proxy_pid": proxy.pid,
                },
            )

        if not args.disable_echo:
            echo_thread = UdpEcho(
                APP_BIND_HOST,
                APP_RECV_PORT,
                APP_SEND_HOST,
                APP_SEND_PORT,
                stop_event,
                telemetry,
            )
            echo_thread.start()

        state = {
            "suite": initial_suite,
            "pending_suite": None,
            "prev_suite": None,
            "proxy": proxy,
            "proxy_stdin": proxy.stdin,
            "stop_event": stop_event,
            "telemetry": telemetry,
        }
        lock = threading.RLock()
        control_thread = ControlServer(CONTROL_HOST, CONTROL_PORT, state, lock)
        control_thread.start()

        print(f"[gcs-follower] awaiting stop signal (session {session_id})", flush=True)
        while not stop_event.is_set():
            if proxy.poll() is not None:
                print(f"[gcs-follower] proxy exited with {proxy.returncode}", flush=True)
                stop_event.set()
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        stop_event.set()
    finally:
        try:
            ctl_sock = socket.create_connection((CONTROL_HOST, CONTROL_PORT), timeout=1.0)
            ctl_sock.sendall((json.dumps({"cmd": "stop"}) + "\n").encode())
            ctl_sock.close()
        except Exception:
            pass

        if control_thread and control_thread.is_alive():
            control_thread.join(timeout=1.5)

        stop_event.set()
        if echo_thread and echo_thread.is_alive():
            echo_thread.join(timeout=1.0)

        if proxy and proxy.stdin:
            try:
                proxy.stdin.write("quit\n")
                proxy.stdin.flush()
            except Exception:
                pass
        if proxy:
            try:
                proxy.wait(timeout=5)
            except Exception:
                killtree(proxy)

        if log_handle:
            try:
                log_handle.close()
            except Exception:
                pass

        if telemetry:
            telemetry.stop()


if __name__ == "__main__":
    main()

============================================================

FILE 7/10: gcs_scheduler copy.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler copy.py
Size: 16,757 bytes
Modified: 2025-09-29 10:04:12
------------------------------------------------------------
#!/usr/bin/env python3
"""GCS scheduler that drives rekeys and traffic using central configuration."""

from __future__ import annotations

import argparse
import csv
import json
import sys
from pathlib import Path

# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import os
import shutil
import socket
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Iterable, List, Optional

from core.config import CONFIG
from core import suites as suites_mod


DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("GCS_PLAINTEXT_TX", 47001))
APP_RECV_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("GCS_PLAINTEXT_RX", 47002))

OUTDIR = Path("logs/auto")
SECRETS_DIR = Path("secrets/matrix")
PROXY_STATUS_PATH = OUTDIR / "gcs_proxy_status.json"
PROXY_SUMMARY_PATH = OUTDIR / "gcs_proxy_summary.json"
SUMMARY_CSV = OUTDIR / "summary.csv"
EVENTS_FILENAME = "gcs_events.jsonl"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def suite_outdir(suite: str) -> Path:
    return mkdirp(OUTDIR / suite)


def resolve_suites(requested: Optional[Iterable[str]]) -> List[str]:
    available = suites_mod.list_suites()
    if not available:
        raise RuntimeError("No suites registered in core.suites; cannot proceed")

    if not requested:
        return sorted(available.keys())

    resolved = []
    seen = set()
    for name in requested:
        info = suites_mod.get_suite(name)
        suite_id = info["suite_id"]
        if suite_id not in available:
            raise RuntimeError(f"Suite {name} not present in core registry")
        if suite_id not in seen:
            resolved.append(suite_id)
            seen.add(suite_id)
    return resolved


def preferred_initial_suite(candidates: List[str]) -> Optional[str]:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if not configured:
        return None
    try:
        suite_id = suites_mod.get_suite(configured)["suite_id"]
    except NotImplementedError:
        return None
    return suite_id if suite_id in candidates else None


def ctl_send(obj: dict, timeout: float = 2.0, retries: int = 4, backoff: float = 0.5) -> dict:
    last_exc: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((DRONE_HOST, CONTROL_PORT), timeout=timeout) as sock:
                sock.sendall((json.dumps(obj) + "\n").encode())
                sock.shutdown(socket.SHUT_WR)
                line = sock.makefile().readline()
                return json.loads(line.strip()) if line else {}
        except Exception as exc:
            last_exc = exc
            if attempt < retries:
                time.sleep(backoff * attempt)
                continue
            raise
    if last_exc:
        raise last_exc
    return {}


class UdpTraffic:
    def __init__(
        self,
        send_host: str,
        send_port: int,
        recv_host: str,
        recv_port: int,
        events_path: Path,
        rate_pps: int,
        max_packets: Optional[int] = None,
    ) -> None:
        self.send_addr = (send_host, send_port)
        self.recv_addr = (recv_host, recv_port)
        self.rate_pps = max(rate_pps, 1)
        self.max_packets = max_packets if max_packets and max_packets > 0 else None
        self.stop = threading.Event()
        self.sent = 0
        self.rcvd = 0
        mkdirp(events_path.parent)
        self.events = open(events_path, "w", encoding="utf-8")
        self.tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx.bind(self.recv_addr)
        self.rx.settimeout(0.2)

    def start(self) -> None:
        self.tx_thread = threading.Thread(target=self._sender, daemon=True)
        self.rx_thread = threading.Thread(target=self._receiver, daemon=True)
        self.tx_thread.start()
        self.rx_thread.start()

    def _sender(self) -> None:
        interval = 1.0 / self.rate_pps
        seq = 0
        while not self.stop.is_set():
            payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
            try:
                self.tx.sendto(payload, self.send_addr)
                self.events.write(json.dumps({"event": "send", "seq": seq, "t_send_ns": time.time_ns()}) + "\n")
                self.events.flush()
                self.sent += 1
            except Exception as exc:
                self.events.write(json.dumps({"event": "send_error", "err": str(exc), "ts": ts()}) + "\n")
                self.events.flush()
            if self.max_packets is not None and self.sent >= self.max_packets:
                self.stop.set()
            seq += 1
            time.sleep(interval)

    def _receiver(self) -> None:
        while not self.stop.is_set():
            try:
                data, _ = self.rx.recvfrom(65535)
            except socket.timeout:
                continue
            except Exception as exc:
                self.events.write(json.dumps({"event": "recv_error", "err": str(exc), "ts": ts()}) + "\n")
                self.events.flush()
                continue
            now = time.time_ns()
            seq = int.from_bytes(data[:4], "big") if len(data) >= 4 else -1
            self.events.write(json.dumps({"event": "recv", "seq": seq, "t_recv_ns": now}) + "\n")
            self.events.flush()
            self.rcvd += 1

    def stop_and_close(self) -> None:
        self.stop.set()
        for thread in (self.tx_thread, self.rx_thread):
            if thread.is_alive():
                thread.join(timeout=1.0)
        self.events.close()
        self.tx.close()
        self.rx.close()


def wait_handshake(timeout: float = 20.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        if PROXY_STATUS_PATH.exists():
            try:
                js = json.load(open(PROXY_STATUS_PATH, encoding="utf-8"))
            except Exception:
                js = {}
            state = js.get("state") or js.get("status")
            if state in {"running", "completed", "ready", "handshake_ok"}:
                return True
        time.sleep(0.3)
    return False


def wait_active_suite(target: str, timeout: float = 10.0) -> bool:
    """Wait until the proxy status file reports the given suite as active.

    This is a small guard used after issuing a rekey so traffic isn't started
    until the proxy has applied the new suite.
    """
    deadline = time.time() + timeout
    while time.time() < deadline:
        try:
            js = json.load(open(PROXY_STATUS_PATH, encoding="utf-8"))
        except Exception:
            js = {}
        active = js.get("suite") or js.get("active_suite") or js.get("last_rekey_suite")
        if active == target:
            return True
        time.sleep(0.2)
    return False


def snapshot_proxy_artifacts(suite: str) -> None:
    target_dir = suite_outdir(suite)
    if PROXY_STATUS_PATH.exists():
        shutil.copy(PROXY_STATUS_PATH, target_dir / "gcs_status.json")
    if PROXY_SUMMARY_PATH.exists():
        shutil.copy(PROXY_SUMMARY_PATH, target_dir / "gcs_summary.json")


def start_gcs_proxy(initial_suite: str) -> tuple[subprocess.Popen, Path]:
    key_path = SECRETS_DIR / initial_suite / "gcs_signing.key"
    if not key_path.exists():
        raise FileNotFoundError(f"Missing GCS signing key for suite {initial_suite}: {key_path}")

    mkdirp(OUTDIR)
    log_path = OUTDIR / f"gcs_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8", errors="replace")

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    proc = subprocess.Popen(
        [
            sys.executable,
            "-m",
            "core.run_proxy",
            "gcs",
            "--suite",
            initial_suite,
            "--gcs-secret-file",
            str(key_path),
            "--control-manual",
            "--status-file",
            str(PROXY_STATUS_PATH),
            "--json-out",
            str(PROXY_SUMMARY_PATH),
        ],
        stdin=subprocess.PIPE,
        stdout=log_handle,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    return proc, log_handle


def read_proxy_stats_live() -> dict:
    """Read live proxy status file and return counters dict when available.

    Returns an empty dict if the status file is missing or malformed.
    """
    try:
        js = json.load(open(PROXY_STATUS_PATH, encoding="utf-8"))
    except Exception:
        return {}
    # If the status payload wraps counters under "counters", return that.
    if isinstance(js, dict):
        if "counters" in js and isinstance(js["counters"], dict):
            return js["counters"]
        # Some builds may put counters at the top-level
        if any(k in js for k in ("enc_out", "enc_in")):
            return js
    return {}


def read_proxy_summary() -> dict:
    if not PROXY_SUMMARY_PATH.exists():
        return {}
    try:
        return json.load(open(PROXY_SUMMARY_PATH, encoding="utf-8"))
    except Exception:
        return {}


def run_suite(
    gcs: subprocess.Popen,
    suite: str,
    is_first: bool,
    duration_s: float,
    rate_pps: int,
    packets_per_suite: Optional[int],
    delay_between_suites: float,
    pass_index: int,
) -> dict:
    if gcs.poll() is not None:
        raise RuntimeError("GCS proxy is not running; cannot continue")

    if is_first:
        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception as exc:
            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)
    else:
        assert gcs.stdin is not None
        print(f"[{ts()}] rekey -> {suite}")
        gcs.stdin.write(suite + "\n")
        gcs.stdin.flush()
        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception as exc:
            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)
        # Wait until the proxy reports the target suite as active to avoid early sends
        try:
            ok = wait_active_suite(suite, timeout=10.0)
            if not ok:
                print(f"[WARN] timed out waiting for proxy to activate suite {suite}", file=sys.stderr)
        except Exception:
            print(f"[WARN] error while waiting for active suite {suite}", file=sys.stderr)

    events_path = suite_outdir(suite) / EVENTS_FILENAME
    traffic = UdpTraffic(
        APP_SEND_HOST,
        APP_SEND_PORT,
        APP_RECV_HOST,
        APP_RECV_PORT,
        events_path,
        rate_pps,
        packets_per_suite,
    )
    start_ns = time.time_ns()
    traffic.start()

    timeout = duration_s if duration_s > 0 else None
    if timeout is None:
        traffic.stop.wait()
    else:
        traffic.stop.wait(timeout=timeout)

    traffic.stop_and_close()
    end_ns = time.time_ns()

    snapshot_proxy_artifacts(suite)
    # Prefer live status counters if present, falling back to summary file emitted at exit
    proxy_stats = read_proxy_stats_live() or read_proxy_summary()

    row = {
        "pass": pass_index,
        "suite": suite,
        "duration_s": round((end_ns - start_ns) / 1e9, 3),
        "sent": traffic.sent,
        "rcvd": traffic.rcvd,
        "enc_out": proxy_stats.get("enc_out", 0),
        "enc_in": proxy_stats.get("enc_in", 0),
        "drops": proxy_stats.get("drops", 0),
        "rekeys_ok": proxy_stats.get("rekeys_ok", 0),
        "rekeys_fail": proxy_stats.get("rekeys_fail", 0),
        "start_ns": start_ns,
        "end_ns": end_ns,
    }

    print(
        f"[{ts()}] {suite}: sent={traffic.sent} rcvd={traffic.rcvd} "
        f"enc_out={row['enc_out']} enc_in={row['enc_in']}"
    )

    if delay_between_suites > 0:
        time.sleep(delay_between_suites)

    return row


def write_summary(rows: List[dict]) -> None:
    if not rows:
        return
    mkdirp(OUTDIR)
    with open(SUMMARY_CSV, "w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)
    print(f"[{ts()}] wrote {SUMMARY_CSV}")


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)

    parser = argparse.ArgumentParser(description="GCS automation scheduler (CONFIG-driven)")
    parser.add_argument("--duration", type=float, default=25.0, help="Seconds per suite (0 = until packets are sent)")
    parser.add_argument("--rate", type=int, default=100, help="Packet rate in packets/sec")
    parser.add_argument("--packets-per-suite", type=int, default=0, help="Optional cap on packets per suite")
    parser.add_argument("--passes", type=int, default=1, help="Number of full sweeps across suites")
    parser.add_argument("--delay-between-suites", type=float, default=0.0, help="Seconds to wait between suites")
    parser.add_argument("--suites", nargs="*", help="Optional subset of suites to exercise")
    args = parser.parse_args()

    if args.duration <= 0 and args.packets_per_suite <= 0:
        raise ValueError("Provide --duration > 0 or --packets-per-suite > 0 so runs terminate deterministically")
    if args.rate <= 0:
        raise ValueError("--rate must be a positive integer")
    if args.passes <= 0:
        raise ValueError("--passes must be >= 1")

    suites = resolve_suites(args.suites)
    if not suites:
        raise RuntimeError("No suites selected for execution")

    initial_suite = preferred_initial_suite(suites)
    if initial_suite and suites[0] != initial_suite:
        suites = [initial_suite] + [s for s in suites if s != initial_suite]
        print(f"[{ts()}] reordered suites to start with {initial_suite} (from CONFIG)")

    # Ensure follower control is reachable with a few retries before starting
    reachable = False
    for attempt in range(8):
        try:
            resp = ctl_send({"cmd": "ping"}, timeout=1.0, retries=1)
            if resp.get("ok"):
                reachable = True
                break
        except Exception:
            pass
        time.sleep(0.5)
    if reachable:
        print(f"[{ts()}] follower reachable at {DRONE_HOST}:{CONTROL_PORT}")
    else:
        print(f"[WARN] follower not reachable at {DRONE_HOST}:{CONTROL_PORT}", file=sys.stderr)

    gcs_proc, log_handle = start_gcs_proxy(suites[0])

    try:
        ready = wait_handshake(timeout=20.0)
        print(f"[{ts()}] initial handshake ready? {ready}")

        summary_rows: List[dict] = []
        for pass_index in range(args.passes):
            for idx, suite in enumerate(suites):
                row = run_suite(
                    gcs_proc,
                    suite,
                    is_first=(pass_index == 0 and idx == 0),
                    duration_s=args.duration,
                    rate_pps=args.rate,
                    packets_per_suite=(args.packets_per_suite or None),
                    delay_between_suites=args.delay_between_suites,
                    pass_index=pass_index,
                )
                summary_rows.append(row)

        write_summary(summary_rows)

    finally:
        try:
            ctl_send({"cmd": "stop"})
        except Exception:
            pass

        if gcs_proc.stdin:
            try:
                gcs_proc.stdin.write("quit\n")
                gcs_proc.stdin.flush()
            except Exception:
                pass
        try:
            gcs_proc.wait(timeout=5)
        except Exception:
            gcs_proc.kill()

        try:
            log_handle.close()
        except Exception:
            pass


if __name__ == "__main__":
    main()

============================================================

FILE 8/10: gcs_scheduler.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler.py
Size: 46,297 bytes
Modified: 2025-10-05 00:54:17
------------------------------------------------------------
#!/usr/bin/env python3
"""GCS scheduler that drives rekeys and UDP traffic using central configuration."""

from __future__ import annotations

import argparse
import csv
import json
import os
import shutil
import socket
import struct
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Set

try:
    from openpyxl import Workbook
except ImportError:  # pragma: no cover
    Workbook = None

# Ensure project root is on sys.path so `import core` works when running this file
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from core import suites as suites_mod
from core.config import CONFIG


DRONE_HOST = CONFIG["DRONE_HOST"]
GCS_HOST = CONFIG["GCS_HOST"]

CONTROL_PORT = int(CONFIG.get("DRONE_CONTROL_PORT", 48080))

APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = int(CONFIG.get("GCS_PLAINTEXT_TX", 47001))
APP_RECV_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_RECV_PORT = int(CONFIG.get("GCS_PLAINTEXT_RX", 47002))

OUTDIR = Path("logs/auto/gcs")
SUITES_OUTDIR = OUTDIR / "suites"
SECRETS_DIR = Path("secrets/matrix")

EXCEL_OUTPUT_DIR = Path(
    CONFIG.get("GCS_EXCEL_OUTPUT")
    or os.getenv("GCS_EXCEL_OUTPUT", "output/gcs")
)

COMBINED_OUTPUT_DIR = Path(
    CONFIG.get("GCS_COMBINED_OUTPUT_BASE")
    or os.getenv("GCS_COMBINED_OUTPUT_BASE", "output/gcs")
)

DRONE_MONITOR_BASE = Path(
    CONFIG.get("DRONE_MONITOR_OUTPUT_BASE")
    or os.getenv("DRONE_MONITOR_OUTPUT_BASE", "output/drone")
)

TELEMETRY_BIND_HOST = CONFIG.get("GCS_TELEMETRY_BIND", "0.0.0.0")
TELEMETRY_PORT = int(
    CONFIG.get("GCS_TELEMETRY_PORT")
    or CONFIG.get("DRONE_TELEMETRY_PORT")
    or 52080
)

SATURATION_TEST_RATES = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200]
SATURATION_RTT_SPIKE = 1.8

PROXY_STATUS_PATH = OUTDIR / "gcs_status.json"
PROXY_SUMMARY_PATH = OUTDIR / "gcs_summary.json"
SUMMARY_CSV = OUTDIR / "summary.csv"
EVENTS_FILENAME = "blaster_events.jsonl"


def ts() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def suite_outdir(suite: str) -> Path:
    target = SUITES_OUTDIR / suite
    mkdirp(target)
    return target


def resolve_suites(requested: Optional[Iterable[str]]) -> List[str]:
    available = list(suites_mod.list_suites())
    if not available:
        raise RuntimeError("No suites registered in core.suites; cannot proceed")

    if not requested:
        return available

    resolved: List[str] = []
    seen: Set[str] = set()
    for name in requested:
        info = suites_mod.get_suite(name)
        suite_id = info["suite_id"]
        if suite_id not in available:
            raise RuntimeError(f"Suite {name} not present in core registry")
        if suite_id not in seen:
            resolved.append(suite_id)
            seen.add(suite_id)
    return resolved


def preferred_initial_suite(candidates: List[str]) -> Optional[str]:
    configured = CONFIG.get("SIMPLE_INITIAL_SUITE")
    if not configured:
        return None
    try:
        suite_id = suites_mod.get_suite(configured)["suite_id"]
    except NotImplementedError:
        return None
    return suite_id if suite_id in candidates else None


def ctl_send(obj: dict, timeout: float = 2.0, retries: int = 4, backoff: float = 0.5) -> dict:
    last_exc: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((DRONE_HOST, CONTROL_PORT), timeout=timeout) as sock:
                sock.sendall((json.dumps(obj) + "\n").encode())
                sock.shutdown(socket.SHUT_WR)
                line = sock.makefile().readline()
                return json.loads(line.strip()) if line else {}
        except Exception as exc:
            last_exc = exc
            if attempt < retries:
                time.sleep(backoff * attempt)
                continue
            raise
    if last_exc:
        raise last_exc
    return {}


def request_power_capture(suite: str, duration_s: float, start_ns: Optional[int]) -> dict:
    payload = {
        "cmd": "power_capture",
        "suite": suite,
        "duration_s": duration_s,
    }
    if start_ns is not None:
        payload["start_ns"] = int(start_ns)
    try:
        resp = ctl_send(payload, timeout=1.5, retries=2, backoff=0.4)
    except Exception as exc:
        print(f"[WARN] power_capture request failed: {exc}", file=sys.stderr)
        return {"ok": False, "error": str(exc)}
    return resp


def poll_power_status(max_wait_s: float = 12.0, poll_s: float = 0.6) -> dict:
    deadline = time.time() + max_wait_s
    last: dict = {}
    while time.time() < deadline:
        try:
            resp = ctl_send({"cmd": "power_status"}, timeout=1.5, retries=1, backoff=0.3)
        except Exception as exc:
            last = {"ok": False, "error": str(exc)}
            time.sleep(poll_s)
            continue
        last = resp
        if not resp.get("ok"):
            break
        if not resp.get("available", True):
            break
        if not resp.get("busy", False):
            break
        time.sleep(poll_s)
    return last


class Blaster:
    """High-rate UDP blaster with RTT sampling and throughput accounting."""

    def __init__(
        self,
        send_host: str,
        send_port: int,
        recv_host: str,
        recv_port: int,
        events_path: Path,
        payload_bytes: int,
        sample_every: int,
        offset_ns: int,
    ) -> None:
        self.send_addr = (send_host, send_port)
        self.recv_addr = (recv_host, recv_port)
        self.payload_bytes = max(12, int(payload_bytes))
        self.sample_every = max(0, int(sample_every))
        self.offset_ns = offset_ns
        self.tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.rx.bind(self.recv_addr)
        self.rx.settimeout(0.001)
        self.rx_burst = max(1, int(os.getenv("GCS_RX_BURST", "32")))
        try:
            # Allow overriding socket buffer sizes via environment variables
            # Use GCS_SOCK_SNDBUF and GCS_SOCK_RCVBUF if present, otherwise default to 1 MiB
            sndbuf = int(os.getenv("GCS_SOCK_SNDBUF", str(1 << 20)))
            rcvbuf = int(os.getenv("GCS_SOCK_RCVBUF", str(1 << 20)))
            self.tx.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, sndbuf)
            self.rx.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, rcvbuf)
        except Exception:
            # best-effort; continue even if setting buffers fails
            pass

        mkdirp(events_path.parent)
        self.events = open(events_path, "w", encoding="utf-8")

        self.sent = 0
        self.rcvd = 0
        self.sent_bytes = 0
        self.rcvd_bytes = 0
        self.rtt_sum_ns = 0
        self.rtt_samples = 0
        self.rtt_max_ns = 0
        self.rtt_min_ns: Optional[int] = None
        self.pending: Dict[int, int] = {}

    def _log_event(self, payload: dict) -> None:
        # Buffered write; caller flushes at end of run()
        self.events.write(json.dumps(payload) + "\n")

    def _now(self) -> int:
        return time.time_ns() + self.offset_ns

    def _maybe_log(self, kind: str, seq: int, t_ns: int) -> None:
        if self.sample_every == 0:
            return
        if kind == "send":
            if seq % self.sample_every:
                return
        else:
            if self.rcvd % self.sample_every:
                return
        self._log_event({"event": kind, "seq": seq, "t_ns": t_ns})

    def run(self, duration_s: float, rate_pps: int, max_packets: Optional[int] = None) -> None:
        stop_at = self._now() + int(max(0.0, duration_s) * 1e9)
        payload_pad = b"\x00" * (self.payload_bytes - 12)
        interval = 0.0 if rate_pps <= 0 else 1.0 / max(1, rate_pps)
        stop_event = threading.Event()
        rx_thread = threading.Thread(target=self._rx_loop, args=(stop_event,), daemon=True)
        rx_thread.start()

        seq = 0
        burst = 32 if interval == 0.0 else 1
        while self._now() < stop_at:
            sends_this_loop = burst
            while sends_this_loop > 0:
                if self._now() >= stop_at:
                    break
                t_send = self._now()
                packet = seq.to_bytes(4, "big") + int(t_send).to_bytes(8, "big") + payload_pad
                try:
                    self.tx.sendto(packet, self.send_addr)
                    if self.sample_every == 0 or (self.sample_every and seq % self.sample_every == 0):
                        self.pending[seq] = int(t_send)
                    self.sent += 1
                    self.sent_bytes += len(packet)
                    self._maybe_log("send", seq, int(t_send))
                except Exception as exc:
                    self._log_event({"event": "send_error", "err": str(exc), "ts": ts()})
                seq += 1
                sends_this_loop -= 1
            if max_packets is not None and self.sent >= max_packets:
                break
            if interval > 0.0:
                time.sleep(interval)
            elif (seq & 0x3FFF) == 0:
                time.sleep(0)

        tail_deadline = self._now() + int(0.25 * 1e9)
        while self._now() < tail_deadline:
            if not self._rx_once():
                time.sleep(0)
        stop_event.set()
        rx_thread.join(timeout=0.2)
        # Bug #5 fix: Ensure cleanup happens even on exceptions
        try:
            try:
                self.events.flush()
            except Exception:
                pass
        finally:
            try:
                self.events.close()
            except Exception:
                pass
            try:
                self.tx.close()
            except Exception:
                pass
            try:
                self.rx.close()
            except Exception:
                pass
    def _rx_loop(self, stop_event: threading.Event) -> None:
        while not stop_event.is_set():
            progressed = False
            for _ in range(self.rx_burst):
                if self._rx_once():
                    progressed = True
                else:
                    break
            if not progressed:
                time.sleep(0)

    def _rx_once(self) -> bool:
        try:
            data, _ = self.rx.recvfrom(65535)
        except socket.timeout:
            return False
        except (socket.error, OSError) as exc:
            # Bug #4 fix: Catch specific exceptions, log unexpected errors
            if not isinstance(exc, (ConnectionResetError, ConnectionRefusedError)):
                self._log_event({"event": "rx_error", "err": str(exc), "ts": ts()})
            return False
        t_recv = self._now()
        self.rcvd += 1
        self.rcvd_bytes += len(data)
        if len(data) >= 12:
            seq = int.from_bytes(data[:4], "big")
            t_send = self.pending.pop(seq, None)
            if t_send is not None:
                rtt = t_recv - t_send
                self.rtt_sum_ns += rtt
                self.rtt_samples += 1
                if rtt > self.rtt_max_ns:
                    self.rtt_max_ns = rtt
                if self.rtt_min_ns is None or rtt < self.rtt_min_ns:
                    self.rtt_min_ns = rtt
                self._maybe_log("recv", seq, int(t_recv))
        return True


def wait_handshake(timeout: float = 20.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        if PROXY_STATUS_PATH.exists():
            try:
                with open(PROXY_STATUS_PATH, encoding="utf-8") as handle:
                    js = json.load(handle)
            except Exception:
                js = {}
            state = js.get("state") or js.get("status")
            if state in {"running", "completed", "ready", "handshake_ok"}:
                return True
        time.sleep(0.3)
    return False


def wait_active_suite(target: str, timeout: float = 10.0) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        try:
            status = ctl_send({"cmd": "status"}, timeout=0.6, retries=1)
        except Exception:
            status = {}
        if status.get("suite") == target:
            return True
        time.sleep(0.2)
    return False


def timesync() -> dict:
    t1 = time.time_ns()
    resp = ctl_send({"cmd": "timesync", "t1_ns": t1})
    t4 = time.time_ns()
    t2 = int(resp.get("t2_ns", t1))
    t3 = int(resp.get("t3_ns", t4))
    delay_ns = (t4 - t1) - (t3 - t2)
    offset_ns = ((t2 - t1) + (t3 - t4)) // 2
    return {"offset_ns": offset_ns, "rtt_ns": delay_ns}


def snapshot_proxy_artifacts(suite: str) -> None:
    target_dir = suite_outdir(suite)
    if PROXY_STATUS_PATH.exists():
        shutil.copy(PROXY_STATUS_PATH, target_dir / "gcs_status.json")
    if PROXY_SUMMARY_PATH.exists():
        shutil.copy(PROXY_SUMMARY_PATH, target_dir / "gcs_summary.json")


def start_gcs_proxy(initial_suite: str) -> tuple[subprocess.Popen, Path]:
    key_path = SECRETS_DIR / initial_suite / "gcs_signing.key"
    if not key_path.exists():
        raise FileNotFoundError(f"Missing GCS signing key for suite {initial_suite}: {key_path}")

    mkdirp(OUTDIR)
    log_path = OUTDIR / f"gcs_{time.strftime('%Y%m%d-%H%M%S')}.log"
    log_handle = open(log_path, "w", encoding="utf-8", errors="replace")

    os.environ["DRONE_HOST"] = DRONE_HOST
    os.environ["GCS_HOST"] = GCS_HOST
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    proc = subprocess.Popen(
        [
            sys.executable,
            "-m",
            "core.run_proxy",
            "gcs",
            "--suite",
            initial_suite,
            "--gcs-secret-file",
            str(key_path),
            "--control-manual",
            "--status-file",
            str(PROXY_STATUS_PATH),
            "--json-out",
            str(PROXY_SUMMARY_PATH),
        ],
        stdin=subprocess.PIPE,
        stdout=log_handle,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    return proc, log_handle


def read_proxy_stats_live() -> dict:
    try:
        with open(PROXY_STATUS_PATH, encoding="utf-8") as handle:
            js = json.load(handle)
    except Exception:
        return {}
    if isinstance(js, dict):
        counters = js.get("counters")
        if isinstance(counters, dict):
            return counters
        if any(k in js for k in ("enc_out", "enc_in")):
            return js
    return {}


def read_proxy_summary() -> dict:
    if not PROXY_SUMMARY_PATH.exists():
        return {}
    try:
        with open(PROXY_SUMMARY_PATH, encoding="utf-8") as handle:
            return json.load(handle)
    except Exception:
        return {}



def _read_proxy_counters() -> dict:

    counters = read_proxy_stats_live()

    if isinstance(counters, dict) and counters:

        return counters

    summary = read_proxy_summary()

    if isinstance(summary, dict):

        summary_counters = summary.get("counters")

        if isinstance(summary_counters, dict):

            return summary_counters

        if any(key in summary for key in ("enc_out", "enc_in", "rekeys_ok", "rekeys_fail", "last_rekey_suite")):

            return summary

    return {}





def wait_proxy_rekey(

    target_suite: str,

    baseline: Dict[str, object],

    *,

    timeout: float = 20.0,

    poll_interval: float = 0.4,

    proc: subprocess.Popen,

) -> str:

    start = time.time()

    baseline_ok = int(baseline.get("rekeys_ok", 0) or 0)

    baseline_fail = int(baseline.get("rekeys_fail", 0) or 0)

    while time.time() - start < timeout:

        if proc.poll() is not None:

            raise RuntimeError("GCS proxy exited during rekey")

        counters = _read_proxy_counters()

        if counters:

            rekeys_ok = int(counters.get("rekeys_ok", 0) or 0)

            rekeys_fail = int(counters.get("rekeys_fail", 0) or 0)

            last_suite = counters.get("last_rekey_suite") or counters.get("suite") or ""

            if rekeys_fail > baseline_fail:

                return "fail"

            if rekeys_ok > baseline_ok and (not last_suite or last_suite == target_suite):

                return "ok"

        time.sleep(poll_interval)

    return "timeout"


def activate_suite(gcs: subprocess.Popen, suite: str, is_first: bool) -> float:

    if gcs.poll() is not None:

        raise RuntimeError("GCS proxy is not running; cannot continue")

    start_ns = time.time_ns()

    if is_first:

        try:

            ctl_send({"cmd": "mark", "suite": suite})

        except Exception as exc:

            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)

        finally:

            try:

                ctl_send({"cmd": "rekey_complete", "suite": suite, "status": "ok"})

            except Exception:

                pass

    else:

        assert gcs.stdin is not None

        print(f"[{ts()}] rekey -> {suite}")

        gcs.stdin.write(suite + "\n")
        gcs.stdin.flush()

        baseline = _read_proxy_counters()

        try:
            ctl_send({"cmd": "mark", "suite": suite})
        except Exception as exc:
            print(f"[WARN] control mark failed for {suite}: {exc}", file=sys.stderr)
        try:
            follower_ready = wait_active_suite(suite, timeout=5.0)
            if not follower_ready:
                print(f"[WARN] follower did not report suite {suite} active before timeout", file=sys.stderr)
        except Exception:
            print(f"[WARN] follower status check failed for suite {suite}", file=sys.stderr)

        rekey_status = "timeout"

        try:

            result = wait_proxy_rekey(suite, baseline, timeout=15.0, proc=gcs)

            rekey_status = result

            if result == "timeout":

                print(f"[WARN] timed out waiting for proxy to activate suite {suite}", file=sys.stderr)

            elif result == "fail":

                print(f"[WARN] proxy reported failed rekey for suite {suite}", file=sys.stderr)

        except RuntimeError as exc:

            rekey_status = "error"

            raise

        except Exception as exc:

            rekey_status = "error"

            print(f"[WARN] error while waiting for proxy rekey {suite}: {exc}", file=sys.stderr)

        finally:

            try:

                ctl_send({"cmd": "rekey_complete", "suite": suite, "status": rekey_status})

            except Exception as exc:

                print(f"[WARN] rekey_complete failed for {suite}: {exc}", file=sys.stderr)

    return (time.time_ns() - start_ns) / 1_000_000




def run_suite(
    gcs: subprocess.Popen,
    suite: str,
    is_first: bool,
    duration_s: float,
    payload_bytes: int,
    event_sample: int,
    offset_ns: int,
    pass_index: int,
    traffic_mode: str,
    pre_gap: float,
    rate_pps: int,
) -> dict:
    rekey_duration_ms = activate_suite(gcs, suite, is_first)

    events_path = suite_outdir(suite) / EVENTS_FILENAME
    start_mark_ns = time.time_ns() + offset_ns + int(0.150 * 1e9) + int(max(pre_gap, 0.0) * 1e9)
    try:
        ctl_send({"cmd": "schedule_mark", "suite": suite, "t0_ns": start_mark_ns})
    except Exception as exc:
        print(f"[WARN] schedule_mark failed for {suite}: {exc}", file=sys.stderr)

    power_start_ns = time.time_ns() + offset_ns + int(max(pre_gap, 0.0) * 1e9)
    power_resp = request_power_capture(suite, duration_s, power_start_ns)
    power_request_ok = bool(power_resp.get("ok"))
    power_request_error = power_resp.get("error") if not power_request_ok else None
    if not power_request_ok and power_request_error:
        print(f"[WARN] power capture not scheduled: {power_request_error}", file=sys.stderr)

    print(
        f"[{ts()}] ===== POWER: START in {pre_gap:.1f}s | suite={suite} | duration={duration_s:.1f}s mode={traffic_mode} ====="
    )
    if pre_gap > 0:
        time.sleep(pre_gap)

    start_wall_ns = time.time_ns()
    start_perf_ns = time.perf_counter_ns()
    sent_packets = 0
    rcvd_packets = 0
    rcvd_bytes = 0
    avg_rtt_ns = 0
    max_rtt_ns = 0
    rtt_samples = 0
    blaster_sent_bytes = 0

    if traffic_mode == "blast":
        blaster = Blaster(
            APP_SEND_HOST,
            APP_SEND_PORT,
            APP_RECV_HOST,
            APP_RECV_PORT,
            events_path,
            payload_bytes=payload_bytes,
            sample_every=event_sample,
            offset_ns=offset_ns,
        )
        blaster.run(duration_s=duration_s, rate_pps=rate_pps)
        sent_packets = blaster.sent
        rcvd_packets = blaster.rcvd
        rcvd_bytes = blaster.rcvd_bytes
        blaster_sent_bytes = blaster.sent_bytes
        sample_count = max(1, blaster.rtt_samples)
        avg_rtt_ns = blaster.rtt_sum_ns // sample_count
        max_rtt_ns = blaster.rtt_max_ns
        rtt_samples = blaster.rtt_samples
    else:
        time.sleep(duration_s)

    end_wall_ns = time.time_ns()
    end_perf_ns = time.perf_counter_ns()
    print(f"[{ts()}] ===== POWER: STOP | suite={suite} =====")

    snapshot_proxy_artifacts(suite)
    proxy_stats = read_proxy_stats_live() or read_proxy_summary()

    power_status = {}
    if power_request_ok:
        power_status = poll_power_status(max_wait_s=max(6.0, duration_s * 0.25))
        if power_status.get("error"):
            print(f"[WARN] power status error: {power_status['error']}", file=sys.stderr)

    power_summary = power_status.get("last_summary") if isinstance(power_status, dict) else None
    power_capture_complete = bool(power_summary)
    power_error = None
    if not power_capture_complete:
        if isinstance(power_status, dict):
            power_error = power_status.get("error")
            if not power_error and power_status.get("busy"):
                power_error = "capture_incomplete"
        if power_error is None:
            power_error = power_request_error

    elapsed_s = max(1e-9, (end_perf_ns - start_perf_ns) / 1e9)
    pps = sent_packets / elapsed_s
    throughput_mbps = (rcvd_bytes * 8) / (elapsed_s * 1_000_000)
    sent_mbps = (blaster_sent_bytes * 8) / (elapsed_s * 1_000_000) if blaster_sent_bytes else 0.0
    delivered_ratio = throughput_mbps / sent_mbps if sent_mbps > 0 else 0.0
    avg_rtt_ms = avg_rtt_ns / 1_000_000
    max_rtt_ms = max_rtt_ns / 1_000_000

    loss_pct = 0.0
    if sent_packets:
        loss_pct = max(0.0, (sent_packets - rcvd_packets) * 100.0 / sent_packets)

    row = {
        "pass": pass_index,
        "suite": suite,
        "duration_s": round(elapsed_s, 3),
        "sent": sent_packets,
        "rcvd": rcvd_packets,
        "pps": round(pps, 1),
        "throughput_mbps": round(throughput_mbps, 3),
        "sent_mbps": round(sent_mbps, 3),
        "delivered_ratio": round(delivered_ratio, 3) if sent_mbps > 0 else 0.0,
        "rtt_avg_ms": round(avg_rtt_ms, 3),
        "rtt_max_ms": round(max_rtt_ms, 3),
        "rtt_samples": rtt_samples,
        "loss_pct": round(loss_pct, 3),
        "enc_out": proxy_stats.get("enc_out", 0),
        "enc_in": proxy_stats.get("enc_in", 0),
        "drops": proxy_stats.get("drops", 0),
        "rekeys_ok": proxy_stats.get("rekeys_ok", 0),
        "rekeys_fail": proxy_stats.get("rekeys_fail", 0),
        "start_ns": start_wall_ns,
        "end_ns": end_wall_ns,
        "rekey_ms": round(rekey_duration_ms, 3),
    "power_request_ok": power_request_ok,
    "power_capture_ok": power_capture_complete,
    "power_error": power_error,
        "power_avg_w": round(power_summary.get("avg_power_w", 0.0), 6) if power_summary else 0.0,
        "power_energy_j": round(power_summary.get("energy_j", 0.0), 6) if power_summary else 0.0,
        "power_samples": power_summary.get("samples") if power_summary else 0,
        "power_avg_current_a": round(power_summary.get("avg_current_a", 0.0), 6) if power_summary else 0.0,
        "power_avg_voltage_v": round(power_summary.get("avg_voltage_v", 0.0), 6) if power_summary else 0.0,
        "power_sample_rate_hz": round(power_summary.get("sample_rate_hz", 0.0), 3) if power_summary else 0.0,
        "power_duration_s": round(power_summary.get("duration_s", 0.0), 3) if power_summary else 0.0,
        "power_csv_path": power_summary.get("csv_path") if power_summary else "",
        "power_summary_path": power_summary.get("summary_json_path") if power_summary else "",
    }

    print(
        f"[{ts()}] <<< FINISH suite={suite} mode={traffic_mode} sent={sent_packets} rcvd={rcvd_packets} "
        f"pps~{pps:.0f} thr~{throughput_mbps:.2f} Mb/s sent~{sent_mbps:.2f} Mb/s loss={loss_pct:.2f}% "
        f"rtt_avg={avg_rtt_ms:.3f}ms rtt_max={max_rtt_ms:.3f}ms rekey={rekey_duration_ms:.2f}ms "
        f"enc_out={row['enc_out']} enc_in={row['enc_in']} >>>"
    )

    return row


def write_summary(rows: List[dict]) -> None:
    if not rows:
        return
    mkdirp(OUTDIR)
    with open(SUMMARY_CSV, "w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)
    print(f"[{ts()}] wrote {SUMMARY_CSV}")


class SaturationTester:
    def __init__(
        self,
        suite: str,
        payload_bytes: int,
        duration_s: float,
        event_sample: int,
        offset_ns: int,
        output_dir: Path,
        max_rate_mbps: int,
    ):
        self.suite = suite
        self.payload_bytes = payload_bytes
        self.duration_s = duration_s
        self.event_sample = event_sample
        self.offset_ns = offset_ns
        self.output_dir = output_dir
        self.max_rate_mbps = max_rate_mbps
        self.records: List[Dict[str, float]] = []

    def run(self) -> Dict[str, Optional[float]]:
        baseline_rtt = None
        saturation_point = None
        for rate in SATURATION_TEST_RATES:
            if rate > self.max_rate_mbps:
                break
            metrics = self._run_rate(rate)
            metrics["suite"] = self.suite
            self.records.append(metrics)
            avg_rtt = metrics["avg_rtt_ms"]
            achieved = metrics["throughput_mbps"]
            sent_mbps = metrics.get("sent_mbps", 0.0)
            ratio = metrics.get("delivered_ratio", 1.0) if sent_mbps > 0 else 1.0
            samples = metrics.get("rtt_samples", 0)
            if baseline_rtt is None and samples and avg_rtt > 0:
                baseline_rtt = avg_rtt
            if baseline_rtt is not None and samples:
                delivery_degraded = sent_mbps > 0 and ratio < 0.8
                if avg_rtt > baseline_rtt * SATURATION_RTT_SPIKE or delivery_degraded:
                    saturation_point = rate
                    break
        return {
            "suite": self.suite,
            "baseline_rtt_ms": baseline_rtt,
            "saturation_point_mbps": saturation_point,
        }

    def _run_rate(self, rate_mbps: int) -> Dict[str, float]:
        rate_pps = int((rate_mbps * 1_000_000) / (self.payload_bytes * 8))
        if rate_pps <= 0:
            rate_pps = 1
        events_path = self.output_dir / f"saturation_{rate_mbps}Mbps.jsonl"
        blaster = Blaster(
            APP_SEND_HOST,
            APP_SEND_PORT,
            APP_RECV_HOST,
            APP_RECV_PORT,
            events_path,
            payload_bytes=self.payload_bytes,
            sample_every=max(1, self.event_sample),
            offset_ns=self.offset_ns,
        )
        blaster.run(duration_s=self.duration_s, rate_pps=rate_pps)
        duration = max(self.duration_s, 1e-3)
        throughput_mbps = (blaster.rcvd_bytes * 8) / (duration * 1_000_000)
        sent_mbps = (blaster.sent_bytes * 8) / (duration * 1_000_000)
        delivered_ratio = throughput_mbps / sent_mbps if sent_mbps > 0 else 0.0
        loss_pct = 0.0
        if blaster.sent:
            loss_pct = max(0.0, (blaster.sent - blaster.rcvd) * 100.0 / blaster.sent)
        if blaster.rtt_samples:
            avg_rtt_ms = (blaster.rtt_sum_ns / blaster.rtt_samples) / 1_000_000
        else:
            avg_rtt_ms = 0.0
        min_rtt_ms = (blaster.rtt_min_ns or 0) / 1_000_000
        max_rtt_ms = blaster.rtt_max_ns / 1_000_000
        return {
            "rate_mbps": float(rate_mbps),
            "pps": float(rate_pps),
            "throughput_mbps": round(throughput_mbps, 3),
            "sent_mbps": round(sent_mbps, 3),
            "loss_pct": round(loss_pct, 3),
            "delivered_ratio": round(delivered_ratio, 3) if sent_mbps > 0 else 0.0,
            "avg_rtt_ms": round(avg_rtt_ms, 3),
            "min_rtt_ms": round(min_rtt_ms, 3),
            "max_rtt_ms": round(max_rtt_ms, 3),
            "rtt_samples": blaster.rtt_samples,
        }

    def export_excel(self, session_id: str) -> Optional[Path]:
        if Workbook is None:
            print("[WARN] openpyxl not available; skipping Excel export")
            return None
        EXCEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        path = EXCEL_OUTPUT_DIR / f"saturation_{self.suite}_{session_id}.xlsx"
        wb = Workbook()
        ws = wb.active
        ws.title = "Saturation"
        ws.append([
            "rate_mbps",
            "pps",
            "sent_mbps",
            "throughput_mbps",
            "loss_pct",
            "delivered_ratio",
            "avg_rtt_ms",
            "min_rtt_ms",
            "max_rtt_ms",
            "rtt_samples",
        ])
        for record in self.records:
            ws.append([
                record["rate_mbps"],
                record["pps"],
                record.get("sent_mbps", 0),
                record["throughput_mbps"],
                record["loss_pct"],
                record.get("delivered_ratio", 0),
                record["avg_rtt_ms"],
                record["min_rtt_ms"],
                record["max_rtt_ms"],
                record.get("rtt_samples", 0),
            ])
        wb.save(path)
        return path


class TelemetryCollector:
    def __init__(self, host: str, port: int) -> None:
        self.host = host
        self.port = port
        self.stop_event = threading.Event()
        self.server: Optional[socket.socket] = None
        self.accept_thread: Optional[threading.Thread] = None
        self.client_threads: List[threading.Thread] = []
        # Bug #9 fix: Use deque with maxlen to prevent unbounded memory growth
        from collections import deque
        self.samples: deque = deque(maxlen=100000)  # ~10MB limit for long tests
        self.lock = threading.Lock()
        self.enabled = True

    def start(self) -> None:
        try:
            srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            srv.bind((self.host, self.port))
            srv.listen(8)
            srv.settimeout(0.5)
            self.server = srv
            self.accept_thread = threading.Thread(target=self._accept_loop, daemon=True)
            self.accept_thread.start()
            print(f"[{ts()}] telemetry collector listening on {self.host}:{self.port}")
        except Exception as exc:
            print(f"[WARN] telemetry collector disabled: {exc}", file=sys.stderr)
            self.enabled = False
            if self.server:
                try:
                    self.server.close()
                except Exception:
                    pass
            self.server = None

    def _accept_loop(self) -> None:
        assert self.server is not None
        while not self.stop_event.is_set():
            try:
                conn, addr = self.server.accept()
            except socket.timeout:
                continue
            except OSError:
                break
            except Exception as exc:
                if not self.stop_event.is_set():
                    print(f"[WARN] telemetry accept error: {exc}", file=sys.stderr)
                continue
            thread = threading.Thread(target=self._client_loop, args=(conn, addr), daemon=True)
            thread.start()
            self.client_threads.append(thread)

    def _client_loop(self, conn: socket.socket, addr) -> None:
        peer = f"{addr[0]}:{addr[1]}"
        try:
            conn.settimeout(1.0)
            with conn, conn.makefile("r", encoding="utf-8") as reader:
                for line in reader:
                    if self.stop_event.is_set():
                        break
                    data = line.strip()
                    if not data:
                        continue
                    try:
                        payload = json.loads(data)
                    except json.JSONDecodeError:
                        continue
                    payload.setdefault("collector_ts_ns", time.time_ns())
                    payload.setdefault("source", "drone")
                    payload.setdefault("peer", peer)
                    with self.lock:
                        self.samples.append(payload)
        except Exception:
            # drop connection silently
            pass

    def snapshot(self) -> List[dict]:
        with self.lock:
            # Convert deque to list for compatibility
            return list(self.samples)

    def stop(self) -> None:
        self.stop_event.set()
        if self.server:
            try:
                self.server.close()
            except Exception:
                pass
        if self.accept_thread and self.accept_thread.is_alive():
            self.accept_thread.join(timeout=1.5)
        for thread in self.client_threads:
            if thread.is_alive():
                thread.join(timeout=1.0)

def resolve_under_root(path: Path) -> Path:
    return path if path.is_absolute() else ROOT / path


def safe_sheet_name(name: str) -> str:
    sanitized = "".join("_" if ch in '[]:*?/\\' else ch for ch in name).strip()
    if not sanitized:
        sanitized = "Sheet"
    return sanitized[:31]


def unique_sheet_name(workbook, base_name: str) -> str:
    base = safe_sheet_name(base_name)
    if base not in workbook.sheetnames:
        return base
    index = 1
    while True:
        suffix = f"_{index}"
        name = base[: 31 - len(suffix)] + suffix
        if name not in workbook.sheetnames:
            return name
        index += 1


def append_dict_sheet(workbook, title: str, rows: List[dict]) -> None:
    if not rows:
        return
    sheet_name = unique_sheet_name(workbook, title)
    ws = workbook.create_sheet(sheet_name)
    headers: List[str] = []
    for row in rows:
        for key in row.keys():
            if key not in headers:
                headers.append(key)
    ws.append(headers)
    for row in rows:
        ws.append([row.get(header, "") for header in headers])


def append_csv_sheet(workbook, path: Path, title: str) -> None:
    if not path.exists():
        return
    try:
        with open(path, newline="", encoding="utf-8") as handle:
            reader = csv.reader(handle)
            rows = list(reader)
    except Exception as exc:
        print(f"[WARN] failed to read CSV {path}: {exc}", file=sys.stderr)
        return
    if not rows:
        return
    sheet_name = unique_sheet_name(workbook, title)
    ws = workbook.create_sheet(sheet_name)
    for row in rows:
        ws.append(row)


def locate_drone_session_dir(session_id: str) -> Optional[Path]:
    candidates = []
    try:
        candidates.append(resolve_under_root(DRONE_MONITOR_BASE) / session_id)
    except Exception:
        pass
    fallback = Path("/home/dev/research/output/drone") / session_id
    candidates.append(fallback)
    repo_default = ROOT / "output" / "drone" / session_id
    candidates.append(repo_default)
    seen = set()
    for candidate in candidates:
        if candidate in seen:
            continue
        seen.add(candidate)
        try:
            if candidate.exists():
                return candidate
        except Exception:
            continue
    return None


def export_combined_excel(
    session_id: str,
    summary_rows: List[dict],
    saturation_overview: List[dict],
    saturation_samples: List[dict],
    telemetry_samples: List[dict],
) -> Optional[Path]:
    if Workbook is None:
        print("[WARN] openpyxl not available; skipping combined Excel export", file=sys.stderr)
        return None

    workbook = Workbook()
    info_sheet = workbook.active
    info_sheet.title = "run_info"
    info_sheet.append(["generated_utc", ts()])
    info_sheet.append(["session_id", session_id])

    append_dict_sheet(workbook, "gcs_summary", summary_rows)
    append_dict_sheet(workbook, "saturation_overview", saturation_overview)
    append_dict_sheet(workbook, "saturation_samples", saturation_samples)
    append_dict_sheet(workbook, "telemetry_samples", telemetry_samples)

    if SUMMARY_CSV.exists():
        append_csv_sheet(workbook, SUMMARY_CSV, "gcs_summary_csv")

    drone_session_dir = locate_drone_session_dir(session_id)
    if drone_session_dir:
        info_sheet.append(["drone_session_dir", str(drone_session_dir)])
        for csv_path in sorted(drone_session_dir.glob("*.csv")):
            append_csv_sheet(workbook, csv_path, csv_path.stem[:31])
    else:
        info_sheet.append(["drone_session_dir", "not_found"])

    combined_dir = resolve_under_root(COMBINED_OUTPUT_DIR)
    combined_dir.mkdir(parents=True, exist_ok=True)
    target_path = combined_dir / f"{session_id}_combined.xlsx"
    workbook.save(target_path)
    return target_path


def main() -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)

    parser = argparse.ArgumentParser(description="GCS automation scheduler (CONFIG-driven)")
    parser.add_argument(
        "--traffic",
        choices=["blast", "mavproxy", "saturation"],
        default="blast",
        help="blast = internal UDP blaster; saturation = ramp rates until RTT spike.",
    )
    parser.add_argument(
        "--pre-gap",
        type=float,
        default=1.0,
        help="Seconds to wait after (re)key before sending.",
    )
    parser.add_argument(
        "--inter-gap",
        type=float,
        default=15.0,
        help="Seconds to wait between suites.",
    )
    parser.add_argument(
        "--duration",
        type=float,
        default=45.0,
        help="Active send window per suite.",
    )
    parser.add_argument(
        "--rate",
        type=int,
        default=0,
        help="Packets/sec for blast; 0 = as fast as possible.",
    )
    parser.add_argument(
        "--max-rate",
        type=int,
        default=200,
        help="Upper bound Mbps for saturation testing.",
    )
    parser.add_argument(
        "--payload-bytes",
        type=int,
        default=256,
        help="UDP payload size used for throughput calc.",
    )
    parser.add_argument(
        "--event-sample",
        type=int,
        default=100,
        help="Log every Nth send/recv event (0 = disable).",
    )
    parser.add_argument("--passes", type=int, default=1, help="Number of full sweeps across suites")
    parser.add_argument("--suites", nargs="*", help="Optional subset of suites to exercise")
    parser.add_argument("--session-id", help="Identifier for output artifacts")
    args = parser.parse_args()

    if args.duration <= 0:
        raise ValueError("--duration must be positive")
    if args.pre_gap < 0:
        raise ValueError("--pre-gap must be >= 0")
    if args.inter_gap < 0:
        raise ValueError("--inter-gap must be >= 0")
    if args.rate < 0:
        raise ValueError("--rate must be >= 0")
    if args.passes <= 0:
        raise ValueError("--passes must be >= 1")

    suites = resolve_suites(args.suites)
    if not suites:
        raise RuntimeError("No suites selected for execution")

    session_id = args.session_id or f"session_{int(time.time())}"

    initial_suite = preferred_initial_suite(suites)
    if initial_suite and suites[0] != initial_suite:
        suites = [initial_suite] + [s for s in suites if s != initial_suite]
        print(f"[{ts()}] reordered suites to start with {initial_suite} (from CONFIG)")

    reachable = False
    for attempt in range(8):
        try:
            resp = ctl_send({"cmd": "ping"}, timeout=1.0, retries=1)
            if resp.get("ok"):
                reachable = True
                break
        except Exception:
            pass
        time.sleep(0.5)
    if reachable:
        print(f"[{ts()}] follower reachable at {DRONE_HOST}:{CONTROL_PORT}")
    else:
        print(f"[WARN] follower not reachable at {DRONE_HOST}:{CONTROL_PORT}", file=sys.stderr)

    offset_ns = 0
    try:
        sync = timesync()
        offset_ns = sync["offset_ns"]
        print(f"[{ts()}] clocks synced: offset_ns={offset_ns} ns, link_rtt~{sync['rtt_ns']} ns")
    except Exception as exc:
        print(f"[WARN] timesync failed: {exc}", file=sys.stderr)

    telemetry_collector = TelemetryCollector(TELEMETRY_BIND_HOST, TELEMETRY_PORT)
    telemetry_collector.start()

    gcs_proc, log_handle = start_gcs_proxy(suites[0])

    try:
        ready = wait_handshake(timeout=20.0)
        print(f"[{ts()}] initial handshake ready? {ready}")

        summary_rows: List[dict] = []
        saturation_reports: List[dict] = []
        all_rate_samples: List[dict] = []
        telemetry_samples: List[dict] = []

        if args.traffic == "saturation":
            for idx, suite in enumerate(suites):
                rekey_ms = activate_suite(gcs_proc, suite, is_first=(idx == 0))
                outdir = suite_outdir(suite)
                tester = SaturationTester(
                    suite=suite,
                    payload_bytes=args.payload_bytes,
                    duration_s=args.duration,
                    event_sample=args.event_sample,
                    offset_ns=offset_ns,
                    output_dir=outdir,
                    max_rate_mbps=args.max_rate,
                )
                summary = tester.run()
                summary["rekey_ms"] = rekey_ms
                excel_path = tester.export_excel(session_id)
                if excel_path:
                    summary["excel_path"] = str(excel_path)
                saturation_reports.append(summary)
                all_rate_samples.extend(dict(record) for record in tester.records)
                if args.inter_gap > 0 and idx < len(suites) - 1:
                    time.sleep(args.inter_gap)
            report_path = OUTDIR / f"saturation_summary_{session_id}.json"
            with open(report_path, "w", encoding="utf-8") as handle:
                json.dump(saturation_reports, handle, indent=2)
            print(f"[{ts()}] saturation summary written to {report_path}")
        else:
            for pass_index in range(args.passes):
                for idx, suite in enumerate(suites):
                    row = run_suite(
                        gcs_proc,
                        suite,
                        is_first=(pass_index == 0 and idx == 0),
                        duration_s=args.duration,
                        payload_bytes=args.payload_bytes,
                        event_sample=args.event_sample,
                        offset_ns=offset_ns,
                        pass_index=pass_index,
                        traffic_mode=args.traffic,
                        pre_gap=args.pre_gap,
                        rate_pps=args.rate,
                    )
                    summary_rows.append(row)
                    is_last_suite = idx == len(suites) - 1
                    is_last_pass = pass_index == args.passes - 1
                    if args.inter_gap > 0 and not (is_last_suite and is_last_pass):
                        time.sleep(args.inter_gap)

            write_summary(summary_rows)

        if telemetry_collector.enabled:
            telemetry_samples = telemetry_collector.snapshot()

        combined_path = export_combined_excel(
            session_id=session_id,
            summary_rows=summary_rows,
            saturation_overview=saturation_reports,
            saturation_samples=all_rate_samples,
            telemetry_samples=telemetry_samples,
        )
        if combined_path:
            print(f"[{ts()}] combined workbook written to {combined_path}")

    finally:
        try:
            ctl_send({"cmd": "stop"})
        except Exception:
            pass

        if gcs_proc.stdin:
            try:
                gcs_proc.stdin.write("quit\n")
                gcs_proc.stdin.flush()
            except Exception:
                pass
        try:
            gcs_proc.wait(timeout=5)
        except Exception:
            gcs_proc.kill()

        try:
            log_handle.close()
        except Exception:
            pass

        telemetry_collector.stop()


if __name__ == "__main__":
    main()

============================================================

FILE 9/10: gcs_scheduler_quickpass.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler_quickpass.py
Size: 7,899 bytes
Modified: 2025-09-29 03:53:14
------------------------------------------------------------
#!/usr/bin/env python3
"""
Quick-pass scheduler: send-one?wait-echo?next suite.

Minimal, self-contained scheduler intended to run on the GCS host.
It assumes a running drone follower on the Pi exposing a tiny JSON control API
and a running GCS proxy launched with "--control-manual" so rekeys can be
performed by writing suite IDs to the proxy's stdin.

Outputs:
- logs/auto/quickpass_events.jsonl
- logs/auto/quickpass_summary.csv

Usage (example):
  python -m tools.auto.gcs_scheduler_quickpass \
            --gcs 192.168.0.103 --drone 192.168.0.102 \
    --control-port 48080 --app-send-port 47001 --app-recv-port 47002 \
    --passes 1
"""
import argparse
import csv
import json
import os
import pathlib
import socket
import subprocess
import sys
import time

SUITES = [
    "cs-mlkem512-aesgcm-mldsa44","cs-mlkem512-aesgcm-mldsa65","cs-mlkem512-aesgcm-mldsa87",
    "cs-mlkem512-aesgcm-falcon512","cs-mlkem512-aesgcm-falcon1024",
    "cs-mlkem512-aesgcm-sphincs128fsha2","cs-mlkem512-aesgcm-sphincs256fsha2",
    "cs-mlkem768-aesgcm-mldsa44","cs-mlkem768-aesgcm-mldsa65","cs-mlkem768-aesgcm-mldsa87",
    "cs-mlkem768-aesgcm-falcon512","cs-mlkem768-aesgcm-falcon1024",
    "cs-mlkem768-aesgcm-sphincs128fsha2","cs-mlkem768-aesgcm-sphincs256fsha2",
    "cs-mlkem1024-aesgcm-mldsa44","cs-mlkem1024-aesgcm-mldsa65","cs-mlkem1024-aesgcm-mldsa87",
    "cs-mlkem1024-aesgcm-falcon512","cs-mlkem1024-aesgcm-falcon1024",
    "cs-mlkem1024-aesgcm-sphincs128fsha2","cs-mlkem1024-aesgcm-sphincs256fsha2"
]


def ts():
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def mkdirp(p):
    pathlib.Path(p).mkdir(parents=True, exist_ok=True)


# simple control client for drone follower
def ctl(host, port, obj, timeout=3.0):
    with socket.create_connection((host, port), timeout=timeout) as s:
        s.sendall((json.dumps(obj) + "\n").encode())
        s.shutdown(socket.SHUT_WR)
        line = s.makefile().readline()
        return json.loads(line.strip()) if line else {"ok": False, "error": "no reply"}


# send a single UDP packet and wait for an echo
def send_and_wait_echo(send_port: int, recv_port: int, payload: bytes, timeout_s: float):
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx.bind(("0.0.0.0", recv_port))
        rx.settimeout(min(0.2, timeout_s))
        t0 = time.time_ns()
        seq = int.from_bytes(payload[:4], "big") if len(payload) >= 4 else 0
        tx.sendto(payload, ("127.0.0.1", send_port))
        deadline = time.time() + timeout_s
        while time.time() < deadline:
            try:
                data, _ = rx.recvfrom(65535)
                if len(data) >= 4 and int.from_bytes(data[:4], "big") == seq:
                    t1 = time.time_ns()
                    return True, t0, t1, len(data)
            except socket.timeout:
                pass
        return False, t0, None, 0
    finally:
        try:
            tx.close()
        except Exception:
            pass
        try:
            rx.close()
        except Exception:
            pass


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--gcs", required=True)
    ap.add_argument("--drone", required=True)
    ap.add_argument("--control-port", type=int, default=48080)
    ap.add_argument("--app-send-port", type=int, default=47001)
    ap.add_argument("--app-recv-port", type=int, default=47002)
    ap.add_argument("--verify-timeout", type=float, default=5.0)
    ap.add_argument("--passes", type=int, default=1)
    ap.add_argument("--outdir", default="logs/auto")
    ap.add_argument("--secrets-dir", default="secrets/matrix")
    ap.add_argument("--initial-suite", default=None)
    ap.add_argument("--suites", nargs="*", default=SUITES)
    args = ap.parse_args()

    os.environ["DRONE_HOST"] = args.drone
    os.environ["GCS_HOST"] = args.gcs
    os.environ["ENABLE_PACKET_TYPE"] = "1"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1"

    mkdirp(args.outdir)
    evlog = open(f"{args.outdir}/quickpass_events.jsonl", "a", encoding="utf-8")

    def log_event(**row):
        row.setdefault("ts", ts())
        evlog.write(json.dumps(row) + "\n")
        evlog.flush()

    suites = list(args.suites)
    if args.initial_suite and args.initial_suite in suites:
        i = suites.index(args.initial_suite)
        suites = suites[i:] + suites[:i]

    first = suites[0]
    keyfile = f"{args.secrets_dir}/{first}/gcs_signing.key"
    mkdirp(f"{args.outdir}/{first}")
    status_file = f"{args.outdir}/{first}/gcs_status.json"
    summary_file = f"{args.outdir}/{first}/gcs_summary.json"
    gcs_log = open(f"{args.outdir}/gcs_{time.strftime('%Y%m%d-%H%M%S')}.log", "w", encoding="utf-8", errors="replace")

    gcs = subprocess.Popen([
        sys.executable, "-m", "core.run_proxy", "gcs",
        "--suite", first, "--gcs-secret-file", keyfile,
        "--control-manual",
        "--status-file", status_file, "--json-out", summary_file
    ], stdin=subprocess.PIPE, stdout=gcs_log, stderr=subprocess.STDOUT, text=True, bufsize=1)

    # initial ping/mark
    try:
        ctl(args.drone, args.control_port, {"cmd": "ping"})
        ctl(args.drone, args.control_port, {"cmd": "mark", "suite": first})
    except Exception as e:
        log_event(event="control_warn", msg=str(e))

    csv_path = f"{args.outdir}/quickpass_summary.csv"
    have_header = os.path.exists(csv_path)
    csvf = open(csv_path, "a", newline="", encoding="utf-8")
    w = csv.DictWriter(csvf, fieldnames=["pass_idx", "suite", "ok", "attempt_ns", "payload_bytes", "note"])
    if not have_header:
        w.writeheader(); csvf.flush()

    def rekey(to_suite: str):
        try:
            gcs.stdin.write(to_suite + "\n"); gcs.stdin.flush()
        except Exception as e:
            log_event(event="gcs_write_fail", msg=str(e))
        try:
            ctl(args.drone, args.control_port, {"cmd": "mark", "suite": to_suite})
        except Exception as e:
            log_event(event="control_warn", msg=f"mark failed: {e}")

    try:
        for p in range(args.passes):
            for idx, suite in enumerate(suites):
                if p == 0 and idx == 0:
                    current = first
                else:
                    current = suite
                    log_event(event="rekey", to=current, pass_idx=p)
                    rekey(current)

                seq = int(time.time_ns() & 0xFFFFFFFF)
                payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
                ok, t0_ns, t1_ns, nbytes = send_and_wait_echo(args.app_send_port, args.app_recv_port, payload, args.verify_timeout)

                if ok:
                    attempt_ns = t1_ns - t0_ns
                    w.writerow({"pass_idx": p, "suite": current, "ok": True, "attempt_ns": attempt_ns, "payload_bytes": nbytes, "note": "echo"})
                    csvf.flush()
                    log_event(event="echo_ok", suite=current, pass_idx=p, rtt_ns=attempt_ns)
                else:
                    w.writerow({"pass_idx": p, "suite": current, "ok": False, "attempt_ns": "", "payload_bytes": 0, "note": "timeout"})
                    csvf.flush()
                    log_event(event="echo_timeout", suite=current, pass_idx=p)
    finally:
        try:
            ctl(args.drone, args.control_port, {"cmd": "stop"})
        except Exception:
            pass
        try:
            gcs.stdin.write("quit\n"); gcs.stdin.flush()
        except Exception:
            pass
        try:
            gcs.wait(timeout=3)
        except Exception:
            gcs.kill()
        evlog.close(); csvf.close(); gcs_log.close()


if __name__ == "__main__":
    main()

============================================================

FILE 10/10: gcs_scheduler_simple.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\auto\gcs_scheduler_simple.py
Size: 9,391 bytes
Modified: 2025-09-29 03:50:13
------------------------------------------------------------
#!/usr/bin/env python3
"""
GCS scheduler (interactive by default; --auto runs whole list):
- Starts the GCS proxy in --control-manual with the first suite.
- For each chosen suite: rekey -> send UDP -> wait for echo(s) -> proceed.
- All networking parameters are sourced from core.config.CONFIG.
"""

import os, sys, time, json, csv, pathlib, socket, subprocess

from core.config import CONFIG
from core import suites as suite_registry

SECRETS_DIR = "secrets/matrix"
OUTDIR = "logs/auto"

CONTROL_HOST = CONFIG["DRONE_HOST"]
CONTROL_PORT = CONFIG.get("DRONE_CONTROL_PORT", 48080)

APP_BIND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_HOST = CONFIG.get("GCS_PLAINTEXT_HOST", "127.0.0.1")
APP_SEND_PORT = CONFIG.get("GCS_PLAINTEXT_TX", 47001)
APP_RECV_PORT = CONFIG.get("GCS_PLAINTEXT_RX", 47002)

VERIFY_TIMEOUT_S = float(CONFIG.get("SIMPLE_VERIFY_TIMEOUT_S", 5.0))
PACKETS_PER_SUITE = max(1, int(CONFIG.get("SIMPLE_PACKETS_PER_SUITE", 1)))
PACKET_DELAY_S = max(0.0, float(CONFIG.get("SIMPLE_PACKET_DELAY_S", 0.0)))
SUITE_DWELL_S = max(0.0, float(CONFIG.get("SIMPLE_SUITE_DWELL_S", 0.0)))
DEFAULT_PASSES = max(1, int(CONFIG.get("SIMPLE_AUTO_PASSES", 1)))

SUITES = sorted(suite_registry.SUITES.keys())
FIRST_SUITE = suite_registry.get_suite(CONFIG.get("SIMPLE_INITIAL_SUITE", SUITES[0]))["suite_id"]

def ts(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
def mkdirp(p): pathlib.Path(p).mkdir(parents=True, exist_ok=True)

def ctl(obj, timeout=3.0):
    with socket.create_connection((CONTROL_HOST, CONTROL_PORT), timeout=timeout) as s:
        s.sendall((json.dumps(obj)+"\n").encode()); s.shutdown(socket.SHUT_WR)
        line = s.makefile().readline()
        return json.loads(line.strip()) if line else {"ok": False, "error": "no reply"}

def send_and_wait_echo(payload: bytes, timeout_s: float):
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind((APP_BIND_HOST, APP_RECV_PORT))
    rx.settimeout(min(0.2, timeout_s))
    t0 = time.time_ns()
    tx.sendto(payload, (APP_SEND_HOST, APP_SEND_PORT))
    deadline = time.time() + timeout_s
    while time.time() < deadline:
        try:
            data, _ = rx.recvfrom(65535)
            t1 = time.time_ns()
            tx.close(); rx.close()
            return True, t0, t1, len(data)
        except socket.timeout:
            pass
    tx.close(); rx.close()
    return False, t0, None, 0

def start_gcs_proxy(first_suite: str):
    os.environ["DRONE_HOST"] = CONFIG["DRONE_HOST"]
    os.environ["GCS_HOST"] = CONFIG["GCS_HOST"]
    os.environ["ENABLE_PACKET_TYPE"] = "1" if CONFIG.get("ENABLE_PACKET_TYPE", True) else "0"
    os.environ["STRICT_UDP_PEER_MATCH"] = "1" if CONFIG.get("STRICT_UDP_PEER_MATCH", True) else "0"

    keyfile = f"{SECRETS_DIR}/{first_suite}/gcs_signing.key"
    status = f"{OUTDIR}/{first_suite}/gcs_status.json"
    summary = f"{OUTDIR}/{first_suite}/gcs_summary.json"
    mkdirp(f"{OUTDIR}/{first_suite}")
    log = open(f"{OUTDIR}/gcs_{time.strftime('%Y%m%d-%H%M%S')}.log","w", encoding="utf-8", errors="replace")
    print(f"[scheduler] launching GCS proxy on suite {first_suite}")
    p = subprocess.Popen([
        sys.executable,"-m","core.run_proxy","gcs",
        "--suite", first_suite, "--gcs-secret-file", keyfile,
        "--control-manual","--status-file", status, "--json-out", summary
    ], stdin=subprocess.PIPE, stdout=log, stderr=subprocess.STDOUT, text=True, bufsize=1)
    return p

def rekey(gcs_proc, suite: str):
    try:
        gcs_proc.stdin.write(suite + "\n"); gcs_proc.stdin.flush()
    except Exception as e:
        print(f"[scheduler] ERROR writing to proxy stdin: {e}", flush=True)
    try:
        ctl({"cmd":"mark","suite": suite})
    except Exception:
        pass

def run_one(gcs_proc, suite: str, writer, csv_file):
    print(f"[scheduler] ? {suite}")
    # If the proxy died, restart it
    try:
        if gcs_proc is None or (hasattr(gcs_proc, 'poll') and gcs_proc.poll() is not None):
            print('[scheduler] GCS proxy not running; restarting...')
            try:
                gcs_proc = start_gcs_proxy(suite)
                # give proxy a short moment to warm up
                time.sleep(0.5)
            except Exception as e:
                print(f"[scheduler] failed to restart proxy: {e}")
                return gcs_proc

    except Exception:
        # Defensive: if any introspection fails, proceed to attempt rekey and catch errors
        pass

    rekey(gcs_proc, suite)
    attempts = []
    for attempt_idx in range(PACKETS_PER_SUITE):
        seq = (attempt_idx + 1) & 0xFFFFFFFF
        payload = seq.to_bytes(4, "big") + int(time.time_ns()).to_bytes(8, "big")
        ok, t0, t1, n = send_and_wait_echo(payload, VERIFY_TIMEOUT_S)
        attempts.append((ok, t0, t1, n))
        if ok:
            print(f"[scheduler]   packet {attempt_idx+1}/{PACKETS_PER_SUITE} OK")
        else:
            print(f"[scheduler]   packet {attempt_idx+1}/{PACKETS_PER_SUITE} TIMEOUT")
        if PACKET_DELAY_S > 0 and attempt_idx < PACKETS_PER_SUITE - 1:
            time.sleep(PACKET_DELAY_S)

    successes = sum(1 for ok, *_ in attempts if ok)
    best_rtt = min((t1 - t0) for ok, t0, t1, _ in attempts if ok) if successes else ""
    last_bytes = next((n for ok, _, _, n in reversed(attempts) if ok), 0)
    note = "" if successes == PACKETS_PER_SUITE else "timeout"

    writer.writerow({
        "ts": ts(),
        "suite": suite,
        "packets": PACKETS_PER_SUITE,
        "success_packets": successes,
        "ok": successes == PACKETS_PER_SUITE,
        "best_rtt_ns": best_rtt,
        "bytes": last_bytes,
        "note": note,
    })
    csv_file.flush()

    if SUITE_DWELL_S > 0:
        time.sleep(SUITE_DWELL_S)
    return gcs_proc

def interactive_loop(gcs_proc):
    print("\nMANUAL MODE. Commands:")
    print("  list                - show suites")
    print("  next                - advance to the next suite in the list")
    print("  all                 - run full quick-pass across all suites once")
    print("  <suite-id>          - switch to a specific suite and test once")
    print("  quit                - exit\n")

    idx = 0
    csvp = f"{OUTDIR}/quickpass_summary.csv"
    have = os.path.exists(csvp)
    with open(csvp, "a", newline="") as f:
        w = csv.DictWriter(
            f,
            fieldnames=[
                "ts",
                "suite",
                "packets",
                "success_packets",
                "ok",
                "best_rtt_ns",
                "bytes",
                "note",
            ],
        )
        if not have: w.writeheader()
        while True:
            cmd = input("rekey> ").strip()
            if cmd == "quit": break
            if cmd == "list":
                for s in SUITES: print("  ", s)
                continue
            if cmd == "next":
                suite = SUITES[idx % len(SUITES)]; idx += 1
                gcs_proc = run_one(gcs_proc, suite, w, f)
                continue
            if cmd == "all":
                for suite in SUITES:
                    gcs_proc = run_one(gcs_proc, suite, w, f)
                print("[scheduler] full sweep done")
                continue
            # treat as suite-id
            try:
                target_suite = suite_registry.get_suite(cmd)["suite_id"]
            except NotImplementedError:
                print("Unknown command or suite. Type 'list'.")
                continue
            gcs_proc = run_one(gcs_proc, target_suite, w, f)
    return gcs_proc

def auto_sweep(gcs_proc, passes=DEFAULT_PASSES):
    csvp = f"{OUTDIR}/quickpass_summary.csv"
    have = os.path.exists(csvp)
    with open(csvp, "a", newline="") as f:
        w = csv.DictWriter(
            f,
            fieldnames=[
                "ts",
                "suite",
                "packets",
                "success_packets",
                "ok",
                "best_rtt_ns",
                "bytes",
                "note",
            ],
        )
        if not have: w.writeheader()
        for _ in range(passes):
            for suite in SUITES:
                gcs_proc = run_one(gcs_proc, suite, w, f)
    print("[scheduler] auto sweep complete")
    return gcs_proc

def main():
    pathlib.Path(OUTDIR).mkdir(parents=True, exist_ok=True)
    try:
        ctl({"cmd":"ping"})
        print(f"[scheduler] follower reachable at {CONTROL_HOST}:{CONTROL_PORT}")
    except Exception as e:
        print(f"[scheduler] WARNING follower not reachable: {e}")

    gcs = start_gcs_proxy(FIRST_SUITE)
    try:
        mode = "manual"
        if len(sys.argv) > 1 and sys.argv[1] == "--auto":
            mode = "auto"
        if mode == "manual":
            gcs = interactive_loop(gcs)
        else:
            gcs = auto_sweep(gcs, passes=DEFAULT_PASSES)
    finally:
        try: gcs.stdin.write("quit\n"); gcs.stdin.flush()
        except Exception: pass
        try: gcs.wait(timeout=2)
        except Exception: gcs.kill()
        try: ctl({"cmd":"stop"})
        except Exception: pass

if __name__ == "__main__":
    main()

============================================================

================================================================================
END OF LOG
================================================================================
