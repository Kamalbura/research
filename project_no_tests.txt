PROJECT STRUCTURE AND PYTHON FILES LOG
================================================================================
Root Directory: C:\Users\burak\Desktop\research
Output File: C:\Users\burak\Desktop\research\project_no_tests.txt
Generated: 2025-09-27 01:23:35
================================================================================

================================================================================
DIRECTORY TREE STRUCTURE
================================================================================
Root Directory: C:\Users\burak\Desktop\research
Generated: 2025-09-27 01:23:35

├── artifacts/
│   └── gcs-test/
│       └── traffic/
│           └── cs-mlkem768-aesgcm-mldsa65/
├── benchmarks/
│   ├── matrix.yaml (159 bytes)
│   └── run_matrix.py (11,095 bytes)
├── captures/
├── core/
│   ├── __pycache__/
│   │   ├── __init__.cpython-311.pyc (290 bytes)
│   │   ├── __init__.cpython-313.pyc (273 bytes)
│   │   ├── aead.cpython-311.pyc (14,355 bytes)
│   │   ├── aead.cpython-313.pyc (14,184 bytes)
│   │   ├── async_proxy.cpython-311.pyc (38,513 bytes)
│   │   ├── async_proxy.cpython-313.pyc (38,985 bytes)
│   │   ├── config.cpython-311.pyc (5,682 bytes)
│   │   ├── config.cpython-313.pyc (6,289 bytes)
│   │   ├── handshake.cpython-311.pyc (13,111 bytes)
│   │   ├── handshake.cpython-313.pyc (15,240 bytes)
│   │   ├── logging_utils.cpython-313.pyc (5,872 bytes)
│   │   ├── policy_engine.cpython-311.pyc (11,201 bytes)
│   │   ├── policy_engine.cpython-313.pyc (9,972 bytes)
│   │   ├── run_proxy.cpython-311.pyc (25,109 bytes)
│   │   ├── run_proxy.cpython-313.pyc (23,539 bytes)
│   │   ├── suites.cpython-311.pyc (13,950 bytes)
│   │   └── suites.cpython-313.pyc (11,609 bytes)
│   ├── __init__.py (121 bytes)
│   ├── aead.py (11,310 bytes)
│   ├── async_proxy.py (37,380 bytes)
│   ├── config.py (7,738 bytes)
│   ├── handshake.py (12,545 bytes)
│   ├── logging_utils.py (2,957 bytes)
│   ├── policy_engine.py (7,034 bytes)
│   ├── project_config.py (168 bytes)
│   ├── run_proxy.py (20,487 bytes)
│   ├── suites.py (11,602 bytes)
│   └── temp-file.py (18,859 bytes)
├── ddos/
│   ├── features.py (107 bytes)
│   ├── mitigations.py (112 bytes)
│   ├── tst_stage2.py (104 bytes)
│   └── xgb_stage1.py (106 bytes)
├── docs/
│   ├── aead-and-framing.txt (961 bytes)
│   ├── all-context.txt (49,418 bytes)
│   ├── context.txt (10,234 bytes)
│   ├── ddos-pipeline.txt (927 bytes)
│   ├── deep-research.txt (62,258 bytes)
│   ├── handshake.txt (1,237 bytes)
│   ├── lan-test.txt (10,136 bytes)
│   ├── measurement-and-results.txt (3,068 bytes)
│   ├── mqtt.txt (5,415 bytes)
│   ├── oqs-py.txt (2,211 bytes)
│   ├── plan.md (19,727 bytes)
│   ├── portss-and-networking.txt (1,191 bytes)
│   ├── PQC.txt (4,651 bytes)
│   ├── README.md (196 bytes)
│   ├── replay-and-rekey.txt (927 bytes)
│   ├── repo-structure.txt (1,588 bytes)
│   ├── requirements.txt (25 bytes)
│   ├── rl-controller.txt (1,191 bytes)
│   └── todo.md (7,325 bytes)
├── drone/
│   └── scripts/
│       ├── env_check.py (396 bytes)
│       ├── start_suite.ps1 (728 bytes)
│       └── start_suite.sh (720 bytes)
├── gcs/
│   └── scripts/
│       ├── env_check.py (396 bytes)
│       ├── start_suite.ps1 (700 bytes)
│       └── start_suite.sh (692 bytes)
├── logs/
│   ├── handshake/
│   │   ├── gcs_cs-mlkem1024-aesgcm-falcon1024_handshake.err (0 bytes)
│   │   ├── gcs_cs-mlkem1024-aesgcm-falcon1024_handshake.log (52 bytes)
│   │   ├── gcs_cs-mlkem1024-aesgcm-falcon512_handshake.err (0 bytes)
│   │   ├── gcs_cs-mlkem1024-aesgcm-falcon512_handshake.log (52 bytes)
│   │   ├── gcs_cs-mlkem512-aesgcm-mldsa44_handshake.err (0 bytes)
│   │   └── gcs_cs-mlkem512-aesgcm-mldsa44_handshake.log (0 bytes)
│   ├── matrix/
│   │   └── traffic/
│   │       ├── cs-mlkem1024-aesgcm-falcon1024/
│   │       │   ├── gcs_events.jsonl (27,276 bytes)
│   │       │   └── gcs_summary.json (348 bytes)
│   │       └── cs-mlkem1024-aesgcm-falcon512/
│   │           └── gcs_events.jsonl (15,692 bytes)
│   ├── traffic/
│   │   ├── cs-mlkem1024-aesgcm-falcon1024/
│   │   ├── cs-mlkem1024-aesgcm-falcon512/
│   │   └── cs-mlkem512-aesgcm-mldsa44/
│   ├── drone-20250925-194546.log (0 bytes)
│   ├── drone-20250925-194845.log (0 bytes)
│   ├── drone-20250925-194857.log (0 bytes)
│   ├── gcs-20250925-194526.log (0 bytes)
│   ├── gcs-20250925-194854.log (0 bytes)
│   ├── gcs-20250925-204021.log (0 bytes)
│   ├── gcs-20250925-204214.log (227 bytes)
│   ├── gcs-20250925-205351.log (227 bytes)
│   ├── gcs-20250925-223707.log (227 bytes)
│   ├── gcs-20250926-042434.log (590 bytes)
│   ├── gcs-20250926-042726.log (0 bytes)
│   ├── gcs-20250926-042842.log (0 bytes)
│   ├── gcs-20250926-043403.log (0 bytes)
│   ├── gcs-20250926-043726.log (590 bytes)
│   ├── gcs-20250926-043939.log (227 bytes)
│   ├── gcs-20250926-055913.log (227 bytes)
│   ├── gcs-20250926-060045.log (227 bytes)
│   ├── gcs-20250926-060723.log (590 bytes)
│   ├── gcs-20250926-061859.log (227 bytes)
│   ├── gcs-20250926-062115.log (227 bytes)
│   ├── gcs-20250926-062205.log (590 bytes)
│   ├── gcs-20250926-062859.log (227 bytes)
│   ├── gcs-20250926-063322.log (227 bytes)
│   ├── gcs-20250926-063650.log (590 bytes)
│   ├── gcs-20250926-105536.log (0 bytes)
│   ├── gcs-20250926-110059.log (0 bytes)
│   ├── gcs-20250926-134935.log (0 bytes)
│   ├── gcs-20250926-135000.log (0 bytes)
│   ├── gcs-20250926-135101.log (0 bytes)
│   ├── gcs-20250926-135127.log (0 bytes)
│   ├── gcs-20250926-142356.log (0 bytes)
│   ├── gcs-20250926-144044.log (0 bytes)
│   ├── gcs-20250926-145328.log (0 bytes)
│   ├── gcs-20250926-145436.log (0 bytes)
│   ├── gcs-20250926-145701.log (0 bytes)
│   ├── gcs-20250926-145727.log (0 bytes)
│   ├── gcs-20250926-145739.log (0 bytes)
│   ├── gcs-20250926-145803.log (0 bytes)
│   ├── gcs-20250926-151243.log (0 bytes)
│   ├── gcs-20250926-151244.log (0 bytes)
│   ├── gcs-20250926-153459.log (0 bytes)
│   ├── gcs-20250926-153514.log (0 bytes)
│   ├── gcs-20250926-174200.log (590 bytes)
│   └── gcs_cs-mlkem512-aesgcm-mldsa44.json (431 bytes)
├── pqc_proxy.egg-info/
│   ├── dependency_links.txt (1 bytes)
│   ├── PKG-INFO (317 bytes)
│   ├── requires.txt (59 bytes)
│   ├── SOURCES.txt (740 bytes)
│   └── top_level.txt (5 bytes)
├── rl/
│   ├── agent_runtime.py (117 bytes)
│   ├── linucb.py (107 bytes)
│   └── safety.py (105 bytes)
├── scripts/
│   ├── lan_matrix_runner.ps1 (9,554 bytes)
│   └── orchestrate_e2e.py (19,886 bytes)
├── secrets/
│   ├── matrix/
│   │   ├── cs-mlkem1024-aesgcm-falcon1024/
│   │   │   ├── gcs_signing.key (2,305 bytes)
│   │   │   └── gcs_signing.pub (1,793 bytes)
│   │   ├── cs-mlkem1024-aesgcm-falcon512/
│   │   │   ├── gcs_signing.key (1,281 bytes)
│   │   │   └── gcs_signing.pub (897 bytes)
│   │   └── cs-mlkem512-aesgcm-mldsa44/
│   │       ├── gcs_signing.key (2,560 bytes)
│   │       └── gcs_signing.pub (1,312 bytes)
│   ├── gcs_signing.key (4,032 bytes)
│   └── gcs_signing.pub (1,952 bytes)
├── tests/
│   ├── __pycache__/
│   │   ├── __init__.cpython-311.pyc (226 bytes)
│   │   ├── __init__.cpython-313.pyc (209 bytes)
│   │   ├── test_aead_framing.cpython-311-pytest-8.3.5.pyc (15,017 bytes)
│   │   ├── test_aead_framing.cpython-313-pytest-8.4.2.pyc (13,077 bytes)
│   │   ├── test_aead_framing.cpython-313.pyc (7,620 bytes)
│   │   ├── test_cli_identity.cpython-311-pytest-8.3.5.pyc (54,865 bytes)
│   │   ├── test_cli_identity.cpython-313-pytest-8.4.2.pyc (50,345 bytes)
│   │   ├── test_control_sm.cpython-311-pytest-8.3.5.pyc (19,398 bytes)
│   │   ├── test_control_sm.cpython-313-pytest-8.4.2.pyc (17,183 bytes)
│   │   ├── test_counter_utils.cpython-311-pytest-8.3.5.pyc (17,661 bytes)
│   │   ├── test_counter_utils.cpython-313-pytest-8.4.2.pyc (15,750 bytes)
│   │   ├── test_end_to_end_proxy.cpython-311-pytest-8.3.5.pyc (21,937 bytes)
│   │   ├── test_end_to_end_proxy.cpython-313-pytest-8.4.2.pyc (19,080 bytes)
│   │   ├── test_handshake.cpython-311-pytest-8.3.5.pyc (13,333 bytes)
│   │   ├── test_handshake.cpython-313-pytest-8.4.2.pyc (14,887 bytes)
│   │   ├── test_handshake_downgrade.cpython-311-pytest-8.3.5.pyc (2,310 bytes)
│   │   ├── test_handshake_downgrade.cpython-313-pytest-8.4.2.pyc (1,818 bytes)
│   │   ├── test_hardening_features.cpython-311-pytest-8.3.5.pyc (31,118 bytes)
│   │   ├── test_hardening_features.cpython-313-pytest-8.4.2.pyc (27,504 bytes)
│   │   ├── test_kdf_roles.cpython-311-pytest-8.3.5.pyc (9,316 bytes)
│   │   ├── test_kdf_roles.cpython-313-pytest-8.4.2.pyc (7,996 bytes)
│   │   ├── test_loss_dup_oom.cpython-311-pytest-8.3.5.pyc (649 bytes)
│   │   ├── test_loss_dup_oom.cpython-313-pytest-8.4.2.pyc (586 bytes)
│   │   ├── test_packet_types.cpython-311-pytest-8.3.5.pyc (8,399 bytes)
│   │   ├── test_packet_types.cpython-313-pytest-8.4.2.pyc (7,499 bytes)
│   │   ├── test_rekey_epoch.cpython-311-pytest-8.3.5.pyc (33,844 bytes)
│   │   ├── test_rekey_epoch.cpython-313-pytest-8.4.2.pyc (30,548 bytes)
│   │   ├── test_replay_window.cpython-311-pytest-8.3.5.pyc (8,870 bytes)
│   │   ├── test_replay_window.cpython-313-pytest-8.4.2.pyc (7,516 bytes)
│   │   ├── test_security_hardening.cpython-313-pytest-8.4.2.pyc (13,935 bytes)
│   │   ├── test_suites_config.cpython-311-pytest-8.3.5.pyc (45,262 bytes)
│   │   └── test_suites_config.cpython-313-pytest-8.4.2.pyc (39,783 bytes)
│   ├── __init__.py (54 bytes)
│   ├── test-oqs.py (2,821 bytes)
│   ├── test_aead_framing.py (6,589 bytes)
│   ├── test_cli_identity.py (13,002 bytes)
│   ├── test_control_sm.py (3,095 bytes)
│   ├── test_counter_utils.py (3,143 bytes)
│   ├── test_end_to_end_proxy.py (12,139 bytes)
│   ├── test_handshake.py (3,895 bytes)
│   ├── test_handshake_downgrade.py (1,430 bytes)
│   ├── test_hardening_features.py (7,879 bytes)
│   ├── test_kdf_roles.py (1,630 bytes)
│   ├── test_loss_dup_oom.py (149 bytes)
│   ├── test_packet_types.py (4,544 bytes)
│   ├── test_rekey_epoch.py (11,882 bytes)
│   ├── test_replay_window.py (3,723 bytes)
│   ├── test_security_hardening.py (5,148 bytes)
│   └── test_suites_config.py (12,691 bytes)
├── tools/
│   ├── __pycache__/
│   │   ├── __init__.cpython-311.pyc (233 bytes)
│   │   ├── __init__.cpython-313.pyc (222 bytes)
│   │   ├── counter_utils.cpython-311.pyc (9,271 bytes)
│   │   ├── counter_utils.cpython-313.pyc (8,121 bytes)
│   │   ├── diag_udp.cpython-313.pyc (12,199 bytes)
│   │   ├── traffic_common.cpython-313.pyc (5,892 bytes)
│   │   ├── traffic_gcs.cpython-313.pyc (451 bytes)
│   │   └── traffic_runner.cpython-313.pyc (8,529 bytes)
│   ├── captures/
│   ├── manual_4term/
│   │   ├── __pycache__/
│   │   │   ├── drone_autopilot_sim.cpython-313.pyc (6,509 bytes)
│   │   │   ├── drone_tty.cpython-313.pyc (7,352 bytes)
│   │   │   ├── encrypted_bridge_logger.cpython-313.pyc (7,713 bytes)
│   │   │   ├── gcs_ground_station_sim.cpython-313.pyc (6,496 bytes)
│   │   │   ├── gcs_tty.cpython-313.pyc (7,344 bytes)
│   │   │   ├── launch_manual_test.cpython-311-pytest-8.3.5.pyc (16,348 bytes)
│   │   │   ├── launch_manual_test.cpython-313-pytest-8.4.2.pyc (15,131 bytes)
│   │   │   └── launch_manual_test.cpython-313.pyc (14,205 bytes)
│   │   ├── keys/
│   │   │   ├── gcs_pub.bin (1,952 bytes)
│   │   │   └── gcs_sec.bin (4,032 bytes)
│   │   ├── drone_autopilot_sim.py (3,933 bytes)
│   │   ├── drone_tty.py (4,213 bytes)
│   │   ├── encrypted_bridge_logger.py (4,355 bytes)
│   │   ├── gcs_ground_station_sim.py (3,927 bytes)
│   │   ├── gcs_tty.py (4,207 bytes)
│   │   ├── launch_manual_test.py (9,824 bytes)
│   │   └── README.md (6,886 bytes)
│   ├── netcapture/
│   │   ├── drone_capture.py (3,434 bytes)
│   │   └── gcs_capture.py (5,576 bytes)
│   ├── port_profiles/
│   │   ├── default.ps1 (380 bytes)
│   │   └── default.sh (395 bytes)
│   ├── wireshark/
│   │   └── pqc_tunnel.lua (1,267 bytes)
│   ├── __init__.py (69 bytes)
│   ├── aggregate_lan_results.py (4,639 bytes)
│   ├── audit_endpoints.py (5,511 bytes)
│   ├── bench_cli.py (841 bytes)
│   ├── check_no_hardcoded_ips.py (2,448 bytes)
│   ├── check_ports.py (3,618 bytes)
│   ├── counter_utils.py (6,381 bytes)
│   ├── diag_udp.py (8,245 bytes)
│   ├── encrypted_sniffer.py (1,570 bytes)
│   ├── full_comm_check.py (9,657 bytes)
│   ├── generate_identity.py (2,266 bytes)
│   ├── markers.py (3,323 bytes)
│   ├── matrix_runner_drone.sh (8,323 bytes)
│   ├── matrix_runner_gcs.ps1 (10,767 bytes)
│   ├── merge_power_csv.py (5,656 bytes)
│   ├── packet_interceptor.py (2,494 bytes)
│   ├── power_hooks.py (208 bytes)
│   ├── prepare_matrix_keys.py (3,043 bytes)
│   ├── project_structure_20250926_023741.txt (85,027 bytes)
│   ├── scaffold_repo.py (17,074 bytes)
│   ├── traffic_common.py (3,551 bytes)
│   ├── traffic_drone.py (206 bytes)
│   ├── traffic_gcs.py (202 bytes)
│   ├── traffic_runner.py (7,778 bytes)
│   ├── udp_dual_probe.py (5,048 bytes)
│   ├── udp_echo_server.py (2,488 bytes)
│   └── udp_forward_log.py (2,796 bytes)
├── CHANGELOG.md (10,969 bytes)
├── diagnose_aead.py (620 bytes)
├── diagnose_handshake.py (1,566 bytes)
├── environment.yml (179 bytes)
├── gcs_debug.json (431 bytes)
├── gcs_suites.txt (661 bytes)
├── log_project_structure.py (8,868 bytes)
├── manual.md (11,124 bytes)
├── manual.txt (11,124 bytes)
├── PR1_IMPLEMENTATION_SUMMARY.md (6,636 bytes)
├── progresslog.md (5,537 bytes)
├── project_no_tests.txt (8,217 bytes)
├── PROJECT_STATUS.md (11,726 bytes)
├── project_structure_20250927_002526.txt (445,775 bytes)
├── pyproject.toml (479 bytes)
├── pytest.out (390 bytes)
├── README.md (13,831 bytes)
├── strict_mode_demo.py (3,479 bytes)
└── tlog.log (70,350 bytes)


================================================================================
PYTHON FILE CONTENTS
================================================================================

Found 58 Python files:
   1. benchmarks\run_matrix.py
   2. core\__init__.py
   3. core\aead.py
   4. core\async_proxy.py
   5. core\config.py
   6. core\handshake.py
   7. core\logging_utils.py
   8. core\policy_engine.py
   9. core\project_config.py
  10. core\run_proxy.py
  11. core\suites.py
  12. core\temp-file.py
  13. ddos\features.py
  14. ddos\mitigations.py
  15. ddos\tst_stage2.py
  16. ddos\xgb_stage1.py
  17. diagnose_aead.py
  18. diagnose_handshake.py
  19. drone\scripts\env_check.py
  20. gcs\scripts\env_check.py
  21. log_project_structure.py
  22. rl\agent_runtime.py
  23. rl\linucb.py
  24. rl\safety.py
  25. scripts\orchestrate_e2e.py
  26. strict_mode_demo.py
  27. tools\__init__.py
  28. tools\aggregate_lan_results.py
  29. tools\audit_endpoints.py
  30. tools\bench_cli.py
  31. tools\check_no_hardcoded_ips.py
  32. tools\check_ports.py
  33. tools\counter_utils.py
  34. tools\diag_udp.py
  35. tools\encrypted_sniffer.py
  36. tools\full_comm_check.py
  37. tools\generate_identity.py
  38. tools\manual_4term\drone_autopilot_sim.py
  39. tools\manual_4term\drone_tty.py
  40. tools\manual_4term\encrypted_bridge_logger.py
  41. tools\manual_4term\gcs_ground_station_sim.py
  42. tools\manual_4term\gcs_tty.py
  43. tools\manual_4term\launch_manual_test.py
  44. tools\markers.py
  45. tools\merge_power_csv.py
  46. tools\netcapture\drone_capture.py
  47. tools\netcapture\gcs_capture.py
  48. tools\packet_interceptor.py
  49. tools\power_hooks.py
  50. tools\prepare_matrix_keys.py
  51. tools\scaffold_repo.py
  52. tools\traffic_common.py
  53. tools\traffic_drone.py
  54. tools\traffic_gcs.py
  55. tools\traffic_runner.py
  56. tools\udp_dual_probe.py
  57. tools\udp_echo_server.py
  58. tools\udp_forward_log.py

--------------------------------------------------------------------------------

FILE 1/58: benchmarks\run_matrix.py
============================================================
Full Path: C:\Users\burak\Desktop\research\benchmarks\run_matrix.py
Size: 11,095 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""Benchmark driver for orchestrated multi-run measurements.

Runs paired GCS/Drone proxies for a fixed duration, emits external power
markers, optionally captures Windows Performance Recorder traces, and writes a
manifest describing each run artifact.
"""

from __future__ import annotations

import argparse
import json
import math
import platform
import re
import shlex
import shutil
import subprocess
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import psutil

from core.suites import get_suite
from tools.markers import FileMarker, MarkerSink, NullMarker, SerialMarker, UdpMarker


DEFAULT_OUTDIR = Path("benchmarks/out")
GCS_JSON_NAME = "gcs.json"
DRONE_JSON_NAME = "drone.json"
GCS_LOG_NAME = "gcs.log"
DRONE_LOG_NAME = "drone.log"
WPR_FILE_NAME = "system_trace.etl"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run PQC proxy benchmarks with external power markers")
    parser.add_argument("--suite", required=True, help="Suite identifier to run (e.g., cs-mlkem768-aesgcm-mldsa65)")
    parser.add_argument("--duration", required=True, type=float, help="Measurement duration in seconds")
    parser.add_argument("--repeat", type=int, default=1, help="Number of repetitions for the suite")
    parser.add_argument("--start-delay", type=float, default=0.0, help="Optional delay before emitting START marker")
    parser.add_argument("--marker", choices=["null", "file", "serial", "udp"], default="null", help="Marker sink backend")
    parser.add_argument("--marker-file", help="Path for file marker output")
    parser.add_argument("--marker-serial-port", help="Serial port (e.g., COM3) for marker emission")
    parser.add_argument("--marker-udp", help="host:port for UDP marker emission")
    parser.add_argument("--outdir", default=str(DEFAULT_OUTDIR), help="Base output directory for artifacts")
    parser.add_argument("--wpr", choices=["on", "off"], default="off", help="Enable Windows Performance Recorder capture")
    parser.add_argument("--gcs-args", help="Additional arguments appended to the GCS command")
    parser.add_argument("--drone-args", help="Additional arguments appended to the drone command")
    return parser.parse_args()


def sanitize_run_id(value: str) -> str:
    return re.sub(r"[^A-Za-z0-9_.-]", "_", value)


def resolve_marker(args: argparse.Namespace) -> MarkerSink:
    marker_type = args.marker
    if marker_type == "null":
        return NullMarker()
    if marker_type == "file":
        if not args.marker_file:
            raise SystemExit("--marker-file is required when --marker=file")
        Path(args.marker_file).parent.mkdir(parents=True, exist_ok=True)
        return FileMarker(args.marker_file)
    if marker_type == "serial":
        if not args.marker_serial_port:
            raise SystemExit("--marker-serial-port is required when --marker=serial")
        return SerialMarker(args.marker_serial_port)
    if marker_type == "udp":
        if not args.marker_udp:
            raise SystemExit("--marker-udp is required when --marker=udp")
        return UdpMarker(args.marker_udp)
    raise SystemExit(f"Unknown marker type: {marker_type}")


def maybe_split_args(arg_string: Optional[str]) -> List[str]:
    if not arg_string:
        return []
    return shlex.split(arg_string)


def build_command(role: str, suite_id: str, stop_seconds: float, json_path: Path, extra_args: List[str]) -> List[str]:
    base_cmd = [
        sys.executable,
        "-m",
        "core.run_proxy",
        role,
        "--suite",
        suite_id,
        "--stop-seconds",
        f"{stop_seconds:.3f}",
        "--json-out",
        str(json_path),
    ]
    return base_cmd + extra_args


def start_wpr(run_dir: Path) -> Tuple[bool, Optional[Path]]:
    if shutil.which("wpr") is None:
        print("Warning: wpr.exe not found in PATH; skipping WPR capture.")
        return False, None

    print("Starting Windows Performance Recorder (GeneralProfile.Light)...")
    subprocess.run(["wpr", "-start", "GeneralProfile.Light", "-filemode"], check=False)
    return True, run_dir / WPR_FILE_NAME


def stop_wpr(etl_path: Optional[Path]) -> None:
    if not etl_path:
        return
    args = ["wpr", "-stop", str(etl_path)]
    subprocess.run(args, check=False)


def init_psutil_process(pid: int) -> Optional[psutil.Process]:
    try:
        proc = psutil.Process(pid)
        proc.cpu_percent(None)  # prime
        return proc
    except psutil.Error:
        return None


def sample_stats(process: Optional[psutil.Process]) -> Tuple[Optional[float], Optional[int]]:
    if process is None:
        return None, None
    try:
        cpu = process.cpu_percent(None)
        rss = process.memory_info().rss
        return cpu, rss
    except psutil.Error:
        return None, None


def summarise(samples: List[float]) -> Dict[str, Optional[float]]:
    if not samples:
        return {"avg": None, "max": None, "p95": None}
    sorted_samples = sorted(samples)
    avg = sum(sorted_samples) / len(sorted_samples)
    max_val = sorted_samples[-1]
    p95_index = max(0, min(len(sorted_samples) - 1, math.floor(0.95 * (len(sorted_samples) - 1))))
    return {"avg": avg, "max": max_val, "p95": sorted_samples[p95_index]}


def ensure_run_dir(base_outdir: Path) -> Path:
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    run_root = base_outdir / timestamp
    run_root.mkdir(parents=True, exist_ok=True)
    return run_root


def write_manifest(run_dir: Path, manifest: Dict[str, object]) -> None:
    manifest_path = run_dir / "manifest.json"
    manifest_path.write_text(json.dumps(manifest, indent=2), encoding="utf-8")
    print(f"Wrote manifest to {manifest_path}")


def orchestrate_run(
    args: argparse.Namespace,
    suite_info: Dict[str, object],
    run_root: Path,
    repeat_idx: int,
    marker: MarkerSink,
) -> None:
    suite_id = suite_info["suite_id"]
    run_id = sanitize_run_id(f"{suite_id}_rep{repeat_idx}")
    run_dir = run_root / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    gcs_json_path = run_dir / GCS_JSON_NAME
    drone_json_path = run_dir / DRONE_JSON_NAME
    gcs_log_path = run_dir / GCS_LOG_NAME
    drone_log_path = run_dir / DRONE_LOG_NAME

    stop_seconds = args.duration + 2.0
    gcs_cmd = build_command("gcs", suite_id, stop_seconds, gcs_json_path, maybe_split_args(args.gcs_args))
    drone_cmd = build_command("drone", suite_id, stop_seconds, drone_json_path, maybe_split_args(args.drone_args))

    wpr_enabled = args.wpr == "on"
    wpr_started = False
    wpr_path: Optional[Path] = None

    print(f"\n=== Run {repeat_idx}/{args.repeat} :: {suite_id} ===")
    print(f"Output directory: {run_dir}")
    print(f"GCS command: {' '.join(gcs_cmd)}")
    print(f"Drone command: {' '.join(drone_cmd)}")

    if wpr_enabled:
        wpr_started, wpr_path = start_wpr(run_dir)

    if args.start_delay > 0:
        print(f"Waiting {args.start_delay:.2f}s before start marker...")
        time.sleep(args.start_delay)

    wall_start_ns = time.time_ns()
    perf_start_ns = time.perf_counter_ns()
    marker.start(run_id, wall_start_ns)

    with open(gcs_log_path, "w", encoding="utf-8", buffering=1) as gcs_log, open(
        drone_log_path, "w", encoding="utf-8", buffering=1
    ) as drone_log:
        gcs_proc = subprocess.Popen(gcs_cmd, stdout=gcs_log, stderr=subprocess.STDOUT)
        drone_proc = subprocess.Popen(drone_cmd, stdout=drone_log, stderr=subprocess.STDOUT)

        gcs_ps = init_psutil_process(gcs_proc.pid)
        drone_ps = init_psutil_process(drone_proc.pid)

        deadline = time.perf_counter() + args.duration
        cpu_samples = {"gcs": [], "drone": []}
        rss_samples = {"gcs": [], "drone": []}

        try:
            while True:
                now = time.perf_counter()
                if now >= deadline:
                    break
                to_sleep = min(1.0, deadline - now)
                if to_sleep > 0:
                    time.sleep(to_sleep)
                gcs_cpu, gcs_rss = sample_stats(gcs_ps)
                drone_cpu, drone_rss = sample_stats(drone_ps)
                if gcs_cpu is not None:
                    cpu_samples["gcs"].append(gcs_cpu)
                if drone_cpu is not None:
                    cpu_samples["drone"].append(drone_cpu)
                if gcs_rss is not None:
                    rss_samples["gcs"].append(gcs_rss)
                if drone_rss is not None:
                    rss_samples["drone"].append(drone_rss)
        finally:
            wall_end_ns = time.time_ns()
            perf_end_ns = time.perf_counter_ns()
            marker.end(run_id, wall_end_ns)

            for proc_name, proc in {"gcs": gcs_proc, "drone": drone_proc}.items():
                try:
                    proc.wait(timeout=3)
                except subprocess.TimeoutExpired:
                    print(f"{proc_name.upper()} still running; terminating...")
                    proc.terminate()
                    try:
                        proc.wait(timeout=2)
                    except subprocess.TimeoutExpired:
                        print(f"{proc_name.upper()} unresponsive; killing...")
                        proc.kill()

    if wpr_started:
        stop_wpr(wpr_path)

    gcs_exit = gcs_proc.returncode
    drone_exit = drone_proc.returncode

    manifest: Dict[str, object] = {
        "run_id": run_id,
        "kem": suite_info["kem_name"],
        "sig": suite_info["sig_name"],
        "aead": suite_info["aead"],
        "suite": suite_id,
        "duration_s": args.duration,
        "repeat_idx": repeat_idx,
        "host": platform.system(),
        "start_wall_ns": wall_start_ns,
        "end_wall_ns": wall_end_ns,
        "start_perf_ns": perf_start_ns,
        "end_perf_ns": perf_end_ns,
        "gcs_json": GCS_JSON_NAME,
        "drone_json": DRONE_JSON_NAME,
        "gcs_log": GCS_LOG_NAME,
        "drone_log": DRONE_LOG_NAME,
        "wpr_etl": WPR_FILE_NAME if wpr_started else None,
        "gcs_exit_code": gcs_exit,
        "drone_exit_code": drone_exit,
        "gcs_cmd": gcs_cmd,
        "drone_cmd": drone_cmd,
        "notes": "external-power-mode",
        "cpu_stats": {
            "gcs": summarise(cpu_samples["gcs"]),
            "drone": summarise(cpu_samples["drone"]),
        },
        "rss_stats": {
            "gcs_max": max(rss_samples["gcs"]) if rss_samples["gcs"] else None,
            "drone_max": max(rss_samples["drone"]) if rss_samples["drone"] else None,
        },
    }

    write_manifest(run_dir, manifest)


def main() -> None:
    args = parse_args()
    suite_info = get_suite(args.suite)
    run_root = ensure_run_dir(Path(args.outdir))
    marker = resolve_marker(args)

    try:
        for repeat_idx in range(1, args.repeat + 1):
            orchestrate_run(args, suite_info, run_root, repeat_idx, marker)
    except KeyboardInterrupt:
        print("\nBenchmark interrupted by user.")
    finally:
        marker.close()


if __name__ == "__main__":
    main()

============================================================

FILE 2/58: core\__init__.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\__init__.py
Size: 121 bytes
Modified: 2025-09-24 05:23:26
------------------------------------------------------------
"""
PQC Drone-GCS Secure Proxy Core Package.

Provides post-quantum cryptography secure communication components.
"""

============================================================

FILE 3/58: core\aead.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\aead.py
Size: 11,310 bytes
Modified: 2025-09-27 01:00:21
------------------------------------------------------------
"""
AEAD framing for PQC drone-GCS secure proxy.

Provides authenticated encryption (AES-256-GCM) with wire header bound as AAD,
deterministic 96-bit counter IVs, sliding replay window, and epoch support for rekeys.
"""

import struct
from dataclasses import dataclass
from typing import Optional

from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.exceptions import InvalidTag

from .config import CONFIG
from .suites import header_ids_for_suite


# Exception types
class HeaderMismatch(Exception):
    """Header validation failed (version, IDs, or session_id mismatch)."""
    pass


class AeadAuthError(Exception):
    """AEAD authentication failed during decryption."""
    pass


class ReplayError(Exception):
    """Packet replay detected or outside acceptable window."""
    pass


# Constants
HEADER_STRUCT = "!BBBBB8sQB"
HEADER_LEN = 22
# IV is still logically 12 bytes (1 epoch + 11 seq bytes) but is NO LONGER transmitted on wire.
# Wire format: header(22) || ciphertext+tag
IV_LEN = 0  # length of IV bytes present on wire (0 after optimization)


@dataclass(frozen=True)
class AeadIds:
    kem_id: int
    kem_param: int
    sig_id: int
    sig_param: int

    def __post_init__(self):
        for field_name, value in [("kem_id", self.kem_id), ("kem_param", self.kem_param), 
                                  ("sig_id", self.sig_id), ("sig_param", self.sig_param)]:
            if not isinstance(value, int) or not (0 <= value <= 255):
                raise NotImplementedError(f"{field_name} must be int in range 0-255")


@dataclass
class Sender:
    version: int
    ids: AeadIds
    session_id: bytes
    epoch: int
    key_send: bytes
    _seq: int = 0

    def __post_init__(self):
        if not isinstance(self.version, int) or self.version != CONFIG["WIRE_VERSION"]:
            raise NotImplementedError(f"version must equal CONFIG WIRE_VERSION ({CONFIG['WIRE_VERSION']})")
        
        if not isinstance(self.ids, AeadIds):
            raise NotImplementedError("ids must be AeadIds instance")
        
        if not isinstance(self.session_id, bytes) or len(self.session_id) != 8:
            raise NotImplementedError("session_id must be exactly 8 bytes")
        
        if not isinstance(self.epoch, int) or not (0 <= self.epoch <= 255):
            raise NotImplementedError("epoch must be int in range 0-255")
        
        if not isinstance(self.key_send, bytes) or len(self.key_send) != 32:
            raise NotImplementedError("key_send must be exactly 32 bytes")
        
        if not isinstance(self._seq, int) or self._seq < 0:
            raise NotImplementedError("_seq must be non-negative int")
        
        self._aesgcm = AESGCM(self.key_send)

    @property
    def seq(self):
        """Current sequence number."""
        return self._seq

    def pack_header(self, seq: int) -> bytes:
        """Pack header with given sequence number."""
        if not isinstance(seq, int) or seq < 0:
            raise NotImplementedError("seq must be non-negative int")
        
        return struct.pack(
            HEADER_STRUCT,
            self.version,
            self.ids.kem_id,
            self.ids.kem_param, 
            self.ids.sig_id,
            self.ids.sig_param,
            self.session_id,
            seq,
            self.epoch
        )

    def encrypt(self, plaintext: bytes) -> bytes:
        """Encrypt plaintext returning: header || ciphertext + tag.

        Deterministic IV (epoch||seq) is derived locally and NOT sent on wire to
        reduce overhead (saves 12 bytes per packet). Receiver reconstructs it.
        """
        if not isinstance(plaintext, bytes):
            raise NotImplementedError("plaintext must be bytes")
        
        # Check for sequence overflow - header uses uint64, so check that limit
        if self._seq > (2**64 - 1):
            raise NotImplementedError("packet_seq overflow (uint64)")
        
        # Pack header with current sequence
        header = self.pack_header(self._seq)
        
        # Derive deterministic IV = epoch (1 byte) || seq (11 bytes)
        iv = bytes([self.epoch & 0xFF]) + self._seq.to_bytes(11, "big")

        try:
            ciphertext = self._aesgcm.encrypt(iv, plaintext, header)
        except Exception as e:
            raise NotImplementedError(f"AEAD encryption failed: {e}")
        
        # Increment sequence on success
        self._seq += 1
        
        # Return optimized wire format: header || ciphertext+tag (IV omitted)
        return header + ciphertext

    def bump_epoch(self) -> None:
        """Increase epoch and reset sequence.

        Safety policy: forbid wrapping 255->0 with the same key to avoid IV reuse.
        Callers should perform a new handshake to rotate keys before wrap.
        """
        if self.epoch == 255:
            raise NotImplementedError("epoch wrap forbidden without rekey; perform handshake to rotate keys")
        self.epoch = (self.epoch + 1) % 256
        self._seq = 0


@dataclass
class Receiver:
    version: int
    ids: AeadIds
    session_id: bytes
    epoch: int
    key_recv: bytes
    window: int
    strict_mode: bool = False  # True = raise exceptions, False = return None
    _high: int = -1
    _mask: int = 0

    def __post_init__(self):
        if not isinstance(self.version, int) or self.version != CONFIG["WIRE_VERSION"]:
            raise NotImplementedError(f"version must equal CONFIG WIRE_VERSION ({CONFIG['WIRE_VERSION']})")
        
        if not isinstance(self.ids, AeadIds):
            raise NotImplementedError("ids must be AeadIds instance")
        
        if not isinstance(self.session_id, bytes) or len(self.session_id) != 8:
            raise NotImplementedError("session_id must be exactly 8 bytes")
        
        if not isinstance(self.epoch, int) or not (0 <= self.epoch <= 255):
            raise NotImplementedError("epoch must be int in range 0-255")
        
        if not isinstance(self.key_recv, bytes) or len(self.key_recv) != 32:
            raise NotImplementedError("key_recv must be exactly 32 bytes")
        
        if not isinstance(self.window, int) or self.window < 64:
            raise NotImplementedError(f"window must be int >= 64")
        
        if not isinstance(self._high, int):
            raise NotImplementedError("_high must be int")
        
        if not isinstance(self._mask, int) or self._mask < 0:
            raise NotImplementedError("_mask must be non-negative int")
        
        self._aesgcm = AESGCM(self.key_recv)
        self._last_error: Optional[str] = None

    def _check_replay(self, seq: int) -> None:
        """Check if sequence number should be accepted (anti-replay)."""
        if seq > self._high:
            # Future packet - shift window forward
            shift = seq - self._high
            if shift >= self.window:
                # Window completely shifts
                self._mask = 1  # Only mark the current position
            else:
                # Partial shift
                self._mask = (self._mask << shift) | 1
                # Mask to window size to prevent overflow
                self._mask &= (1 << self.window) - 1
            self._high = seq
        elif seq > self._high - self.window:
            # Within window - check if already seen
            offset = self._high - seq
            bit_pos = offset
            if self._mask & (1 << bit_pos):
                raise ReplayError(f"duplicate packet seq={seq}")
            # Mark as seen
            self._mask |= (1 << bit_pos)
        else:
            # Too old - outside window
            raise ReplayError(f"packet too old seq={seq}, high={self._high}, window={self.window}")

    def decrypt(self, wire: bytes) -> bytes:
        """Validate header, perform anti-replay, reconstruct IV, decrypt.

        Returns plaintext bytes or None (silent mode) on failure.
        """
        if not isinstance(wire, bytes):
            raise NotImplementedError("wire must be bytes")
        
        if len(wire) < HEADER_LEN:
            raise NotImplementedError("wire too short for header")
        
        # Extract header
        header = wire[:HEADER_LEN]
        
        # Unpack and validate header
        try:
            fields = struct.unpack(HEADER_STRUCT, header)
            version, kem_id, kem_param, sig_id, sig_param, session_id, seq, epoch = fields
        except struct.error as e:
            raise NotImplementedError(f"header unpack failed: {e}")
        
        # Validate header fields
        if version != self.version:
            self._last_error = "header"
            if self.strict_mode:
                raise HeaderMismatch(f"version mismatch: expected {self.version}, got {version}")
            return None
        
        if (kem_id, kem_param, sig_id, sig_param) != (self.ids.kem_id, self.ids.kem_param, self.ids.sig_id, self.ids.sig_param):
            self._last_error = "header"
            if self.strict_mode:
                raise HeaderMismatch(f"crypto ID mismatch")
            return None
        
        if session_id != self.session_id:
            self._last_error = "session"
            return None  # Wrong session - always fail silently for security
        
        if epoch != self.epoch:
            self._last_error = "session"
            return None  # Wrong epoch - always fail silently for rekeying
        
        # Check replay protection
        try:
            self._check_replay(seq)
        except ReplayError:
            self._last_error = "replay"
            if self.strict_mode:
                raise
            return None
        
        # Reconstruct deterministic IV instead of reading from wire
        iv = bytes([epoch & 0xFF]) + seq.to_bytes(11, "big")
        ciphertext = wire[HEADER_LEN:]
        
        # Decrypt with header as AAD
        try:
            plaintext = self._aesgcm.decrypt(iv, ciphertext, header)
        except InvalidTag:
            self._last_error = "auth"
            if self.strict_mode:
                raise AeadAuthError("AEAD authentication failed")
            return None
        except Exception as e:
            raise NotImplementedError(f"AEAD decryption failed: {e}")
        self._last_error = None
        return plaintext

    def reset_replay(self) -> None:
        """Clear replay protection state."""
        self._high = -1
        self._mask = 0

    def bump_epoch(self) -> None:
        """Increase epoch and reset replay state.
        
        Safety policy: forbid wrapping 255->0 with the same key to avoid IV reuse.
        Callers should perform a new handshake to rotate keys before wrap.
        """
        if self.epoch == 255:
            raise NotImplementedError("epoch wrap forbidden without rekey; perform handshake to rotate keys")
        self.epoch = (self.epoch + 1) % 256
        self.reset_replay()

    def last_error_reason(self) -> Optional[str]:
        return getattr(self, "_last_error", None)

============================================================

FILE 4/58: core\async_proxy.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\async_proxy.py
Size: 37,380 bytes
Modified: 2025-09-27 01:00:20
------------------------------------------------------------
"""
Selectors-based network transport proxy.

Responsibilities:
1. Perform authenticated TCP handshake (PQC KEM + signature) using `core.handshake`.
2. Bridge plaintext UDP <-> encrypted UDP (AEAD framing) both directions.
3. Enforce replay window and per-direction sequence via `core.aead`.

Note: This module uses the low-level `selectors` stdlib facility—not `asyncio`—to
remain dependency-light and fully deterministic for test harnesses. The filename
is retained for backward compatibility; a future refactor may rename it to
`selector_proxy.py` and/or introduce an asyncio variant.
"""

from __future__ import annotations

import json
import queue
import socket
import selectors
import sys
import threading
import time
import struct
from pathlib import Path
from typing import Optional, Dict, Tuple
from contextlib import contextmanager

from core.config import CONFIG
from core.suites import SUITES, header_ids_for_suite, get_suite, list_suites
try:
    # Optional helper (if you implemented it)
    from core.suites import header_ids_from_names  # type: ignore
except Exception:
    header_ids_from_names = None  # type: ignore

from core.handshake import (
    server_gcs_handshake,
    client_drone_handshake,
    HandshakeVerifyError,
)
from core.logging_utils import get_logger

from core.aead import (
    Sender,
    Receiver,
    HeaderMismatch,
    ReplayError,
    AeadAuthError,
    AeadIds,
)

from core.policy_engine import (
    ControlState,
    ControlResult,
    create_control_state,
    handle_control,
    request_prepare,
    record_rekey_result,
)

logger = get_logger("pqc")


class ProxyCounters:
    """Simple counters for proxy statistics."""

    def __init__(self) -> None:
        self.ptx_out = 0      # plaintext packets sent out to app
        self.ptx_in = 0       # plaintext packets received from app
        self.enc_out = 0      # encrypted packets sent to peer
        self.enc_in = 0       # encrypted packets received from peer
        self.drops = 0        # total drops
        # Granular drop reasons
        self.drop_replay = 0
        self.drop_auth = 0
        self.drop_header = 0
        self.drop_session_epoch = 0
        self.drop_other = 0
        self.drop_src_addr = 0
        self.rekeys_ok = 0
        self.rekeys_fail = 0
        self.last_rekey_ms = 0
        self.last_rekey_suite: Optional[str] = None

    def to_dict(self) -> Dict[str, object]:
        return {
            "ptx_out": self.ptx_out,
            "ptx_in": self.ptx_in,
            "enc_out": self.enc_out,
            "enc_in": self.enc_in,
            "drops": self.drops,
            "drop_replay": self.drop_replay,
            "drop_auth": self.drop_auth,
            "drop_header": self.drop_header,
            "drop_session_epoch": self.drop_session_epoch,
            "drop_other": self.drop_other,
            "drop_src_addr": self.drop_src_addr,
            "rekeys_ok": self.rekeys_ok,
            "rekeys_fail": self.rekeys_fail,
            "last_rekey_ms": self.last_rekey_ms,
            "last_rekey_suite": self.last_rekey_suite or "",
        }


def _dscp_to_tos(dscp: Optional[int]) -> Optional[int]:
    """Convert DSCP value to TOS byte for socket options."""
    if dscp is None:
        return None
    try:
        d = int(dscp)
        if 0 <= d <= 63:
            return d << 2  # DSCP occupies high 6 bits of TOS/Traffic Class
    except Exception:
        pass
    return None


def _parse_header_fields(
    expected_version: int,
    aead_ids: AeadIds,
    session_id: bytes,
    wire: bytes,
) -> Tuple[str, Optional[int]]:
    """
    Try to unpack the header and classify the most likely drop reason *without* AEAD work.
    Returns (reason, seq_if_available).
    """
    HEADER_STRUCT = "!BBBBB8sQB"
    HEADER_LEN = struct.calcsize(HEADER_STRUCT)
    if len(wire) < HEADER_LEN:
        return ("header_too_short", None)
    try:
        (version, kem_id, kem_param, sig_id, sig_param, sess, seq, epoch) = struct.unpack(
            HEADER_STRUCT, wire[:HEADER_LEN]
        )
    except struct.error:
        return ("header_unpack_error", None)
    if version != expected_version:
        return ("version_mismatch", seq)
    if (kem_id, kem_param, sig_id, sig_param) != (
        aead_ids.kem_id,
        aead_ids.kem_param,
        aead_ids.sig_id,
        aead_ids.sig_param,
    ):
        return ("crypto_id_mismatch", seq)
    if sess != session_id:
        return ("session_mismatch", seq)
    # If we got here, header matches; any decrypt failure that returns None is auth/tag failure.
    return ("auth_fail_or_replay", seq)


class _TokenBucket:
    """Per-IP rate limiter using token bucket algorithm."""
    def __init__(self, capacity: int, refill_per_sec: float) -> None:
        self.capacity = max(1, capacity)
        self.refill = max(0.01, float(refill_per_sec))
        self.tokens: Dict[str, float] = {}      # ip -> tokens
        self.last: Dict[str, float] = {}        # ip -> last timestamp

    def allow(self, ip: str) -> bool:
        """Check if request from IP should be allowed."""
        now = time.monotonic()
        t = self.tokens.get(ip, self.capacity)
        last = self.last.get(ip, now)
        # refill
        t = min(self.capacity, t + (now - last) * self.refill)
        self.last[ip] = now
        if t >= 1.0:
            t -= 1.0
            self.tokens[ip] = t
            return True
        self.tokens[ip] = t
        return False


def _validate_config(cfg: dict) -> None:
    """Validate required configuration keys are present."""
    required_keys = [
        "TCP_HANDSHAKE_PORT", "UDP_DRONE_RX", "UDP_GCS_RX",
        "DRONE_PLAINTEXT_TX", "DRONE_PLAINTEXT_RX",
        "GCS_PLAINTEXT_TX", "GCS_PLAINTEXT_RX",
        "DRONE_HOST", "GCS_HOST", "REPLAY_WINDOW",
    ]
    for key in required_keys:
        if key not in cfg:
            raise NotImplementedError(f"CONFIG missing: {key}")


def _perform_handshake(
    role: str,
    suite: dict,
    gcs_sig_secret: Optional[bytes],
    gcs_sig_public: Optional[bytes],
    cfg: dict,
    stop_after_seconds: Optional[float] = None,
    ready_event: Optional[threading.Event] = None,
) -> Tuple[
    bytes,
    bytes,
    bytes,
    bytes,
    bytes,
    Optional[str],
    Optional[str],
    Tuple[str, int],
]:
    """Perform TCP handshake and return keys, session details, and authenticated peer address."""
    if role == "gcs":
        if gcs_sig_secret is None:
            raise NotImplementedError("GCS signature secret not provided")

        server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        server_sock.bind(("0.0.0.0", cfg["TCP_HANDSHAKE_PORT"]))
        server_sock.listen(32)

        if ready_event:
            ready_event.set()

        timeout = stop_after_seconds if stop_after_seconds is not None else 30.0
        deadline: Optional[float] = None
        if stop_after_seconds is not None:
            deadline = time.monotonic() + stop_after_seconds

        gate = _TokenBucket(
            cfg.get("HANDSHAKE_RL_BURST", 5),
            cfg.get("HANDSHAKE_RL_REFILL_PER_SEC", 1),
        )

        try:
            try:
                while True:
                    if deadline is not None:
                        remaining = deadline - time.monotonic()
                        if remaining <= 0:
                            raise socket.timeout
                        server_sock.settimeout(max(0.01, remaining))
                    else:
                        server_sock.settimeout(timeout)

                    conn, addr = server_sock.accept()
                    try:
                        ip, _port = addr
                        if ip != cfg["DRONE_HOST"]:
                            logger.warning(
                                "Rejected handshake from unauthorized IP",
                                extra={"role": role, "expected": cfg["DRONE_HOST"], "received": ip},
                            )
                            conn.close()
                            continue

                        if not gate.allow(ip):
                            try:
                                conn.settimeout(0.2)
                                conn.sendall(b"\x00")
                            except Exception:
                                pass
                            finally:
                                conn.close()
                            raise NotImplementedError("Handshake rate-limit: too many attempts")

                        try:
                            result = server_gcs_handshake(conn, suite, gcs_sig_secret)
                        except HandshakeVerifyError:
                            logger.warning(
                                "Rejected drone handshake with failed authentication",
                                extra={"role": role, "expected": cfg["DRONE_HOST"], "received": ip},
                            )
                            continue
                        # Support either 5-tuple or 7-tuple
                        if len(result) >= 7:
                            k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name = result[:7]
                        else:
                            k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id = result
                            kem_name = sig_name = None
                        peer_addr = (ip, cfg["UDP_DRONE_RX"])
                        return (
                            k_d2g,
                            k_g2d,
                            nseed_d2g,
                            nseed_g2d,
                            session_id,
                            kem_name,
                            sig_name,
                            peer_addr,
                        )
                    finally:
                        try:
                            conn.close()
                        except Exception:
                            pass
            except socket.timeout:
                raise NotImplementedError("No drone connection received within timeout")
        finally:
            server_sock.close()

    elif role == "drone":
        if gcs_sig_public is None:
            raise NotImplementedError("GCS signature public key not provided")

        client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        try:
            client_sock.connect((cfg["GCS_HOST"], cfg["TCP_HANDSHAKE_PORT"]))
            peer_ip, _peer_port = client_sock.getpeername()
            result = client_drone_handshake(client_sock, suite, gcs_sig_public)
            if len(result) >= 7:
                k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name = result[:7]
            else:
                k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id = result
                kem_name = sig_name = None
            peer_addr = (peer_ip, cfg["UDP_GCS_RX"])
            return (
                k_d2g,
                k_g2d,
                nseed_d2g,
                nseed_g2d,
                session_id,
                kem_name,
                sig_name,
                peer_addr,
            )
        finally:
            client_sock.close()
    else:
        raise ValueError(f"Invalid role: {role}")


@contextmanager
def _setup_sockets(role: str, cfg: dict, *, encrypted_peer: Optional[Tuple[str, int]] = None):
    """Setup and cleanup all UDP sockets for the proxy."""
    sockets = {}
    try:
        if role == "drone":
            # Encrypted socket - receive from GCS
            enc_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            enc_sock.bind(("0.0.0.0", cfg["UDP_DRONE_RX"]))
            enc_sock.setblocking(False)
            tos = _dscp_to_tos(cfg.get("ENCRYPTED_DSCP"))
            if tos is not None:
                try:
                    enc_sock.setsockopt(socket.IPPROTO_IP, socket.IP_TOS, tos)
                except Exception:
                    pass
            sockets["encrypted"] = enc_sock

            # Plaintext ingress - receive from local app
            ptx_in_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            ptx_in_sock.bind((cfg["DRONE_PLAINTEXT_HOST"], cfg["DRONE_PLAINTEXT_TX"]))
            ptx_in_sock.setblocking(False)
            sockets["plaintext_in"] = ptx_in_sock

            # Plaintext egress - send to local app (no bind needed)
            ptx_out_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sockets["plaintext_out"] = ptx_out_sock

            # Peer addresses
            sockets["encrypted_peer"] = encrypted_peer or (cfg["GCS_HOST"], cfg["UDP_GCS_RX"])
            sockets["plaintext_peer"] = (cfg["DRONE_PLAINTEXT_HOST"], cfg["DRONE_PLAINTEXT_RX"])

        elif role == "gcs":
            # Encrypted socket - receive from Drone
            enc_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            enc_sock.bind(("0.0.0.0", cfg["UDP_GCS_RX"]))
            enc_sock.setblocking(False)
            tos = _dscp_to_tos(cfg.get("ENCRYPTED_DSCP"))
            if tos is not None:
                try:
                    enc_sock.setsockopt(socket.IPPROTO_IP, socket.IP_TOS, tos)
                except Exception:
                    pass
            sockets["encrypted"] = enc_sock

            # Plaintext ingress - receive from local app
            ptx_in_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            ptx_in_sock.bind((cfg["GCS_PLAINTEXT_HOST"], cfg["GCS_PLAINTEXT_TX"]))
            ptx_in_sock.setblocking(False)
            sockets["plaintext_in"] = ptx_in_sock

            # Plaintext egress - send to local app (no bind needed)
            ptx_out_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sockets["plaintext_out"] = ptx_out_sock

            # Peer addresses
            sockets["encrypted_peer"] = encrypted_peer or (cfg["DRONE_HOST"], cfg["UDP_DRONE_RX"])
            sockets["plaintext_peer"] = (cfg["GCS_PLAINTEXT_HOST"], cfg["GCS_PLAINTEXT_RX"])
        else:
            raise ValueError(f"Invalid role: {role}")

        yield sockets
    finally:
        for sock in list(sockets.values()):
            if isinstance(sock, socket.socket):
                try:
                    sock.close()
                except Exception:
                    pass


def _compute_aead_ids(suite: dict, kem_name: Optional[str], sig_name: Optional[str]) -> AeadIds:
    if kem_name and sig_name and header_ids_from_names:
        ids_tuple = header_ids_from_names(kem_name, sig_name)  # type: ignore
    else:
        ids_tuple = header_ids_for_suite(suite)
    return AeadIds(*ids_tuple)


def _build_sender_receiver(
    role: str,
    ids: AeadIds,
    session_id: bytes,
    k_d2g: bytes,
    k_g2d: bytes,
    cfg: dict,
):
    if role == "drone":
        sender = Sender(CONFIG["WIRE_VERSION"], ids, session_id, 0, k_d2g)
        receiver = Receiver(CONFIG["WIRE_VERSION"], ids, session_id, 0, k_g2d, cfg["REPLAY_WINDOW"])
    else:
        sender = Sender(CONFIG["WIRE_VERSION"], ids, session_id, 0, k_g2d)
        receiver = Receiver(CONFIG["WIRE_VERSION"], ids, session_id, 0, k_d2g, cfg["REPLAY_WINDOW"])
    return sender, receiver


def _launch_manual_console(control_state: ControlState, *, quiet: bool) -> Tuple[threading.Event, Tuple[threading.Thread, ...]]:
    suites_catalog = sorted(list_suites().keys())
    stop_event = threading.Event()

    def status_loop() -> None:
        last_line = ""
        while not stop_event.is_set():
            with control_state.lock:
                state = control_state.state
                suite_id = control_state.current_suite
            line = f"[{state}] {suite_id}"
            if line != last_line and not quiet:
                sys.stderr.write(f"\r{line:<80}")
                sys.stderr.flush()
                last_line = line
            time.sleep(0.5)
        if not quiet:
            sys.stderr.write("\r" + " " * 80 + "\r")
            sys.stderr.flush()

    def operator_loop() -> None:
        if not quiet:
            print("Manual control ready. Type a suite ID, 'list', 'status', or 'quit'.")
        while not stop_event.is_set():
            try:
                line = input("rekey> ")
            except EOFError:
                break
            if line is None:
                continue
            line = line.strip()
            if not line:
                continue
            lowered = line.lower()
            if lowered in {"quit", "exit"}:
                break
            if lowered == "list":
                if not quiet:
                    print("Available suites:")
                    for sid in suites_catalog:
                        print(f"  {sid}")
                continue
            if lowered == "status":
                with control_state.lock:
                    summary = f"state={control_state.state} suite={control_state.current_suite}"
                    if control_state.last_status:
                        summary += f" last_status={control_state.last_status}"
                if not quiet:
                    print(summary)
                continue
            try:
                target_suite = get_suite(line)
                rid = request_prepare(control_state, target_suite["suite_id"])
                if not quiet:
                    print(f"prepare queued for {target_suite['suite_id']} rid={rid}")
            except RuntimeError as exc:
                if not quiet:
                    print(f"Busy: {exc}")
            except Exception as exc:
                if not quiet:
                    print(f"Invalid suite: {exc}")

        stop_event.set()

    status_thread = threading.Thread(target=status_loop, daemon=True)
    operator_thread = threading.Thread(target=operator_loop, daemon=True)
    status_thread.start()
    operator_thread.start()
    return stop_event, (status_thread, operator_thread)


def run_proxy(
    *,
    role: str,
    suite: dict,
    cfg: dict,
    gcs_sig_secret: Optional[bytes] = None,
    gcs_sig_public: Optional[bytes] = None,
    stop_after_seconds: Optional[float] = None,
    manual_control: bool = False,
    quiet: bool = False,
    ready_event: Optional[threading.Event] = None,
    status_file: Optional[str] = None,
) -> Dict[str, object]:
    """
    Start a blocking proxy process for `role` in {"drone","gcs"}.

    Performs the TCP handshake, bridges plaintext/encrypted UDP, and processes
    in-band control messages for rekey negotiation. Returns counters on clean exit.
    """
    if role not in {"drone", "gcs"}:
        raise ValueError(f"Invalid role: {role}")

    _validate_config(cfg)

    counters = ProxyCounters()
    start_time = time.time()

    status_path: Optional[Path] = None
    if status_file:
        status_path = Path(status_file).expanduser()

    def write_status(payload: Dict[str, object]) -> None:
        if status_path is None:
            return
        try:
            status_path.parent.mkdir(parents=True, exist_ok=True)
            status_path.write_text(json.dumps(payload), encoding="utf-8")
        except Exception as exc:
            logger.warning(
                "Failed to write status file",
                extra={"role": role, "error": str(exc), "path": str(status_path)},
            )

    handshake_result = _perform_handshake(
        role, suite, gcs_sig_secret, gcs_sig_public, cfg, stop_after_seconds, ready_event
    )

    (
        k_d2g,
        k_g2d,
        _nseed_d2g,
        _nseed_g2d,
        session_id,
        kem_name,
        sig_name,
        peer_addr,
    ) = handshake_result

    suite_id = suite.get("suite_id")
    if not suite_id:
        try:
            suite_id = next((sid for sid, s in SUITES.items() if dict(s) == suite), "unknown")
        except Exception:
            suite_id = "unknown"

    write_status({
        "status": "handshake_ok",
        "suite": suite_id,
        "session_id": session_id.hex(),
    })

    logger.info(
        "PQC handshake completed successfully",
        extra={
            "suite_id": suite_id,
            "peer_role": ("drone" if role == "gcs" else "gcs"),
            "session_id": session_id.hex(),
        },
    )

    aead_ids = _compute_aead_ids(suite, kem_name, sig_name)
    sender, receiver = _build_sender_receiver(role, aead_ids, session_id, k_d2g, k_g2d, cfg)

    control_state = create_control_state(role, suite_id)
    context_lock = threading.RLock()
    active_context: Dict[str, object] = {
        "suite": suite_id,
        "suite_dict": suite,
        "session_id": session_id,
        "aead_ids": aead_ids,
        "sender": sender,
        "receiver": receiver,
        "peer_addr": peer_addr,
        "peer_match_strict": bool(cfg.get("STRICT_UDP_PEER_MATCH", True)),
    }

    active_rekeys: set[str] = set()
    rekey_guard = threading.Lock()

    if manual_control and role == "gcs" and not cfg.get("ENABLE_PACKET_TYPE"):
        logger.warning("ENABLE_PACKET_TYPE is disabled; control-plane packets may not be processed correctly.")

    manual_stop: Optional[threading.Event] = None
    manual_threads: Tuple[threading.Thread, ...] = ()
    if manual_control and role == "gcs":
        manual_stop, manual_threads = _launch_manual_console(control_state, quiet=quiet)

    def _launch_rekey(target_suite_id: str, rid: str) -> None:
        with rekey_guard:
            if rid in active_rekeys:
                return
            active_rekeys.add(rid)

        logger.info(
            "Control rekey negotiation started",
            extra={"role": role, "suite_id": target_suite_id, "rid": rid},
        )

        def worker() -> None:
            try:
                new_suite = get_suite(target_suite_id)
            except NotImplementedError as exc:
                with context_lock:
                    current_suite = active_context["suite"]
                counters.rekeys_fail += 1
                record_rekey_result(control_state, rid, current_suite, success=False)
                logger.warning(
                    "Control rekey rejected: unknown suite",
                    extra={"role": role, "suite_id": target_suite_id, "rid": rid, "error": str(exc)},
                )
                with rekey_guard:
                    active_rekeys.discard(rid)
                return

            try:
                timeout = cfg.get("REKEY_HANDSHAKE_TIMEOUT", 20.0)
                rk_result = _perform_handshake(role, new_suite, gcs_sig_secret, gcs_sig_public, cfg, timeout)
                (
                    new_k_d2g,
                    new_k_g2d,
                    _nd1,
                    _nd2,
                    new_session_id,
                    new_kem_name,
                    new_sig_name,
                    new_peer_addr,
                ) = rk_result

                new_ids = _compute_aead_ids(new_suite, new_kem_name, new_sig_name)
                new_sender, new_receiver = _build_sender_receiver(
                    role, new_ids, new_session_id, new_k_d2g, new_k_g2d, cfg
                )

                with context_lock:
                    active_context.update(
                        {
                            "sender": new_sender,
                            "receiver": new_receiver,
                            "session_id": new_session_id,
                            "aead_ids": new_ids,
                            "suite": new_suite["suite_id"],
                            "suite_dict": new_suite,
                            "peer_addr": new_peer_addr,
                        }
                    )
                    sockets["encrypted_peer"] = new_peer_addr

                counters.rekeys_ok += 1
                counters.last_rekey_ms = int(time.time() * 1000)
                counters.last_rekey_suite = new_suite["suite_id"]
                record_rekey_result(control_state, rid, new_suite["suite_id"], success=True)
                write_status(
                    {
                        "status": "rekey_ok",
                        "new_suite": new_suite["suite_id"],
                        "session_id": new_session_id.hex(),
                    }
                )
                logger.info(
                    "Control rekey successful",
                    extra={"role": role, "suite_id": new_suite["suite_id"], "rid": rid, "session_id": new_session_id.hex()},
                )
            except Exception as exc:
                with context_lock:
                    current_suite = active_context["suite"]
                counters.rekeys_fail += 1
                record_rekey_result(control_state, rid, current_suite, success=False)
                logger.warning(
                    "Control rekey failed",
                    extra={"role": role, "suite_id": target_suite_id, "rid": rid, "error": str(exc)},
                )
            finally:
                with rekey_guard:
                    active_rekeys.discard(rid)

        threading.Thread(target=worker, daemon=True).start()

    with _setup_sockets(role, cfg, encrypted_peer=peer_addr) as sockets:
        selector = selectors.DefaultSelector()
        selector.register(sockets["encrypted"], selectors.EVENT_READ, data="encrypted")
        selector.register(sockets["plaintext_in"], selectors.EVENT_READ, data="plaintext_in")

        def send_control(payload: dict) -> None:
            body = json.dumps(payload, separators=(",", ":"), sort_keys=True).encode("utf-8")
            frame = b"\x02" + body
            with context_lock:
                current_sender = active_context["sender"]
            try:
                wire = current_sender.encrypt(frame)
            except Exception as exc:
                counters.drops += 1
                counters.drop_other += 1
                logger.warning("Failed to encrypt control payload", extra={"role": role, "error": str(exc)})
                return
            try:
                sockets["encrypted"].sendto(wire, sockets["encrypted_peer"])
                counters.enc_out += 1
            except socket.error as exc:
                counters.drops += 1
                counters.drop_other += 1
                logger.warning("Failed to send control payload", extra={"role": role, "error": str(exc)})

        try:
            while True:
                if stop_after_seconds is not None and (time.time() - start_time) >= stop_after_seconds:
                    break

                while True:
                    try:
                        control_payload = control_state.outbox.get_nowait()
                    except queue.Empty:
                        break
                    send_control(control_payload)

                events = selector.select(timeout=0.1)
                for key, _mask in events:
                    sock = key.fileobj
                    data_type = key.data

                    if data_type == "plaintext_in":
                        try:
                            payload, _addr = sock.recvfrom(2048)
                            if not payload:
                                continue
                            counters.ptx_in += 1

                            payload_out = (b"\x01" + payload) if cfg.get("ENABLE_PACKET_TYPE") else payload
                            with context_lock:
                                current_sender = active_context["sender"]
                            wire = current_sender.encrypt(payload_out)

                            try:
                                sockets["encrypted"].sendto(wire, sockets["encrypted_peer"])
                                counters.enc_out += 1
                            except socket.error:
                                counters.drops += 1
                        except socket.error:
                            continue

                    elif data_type == "encrypted":
                        try:
                            wire, addr = sock.recvfrom(2048)
                            if not wire:
                                continue

                            with context_lock:
                                current_receiver = active_context["receiver"]
                                expected_peer = active_context.get("peer_addr")
                                strict_match = bool(active_context.get("peer_match_strict", True))

                            src_ip, src_port = addr
                            if expected_peer is not None:
                                exp_ip, exp_port = expected_peer  # type: ignore[misc]
                                mismatch = False
                                if strict_match:
                                    mismatch = src_ip != exp_ip or src_port != exp_port
                                else:
                                    mismatch = src_ip != exp_ip
                                if mismatch:
                                    counters.drops += 1
                                    counters.drop_src_addr += 1
                                    logger.debug(
                                        "Dropped encrypted packet from unauthorized source",
                                        extra={"role": role, "expected": expected_peer, "received": addr},
                                    )
                                    continue

                            counters.enc_in += 1

                            try:
                                plaintext = current_receiver.decrypt(wire)
                                if plaintext is None:
                                    counters.drops += 1
                                    last_reason = current_receiver.last_error_reason()
                                    if last_reason == "auth":
                                        counters.drop_auth += 1
                                    elif last_reason == "header":
                                        counters.drop_header += 1
                                    elif last_reason == "replay":
                                        counters.drop_replay += 1
                                    elif last_reason == "session":
                                        counters.drop_session_epoch += 1
                                    else:
                                        reason, _seq = _parse_header_fields(
                                            CONFIG["WIRE_VERSION"],
                                            current_receiver.ids,
                                            current_receiver.session_id,
                                            wire,
                                        )
                                        if reason in (
                                            "version_mismatch",
                                            "crypto_id_mismatch",
                                            "header_too_short",
                                            "header_unpack_error",
                                        ):
                                            counters.drop_header += 1
                                        elif reason == "session_mismatch":
                                            counters.drop_session_epoch += 1
                                        elif reason == "auth_fail_or_replay":
                                            counters.drop_auth += 1
                                        else:
                                            counters.drop_other += 1
                                    continue
                            except ReplayError:
                                counters.drops += 1
                                counters.drop_replay += 1
                                continue
                            except HeaderMismatch:
                                counters.drops += 1
                                counters.drop_header += 1
                                continue
                            except AeadAuthError:
                                counters.drops += 1
                                counters.drop_auth += 1
                                continue
                            except NotImplementedError as exc:
                                counters.drops += 1
                                reason, _seq = _parse_header_fields(
                                    CONFIG["WIRE_VERSION"], current_receiver.ids, current_receiver.session_id, wire
                                )
                                if reason in (
                                    "version_mismatch",
                                    "crypto_id_mismatch",
                                    "header_too_short",
                                    "header_unpack_error",
                                ):
                                    counters.drop_header += 1
                                elif reason == "session_mismatch":
                                    counters.drop_session_epoch += 1
                                else:
                                    counters.drop_auth += 1
                                logger.warning(
                                    "Decrypt failed (classified)",
                                    extra={
                                        "role": role,
                                        "reason": reason,
                                        "wire_len": len(wire),
                                        "error": str(exc),
                                    },
                                )
                                continue
                            except Exception as exc:
                                counters.drops += 1
                                counters.drop_other += 1
                                logger.warning(
                                    "Decrypt failed (other)",
                                    extra={"role": role, "error": str(exc), "wire_len": len(wire)},
                                )
                                continue

                            try:
                                out_bytes = plaintext
                                if cfg.get("ENABLE_PACKET_TYPE") and plaintext:
                                    ptype = plaintext[0]
                                    if ptype == 0x01:
                                        out_bytes = plaintext[1:]
                                    elif ptype == 0x02:
                                        try:
                                            control_json = json.loads(plaintext[1:].decode("utf-8"))
                                        except (UnicodeDecodeError, json.JSONDecodeError):
                                            counters.drops += 1
                                            counters.drop_other += 1
                                            continue
                                        result = handle_control(control_json, role, control_state)
                                        for note in result.notes:
                                            if note.startswith("prepare_fail"):
                                                counters.rekeys_fail += 1
                                        for payload in result.send:
                                            control_state.outbox.put(payload)
                                        if result.start_handshake:
                                            suite_next, rid = result.start_handshake
                                            _launch_rekey(suite_next, rid)
                                        continue
                                    else:
                                        counters.drops += 1
                                        counters.drop_other += 1
                                        continue

                                sockets["plaintext_out"].sendto(out_bytes, sockets["plaintext_peer"])
                                counters.ptx_out += 1
                            except socket.error:
                                counters.drops += 1
                                counters.drop_other += 1
                        except socket.error:
                            continue
        except KeyboardInterrupt:
            pass
        finally:
            selector.close()
            if manual_stop:
                manual_stop.set()
                for thread in manual_threads:
                    thread.join(timeout=0.5)

    return counters.to_dict()

============================================================

FILE 5/58: core\config.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\config.py
Size: 7,738 bytes
Modified: 2025-09-27 01:00:20
------------------------------------------------------------
"""
Core configuration constants for PQC drone-GCS secure proxy.

Single source of truth for all network ports, hosts, and runtime parameters.
"""

import os
from ipaddress import ip_address
from typing import Dict, Any


# Default configuration - all required keys with correct types
CONFIG = {
    # Handshake (TCP)
    "TCP_HANDSHAKE_PORT": 46000,

    # Encrypted UDP data-plane (network)
    "UDP_DRONE_RX": 46012,   # drone binds here; GCS sends here
    "UDP_GCS_RX": 46011,     # gcs binds here; Drone sends here

    # Plaintext UDP (local loopback to apps/FC)
    "DRONE_PLAINTEXT_TX": 47003,  # app→drone-proxy (to encrypt out)
    "DRONE_PLAINTEXT_RX": 47004,  # drone-proxy→app (after decrypt)
    "GCS_PLAINTEXT_TX": 47001,    # app→gcs-proxy
    "GCS_PLAINTEXT_RX": 47002,    # gcs-proxy→app
    "DRONE_PLAINTEXT_HOST": "127.0.0.1",
    "GCS_PLAINTEXT_HOST": "127.0.0.1",

    # Hosts
    "DRONE_HOST": "192.168.0.102",
    "GCS_HOST": "192.168.0.103",

    # Pre-shared key (hex) for drone authentication during handshake.
    # Default is a placeholder; override in production via environment variable.
    "DRONE_PSK": "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef",

    # Crypto/runtime
    "REPLAY_WINDOW": 1024,
    "WIRE_VERSION": 1,      # header version byte (frozen)

    # --- Optional hardening / QoS knobs (NOT required; safe defaults) ---
    # Limit TCP handshake attempts accepted per IP at the GCS (server) side.
    # Model: token bucket; BURST tokens max, refilling at REFILL_PER_SEC tokens/sec.
    "HANDSHAKE_RL_BURST": 5,
    "HANDSHAKE_RL_REFILL_PER_SEC": 1,

    # Mark encrypted UDP with DSCP EF (46) to prioritize on WMM-enabled APs.
    # Set to None to disable. Implementation multiplies by 4 to form TOS.
    "ENCRYPTED_DSCP": 46,

    # Feature flag: if True, proxy prefixes app->proxy plaintext with 1 byte packet type.
    # 0x01 = MAVLink/data (forward to local app); 0x02 = control (route to policy engine).
    # When False (default), proxy passes bytes unchanged (backward compatible).
    "ENABLE_PACKET_TYPE": False,

    # Enforce strict matching of encrypted UDP peer IP/port with the authenticated handshake peer.
    # Disable (set to False) only when operating behind NAT where source ports may differ.
    "STRICT_UDP_PEER_MATCH": True,
}


# Required keys with their expected types
_REQUIRED_KEYS = {
    "TCP_HANDSHAKE_PORT": int,
    "UDP_DRONE_RX": int,
    "UDP_GCS_RX": int,
    "DRONE_PLAINTEXT_TX": int,
    "DRONE_PLAINTEXT_RX": int,
    "GCS_PLAINTEXT_TX": int,
    "GCS_PLAINTEXT_RX": int,
    "DRONE_HOST": str,
    "GCS_HOST": str,
    "DRONE_PLAINTEXT_HOST": str,
    "GCS_PLAINTEXT_HOST": str,
    "REPLAY_WINDOW": int,
    "WIRE_VERSION": int,
    "ENABLE_PACKET_TYPE": bool,
    "STRICT_UDP_PEER_MATCH": bool,
    "DRONE_PSK": str,
}

# Keys that can be overridden by environment variables
_ENV_OVERRIDABLE = {
    "TCP_HANDSHAKE_PORT",
    "UDP_DRONE_RX", 
    "UDP_GCS_RX",
    "DRONE_PLAINTEXT_TX",  # Added for testing/benchmarking flexibility
    "DRONE_PLAINTEXT_RX",  # Added for testing/benchmarking flexibility  
    "GCS_PLAINTEXT_TX",    # Added for testing/benchmarking flexibility
    "GCS_PLAINTEXT_RX",    # Added for testing/benchmarking flexibility
    "DRONE_PLAINTEXT_HOST",
    "GCS_PLAINTEXT_HOST",
    "DRONE_HOST",
    "GCS_HOST",
    "ENABLE_PACKET_TYPE",
    "STRICT_UDP_PEER_MATCH",
    "DRONE_PSK",
}


def validate_config(cfg: Dict[str, Any]) -> None:
    """
    Ensure all required keys exist with correct types/ranges.
    Raise NotImplementedError("<reason>") on any violation.
    No return value on success.
    """
    # Check all required keys exist
    missing_keys = set(_REQUIRED_KEYS.keys()) - set(cfg.keys())
    if missing_keys:
        raise NotImplementedError(f"CONFIG missing required keys: {', '.join(sorted(missing_keys))}")
    
    # Check types for all keys
    for key, expected_type in _REQUIRED_KEYS.items():
        value = cfg[key]
        if not isinstance(value, expected_type):
            raise NotImplementedError(f"CONFIG[{key}] must be {expected_type.__name__}, got {type(value).__name__}")
    
    # Validate port ranges
    for key in _REQUIRED_KEYS:
        if key.endswith("_PORT") or key.endswith("_RX") or key.endswith("_TX"):
            port = cfg[key]
            if not (1 <= port <= 65535):
                raise NotImplementedError(f"CONFIG[{key}] must be valid port (1-65535), got {port}")
    
    # Validate specific constraints
    if cfg["WIRE_VERSION"] != 1:
        raise NotImplementedError(f"CONFIG[WIRE_VERSION] must be 1 (frozen), got {cfg['WIRE_VERSION']}")
    
    if cfg["REPLAY_WINDOW"] < 64:
        raise NotImplementedError(f"CONFIG[REPLAY_WINDOW] must be >= 64, got {cfg['REPLAY_WINDOW']}")
    
    # Validate hosts are valid strings (basic check)
    for host_key in ["DRONE_HOST", "GCS_HOST"]:
        host = cfg[host_key]
        if not host or not isinstance(host, str):
            raise NotImplementedError(f"CONFIG[{host_key}] must be non-empty string, got {repr(host)}")
        try:
            ip_address(host)
        except ValueError as exc:
            raise NotImplementedError(f"CONFIG[{host_key}] must be a valid IP address: {exc}")

    # Loopback hosts for plaintext path may remain hostnames (e.g., 127.0.0.1).
    for host_key in ["DRONE_PLAINTEXT_HOST", "GCS_PLAINTEXT_HOST"]:
        host = cfg[host_key]
        if not host or not isinstance(host, str):
            raise NotImplementedError(f"CONFIG[{host_key}] must be non-empty string, got {repr(host)}")
    
    # Optional keys are intentionally not required; do light validation if present
    if "ENCRYPTED_DSCP" in cfg and cfg["ENCRYPTED_DSCP"] is not None:
        if not (0 <= int(cfg["ENCRYPTED_DSCP"]) <= 63):
            raise NotImplementedError("CONFIG[ENCRYPTED_DSCP] must be 0..63 or None")

    psk = cfg.get("DRONE_PSK", "")
    try:
        psk_bytes = bytes.fromhex(psk)
    except ValueError:
        raise NotImplementedError("CONFIG[DRONE_PSK] must be a hex string")
    if len(psk_bytes) != 32:
        raise NotImplementedError("CONFIG[DRONE_PSK] must decode to 32 bytes")


def _apply_env_overrides(cfg: Dict[str, Any]) -> Dict[str, Any]:
    """Apply environment variable overrides to config."""
    result = cfg.copy()
    
    for key in _ENV_OVERRIDABLE:
        env_var = key
        if env_var in os.environ:
            env_value = os.environ[env_var]
            expected_type = _REQUIRED_KEYS[key]
            
            try:
                if expected_type == int:
                    result[key] = int(env_value)
                elif expected_type == str:
                    result[key] = str(env_value)
                elif expected_type == bool:
                    lowered = str(env_value).strip().lower()
                    if lowered in {"1", "true", "yes", "on"}:
                        result[key] = True
                    elif lowered in {"0", "false", "no", "off"}:
                        result[key] = False
                    else:
                        raise ValueError(f"invalid boolean literal: {env_value}")
                else:
                    raise NotImplementedError(f"Unsupported type for env override: {expected_type}")
            except ValueError:
                raise NotImplementedError(f"Invalid {expected_type.__name__} value for {env_var}: {env_value}")
    
    return result


# Apply environment overrides and validate
CONFIG = _apply_env_overrides(CONFIG)
validate_config(CONFIG)

============================================================

FILE 6/58: core\handshake.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\handshake.py
Size: 12,545 bytes
Modified: 2025-09-27 01:00:20
------------------------------------------------------------
from dataclasses import dataclass
import hashlib
import hmac
import os
import struct
from core.config import CONFIG
from core.suites import get_suite
from core.logging_utils import get_logger
from oqs.oqs import KeyEncapsulation, Signature

logger = get_logger("pqc")

class HandshakeFormatError(Exception):
    pass

class HandshakeVerifyError(Exception):
    pass

@dataclass(frozen=True)
class ServerHello:
    version: int
    kem_name: bytes
    sig_name: bytes
    session_id: bytes
    kem_pub: bytes
    signature: bytes
    challenge: bytes

@dataclass
class ServerEphemeral:
    kem_name: str
    sig_name: str
    session_id: bytes
    kem_obj: object  # oqs.KeyEncapsulation instance
    challenge: bytes

def build_server_hello(suite_id: str, server_sig_obj):
    suite = get_suite(suite_id)
    if not suite:
        raise NotImplementedError("suite_id not found")
    version = CONFIG["WIRE_VERSION"]
    kem_name = suite["kem_name"].encode()
    sig_name = suite["sig_name"].encode()
    if not kem_name or not sig_name:
        raise NotImplementedError("kem_name/sig_name empty")
    if not isinstance(server_sig_obj, Signature):
        raise NotImplementedError("server_sig_obj must be oqs.Signature")
    session_id = os.urandom(8)
    challenge = os.urandom(8)
    kem_obj = KeyEncapsulation(kem_name.decode())
    kem_pub = kem_obj.generate_keypair()
    # Include negotiated wire version as first byte of transcript to prevent downgrade
    transcript = (
        struct.pack("!B", version)
        + b"|pq-drone-gcs:v1|"
        + session_id
        + b"|"
        + kem_name
        + b"|"
        + sig_name
        + b"|"
        + kem_pub
        + b"|"
        + challenge
    )
    signature = server_sig_obj.sign(transcript)
    wire = struct.pack("!B", version)
    wire += struct.pack("!H", len(kem_name)) + kem_name
    wire += struct.pack("!H", len(sig_name)) + sig_name
    wire += session_id
    wire += challenge
    wire += struct.pack("!I", len(kem_pub)) + kem_pub
    wire += struct.pack("!H", len(signature)) + signature
    ephemeral = ServerEphemeral(
        kem_name=kem_name.decode(),
        sig_name=sig_name.decode(),
        session_id=session_id,
        kem_obj=kem_obj,
        challenge=challenge,
    )
    return wire, ephemeral

def parse_and_verify_server_hello(wire: bytes, expected_version: int, server_sig_pub: bytes) -> ServerHello:
    try:
        offset = 0
        version = wire[offset]
        offset += 1
        if version != expected_version:
            raise HandshakeFormatError("bad wire version")
        kem_name_len = struct.unpack_from("!H", wire, offset)[0]
        offset += 2
        kem_name = wire[offset:offset+kem_name_len]
        offset += kem_name_len
        sig_name_len = struct.unpack_from("!H", wire, offset)[0]
        offset += 2
        sig_name = wire[offset:offset+sig_name_len]
        offset += sig_name_len
        session_id = wire[offset:offset+8]
        offset += 8
        challenge = wire[offset:offset+8]
        offset += 8
        kem_pub_len = struct.unpack_from("!I", wire, offset)[0]
        offset += 4
        kem_pub = wire[offset:offset+kem_pub_len]
        offset += kem_pub_len
        sig_len = struct.unpack_from("!H", wire, offset)[0]
        offset += 2
        signature = wire[offset:offset+sig_len]
        offset += sig_len
    except Exception:
        raise HandshakeFormatError("malformed server hello")
    transcript = (
        struct.pack("!B", version)
        + b"|pq-drone-gcs:v1|"
        + session_id
        + b"|"
        + kem_name
        + b"|"
        + sig_name
        + b"|"
        + kem_pub
        + b"|"
        + challenge
    )
    try:
        sig = Signature(sig_name.decode())
        if not sig.verify(transcript, signature, server_sig_pub):
            raise HandshakeVerifyError("bad signature")
    except HandshakeVerifyError:
        raise
    except Exception:
        raise HandshakeVerifyError("signature verification failed")
    return ServerHello(
        version=version,
        kem_name=kem_name,
        sig_name=sig_name,
        session_id=session_id,
        kem_pub=kem_pub,
        signature=signature,
        challenge=challenge,
    )

def _drone_psk_bytes() -> bytes:
    psk_hex = CONFIG.get("DRONE_PSK", "")
    try:
        psk = bytes.fromhex(psk_hex)
    except ValueError as exc:
        raise NotImplementedError(f"Invalid DRONE_PSK hex: {exc}")
    if len(psk) != 32:
        raise NotImplementedError("DRONE_PSK must decode to 32 bytes")
    return psk


def client_encapsulate(server_hello: ServerHello):
    try:
        kem = KeyEncapsulation(server_hello.kem_name.decode())
        kem_ct, shared_secret = kem.encap_secret(server_hello.kem_pub)
        return kem_ct, shared_secret
    except Exception:
        raise NotImplementedError("client_encapsulate failed")

def server_decapsulate(ephemeral: ServerEphemeral, kem_ct: bytes):
    try:
        shared_secret = ephemeral.kem_obj.decap_secret(kem_ct)
        return shared_secret
    except Exception:
        raise NotImplementedError("server_decapsulate failed")

def derive_transport_keys(role: str, session_id: bytes, kem_name: bytes, sig_name: bytes, shared_secret: bytes):
    if role not in {"client", "server"}:
        raise NotImplementedError("invalid role")
    if not (isinstance(session_id, bytes) and len(session_id) == 8):
        raise NotImplementedError("session_id must be 8 bytes")
    if not kem_name or not sig_name:
        raise NotImplementedError("kem_name/sig_name empty")
    try:
        from cryptography.hazmat.primitives.kdf.hkdf import HKDF
        from cryptography.hazmat.primitives import hashes
    except ImportError:
        raise NotImplementedError("cryptography not available")
    info = b"pq-drone-gcs:kdf:v1|" + session_id + b"|" + kem_name + b"|" + sig_name
    hkdf = HKDF(
        algorithm=hashes.SHA256(),
        length=64,
        salt=b"pq-drone-gcs|hkdf|v1",
        info=info
    )
    okm = hkdf.derive(shared_secret)
    key_d2g = okm[:32]
    key_g2d = okm[32:64]

    if role == "client":
        # Drone acts as client; return (send_to_gcs, receive_from_gcs).
        return key_d2g, key_g2d
    else:  # server == GCS
        # GCS perspective: send_to_drone first, receive_from_drone second.
        return key_g2d, key_d2g
def server_gcs_handshake(conn, suite, gcs_sig_secret):
    """Authenticated GCS side handshake.

    Requires a ready oqs.Signature object (with generated key pair). Fails fast if not.
    """
    from oqs.oqs import Signature
    import struct

    conn.settimeout(10.0)

    if not isinstance(gcs_sig_secret, Signature):
        raise ValueError("gcs_sig_secret must be an oqs.Signature object with a loaded keypair")

    # Resolve suite_id by matching suite dict
    suite_id = None
    from core.suites import SUITES
    for sid, s in SUITES.items():
        if dict(s) == suite:
            suite_id = sid
            break
    if suite_id is None:
        raise ValueError("suite not found in registry")

    hello_wire, ephemeral = build_server_hello(suite_id, gcs_sig_secret)
    conn.sendall(struct.pack("!I", len(hello_wire)) + hello_wire)

    # Receive KEM ciphertext
    ct_len_bytes = b""
    while len(ct_len_bytes) < 4:
        chunk = conn.recv(4 - len(ct_len_bytes))
        if not chunk:
            raise ConnectionError("Connection closed reading ciphertext length")
        ct_len_bytes += chunk
    ct_len = struct.unpack("!I", ct_len_bytes)[0]
    kem_ct = b""
    while len(kem_ct) < ct_len:
        chunk = conn.recv(ct_len - len(kem_ct))
        if not chunk:
            raise ConnectionError("Connection closed reading ciphertext")
        kem_ct += chunk

    tag_len = hashlib.sha256().digest_size
    tag = b""
    while len(tag) < tag_len:
        chunk = conn.recv(tag_len - len(tag))
        if not chunk:
            raise ConnectionError("Connection closed reading drone authentication tag")
        tag += chunk

    expected_tag = hmac.new(_drone_psk_bytes(), hello_wire, hashlib.sha256).digest()
    if not hmac.compare_digest(tag, expected_tag):
        try:
            peer_ip, _peer_port = conn.getpeername()
        except OSError:
            peer_ip = "unknown"
        logger.warning(
            "Rejected drone handshake with bad authentication tag",
            extra={"role": "gcs", "expected_peer": CONFIG["DRONE_HOST"], "received": peer_ip},
        )
        raise HandshakeVerifyError("drone authentication failed")

    shared_secret = server_decapsulate(ephemeral, kem_ct)
    key_send, key_recv = derive_transport_keys(
        "server",
        ephemeral.session_id,
        ephemeral.kem_name.encode(),
        ephemeral.sig_name.encode(),
        shared_secret,
    )
    # Return (drone→gcs key, gcs→drone key, ...)
    return key_recv, key_send, b"", b"", ephemeral.session_id, ephemeral.kem_name, ephemeral.sig_name

def client_drone_handshake(client_sock, suite, gcs_sig_public):
    # Real handshake implementation with MANDATORY signature verification
    import struct
    
    # Add socket timeout to prevent hanging
    client_sock.settimeout(10.0)
    
    # Receive server hello with length prefix
    hello_len_bytes = b""
    while len(hello_len_bytes) < 4:
        chunk = client_sock.recv(4 - len(hello_len_bytes))
        if not chunk:
            raise NotImplementedError("Connection closed reading hello length")
        hello_len_bytes += chunk
        
    hello_len = struct.unpack("!I", hello_len_bytes)[0]
    hello_wire = b""
    while len(hello_wire) < hello_len:
        chunk = client_sock.recv(hello_len - len(hello_wire))
        if not chunk:
            raise NotImplementedError("Connection closed reading hello")
        hello_wire += chunk
    
    # Parse and VERIFY server hello - NO BYPASS ALLOWED
    # This is critical for security - verification failure must abort
    hello = parse_and_verify_server_hello(hello_wire, CONFIG["WIRE_VERSION"], gcs_sig_public)

    expected_kem = suite.get("kem_name") if isinstance(suite, dict) else None
    expected_sig = suite.get("sig_name") if isinstance(suite, dict) else None
    negotiated_kem = hello.kem_name.decode() if isinstance(hello.kem_name, bytes) else hello.kem_name
    negotiated_sig = hello.sig_name.decode() if isinstance(hello.sig_name, bytes) else hello.sig_name
    if expected_kem and negotiated_kem != expected_kem:
        logger.error(
            "Suite mismatch",
            extra={
                "expected_kem": expected_kem,
                "expected_sig": expected_sig,
                "negotiated_kem": negotiated_kem,
                "negotiated_sig": negotiated_sig,
            },
        )
        raise HandshakeVerifyError(
            f"Downgrade attempt detected: expected {expected_kem}, got {negotiated_kem}"
        )
    if expected_sig and negotiated_sig != expected_sig:
        logger.error(
            "Suite mismatch",
            extra={
                "expected_kem": expected_kem,
                "expected_sig": expected_sig,
                "negotiated_kem": negotiated_kem,
                "negotiated_sig": negotiated_sig,
            },
        )
        raise HandshakeVerifyError(
            f"Downgrade attempt detected: expected {expected_sig}, got {negotiated_sig}"
        )
    
    # Encapsulate and send KEM ciphertext + authentication tag
    kem_ct, shared_secret = client_encapsulate(hello)
    tag = hmac.new(_drone_psk_bytes(), hello_wire, hashlib.sha256).digest()
    client_sock.sendall(struct.pack("!I", len(kem_ct)) + kem_ct + tag)
    
    # Derive transport keys
    key_send, key_recv = derive_transport_keys("client", hello.session_id, 
                                              hello.kem_name, hello.sig_name, 
                                              shared_secret)
    
    # Return in expected format (nonce seeds are unused)
    return (
        key_send,
        key_recv,
        b"",
        b"",
        hello.session_id,
        hello.kem_name.decode() if isinstance(hello.kem_name, bytes) else hello.kem_name,
        hello.sig_name.decode() if isinstance(hello.sig_name, bytes) else hello.sig_name,
    )


============================================================

FILE 7/58: core\logging_utils.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\logging_utils.py
Size: 2,957 bytes
Modified: 2025-09-25 23:55:52
------------------------------------------------------------
import json, logging, sys, time
from pathlib import Path

class JsonFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:
        payload = {
            "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(record.created)),
            "level": record.levelname,
            "name": record.name,
            "msg": record.getMessage(),
        }
        if record.exc_info:
            payload["exc_info"] = self.formatException(record.exc_info)
        # Allow extra fields via record.__dict__ (filtered)
        for k, v in record.__dict__.items():
            if k not in ("msg", "args", "exc_info", "exc_text", "stack_info", "stack_level", "created",
                         "msecs", "relativeCreated", "levelno", "levelname", "pathname", "filename",
                         "module", "lineno", "funcName", "thread", "threadName", "processName", "process"):
                try:
                    json.dumps({k: v})
                    payload[k] = v
                except Exception:
                    payload[k] = str(v)
        return json.dumps(payload)

def get_logger(name: str = "pqc") -> logging.Logger:
    logger = logging.getLogger(name)
    if logger.handlers:
        return logger
    logger.setLevel(logging.INFO)
    h = logging.StreamHandler(sys.stdout)
    h.setFormatter(JsonFormatter())
    logger.addHandler(h)
    logger.propagate = False
    return logger


def configure_file_logger(role: str, logger: logging.Logger | None = None) -> Path:
    """Attach a JSON file handler and return log path."""

    active_logger = logger or get_logger()

    # Drop any previous file handlers we attached to avoid duplicate writes during tests.
    for handler in list(active_logger.handlers):
        if getattr(handler, "_pqc_file_handler", False):
            active_logger.removeHandler(handler)
            try:
                handler.close()
            except Exception:
                pass

    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    timestamp = time.strftime("%Y%m%d-%H%M%S", time.gmtime())
    path = logs_dir / f"{role}-{timestamp}.log"

    file_handler = logging.FileHandler(path, encoding="utf-8")
    file_handler.setFormatter(JsonFormatter())
    file_handler._pqc_file_handler = True  # type: ignore[attr-defined]
    active_logger.addHandler(file_handler)

    return path

# Very small metrics hook (no deps)
class Counter:
    def __init__(self): self.value = 0
    def inc(self, n: int = 1): self.value += n

class Gauge:
    def __init__(self): self.value = 0
    def set(self, v: float): self.value = v

class Metrics:
    def __init__(self):
        self.counters = {}
        self.gauges = {}
    def counter(self, name: str) -> Counter:
        self.counters.setdefault(name, Counter()); return self.counters[name]
    def gauge(self, name: str) -> Gauge:
        self.gauges.setdefault(name, Gauge()); return self.gauges[name]

METRICS = Metrics()

============================================================

FILE 8/58: core\policy_engine.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\policy_engine.py
Size: 7,034 bytes
Modified: 2025-09-27 01:00:21
------------------------------------------------------------
"""
In-band control-plane state machine for interactive rekey negotiation.

Implements a two-phase commit protocol carried over packet type 0x02 payloads.
"""

from __future__ import annotations

import queue
import secrets
import threading
import time
from collections import deque
from dataclasses import dataclass, field
from typing import Callable, Dict, List, Optional, Tuple


def _now_ms() -> int:
    """Return monotonic milliseconds for control timestamps."""

    return time.monotonic_ns() // 1_000_000


def _default_safe() -> bool:
    return True


@dataclass
class ControlState:
    """Mutable control-plane state shared between proxy threads."""

    role: str
    current_suite: str
    safe_guard: Callable[[], bool] = field(default_factory=_default_safe)
    lock: threading.Lock = field(default_factory=threading.Lock)
    outbox: "queue.Queue[dict]" = field(default_factory=queue.Queue)
    pending: Dict[str, str] = field(default_factory=dict)
    state: str = "RUNNING"
    active_rid: Optional[str] = None
    last_rekey_ms: Optional[int] = None
    last_rekey_suite: Optional[str] = None
    last_status: Optional[Dict[str, object]] = None
    stats: Dict[str, int] = field(default_factory=lambda: {
        "prepare_sent": 0,
        "prepare_received": 0,
        "rekeys_ok": 0,
        "rekeys_fail": 0,
    })
    seen_rids: deque[str] = field(default_factory=lambda: deque(maxlen=256))


@dataclass
class ControlResult:
    """Outcome of processing a control message."""

    send: List[dict] = field(default_factory=list)
    start_handshake: Optional[Tuple[str, str]] = None  # (suite_id, rid)
    notes: List[str] = field(default_factory=list)


def create_control_state(role: str, suite_id: str, *, safe_guard: Callable[[], bool] | None = None) -> ControlState:
    """Initialise ControlState with the provided role and suite."""

    guard = safe_guard or _default_safe
    return ControlState(role=role, current_suite=suite_id, safe_guard=guard)


def generate_rid() -> str:
    """Generate a random 64-bit hex request identifier."""

    return secrets.token_hex(8)


def enqueue_json(state: ControlState, payload: dict) -> None:
    """Place an outbound JSON payload onto the control outbox."""

    state.outbox.put(payload)


def request_prepare(state: ControlState, suite_id: str) -> str:
    """Queue a prepare_rekey message and transition to NEGOTIATING."""

    rid = generate_rid()
    now = _now_ms()
    with state.lock:
        if state.state != "RUNNING":
            raise RuntimeError("control-plane already negotiating")
        state.pending[rid] = suite_id
        state.active_rid = rid
        state.state = "NEGOTIATING"
        state.stats["prepare_sent"] += 1
    enqueue_json(
        state,
        {
            "type": "prepare_rekey",
            "suite": suite_id,
            "rid": rid,
            "t_ms": now,
        },
    )
    return rid


def record_rekey_result(state: ControlState, rid: str, suite_id: str, *, success: bool) -> None:
    """Record outcome of a rekey attempt and enqueue status update."""

    now = _now_ms()
    status_payload = {
        "type": "status",
        "state": "RUNNING",
        "suite": suite_id if success else state.current_suite,
        "rid": rid,
        "result": "ok" if success else "fail",
        "t_ms": now,
    }
    with state.lock:
        if success:
            state.current_suite = suite_id
            state.last_rekey_suite = suite_id
            state.last_rekey_ms = now
            state.stats["rekeys_ok"] += 1
        else:
            state.stats["rekeys_fail"] += 1
        state.pending.pop(rid, None)
        state.active_rid = None
        state.state = "RUNNING"
    enqueue_json(state, status_payload)


def handle_control(msg: dict, role: str, state: ControlState) -> ControlResult:
    """Process inbound control JSON and return actions for the proxy."""

    result = ControlResult()
    msg_type = msg.get("type")
    if not isinstance(msg_type, str):
        result.notes.append("missing_type")
        return result

    rid = msg.get("rid")
    now = _now_ms()

    if role == "gcs":
        if msg_type == "prepare_ok" and isinstance(rid, str):
            with state.lock:
                suite = state.pending.get(rid)
                if not suite:
                    result.notes.append("unknown_rid")
                    return result
                state.state = "SWAPPING"
                state.seen_rids.append(rid)
            result.send.append({
                "type": "commit_rekey",
                "suite": suite,
                "rid": rid,
                "t_ms": now,
            })
            result.start_handshake = (suite, rid)
        elif msg_type == "prepare_fail" and isinstance(rid, str):
            reason = msg.get("reason", "unknown")
            with state.lock:
                state.pending.pop(rid, None)
                state.active_rid = None
                state.state = "RUNNING"
                state.stats["rekeys_fail"] += 1
                state.seen_rids.append(rid)
            result.notes.append(f"prepare_fail:{reason}")
        elif msg_type == "status":
            with state.lock:
                state.last_status = msg
        else:
            result.notes.append(f"ignored:{msg_type}")
        return result

    if msg_type == "prepare_rekey":
        suite = msg.get("suite")
        if not isinstance(rid, str) or not isinstance(suite, str):
            result.notes.append("invalid_prepare")
            return result

        with state.lock:
            if rid in state.seen_rids:
                allow = False
            else:
                allow = state.state == "RUNNING" and state.safe_guard()
            if allow:
                state.pending[rid] = suite
                state.active_rid = rid
                state.state = "NEGOTIATING"
                state.stats["prepare_received"] += 1
                state.seen_rids.append(rid)
        if allow:
            result.send.append({
                "type": "prepare_ok",
                "rid": rid,
                "t_ms": now,
            })
        else:
            result.send.append({
                "type": "prepare_fail",
                "rid": rid,
                "reason": "unsafe",
                "t_ms": now,
            })
    elif msg_type == "commit_rekey" and isinstance(rid, str):
        with state.lock:
            suite = state.pending.get(rid)
            if not suite:
                result.notes.append("unknown_commit_rid")
                return result
            state.state = "SWAPPING"
        result.start_handshake = (suite, rid)
    elif msg_type == "status":
        with state.lock:
            state.last_status = msg
    else:
        result.notes.append(f"ignored:{msg_type}")

    return result

============================================================

FILE 9/58: core\project_config.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\project_config.py
Size: 168 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
# Thin shim so planned path 'project_config.py' exists without breaking tests.
# Source of truth remains core/config.py
from .config import CONFIG
__all__ = ["CONFIG"]

============================================================

FILE 10/58: core\run_proxy.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\run_proxy.py
Size: 20,487 bytes
Modified: 2025-09-27 01:00:21
------------------------------------------------------------
"""
Unified CLI entrypoint for the PQC drone-GCS proxy.

Supports subcommands:
- init-identity: Create persistent GCS signing identity
- gcs: Start GCS proxy (requires secret key by default)  
- drone: Start drone proxy (requires GCS public key)

Uses persistent file-based keys by default for production security.
"""

import sys
import argparse
import signal
import os
import json
import time
import logging
from pathlib import Path
from typing import Optional

from core.config import CONFIG
from core.suites import get_suite, build_suite_id
from core.logging_utils import get_logger, configure_file_logger

logger = get_logger("pqc")


def _require_signature_class():
    """Lazily import oqs Signature and provide a friendly error if missing."""

    try:
        from oqs.oqs import Signature  # type: ignore
    except ModuleNotFoundError as exc:  # pragma: no cover - exercised via CLI
        if exc.name in {"oqs", "oqs.oqs"}:
            print(
                "Error: oqs-python is required for cryptographic operations. "
                "Install it with 'pip install oqs-python' or activate the project environment."
            )
            sys.exit(1)
        raise

    return Signature


def _require_run_proxy():
    """Import run_proxy only when needed, surfacing helpful guidance on failure."""

    try:
        from core.async_proxy import run_proxy as _run_proxy  # type: ignore
    except ModuleNotFoundError as exc:  # pragma: no cover - exercised via CLI
        if exc.name in {"oqs", "oqs.oqs"}:
            print(
                "Error: oqs-python is required to start the proxy. "
                "Install it with 'pip install oqs-python' or activate the project environment."
            )
            sys.exit(1)
        raise

    return _run_proxy


def signal_handler(signum, frame):
    """Handle interrupt signals gracefully."""
    print("\nReceived interrupt signal. Shutting down...")
    sys.exit(0)


def create_secrets_dir():
    """Create secrets directory if it doesn't exist."""
    secrets_dir = Path("secrets")
    secrets_dir.mkdir(exist_ok=True)
    return secrets_dir


def write_json_report(json_path: Optional[str], payload: dict, *, quiet: bool = False) -> None:
    """Persist counters payload to JSON if a path is provided."""

    if not json_path:
        return

    try:
        path = Path(json_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        if not quiet:
            print(f"Wrote JSON report to {path}")
    except Exception as exc:
        print(f"Warning: Failed to write JSON output to {json_path}: {exc}")


def _resolve_suite(args, role_label: str) -> dict:
    """Resolve suite via legacy --suite or new --kem/--aead/--sig components."""

    suite_arg = getattr(args, "suite", None)
    kem = getattr(args, "kem", None)
    sig = getattr(args, "sig", None)
    aead = getattr(args, "aead", None)

    if suite_arg and any(v is not None for v in (kem, sig, aead)):
        print("Error: --suite cannot be combined with --kem/--sig/--aead")
        sys.exit(1)

    try:
        if suite_arg:
            suite = get_suite(suite_arg)
        elif any(v is not None for v in (kem, sig, aead)):
            if not all(v is not None for v in (kem, sig, aead)):
                print("Error: --kem, --sig, and --aead must be provided together")
                sys.exit(1)
            suite_id = build_suite_id(kem, aead, sig)
            suite = get_suite(suite_id)
        else:
            print(f"Error: {role_label} requires --suite or --kem/--sig/--aead")
            sys.exit(1)
    except NotImplementedError as exc:
        print(f"Error: {exc}")
        sys.exit(1)

    # Normalize suite argument for downstream logging
    setattr(args, "suite", suite.get("suite_id", getattr(args, "suite", None)))
    return suite


def init_identity_command(args):
    """Create GCS signing identity and save to persistent files."""
    # Use custom output_dir if provided, otherwise default secrets directory
    if hasattr(args, 'output_dir') and args.output_dir:
        secrets_dir = Path(args.output_dir)
        secrets_dir.mkdir(parents=True, exist_ok=True)
    else:
        secrets_dir = create_secrets_dir()
    
    try:
        suite = get_suite(args.suite) if hasattr(args, 'suite') and args.suite else get_suite("cs-kyber768-aesgcm-dilithium3")
    except KeyError as e:
        print(f"Error: Unknown suite: {args.suite if hasattr(args, 'suite') else 'default'}")
        sys.exit(1)
    
    secret_path = secrets_dir / "gcs_signing.key"
    public_path = secrets_dir / "gcs_signing.pub"
    
    if secret_path.exists() or public_path.exists():
        print("Warning: Identity files already exist. Overwriting with a new keypair.")
    
    Signature = _require_signature_class()

    try:
        sig = Signature(suite["sig_name"])
        if hasattr(sig, 'export_secret_key'):
            gcs_sig_public = sig.generate_keypair()
            gcs_sig_secret = sig.export_secret_key()
            
            # Write files with appropriate permissions
            secret_path.write_bytes(gcs_sig_secret)
            public_path.write_bytes(gcs_sig_public)
            
            # Secure the secret file
            try:
                os.chmod(secret_path, 0o600)
            except Exception:
                pass  # Best effort on Windows
                
            print(f"Created GCS signing identity:")
            print(f"  Secret: {secret_path}")
            print(f"  Public: {public_path}")
            print(f"  Public key (hex): {gcs_sig_public.hex()}")
            return 0  # Success
            
        else:
            print("Error: oqs build lacks key import/export; use --ephemeral or upgrade oqs-python.")
            sys.exit(1)
            
    except Exception as e:
        print(f"Error creating identity: {e}")
        sys.exit(1)


def gcs_command(args):
    """Start GCS proxy."""
    suite = _resolve_suite(args, "GCS proxy")
    suite_id = suite["suite_id"]
    
    Signature = _require_signature_class()
    proxy_runner = _require_run_proxy()

    gcs_sig_secret = None
    gcs_sig_public = None
    json_out_path = getattr(args, "json_out", None)
    quiet = getattr(args, "quiet", False)
    status_file = getattr(args, "status_file", None)

    def info(msg: str) -> None:
        if not quiet:
            print(msg)
    
    if args.ephemeral:
        info("⚠️  WARNING: Using EPHEMERAL keys - not suitable for production!")
        info("⚠️  Key will be lost when process exits.")
        if not quiet:
            print()
        
        # Generate ephemeral keypair
        sig = Signature(suite["sig_name"])
        gcs_sig_public = sig.generate_keypair()
        gcs_sig_secret = sig
        info("Generated ephemeral GCS signing keypair:")
        if not quiet:
            print(f"Public key (hex): {gcs_sig_public.hex()}")
            print("Provide this to the drone via --gcs-pub-hex or --peer-pubkey-file")
            print()
        
    else:
        # Load persistent key
        if args.gcs_secret_file:
            secret_path = Path(args.gcs_secret_file)
        else:
            secret_path = Path("secrets/gcs_signing.key")
            
        if not secret_path.exists():
            print(f"Error: Secret key file not found: {secret_path}")
            print("Run 'python -m core.run_proxy init-identity' to create one,")
            print("or use --ephemeral for development only.")
            sys.exit(1)
            
        secret_bytes = None
        try:
            secret_bytes = secret_path.read_bytes()
        except Exception as exc:
            print(f"Error reading secret key file: {exc}")
            sys.exit(1)

        load_errors = []
        imported_public: Optional[bytes] = None
        load_method: Optional[str] = None

        try:
            primary_sig = Signature(suite["sig_name"])
        except Exception as exc:
            load_errors.append(f"Signature ctor failed: {exc}")
            primary_sig = None  # type: ignore

        if primary_sig is not None and hasattr(primary_sig, "import_secret_key"):
            try:
                imported_public = primary_sig.import_secret_key(secret_bytes)
                gcs_sig_secret = primary_sig
                load_method = "import_secret_key"
            except Exception as exc:
                load_errors.append(f"import_secret_key failed: {exc}")

        if gcs_sig_secret is None:
            try:
                fallback_sig = Signature(suite["sig_name"], secret_key=secret_bytes)
                gcs_sig_secret = fallback_sig
                load_method = "ctor_secret_key"
            except TypeError as exc:
                load_errors.append(f"ctor secret_key unsupported: {exc}")
            except Exception as exc:
                load_errors.append(f"ctor secret_key failed: {exc}")

        if gcs_sig_secret is None:
            print("Error: oqs build lacks usable key import. Tried import_secret_key and constructor fallback without success.")
            if load_errors:
                print("Details:")
                for err in load_errors:
                    print(f"  - {err}")
            print("Consider running with --ephemeral or upgrading oqs-python/liboqs with key import support.")
            sys.exit(1)

        info("Loaded GCS signing key from file.")
        if load_method == "ctor_secret_key":
            info("Using constructor-based fallback because import/export APIs are unavailable.")

        gcs_sig_public = imported_public
        if gcs_sig_public is None:
            public_candidates = []
            if secret_path.suffix:
                public_candidates.append(secret_path.with_suffix(".pub"))
            public_candidates.append(secret_path.parent / "gcs_signing.pub")
            seen = set()
            for candidate in public_candidates:
                key = str(candidate.resolve()) if candidate.exists() else str(candidate)
                if key in seen:
                    continue
                seen.add(key)
                if candidate.exists():
                    try:
                        gcs_sig_public = candidate.read_bytes()
                        info(f"Loaded public key from {candidate}.")
                    except Exception as exc:
                        load_errors.append(f"public key read failed ({candidate}): {exc}")
                    break

        if gcs_sig_public is not None and not quiet:
            print(f"Public key (hex): {gcs_sig_public.hex()}")
        elif gcs_sig_public is None and not quiet:
            print("Warning: Could not locate public key file for display. Ensure the drone has the matching public key.")
        if not quiet:
            print()
    
    try:
        log_path = configure_file_logger("gcs", logger)
        if not quiet:
            print(f"Log file: {log_path}")

        info(f"Starting GCS proxy with suite {suite_id}")
        if args.stop_seconds:
            info(f"Will auto-stop after {args.stop_seconds} seconds")
        if not quiet:
            print()
        
        counters = proxy_runner(
            role="gcs",
            suite=suite,
            cfg=CONFIG,
            gcs_sig_secret=gcs_sig_secret,
            gcs_sig_public=None,
            stop_after_seconds=args.stop_seconds,
            manual_control=getattr(args, "control_manual", False),
            quiet=quiet,
            status_file=status_file,
        )
        
        # Log final counters as JSON
        logger.info("GCS proxy shutdown", extra={"counters": counters})
        
        if not quiet:
            print("GCS proxy stopped. Final counters:")
            for key, value in counters.items():
                print(f"  {key}: {value}")

        payload = {
            "role": "gcs",
            "suite": suite_id,
            "counters": counters,
            "ts_stop_ns": time.time_ns(),
        }
        write_json_report(json_out_path, payload, quiet=quiet)
            
    except KeyboardInterrupt:
        if not quiet:
            print("\nGCS proxy stopped by user.")
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def drone_command(args):
    """Start drone proxy."""
    suite = _resolve_suite(args, "Drone proxy")
    suite_id = suite["suite_id"]
    
    proxy_runner = _require_run_proxy()

    # Get GCS public key
    gcs_sig_public = None
    json_out_path = getattr(args, "json_out", None)
    quiet = getattr(args, "quiet", False)
    status_file = getattr(args, "status_file", None)

    def info(msg: str) -> None:
        if not quiet:
            print(msg)
    
    try:
        if args.peer_pubkey_file:
            pub_path = Path(args.peer_pubkey_file)
            if not pub_path.exists():
                raise FileNotFoundError(f"Public key file not found: {pub_path}")
            gcs_sig_public = pub_path.read_bytes()
        elif args.gcs_pub_hex:
            gcs_sig_public = bytes.fromhex(args.gcs_pub_hex)
        else:
            # Try default location
            default_pub = Path("secrets/gcs_signing.pub")
            if default_pub.exists():
                gcs_sig_public = default_pub.read_bytes()
                info(f"Using GCS public key from: {default_pub}")
            else:
                raise ValueError("No GCS public key provided. Use --peer-pubkey-file, --gcs-pub-hex, or ensure secrets/gcs_signing.pub exists.")
                
    except Exception as e:
        print(f"Error loading GCS public key: {e}")
        sys.exit(1)
    
    try:
        log_path = configure_file_logger("drone", logger)
        if not quiet:
            print(f"Log file: {log_path}")

        info(f"Starting drone proxy with suite {suite_id}")
        if args.stop_seconds:
            info(f"Will auto-stop after {args.stop_seconds} seconds")
        if not quiet:
            print()
        
        counters = proxy_runner(
            role="drone",
            suite=suite,
            cfg=CONFIG,
            gcs_sig_secret=None,
            gcs_sig_public=gcs_sig_public,
            stop_after_seconds=args.stop_seconds,
            manual_control=False,
            quiet=quiet,
            status_file=status_file,
        )
        
        # Log final counters as JSON
        logger.info("Drone proxy shutdown", extra={"counters": counters})
        
        if not quiet:
            print("Drone proxy stopped. Final counters:")
            for key, value in counters.items():
                print(f"  {key}: {value}")

        payload = {
            "role": "drone",
            "suite": suite_id,
            "counters": counters,
            "ts_stop_ns": time.time_ns(),
        }
        write_json_report(json_out_path, payload, quiet=quiet)
            
    except KeyboardInterrupt:
        if not quiet:
            print("\nDrone proxy stopped by user.")
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def main():
    """Main CLI entrypoint with subcommands."""
    # Set up signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    if hasattr(signal, 'SIGTERM'):
        signal.signal(signal.SIGTERM, signal_handler)
    
    parser = argparse.ArgumentParser(description="PQC Drone-GCS Secure Proxy")
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # init-identity subcommand
    init_parser = subparsers.add_parser('init-identity', 
                                       help='Create persistent GCS signing identity')
    init_parser.add_argument("--suite", default="cs-kyber768-aesgcm-dilithium3",
                            help="Cryptographic suite ID (default: cs-kyber768-aesgcm-dilithium3)")
    init_parser.add_argument("--output-dir", 
                            help="Directory for key files (default: secrets/)")
    
    # gcs subcommand
    gcs_parser = subparsers.add_parser('gcs', help='Start GCS proxy')
    gcs_parser.add_argument("--suite",
                           help="Cryptographic suite ID (e.g., cs-kyber768-aesgcm-dilithium3)")
    gcs_parser.add_argument("--kem",
                           help="KEM alias (e.g., ML-KEM-768, kyber768)")
    gcs_parser.add_argument("--aead",
                           help="AEAD alias (e.g., AES-GCM)")
    gcs_parser.add_argument("--sig",
                           help="Signature alias (e.g., ML-DSA-65, dilithium3)")
    gcs_parser.add_argument("--gcs-secret-file",
                           help="Path to GCS secret key file (default: secrets/gcs_signing.key)")
    gcs_parser.add_argument("--ephemeral", action='store_true',
                           help="Use ephemeral keys (development only - prints warning)")
    gcs_parser.add_argument("--stop-seconds", type=float,
                           help="Auto-stop after N seconds (for testing)")
    gcs_parser.add_argument("--quiet", action="store_true",
                           help="Suppress informational prints (warnings/errors still shown)")
    gcs_parser.add_argument("--json-out",
                           help="Optional path to write counters JSON on shutdown")
    gcs_parser.add_argument("--control-manual", action="store_true",
                           help="Enable interactive manual in-band rekey control thread")
    gcs_parser.add_argument("--status-file",
                           help="Path to write proxy status JSON updates (handshake/rekey)")
    
    # drone subcommand
    drone_parser = subparsers.add_parser('drone', help='Start drone proxy')
    drone_parser.add_argument("--suite",
                             help="Cryptographic suite ID (e.g., cs-kyber768-aesgcm-dilithium3)")
    drone_parser.add_argument("--kem",
                             help="KEM alias (e.g., ML-KEM-768, kyber768)")
    drone_parser.add_argument("--aead",
                             help="AEAD alias (e.g., AES-GCM)")
    drone_parser.add_argument("--sig",
                             help="Signature alias (e.g., ML-DSA-65, dilithium3)")
    drone_parser.add_argument("--peer-pubkey-file",
                             help="Path to GCS public key file (default: secrets/gcs_signing.pub)")
    drone_parser.add_argument("--gcs-pub-hex",
                             help="GCS public key as hex string")
    drone_parser.add_argument("--stop-seconds", type=float,
                             help="Auto-stop after N seconds (for testing)")
    drone_parser.add_argument("--quiet", action="store_true",
                              help="Suppress informational prints (warnings/errors still shown)")
    drone_parser.add_argument("--json-out",
                              help="Optional path to write counters JSON on shutdown")
    drone_parser.add_argument("--status-file",
                              help="Path to write proxy status JSON updates (handshake/rekey)")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # Validate required CONFIG keys
    required_keys = [
        "TCP_HANDSHAKE_PORT", "UDP_DRONE_RX", "UDP_GCS_RX", 
        "DRONE_PLAINTEXT_TX", "DRONE_PLAINTEXT_RX",
        "GCS_PLAINTEXT_TX", "GCS_PLAINTEXT_RX", 
        "DRONE_HOST", "GCS_HOST", "REPLAY_WINDOW"
    ]
    
    missing_keys = [key for key in required_keys if key not in CONFIG]
    if missing_keys:
        print(f"Error: CONFIG missing required keys: {', '.join(missing_keys)}")
        sys.exit(1)
    
    # Route to appropriate command handler
    if args.command == 'init-identity':
        init_identity_command(args)
    elif args.command == 'gcs':
        if getattr(args, "quiet", False):
            logger.setLevel(logging.WARNING)
        gcs_command(args)
    elif args.command == 'drone':
        if getattr(args, "quiet", False):
            logger.setLevel(logging.WARNING)
        drone_command(args)


if __name__ == "__main__":
    main()

============================================================

FILE 11/58: core\suites.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\suites.py
Size: 11,602 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""PQC cryptographic suite registry and algorithm ID mapping.

Provides a composable {KEM × AEAD × SIG} registry with synonym resolution and
helpers for querying oqs availability.
"""

from __future__ import annotations

from itertools import product
from types import MappingProxyType
from typing import Dict, Iterable, Tuple


def _normalize_alias(value: str) -> str:
    """Normalize alias strings for case- and punctuation-insensitive matching."""

    return "".join(ch for ch in value.lower() if ch.isalnum())


_KEM_REGISTRY = {
    "mlkem512": {
        "oqs_name": "ML-KEM-512",
        "token": "mlkem512",
        "nist_level": "L1",
        "kem_id": 1,
        "kem_param_id": 1,
        "aliases": (
            "ML-KEM-512",
            "ml-kem-512",
            "mlkem512",
            "kyber512",
            "kyber-512",
            "kyber_512",
        ),
    },
    "mlkem768": {
        "oqs_name": "ML-KEM-768",
        "token": "mlkem768",
        "nist_level": "L3",
        "kem_id": 1,
        "kem_param_id": 2,
        "aliases": (
            "ML-KEM-768",
            "ml-kem-768",
            "mlkem768",
            "kyber768",
            "kyber-768",
            "kyber_768",
        ),
    },
    "mlkem1024": {
        "oqs_name": "ML-KEM-1024",
        "token": "mlkem1024",
        "nist_level": "L5",
        "kem_id": 1,
        "kem_param_id": 3,
        "aliases": (
            "ML-KEM-1024",
            "ml-kem-1024",
            "mlkem1024",
            "kyber1024",
            "kyber-1024",
            "kyber_1024",
        ),
    },
}


_SIG_REGISTRY = {
    "mldsa44": {
        "oqs_name": "ML-DSA-44",
        "token": "mldsa44",
        "sig_id": 1,
        "sig_param_id": 1,
        "aliases": (
            "ML-DSA-44",
            "ml-dsa-44",
            "mldsa44",
            "dilithium2",
            "dilithium-2",
        ),
    },
    "mldsa65": {
        "oqs_name": "ML-DSA-65",
        "token": "mldsa65",
        "sig_id": 1,
        "sig_param_id": 2,
        "aliases": (
            "ML-DSA-65",
            "ml-dsa-65",
            "mldsa65",
            "dilithium3",
            "dilithium-3",
        ),
    },
    "mldsa87": {
        "oqs_name": "ML-DSA-87",
        "token": "mldsa87",
        "sig_id": 1,
        "sig_param_id": 3,
        "aliases": (
            "ML-DSA-87",
            "ml-dsa-87",
            "mldsa87",
            "dilithium5",
            "dilithium-5",
        ),
    },
    "falcon512": {
        "oqs_name": "Falcon-512",
        "token": "falcon512",
        "sig_id": 2,
        "sig_param_id": 1,
        "aliases": (
            "Falcon-512",
            "falcon512",
            "falcon-512",
        ),
    },
    "falcon1024": {
        "oqs_name": "Falcon-1024",
        "token": "falcon1024",
        "sig_id": 2,
        "sig_param_id": 2,
        "aliases": (
            "Falcon-1024",
            "falcon1024",
            "falcon-1024",
        ),
    },
    "sphincs128fsha2": {
        "oqs_name": "SLH-DSA-SHA2-128f",
        "token": "sphincs128fsha2",
        "sig_id": 3,
        "sig_param_id": 1,
        "aliases": (
            "SLH-DSA-SHA2-128f",
            "sphincs+-sha2-128f-simple",
            "sphincs128fsha2",
            "sphincs128f_sha2",
        ),
    },
    "sphincs256fsha2": {
        "oqs_name": "SLH-DSA-SHA2-256f",
        "token": "sphincs256fsha2",
        "sig_id": 3,
        "sig_param_id": 2,
        "aliases": (
            "SLH-DSA-SHA2-256f",
            "sphincs+-sha2-256f-simple",
            "sphincs256fsha2",
            "sphincs256f_sha2",
        ),
    },
}


_AEAD_REGISTRY = {
    "aesgcm": {
        "display_name": "AES-256-GCM",
        "token": "aesgcm",
        "kdf": "HKDF-SHA256",
        "aliases": (
            "AES-256-GCM",
            "aes-256-gcm",
            "aesgcm",
            "aes256gcm",
            "aes-gcm",
        ),
    },
}


def _build_alias_map(registry: Dict[str, Dict]) -> Dict[str, str]:
    alias_map: Dict[str, str] = {}
    for key, entry in registry.items():
        for alias in entry["aliases"]:
            normalized = _normalize_alias(alias)
            alias_map[normalized] = key
        alias_map[_normalize_alias(entry["oqs_name"]) if "oqs_name" in entry else _normalize_alias(entry["display_name"])] = key
        alias_map[_normalize_alias(entry["token"])] = key
    return alias_map


_KEM_ALIASES = _build_alias_map(_KEM_REGISTRY)
_SIG_ALIASES = _build_alias_map(_SIG_REGISTRY)
_AEAD_ALIASES = _build_alias_map(_AEAD_REGISTRY)


def _resolve_kem_key(name: str) -> str:
    lookup = _KEM_ALIASES.get(_normalize_alias(name))
    if lookup is None:
        raise NotImplementedError(f"unknown KEM: {name}")
    return lookup


def _resolve_sig_key(name: str) -> str:
    lookup = _SIG_ALIASES.get(_normalize_alias(name))
    if lookup is None:
        raise NotImplementedError(f"unknown signature: {name}")
    return lookup


def _resolve_aead_key(name: str) -> str:
    lookup = _AEAD_ALIASES.get(_normalize_alias(name))
    if lookup is None:
        raise NotImplementedError(f"unknown AEAD: {name}")
    return lookup


def build_suite_id(kem: str, aead: str, sig: str) -> str:
    """Build canonical suite identifier from component aliases."""

    kem_key = _resolve_kem_key(kem)
    aead_key = _resolve_aead_key(aead)
    sig_key = _resolve_sig_key(sig)

    kem_entry = _KEM_REGISTRY[kem_key]
    aead_entry = _AEAD_REGISTRY[aead_key]
    sig_entry = _SIG_REGISTRY[sig_key]

    return f"cs-{kem_entry['token']}-{aead_entry['token']}-{sig_entry['token']}"


_LEGACY_SUITE_ALIASES: Tuple[Tuple[str, str, str], ...] = (
    ("ML-KEM-512", "AES-256-GCM", "ML-DSA-44"),
    ("ML-KEM-768", "AES-256-GCM", "ML-DSA-65"),
    ("ML-KEM-1024", "AES-256-GCM", "ML-DSA-87"),
    ("ML-KEM-768", "AES-256-GCM", "Falcon-512"),
    ("ML-KEM-1024", "AES-256-GCM", "Falcon-1024"),
    ("ML-KEM-512", "AES-256-GCM", "SLH-DSA-SHA2-128f"),
    ("ML-KEM-1024", "AES-256-GCM", "SLH-DSA-SHA2-256f"),
)


_SUITE_ALIASES = {
    legacy_id: build_suite_id(*components)
    for legacy_id, components in {
        "cs-kyber512-aesgcm-dilithium2": _LEGACY_SUITE_ALIASES[0],
        "cs-kyber768-aesgcm-dilithium3": _LEGACY_SUITE_ALIASES[1],
        "cs-kyber1024-aesgcm-dilithium5": _LEGACY_SUITE_ALIASES[2],
        "cs-kyber768-aesgcm-falcon512": _LEGACY_SUITE_ALIASES[3],
        "cs-kyber1024-aesgcm-falcon1024": _LEGACY_SUITE_ALIASES[4],
        "cs-kyber512-aesgcm-sphincs128f_sha2": _LEGACY_SUITE_ALIASES[5],
        "cs-kyber1024-aesgcm-sphincs256f_sha2": _LEGACY_SUITE_ALIASES[6],
    }.items()
}


def _compose_suite(kem_key: str, aead_key: str, sig_key: str) -> Dict[str, object]:
    kem_entry = _KEM_REGISTRY[kem_key]
    aead_entry = _AEAD_REGISTRY[aead_key]
    sig_entry = _SIG_REGISTRY[sig_key]

    suite_id = f"cs-{kem_entry['token']}-{aead_entry['token']}-{sig_entry['token']}"

    return {
        "suite_id": suite_id,
        "kem_name": kem_entry["oqs_name"],
        "kem_id": kem_entry["kem_id"],
        "kem_param_id": kem_entry["kem_param_id"],
        "sig_name": sig_entry["oqs_name"],
        "sig_id": sig_entry["sig_id"],
        "sig_param_id": sig_entry["sig_param_id"],
        "nist_level": kem_entry["nist_level"],
        "aead": aead_entry["display_name"],
        "kdf": aead_entry["kdf"],
    }


def _canonicalize_suite_id(suite_id: str) -> str:
    if not suite_id:
        raise NotImplementedError("suite_id cannot be empty")

    candidate = suite_id.strip()
    if candidate in _SUITE_ALIASES:
        return _SUITE_ALIASES[candidate]

    if not candidate.startswith("cs-"):
        raise NotImplementedError(f"unknown suite_id: {suite_id}")

    parts = candidate[3:].split("-")
    if len(parts) < 3:
        raise NotImplementedError(f"unknown suite_id: {suite_id}")

    kem_part = parts[0]
    aead_part = parts[1]
    sig_part = "-".join(parts[2:])

    try:
        return build_suite_id(kem_part, aead_part, sig_part)
    except NotImplementedError as exc:
        raise NotImplementedError(f"unknown suite_id: {suite_id}") from exc


def _generate_suite_registry() -> MappingProxyType:
    suites: Dict[str, MappingProxyType] = {}
    for kem_key, sig_key in product(_KEM_REGISTRY.keys(), _SIG_REGISTRY.keys()):
        suite_dict = _compose_suite(kem_key, "aesgcm", sig_key)
        suites[suite_dict["suite_id"]] = MappingProxyType(suite_dict)
    return MappingProxyType(suites)


SUITES = _generate_suite_registry()


def list_suites() -> Dict[str, Dict]:
    """Return all available suites as immutable mapping."""

    return {suite_id: dict(config) for suite_id, config in SUITES.items()}


def get_suite(suite_id: str) -> Dict:
    """Get suite configuration by ID, resolving legacy aliases and synonyms."""

    canonical_id = _canonicalize_suite_id(suite_id)

    if canonical_id not in SUITES:
        raise NotImplementedError(f"unknown suite_id: {suite_id}")

    suite = SUITES[canonical_id]

    required_fields = {"kem_name", "sig_name", "aead", "kdf", "nist_level"}
    missing_fields = required_fields - set(suite.keys())
    if missing_fields:
        raise NotImplementedError(f"malformed suite {suite_id}: missing fields {missing_fields}")

    return dict(suite)


def _safe_get_enabled_kem_mechanisms() -> Iterable[str]:
    from oqs.oqs import get_enabled_KEM_mechanisms

    return get_enabled_KEM_mechanisms()


def _safe_get_enabled_sig_mechanisms() -> Iterable[str]:
    from oqs.oqs import get_enabled_sig_mechanisms

    return get_enabled_sig_mechanisms()


def enabled_kems() -> Tuple[str, ...]:
    """Return tuple of oqs KEM mechanism names supported by the runtime."""

    mechanisms = {_normalize_alias(name) for name in _safe_get_enabled_kem_mechanisms()}
    result = [
        entry["oqs_name"]
        for entry in _KEM_REGISTRY.values()
        if _normalize_alias(entry["oqs_name"]) in mechanisms
    ]
    return tuple(result)


def enabled_sigs() -> Tuple[str, ...]:
    """Return tuple of oqs signature mechanism names supported by the runtime."""

    mechanisms = {_normalize_alias(name) for name in _safe_get_enabled_sig_mechanisms()}
    result = [
        entry["oqs_name"]
        for entry in _SIG_REGISTRY.values()
        if _normalize_alias(entry["oqs_name"]) in mechanisms
    ]
    return tuple(result)


def header_ids_for_suite(suite: Dict) -> Tuple[int, int, int, int]:
    """Return embedded header ID bytes for provided suite dict copy."""

    try:
        return (
            suite["kem_id"],
            suite["kem_param_id"],
            suite["sig_id"],
            suite["sig_param_id"],
        )
    except KeyError as e:
        raise NotImplementedError(f"suite missing embedded id field: {e}")


def suite_bytes_for_hkdf(suite: Dict) -> bytes:
    """Generate deterministic bytes from suite for HKDF info parameter."""

    if "suite_id" in suite:
        return suite["suite_id"].encode("utf-8")

    try:
        suite_id = build_suite_id(suite["kem_name"], suite["aead"], suite["sig_name"])
    except (KeyError, NotImplementedError) as exc:
        raise NotImplementedError("Suite configuration not found in registry") from exc

    return suite_id.encode("utf-8")

============================================================

FILE 12/58: core\temp-file.py
============================================================
Full Path: C:\Users\burak\Desktop\research\core\temp-file.py
Size: 18,859 bytes
Modified: 2025-09-25 18:06:34
------------------------------------------------------------
"""
Selectors-based network transport proxy.

Responsibilities:
1. Perform authenticated TCP handshake (PQC KEM + signature) using `core.handshake`.
2. Bridge plaintext UDP <-> encrypted UDP (AEAD framing) both directions.
3. Enforce replay window and per-direction sequence via `core.aead`.

Note: This module uses the low-level `selectors` stdlib facility—not `asyncio`—to
remain dependency-light and fully deterministic for test harnesses. The filename
is retained for backward compatibility; a future refactor may rename it to
`selector_proxy.py` and/or introduce an asyncio variant.
"""

from __future__ import annotations

import socket
import selectors
import threading
import time
import struct
from typing import Optional, Dict, Tuple
from contextlib import contextmanager

from core.config import CONFIG
from core.suites import SUITES, header_ids_for_suite
try:
    # Optional helper (if you implemented it)
    from core.suites import header_ids_from_names  # type: ignore
except Exception:
    header_ids_from_names = None  # type: ignore

from core.handshake import server_gcs_handshake, client_drone_handshake
from core.logging_utils import get_logger

from core.aead import (
    Sender,
    Receiver,
    HeaderMismatch,
    ReplayError,
    AeadAuthError,
    AeadIds,
)

from core.policy_engine import handle_control

logger = get_logger("pqc")


class ProxyCounters:
    """Simple counters for proxy statistics."""

    def __init__(self) -> None:
        self.ptx_out = 0      # plaintext packets sent out to app
        self.ptx_in = 0       # plaintext packets received from app
        self.enc_out = 0      # encrypted packets sent to peer
        self.enc_in = 0       # encrypted packets received from peer
        self.drops = 0        # total drops
        # Granular drop reasons
        self.drop_replay = 0
        self.drop_auth = 0
        self.drop_header = 0
        self.drop_session_epoch = 0
        self.drop_other = 0

    def to_dict(self) -> Dict[str, int]:
        return {
            "ptx_out": self.ptx_out,
            "ptx_in": self.ptx_in,
            "enc_out": self.enc_out,
            "enc_in": self.enc_in,
            "drops": self.drops,
            "drop_replay": self.drop_replay,
            "drop_auth": self.drop_auth,
            "drop_header": self.drop_header,
            "drop_session_epoch": self.drop_session_epoch,
            "drop_other": self.drop_other,
        }


def _dscp_to_tos(dscp: Optional[int]) -> Optional[int]:
    """Convert DSCP value to TOS byte for socket options."""
    if dscp is None:
        return None
    try:
        d = int(dscp)
        if 0 <= d <= 63:
            return d << 2  # DSCP occupies high 6 bits of TOS/Traffic Class
    except Exception:
        pass
    return None


def _parse_header_fields(
    expected_version: int,
    aead_ids: AeadIds,
    session_id: bytes,
    wire: bytes,
) -> Tuple[str, Optional[int]]:
    """
    Try to unpack the header and classify the most likely drop reason *without* AEAD work.
    Returns (reason, seq_if_available).
    """
    HEADER_STRUCT = "!BBBBB8sQB"
    HEADER_LEN = struct.calcsize(HEADER_STRUCT)
    if len(wire) < HEADER_LEN:
        return ("header_too_short", None)
    try:
        (version, kem_id, kem_param, sig_id, sig_param, sess, seq, epoch) = struct.unpack(
            HEADER_STRUCT, wire[:HEADER_LEN]
        )
    except struct.error:
        return ("header_unpack_error", None)
    if version != expected_version:
        return ("version_mismatch", seq)
    if (kem_id, kem_param, sig_id, sig_param) != (
        aead_ids.kem_id,
        aead_ids.kem_param,
        aead_ids.sig_id,
        aead_ids.sig_param,
    ):
        return ("crypto_id_mismatch", seq)
    if sess != session_id:
        return ("session_mismatch", seq)
    # If we got here, header matches; any decrypt failure that returns None is auth/tag failure.
    return ("auth_fail_or_replay", seq)


class _TokenBucket:
    """Per-IP rate limiter using token bucket algorithm."""
    def __init__(self, capacity: int, refill_per_sec: float) -> None:
        self.capacity = max(1, capacity)
        self.refill = max(0.01, float(refill_per_sec))
        self.tokens: Dict[str, float] = {}      # ip -> tokens
        self.last: Dict[str, float] = {}        # ip -> last timestamp

    def allow(self, ip: str) -> bool:
        """Check if request from IP should be allowed."""
        now = time.monotonic()
        t = self.tokens.get(ip, self.capacity)
        last = self.last.get(ip, now)
        # refill
        t = min(self.capacity, t + (now - last) * self.refill)
        self.last[ip] = now
        if t >= 1.0:
            t -= 1.0
            self.tokens[ip] = t
            return True
        self.tokens[ip] = t
        return False


def _validate_config(cfg: dict) -> None:
    """Validate required configuration keys are present."""
    required_keys = [
        "TCP_HANDSHAKE_PORT", "UDP_DRONE_RX", "UDP_GCS_RX",
        "DRONE_PLAINTEXT_TX", "DRONE_PLAINTEXT_RX",
        "GCS_PLAINTEXT_TX", "GCS_PLAINTEXT_RX",
        "DRONE_HOST", "GCS_HOST", "REPLAY_WINDOW",
    ]
    for key in required_keys:
        if key not in cfg:
            raise NotImplementedError(f"CONFIG missing: {key}")


def _perform_handshake(
    role: str,
    suite: dict,
    gcs_sig_secret: Optional[bytes],
    gcs_sig_public: Optional[bytes],
    cfg: dict,
    stop_after_seconds: Optional[float] = None,
    ready_event: Optional[threading.Event] = None,
) -> Tuple[bytes, bytes, bytes, bytes, bytes, Optional[str], Optional[str]]:
    """Perform TCP handshake and return derived keys, session_id, and optionally kem/sig names."""
    if role == "gcs":
        if gcs_sig_secret is None:
            raise NotImplementedError("GCS signature secret not provided")

        server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        server_sock.bind(("0.0.0.0", cfg["TCP_HANDSHAKE_PORT"]))
        server_sock.listen(32)

        if ready_event:
            ready_event.set()

        timeout = stop_after_seconds if stop_after_seconds is not None else 30.0
        server_sock.settimeout(timeout)

        gate = _TokenBucket(
            cfg.get("HANDSHAKE_RL_BURST", 5),
            cfg.get("HANDSHAKE_RL_REFILL_PER_SEC", 1),
        )

        try:
            try:
                conn, addr = server_sock.accept()
                try:
                    ip, _port = addr
                    if not gate.allow(ip):
                        try:
                            conn.settimeout(0.2)
                            conn.sendall(b"\x00")
                        except Exception:
                            pass
                        finally:
                            conn.close()
                        raise NotImplementedError("Handshake rate-limit: too many attempts")

                    result = server_gcs_handshake(conn, suite, gcs_sig_secret)
                    # Support either 5-tuple or 7-tuple
                    if len(result) >= 7:
                        k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name = result[:7]
                    else:
                        k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id = result
                        kem_name = sig_name = None
                    return k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name
                finally:
                    conn.close()
            except socket.timeout:
                raise NotImplementedError("No drone connection received within timeout")
        finally:
            server_sock.close()

    elif role == "drone":
        if gcs_sig_public is None:
            raise NotImplementedError("GCS signature public key not provided")

        client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        try:
            client_sock.connect((cfg["GCS_HOST"], cfg["TCP_HANDSHAKE_PORT"]))
            result = client_drone_handshake(client_sock, suite, gcs_sig_public)
            if len(result) >= 7:
                k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name = result[:7]
            else:
                k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id = result
                kem_name = sig_name = None
            return k_d2g, k_g2d, nseed_d2g, nseed_g2d, session_id, kem_name, sig_name
        finally:
            client_sock.close()
    else:
        raise ValueError(f"Invalid role: {role}")


@contextmanager
def _setup_sockets(role: str, cfg: dict):
    """Setup and cleanup all UDP sockets for the proxy."""
    sockets = {}
    try:
        if role == "drone":
            # Encrypted socket - receive from GCS
            enc_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            enc_sock.bind(("0.0.0.0", cfg["UDP_DRONE_RX"]))
            enc_sock.setblocking(False)
            tos = _dscp_to_tos(cfg.get("ENCRYPTED_DSCP"))
            if tos is not None:
                try:
                    enc_sock.setsockopt(socket.IPPROTO_IP, socket.IP_TOS, tos)
                except Exception:
                    pass
            sockets["encrypted"] = enc_sock

            # Plaintext ingress - receive from local app
            ptx_in_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            ptx_in_sock.bind(("127.0.0.1", cfg["DRONE_PLAINTEXT_TX"]))
            ptx_in_sock.setblocking(False)
            sockets["plaintext_in"] = ptx_in_sock

            # Plaintext egress - send to local app (no bind needed)
            ptx_out_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sockets["plaintext_out"] = ptx_out_sock

            # Peer addresses
            sockets["encrypted_peer"] = (cfg["GCS_HOST"], cfg["UDP_GCS_RX"])
            sockets["plaintext_peer"] = ("127.0.0.1", cfg["DRONE_PLAINTEXT_RX"])

        elif role == "gcs":
            # Encrypted socket - receive from Drone
            enc_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            enc_sock.bind(("0.0.0.0", cfg["UDP_GCS_RX"]))
            enc_sock.setblocking(False)
            tos = _dscp_to_tos(cfg.get("ENCRYPTED_DSCP"))
            if tos is not None:
                try:
                    enc_sock.setsockopt(socket.IPPROTO_IP, socket.IP_TOS, tos)
                except Exception:
                    pass
            sockets["encrypted"] = enc_sock

            # Plaintext ingress - receive from local app
            ptx_in_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            ptx_in_sock.bind(("127.0.0.1", cfg["GCS_PLAINTEXT_TX"]))
            ptx_in_sock.setblocking(False)
            sockets["plaintext_in"] = ptx_in_sock

            # Plaintext egress - send to local app (no bind needed)
            ptx_out_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sockets["plaintext_out"] = ptx_out_sock

            # Peer addresses
            sockets["encrypted_peer"] = (cfg["DRONE_HOST"], cfg["UDP_DRONE_RX"])
            sockets["plaintext_peer"] = ("127.0.0.1", cfg["GCS_PLAINTEXT_RX"])
        else:
            raise ValueError(f"Invalid role: {role}")

        yield sockets
    finally:
        for sock in list(sockets.values()):
            if isinstance(sock, socket.socket):
                try:
                    sock.close()
                except Exception:
                    pass


def run_proxy(
    *,
    role: str,
    suite: dict,
    cfg: dict,
    gcs_sig_secret: Optional[bytes] = None,
    gcs_sig_public: Optional[bytes] = None,
    stop_after_seconds: Optional[float] = None,
    ready_event: Optional[threading.Event] = None,
) -> Dict[str, int]:
    """
    Start a blocking proxy process for `role` in {"drone","gcs"}.

    - Performs TCP handshake (server on GCS, client on Drone).
    - Bridges plaintext UDP <-> encrypted UDP in both directions.
    - Returns a dict of simple counters on clean exit:
      {"ptx_out": int, "ptx_in": int, "enc_out": int, "enc_in": int, "drops": int}
    """
    if role not in {"drone", "gcs"}:
        raise ValueError(f"Invalid role: {role}")

    _validate_config(cfg)

    counters = ProxyCounters()
    start_time = time.time()

    # Perform handshake and get session keys (+ optional kem/sig names)
    k_d2g, k_g2d, _nseed_d2g, _nseed_g2d, session_id, kem_name, sig_name = _perform_handshake(
        role, suite, gcs_sig_secret, gcs_sig_public, cfg, stop_after_seconds, ready_event
    )

    # Log successful handshake
    try:
        suite_id = next((sid for sid, s in SUITES.items() if dict(s) == suite), "unknown")
    except Exception:
        suite_id = "unknown"
    logger.info(
        "PQC handshake completed successfully",
        extra={"suite_id": suite_id, "peer_role": ("drone" if role == "gcs" else "gcs"), "session_id": session_id.hex()},
    )

    # Setup AEAD header IDs
    if kem_name and sig_name and header_ids_from_names:
        ids_tuple = header_ids_from_names(kem_name, sig_name)  # type: ignore
    else:
        ids_tuple = header_ids_for_suite(suite)
    aead_ids = AeadIds(*ids_tuple)

    # Role-based key directions
    if role == "drone":
        sender = Sender(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, k_d2g)
        receiver = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, k_g2d, cfg["REPLAY_WINDOW"])
    else:  # gcs
        sender = Sender(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, k_g2d)
        receiver = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, k_d2g, cfg["REPLAY_WINDOW"])

    # UDP bridge loop
    with _setup_sockets(role, cfg) as sockets:
        selector = selectors.DefaultSelector()
        selector.register(sockets["encrypted"], selectors.EVENT_READ, data="encrypted")
        selector.register(sockets["plaintext_in"], selectors.EVENT_READ, data="plaintext_in")

        try:
            while True:
                if stop_after_seconds is not None and (time.time() - start_time) >= stop_after_seconds:
                    break

                events = selector.select(timeout=0.1)
                for key, _mask in events:
                    sock = key.fileobj
                    data_type = key.data

                    if data_type == "plaintext_in":
                        # Plaintext ingress: encrypt and forward
                        try:
                            payload, _addr = sock.recvfrom(2048)
                            if not payload:
                                continue
                            counters.ptx_in += 1

                            payload_out = (b"\x01" + payload) if cfg.get("ENABLE_PACKET_TYPE") else payload
                            wire = sender.encrypt(payload_out)

                            try:
                                sockets["encrypted"].sendto(wire, sockets["encrypted_peer"])
                                counters.enc_out += 1
                            except socket.error:
                                counters.drops += 1
                        except socket.error:
                            continue

                    elif data_type == "encrypted":
                        try:
                            wire, _addr = sock.recvfrom(2048)
                            if not wire:
                                continue
                            counters.enc_in += 1

                            try:
                                plaintext = receiver.decrypt(wire)
                                if plaintext is None:
                                    reason, _seq = _parse_header_fields(
                                        CONFIG["WIRE_VERSION"], receiver.ids, receiver.session_id, wire
                                    )
                                    counters.drops += 1
                                    if reason in ("version_mismatch", "crypto_id_mismatch", "header_too_short", "header_unpack_error"):
                                        counters.drop_header += 1
                                    elif reason == "session_mismatch":
                                        counters.drop_session_epoch += 1
                                    else:
                                        counters.drop_auth += 1
                                    continue
                            except ReplayError:
                                counters.drops += 1
                                counters.drop_replay += 1
                                continue
                            except HeaderMismatch:
                                counters.drops += 1
                                counters.drop_header += 1
                                continue
                            except AeadAuthError:
                                counters.drops += 1
                                counters.drop_auth += 1
                                continue
                            except Exception:
                                counters.drops += 1
                                counters.drop_other += 1
                                continue

                            try:
                                out_bytes = plaintext
                                if cfg.get("ENABLE_PACKET_TYPE") and plaintext:
                                    ptype = plaintext[0]
                                    if ptype == 0x01:
                                        out_bytes = plaintext[1:]  # deliver to app
                                    elif ptype == 0x02:
                                        _ = handle_control(plaintext[1:])
                                        continue
                                    else:
                                        counters.drops += 1
                                        counters.drop_other += 1
                                        continue

                                sockets["plaintext_out"].sendto(out_bytes, sockets["plaintext_peer"])
                                counters.ptx_out += 1
                            except socket.error:
                                counters.drops += 1
                                counters.drop_other += 1
                        except socket.error:
                            continue
        except KeyboardInterrupt:
            pass
        finally:
            selector.close()

    return counters.to_dict()

============================================================

FILE 13/58: ddos\features.py
============================================================
Full Path: C:\Users\burak\Desktop\research\ddos\features.py
Size: 107 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def extract_features(pkt_batch):
    raise NotImplementedError("DDoS pipeline is out of scope right now.")

============================================================

FILE 14/58: ddos\mitigations.py
============================================================
Full Path: C:\Users\burak\Desktop\research\ddos\mitigations.py
Size: 112 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def apply(action):
    raise NotImplementedError("DDoS mitigations controlled by RL/ops; not implemented yet.")

============================================================

FILE 15/58: ddos\tst_stage2.py
============================================================
Full Path: C:\Users\burak\Desktop\research\ddos\tst_stage2.py
Size: 104 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def confirm(features):
    raise NotImplementedError("DDoS stage-2 TST not implemented in this phase.")

============================================================

FILE 16/58: ddos\xgb_stage1.py
============================================================
Full Path: C:\Users\burak\Desktop\research\ddos\xgb_stage1.py
Size: 106 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def score(features):
    raise NotImplementedError("DDoS stage-1 XGBoost not implemented in this phase.")

============================================================

FILE 17/58: diagnose_aead.py
============================================================
Full Path: C:\Users\burak\Desktop\research\diagnose_aead.py
Size: 620 bytes
Modified: 2025-09-25 19:07:57
------------------------------------------------------------
from core.suites import get_suite, header_ids_for_suite
from core.aead import Sender, Receiver, AeadIds
from diagnose_handshake import keys  # reuse from handshake script
from core.config import CONFIG

suite = get_suite("cs-kyber768-aesgcm-dilithium3")
ids = AeadIds(*header_ids_for_suite(suite))

session_id = b'ABCDEFGH'

sender = Sender(CONFIG["WIRE_VERSION"], ids, session_id, 0, keys['client_send'])
receiver = Receiver(CONFIG["WIRE_VERSION"], ids, session_id, 0, keys['server_recv'], CONFIG['REPLAY_WINDOW'])

wire = sender.encrypt(b"hello")
plain = receiver.decrypt(wire)
print("decrypt", plain)

============================================================

FILE 18/58: diagnose_handshake.py
============================================================
Full Path: C:\Users\burak\Desktop\research\diagnose_handshake.py
Size: 1,566 bytes
Modified: 2025-09-25 19:07:57
------------------------------------------------------------
import threading
import socket
from core.suites import get_suite
from core.handshake import server_gcs_handshake, client_drone_handshake
from oqs.oqs import Signature
from core.config import CONFIG

suite = get_suite("cs-kyber768-aesgcm-dilithium3")

keys = {}
errors = {}

ready = threading.Event()

def server_thread():
    sig = Signature(suite["sig_name"])
    pub = sig.generate_keypair()
    keys['pub'] = pub
    srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    srv.bind(('127.0.0.1', CONFIG['TCP_HANDSHAKE_PORT']))
    srv.listen(1)
    ready.set()
    conn, addr = srv.accept()
    with conn:
        k_recv, k_send, *_ = server_gcs_handshake(conn, suite, sig)
        keys['server_recv'] = k_recv
        keys['server_send'] = k_send
    srv.close()


def client_thread():
    if not ready.wait(timeout=3):
        errors['client'] = 'timeout'
        return
    pub = keys['pub']
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect(('127.0.0.1', CONFIG['TCP_HANDSHAKE_PORT']))
    k_send, k_recv, *_ = client_drone_handshake(sock, suite, pub)
    keys['client_send'] = k_send
    keys['client_recv'] = k_recv
    sock.close()

threads = [threading.Thread(target=server_thread), threading.Thread(target=client_thread)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print('errors', errors)
for name, value in keys.items():
    if isinstance(value, bytes):
        print(name, len(value), value[:8].hex())
    else:
        print(name, type(value))

============================================================

FILE 19/58: drone\scripts\env_check.py
============================================================
Full Path: C:\Users\burak\Desktop\research\drone\scripts\env_check.py
Size: 396 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
import sys
status = {}
try:
    import cryptography
    status["cryptography"] = cryptography.__version__
except Exception as e:
    status["cryptography"] = f"ERROR: {e}"
try:
    import oqs.oqs as oqs
    status["oqs-python"] = oqs.oqs_version()
except Exception as e:
    status["oqs-python"] = f"ERROR: {e}"
print(status); sys.exit(0 if all("ERROR" not in v for v in status.values()) else 1)

============================================================

FILE 20/58: gcs\scripts\env_check.py
============================================================
Full Path: C:\Users\burak\Desktop\research\gcs\scripts\env_check.py
Size: 396 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
import sys
status = {}
try:
    import cryptography
    status["cryptography"] = cryptography.__version__
except Exception as e:
    status["cryptography"] = f"ERROR: {e}"
try:
    import oqs.oqs as oqs
    status["oqs-python"] = oqs.oqs_version()
except Exception as e:
    status["oqs-python"] = f"ERROR: {e}"
print(status); sys.exit(0 if all("ERROR" not in v for v in status.values()) else 1)

============================================================

FILE 21/58: log_project_structure.py
============================================================
Full Path: C:\Users\burak\Desktop\research\log_project_structure.py
Size: 8,868 bytes
Modified: 2025-09-27 01:23:04
------------------------------------------------------------
#!/usr/bin/env python3
"""
Directory Tree and Python File Content Logger

This script creates a comprehensive log of:
1. Complete directory tree structure (like 'tree /f' command)
2. Contents of all Python (.py) files found recursively
3. Saves everything to a single .txt file

Usage:
    python log_project_structure.py [root_directory] [output_file]
    
Example:
    python log_project_structure.py . project_structure.txt
    python log_project_structure.py C:/Users/burak/Desktop/research research_complete.txt
"""

import os
import sys
import argparse
from pathlib import Path
from datetime import datetime

def log_directory_tree(root_path, output_file, skip_dirs: set | None = None):
    """Log the complete directory tree structure."""
    output_file.write("="*80 + "\n")
    output_file.write("DIRECTORY TREE STRUCTURE\n")
    output_file.write("="*80 + "\n")
    output_file.write(f"Root Directory: {root_path}\n")
    output_file.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    if skip_dirs is None:
        skip_dirs = set()

    def write_tree(path, prefix="", is_last=True):
        """Recursively write tree structure."""
        try:
            items = sorted(path.iterdir())
            folders = [item for item in items if item.is_dir() and not item.name.startswith('.') and item.name not in skip_dirs]
            files = [item for item in items if item.is_file() and not item.name.startswith('.')]
            
            # Write folders first
            for i, folder in enumerate(folders):
                is_last_folder = (i == len(folders) - 1) and len(files) == 0
                connector = "└── " if is_last_folder else "├── "
                output_file.write(f"{prefix}{connector}{folder.name}/\n")
                
                extension = "    " if is_last_folder else "│   "
                write_tree(folder, prefix + extension, is_last_folder)
            
            # Write files
            for i, file in enumerate(files):
                is_last_file = (i == len(files) - 1)
                connector = "└── " if is_last_file else "├── "
                file_size = file.stat().st_size if file.exists() else 0
                output_file.write(f"{prefix}{connector}{file.name} ({file_size:,} bytes)\n")
                
        except PermissionError:
            output_file.write(f"{prefix}├── [Permission Denied]\n")
        except Exception as e:
            output_file.write(f"{prefix}├── [Error: {e}]\n")
    
    write_tree(Path(root_path))
    output_file.write("\n\n")

def log_python_files(root_path, output_file):
    """Log contents of all Python files found recursively."""
    output_file.write("="*80 + "\n")
    output_file.write("PYTHON FILE CONTENTS\n")
    output_file.write("="*80 + "\n\n")
    
    python_files = []
    
    # Find all Python files
    for root, dirs, files in os.walk(root_path):
        # Skip hidden directories
        # The caller may pass a set of directory NAMES to skip (e.g. 'tests')
        dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__' and d not in SKIP_DIRS]
        
        for file in files:
            if file.endswith('.py') and not file.startswith('.'):
                python_files.append(os.path.join(root, file))
    
    python_files.sort()  # Sort for consistent output
    
    if not python_files:
        output_file.write("No Python files found.\n\n")
        return
    
    output_file.write(f"Found {len(python_files)} Python files:\n")
    for i, py_file in enumerate(python_files, 1):
        rel_path = os.path.relpath(py_file, root_path)
        output_file.write(f"  {i:2d}. {rel_path}\n")
    output_file.write("\n" + "-"*80 + "\n\n")
    
    # Log contents of each Python file
    for i, py_file in enumerate(python_files, 1):
        rel_path = os.path.relpath(py_file, root_path)
        
        output_file.write(f"FILE {i}/{len(python_files)}: {rel_path}\n")
        output_file.write("="*60 + "\n")
        output_file.write(f"Full Path: {py_file}\n")
        
        try:
            file_stat = os.stat(py_file)
            file_size = file_stat.st_size
            mod_time = datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            output_file.write(f"Size: {file_size:,} bytes\n")
            output_file.write(f"Modified: {mod_time}\n")
        except Exception as e:
            output_file.write(f"Error getting file stats: {e}\n")
        
        output_file.write("-"*60 + "\n")
        
        try:
            with open(py_file, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
                if content.strip():
                    output_file.write(content)
                    if not content.endswith('\n'):
                        output_file.write('\n')
                else:
                    output_file.write("[Empty file]\n")
        except Exception as e:
            output_file.write(f"[Error reading file: {e}]\n")
        
        output_file.write("\n" + "="*60 + "\n\n")

def main():
    """Main function."""
    # Parse command line arguments
    parser = argparse.ArgumentParser(
        description="Log directory tree and all Python files. Optionally skip named folders (by name) e.g. 'tests,benchmarks'."
    )
    parser.add_argument("root", nargs="?", default=".", help="Root directory to analyze")
    parser.add_argument("output", nargs="?", help="Output filename (optional)")
    parser.add_argument(
        "-s",
        "--skip",
        action="append",
        help=("Folder name to skip. Can be used multiple times or as a comma-separated list. "
              "Example: -s tests -s docs or -s tests,docs"),
    )

    args = parser.parse_args()

    root_directory = args.root
    if args.output:
        output_filename = args.output
    else:
        output_filename = f"project_structure_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

    # Build skip set (normalize to simple folder names)
    skip_dirs = set()
    if args.skip:
        for entry in args.skip:
            if not entry:
                continue
            for part in entry.split(','):
                name = part.strip()
                if not name:
                    continue
                # normalize possible paths to just the final component
                try:
                    pname = Path(name).name
                except Exception:
                    pname = name
                skip_dirs.add(pname)

    # Never allow skipping the required 'core' directory; remove it if present and warn
    if 'core' in skip_dirs:
        print("Note: 'core' is required and cannot be skipped; ignoring 'core' in --skip list.")
        skip_dirs.discard('core')

    # Make skip set available to module-level walker via global used below
    global SKIP_DIRS
    SKIP_DIRS = skip_dirs

    if SKIP_DIRS:
        print(f"Skipping directories by name: {', '.join(sorted(SKIP_DIRS))}")
    
    # Resolve paths
    root_path = Path(root_directory).resolve()
    output_path = Path(output_filename).resolve()
    
    if not root_path.exists():
        print(f"Error: Root directory '{root_path}' does not exist!")
        sys.exit(1)
    
    if not root_path.is_dir():
        print(f"Error: '{root_path}' is not a directory!")
        sys.exit(1)
    
    print(f"Analyzing directory: {root_path}")
    print(f"Output file: {output_path}")
    print("Processing...")
    
    try:
        with open(output_path, 'w', encoding='utf-8') as output_file:
            # Write header
            output_file.write("PROJECT STRUCTURE AND PYTHON FILES LOG\n")
            output_file.write("="*80 + "\n")
            output_file.write(f"Root Directory: {root_path}\n")
            output_file.write(f"Output File: {output_path}\n")
            output_file.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            output_file.write("="*80 + "\n\n")
            
            # Log directory tree
            log_directory_tree(root_path, output_file)
            
            # Log Python file contents
            log_python_files(root_path, output_file)
            
            # Write footer
            output_file.write("="*80 + "\n")
            output_file.write("END OF LOG\n")
            output_file.write("="*80 + "\n")
    
    except Exception as e:
        print(f"Error writing to output file: {e}")
        sys.exit(1)
    
    print(f"✅ Successfully created: {output_path}")
    print(f"📁 Log contains directory tree + all Python file contents")

if __name__ == "__main__":
    main()

============================================================

FILE 22/58: rl\agent_runtime.py
============================================================
Full Path: C:\Users\burak\Desktop\research\rl\agent_runtime.py
Size: 117 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def main(): raise NotImplementedError("RL runtime not implemented in this phase.")
if __name__ == "__main__": main()

============================================================

FILE 23/58: rl\linucb.py
============================================================
Full Path: C:\Users\burak\Desktop\research\rl\linucb.py
Size: 107 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
class LinUCB:
    def __init__(self, *_, **__): raise NotImplementedError("RL is out of scope right now.")

============================================================

FILE 24/58: rl\safety.py
============================================================
Full Path: C:\Users\burak\Desktop\research\rl\safety.py
Size: 105 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
def guard(action, mission): raise NotImplementedError("RL safety shield not implemented in this phase.")

============================================================

FILE 25/58: scripts\orchestrate_e2e.py
============================================================
Full Path: C:\Users\burak\Desktop\research\scripts\orchestrate_e2e.py
Size: 19,886 bytes
Modified: 2025-09-26 18:45:58
------------------------------------------------------------
#!/usr/bin/env python3
"""Automated two-host harness for PQC drone↔GCS proxy validation.

This script orchestrates a local GCS proxy and a remote drone proxy using SSH.
It drives traffic on both plaintext interfaces, triggers an in-band rekey, and
collects artefacts (counters, logs, and traffic summaries) for post-run
analysis. The helper is intended for repeatable LAN tests between a Windows
GCS host and a Linux-based drone (e.g., Raspberry Pi).
"""
from __future__ import annotations

import argparse
import datetime as _dt
import json
import os
import sys
import posixpath
import shlex
import subprocess
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional

import paramiko

from tools.counter_utils import (
    ProxyCounters,
    TrafficSummary,
    load_proxy_counters,
    load_traffic_summary,
)


HANDSHAKE_PATTERN = "PQC handshake completed successfully"
REKEY_OK_PATTERN = "Control rekey successful"
REKEY_FAIL_MARKERS = ("Control rekey failed", "prepare_fail", "rekeys_fail")


@dataclass
class StreamRelay:
    """Background copier that streams text from a process to a log file."""

    stream: Iterable[str]
    log_path: Path
    patterns: Dict[str, threading.Event]
    failure_hook: Optional[callable]
    thread: threading.Thread

    @classmethod
    def start(
        cls,
        stream: Iterable[str],
        log_path: Path,
        *,
        patterns: Optional[Dict[str, threading.Event]] = None,
        failure_hook: Optional[callable] = None,
    ) -> "StreamRelay":
        log_path.parent.mkdir(parents=True, exist_ok=True)
        relay = cls(stream, log_path, patterns or {}, failure_hook, threading.Thread())
        relay.thread = threading.Thread(target=relay._pump, name=f"relay-{log_path.name}", daemon=True)
        relay.thread.start()
        return relay

    def _pump(self) -> None:
        with open(self.log_path, "w", encoding="utf-8") as sink:
            for raw in iter(self.stream.readline, ""):
                if isinstance(raw, bytes):  # pragma: no cover - defensive
                    raw = raw.decode("utf-8", "replace")
                if not raw:
                    break
                sink.write(raw)
                sink.flush()
                line = raw.rstrip("\r\n")
                for pattern, event in self.patterns.items():
                    if pattern in line:
                        event.set()
                if self.failure_hook:
                    self.failure_hook(line)


@dataclass
class LocalProcess:
    proc: subprocess.Popen[str]
    stdout: StreamRelay
    stderr: StreamRelay

    def terminate(self) -> None:
        if self.proc.poll() is None:
            self.proc.terminate()
            try:
                self.proc.wait(timeout=10)
            except subprocess.TimeoutExpired:
                self.proc.kill()


@dataclass
class RemoteProcess:
    command: str
    channel: paramiko.Channel
    stdin: paramiko.ChannelFile
    stdout_relay: StreamRelay
    stderr_relay: StreamRelay

    def close(self) -> None:
        if not self.channel.closed:
            try:
                self.channel.close()
            except Exception:  # pragma: no cover - best effort
                pass


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Two-host PQC proxy orchestrator")
    parser.add_argument("--suite", required=True, help="Initial suite identifier (e.g. cs-kyber768-aesgcm-dilithium3)")
    parser.add_argument("--rekey-suite", required=True, help="Suite identifier to switch to during the run")
    parser.add_argument("--remote-host", required=True, help="Drone host/IP reachable via SSH")
    parser.add_argument("--remote-user", required=True, help="SSH username for the drone host")
    parser.add_argument("--ssh-key", help="Path to SSH private key for the drone host")
    parser.add_argument("--ssh-password", help="SSH password (discouraged; key auth preferred)")
    parser.add_argument("--remote-root", default="~/research", help="Remote repository root containing this project")
    parser.add_argument("--remote-python", default="python", help="Python executable on the drone host")
    default_local_python = Path(os.environ.get("PYTHON_EXECUTABLE", sys.executable)).resolve()
    parser.add_argument(
        "--local-python",
        default=str(default_local_python),
        help="Python executable on the GCS host",
    )
    parser.add_argument("--artifact-dir", default="artifacts/harness", help="Local directory for collected artefacts")
    parser.add_argument("--remote-artifact-dir", default="artifacts/harness", help="Remote directory (within repo) for run artefacts")
    parser.add_argument("--label", help="Optional label appended to the run identifier")

    parser.add_argument("--traffic-count", type=int, default=400, help="Packets to send from each traffic generator")
    parser.add_argument("--traffic-rate", type=float, default=40.0, help="Packets per second for traffic generators")
    parser.add_argument("--traffic-duration", type=float, default=40.0, help="Duration (seconds) cap for traffic generators")

    parser.add_argument("--stop-seconds", type=float, default=90.0, help="Auto-stop duration supplied to each proxy")
    parser.add_argument("--handshake-timeout", type=float, default=30.0, help="Timeout for initial handshake detection")
    parser.add_argument("--rekey-delay", type=float, default=15.0, help="Delay (seconds) before requesting rekey once traffic is flowing")
    parser.add_argument("--rekey-timeout", type=float, default=60.0, help="Timeout waiting for successful rekey events")
    parser.add_argument("--post-rekey-wait", type=float, default=10.0, help="Additional wait after rekey before teardown")

    return parser.parse_args()


def build_run_id(base_suite: str, label: Optional[str]) -> str:
    stamp = _dt.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    suite_token = base_suite.replace("-", "_")
    if label:
        label_clean = "".join(ch for ch in label if ch.isalnum() or ch in ("_", "-"))
        return f"{stamp}_{suite_token}_{label_clean}"
    return f"{stamp}_{suite_token}"


def wait_event(event: threading.Event, timeout: float, description: str) -> None:
    if not event.wait(timeout):
        raise TimeoutError(f"Timed out waiting for {description}")


def make_failure_hook(errors: List[str], label: str):
    def _hook(line: str) -> None:
        lower = line.lower()
        if any(marker in lower for marker in REKEY_FAIL_MARKERS):
            errors.append(f"{label}: {line}")
    return _hook


def resolve_remote_root(client: paramiko.SSHClient, remote_root: str) -> str:
    cmd = f"cd {shlex.quote(remote_root)} && pwd"
    _stdin, stdout, stderr = client.exec_command(cmd)
    resolved = stdout.read().decode("utf-8", "ignore").strip()
    err = stderr.read().decode("utf-8", "ignore").strip()
    if not resolved:
        raise RuntimeError(f"Failed to resolve remote root: {err or 'unknown error'}")
    return resolved


def start_remote_process(
    client: paramiko.SSHClient,
    command: str,
    stdout_log: Path,
    stderr_log: Path,
    *,
    patterns: Optional[Dict[str, threading.Event]] = None,
    failure_hook=None,
) -> RemoteProcess:
    stdin, stdout, stderr = client.exec_command(command, get_pty=False)
    stdout_file = stdout.channel.makefile("r", encoding="utf-8", errors="replace")
    stderr_file = stderr.channel.makefile("r", encoding="utf-8", errors="replace")

    stdout_relay = StreamRelay.start(stdout_file, stdout_log, patterns=patterns, failure_hook=failure_hook)
    stderr_relay = StreamRelay.start(stderr_file, stderr_log, patterns=patterns, failure_hook=failure_hook)

    return RemoteProcess(command, stdout.channel, stdin, stdout_relay, stderr_relay)


def wait_remote(process: RemoteProcess, timeout: float) -> int:
    deadline = time.time() + timeout
    while not process.channel.exit_status_ready():
        if time.time() > deadline:
            raise TimeoutError(f"Remote command timed out: {process.command}")
        time.sleep(1)
    return process.channel.recv_exit_status()


def start_local_process(
    cmd: List[str],
    *,
    env: Dict[str, str],
    stdout_log: Path,
    stderr_log: Path,
    patterns: Optional[Dict[str, threading.Event]] = None,
    failure_hook=None,
) -> LocalProcess:
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1,
        env=env,
    )
    if proc.stdout is None or proc.stderr is None:
        raise RuntimeError("Failed to capture local process pipes")

    stdout_relay = StreamRelay.start(proc.stdout, stdout_log, patterns=patterns, failure_hook=failure_hook)
    stderr_relay = StreamRelay.start(proc.stderr, stderr_log, patterns=patterns, failure_hook=failure_hook)

    return LocalProcess(proc=proc, stdout=stdout_relay, stderr=stderr_relay)


def send_rekey_command(local_proxy: LocalProcess, suite_id: str) -> None:
    if local_proxy.proc.stdin is None:
        raise RuntimeError("Local proxy stdin not available for rekey command")
    local_proxy.proc.stdin.write(f"{suite_id}\n")
    local_proxy.proc.stdin.flush()


def download_file(sftp: paramiko.SFTPClient, remote_path: str, local_path: Path) -> None:
    local_path.parent.mkdir(parents=True, exist_ok=True)
    sftp.get(remote_path, str(local_path))


def summarize_run(
    run_dir: Path,
    run_id: str,
    suite_initial: str,
    suite_rekey: str,
    gcs_proxy_json: Path,
    drone_proxy_json: Path,
    gcs_traffic_summary: Path,
    drone_traffic_summary: Path,
    errors: List[str],
) -> Dict[str, object]:
    gcs_counters = load_proxy_counters(gcs_proxy_json)
    drone_counters = load_proxy_counters(drone_proxy_json)
    gcs_counters.ensure_rekey(suite_rekey)
    drone_counters.ensure_rekey(suite_rekey)

    gcs_traffic = load_traffic_summary(gcs_traffic_summary)
    drone_traffic = load_traffic_summary(drone_traffic_summary)

    summary = {
        "run_id": run_id,
        "timestamp_utc": _dt.datetime.utcnow().isoformat() + "Z",
        "suite_initial": suite_initial,
        "suite_rekey": suite_rekey,
        "artifacts": {
            "root": str(run_dir.resolve()),
            "gcs_proxy": str(gcs_proxy_json.resolve()),
            "drone_proxy": str(drone_proxy_json.resolve()),
            "gcs_traffic": str(gcs_traffic_summary.resolve()),
            "drone_traffic": str(drone_traffic_summary.resolve()),
        },
        "gcs": {
            "role": gcs_counters.role,
            "suite": gcs_counters.suite,
            "counters": gcs_counters.counters,
        },
        "drone": {
            "role": drone_counters.role,
            "suite": drone_counters.suite,
            "counters": drone_counters.counters,
        },
        "traffic": {
            "gcs": {
                "sent_total": gcs_traffic.sent_total,
                "recv_total": gcs_traffic.recv_total,
                "tx_bytes_total": gcs_traffic.tx_bytes_total,
                "rx_bytes_total": gcs_traffic.rx_bytes_total,
            },
            "drone": {
                "sent_total": drone_traffic.sent_total,
                "recv_total": drone_traffic.recv_total,
                "tx_bytes_total": drone_traffic.tx_bytes_total,
                "rx_bytes_total": drone_traffic.rx_bytes_total,
            },
        },
        "errors": errors,
    }
    summary_path = run_dir / "summary.json"
    summary_path.write_text(json.dumps(summary, indent=2), encoding="utf-8")
    return summary


def main() -> None:
    args = parse_args()
    run_id = build_run_id(args.suite, args.label)

    run_dir = Path(args.artifact_dir).expanduser().resolve() / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    gcs_proxy_json = run_dir / "gcs_proxy.json"
    drone_proxy_json = run_dir / "drone_proxy.json"
    gcs_traffic_out = run_dir / "gcs_traffic.jsonl"
    drone_traffic_out = run_dir / "drone_traffic.jsonl"
    gcs_traffic_summary = run_dir / "gcs_traffic_summary.json"
    drone_traffic_summary = run_dir / "drone_traffic_summary.json"

    logs_dir = run_dir / "logs"
    gcs_stdout_log = logs_dir / "gcs_proxy_stdout.log"
    gcs_stderr_log = logs_dir / "gcs_proxy_stderr.log"
    drone_stdout_log = logs_dir / "drone_proxy_stdout.log"
    drone_stderr_log = logs_dir / "drone_proxy_stderr.log"
    gcs_traffic_stdout = logs_dir / "gcs_traffic_stdout.log"
    gcs_traffic_stderr = logs_dir / "gcs_traffic_stderr.log"
    drone_traffic_stdout = logs_dir / "drone_traffic_stdout.log"
    drone_traffic_stderr = logs_dir / "drone_traffic_stderr.log"

    errors: List[str] = []

    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    client.connect(
        args.remote_host,
        username=args.remote_user,
        key_filename=args.ssh_key,
        password=args.ssh_password,
        look_for_keys=args.ssh_key is None,
    )

    remote_root_abs = resolve_remote_root(client, args.remote_root)
    remote_run_rel = posixpath.join(args.remote_artifact_dir.rstrip("/"), run_id)
    remote_run_abs = posixpath.join(remote_root_abs, remote_run_rel)

    mkdir_cmd = f"cd {shlex.quote(args.remote_root)} && mkdir -p {shlex.quote(remote_run_rel)}"
    client.exec_command(mkdir_cmd)

    handshake_gcs = threading.Event()
    handshake_drone = threading.Event()
    rekey_gcs = threading.Event()
    rekey_drone = threading.Event()

    failure_hook_gcs = make_failure_hook(errors, "gcs")
    failure_hook_drone = make_failure_hook(errors, "drone")

    # Start remote drone proxy
    remote_env = "ENABLE_PACKET_TYPE=1 PYTHONUNBUFFERED=1"
    remote_proxy_json_rel = posixpath.join(remote_run_rel, "drone_proxy.json")
    remote_proxy_cmd = (
        f"cd {shlex.quote(args.remote_root)} && {remote_env} {shlex.quote(args.remote_python)} -m core.run_proxy "
        f"drone --suite {shlex.quote(args.suite)} --stop-seconds {args.stop_seconds} "
        f"--json-out {shlex.quote(remote_proxy_json_rel)}"
    )
    drone_process = start_remote_process(
        client,
        remote_proxy_cmd,
        drone_stdout_log,
        drone_stderr_log,
        patterns={HANDSHAKE_PATTERN: handshake_drone, REKEY_OK_PATTERN: rekey_drone},
        failure_hook=failure_hook_drone,
    )

    # Start local GCS proxy with manual control enabled
    local_env = os.environ.copy()
    local_env["ENABLE_PACKET_TYPE"] = "1"
    local_env.setdefault("PYTHONUNBUFFERED", "1")

    gcs_cmd = [
        args.local_python,
        "-m",
        "core.run_proxy",
        "gcs",
        "--suite",
        args.suite,
        "--stop-seconds",
        str(args.stop_seconds),
        "--json-out",
        str(gcs_proxy_json),
        "--control-manual",
    ]
    gcs_process = start_local_process(
        gcs_cmd,
        env=local_env,
        stdout_log=gcs_stdout_log,
        stderr_log=gcs_stderr_log,
        patterns={HANDSHAKE_PATTERN: handshake_gcs, REKEY_OK_PATTERN: rekey_gcs},
        failure_hook=failure_hook_gcs,
    )

    drone_traffic: Optional[RemoteProcess] = None
    gcs_traffic: Optional[LocalProcess] = None

    try:
        wait_event(handshake_gcs, args.handshake_timeout, "GCS handshake")
        wait_event(handshake_drone, args.handshake_timeout, "drone handshake")

        # Launch traffic generators
        remote_traffic_summary_rel = posixpath.join(remote_run_rel, "drone_traffic_summary.json")
        remote_traffic_out_rel = posixpath.join(remote_run_rel, "drone_traffic.jsonl")
        remote_traffic_cmd = (
            f"cd {shlex.quote(args.remote_root)} && {remote_env} {shlex.quote(args.remote_python)} tools/traffic_drone.py "
            f"--count {args.traffic_count} --rate {args.traffic_rate} --duration {args.traffic_duration} "
            f"--out {shlex.quote(remote_traffic_out_rel)} --summary {shlex.quote(remote_traffic_summary_rel)}"
        )
        drone_traffic = start_remote_process(
            client,
            remote_traffic_cmd,
            drone_traffic_stdout,
            drone_traffic_stderr,
            failure_hook=failure_hook_drone,
        )

        gcs_traffic_cmd = [
            args.local_python,
            "tools/traffic_gcs.py",
            "--count",
            str(args.traffic_count),
            "--rate",
            str(args.traffic_rate),
            "--duration",
            str(args.traffic_duration),
            "--out",
            str(gcs_traffic_out),
            "--summary",
            str(gcs_traffic_summary),
        ]
        gcs_traffic = start_local_process(
            gcs_traffic_cmd,
            env=local_env,
            stdout_log=gcs_traffic_stdout,
            stderr_log=gcs_traffic_stderr,
            failure_hook=failure_hook_gcs,
        )

        time.sleep(max(0.0, args.rekey_delay))
        send_rekey_command(gcs_process, args.rekey_suite)

        wait_event(rekey_gcs, args.rekey_timeout, "GCS rekey completion")
        wait_event(rekey_drone, args.rekey_timeout, "drone rekey completion")

        time.sleep(max(0.0, args.post_rekey_wait))

        # Wait for traffic to complete (they exit once duration reached)
        if gcs_traffic is not None:
            gcs_traffic.proc.wait(timeout=args.traffic_duration + 20)
        if drone_traffic is not None:
            wait_remote(drone_traffic, args.traffic_duration + 20)

        # Wait for proxies to exit after stop-seconds window
        gcs_process.proc.wait(timeout=args.stop_seconds + 30)
        wait_remote(drone_process, args.stop_seconds + 30)

    finally:
        # Cleanup
        gcs_process.terminate()
        drone_process.close()
        # ensure traffic processes stopped
        if gcs_traffic is not None:
            try:
                gcs_traffic.terminate()
            except Exception:
                pass
        if drone_traffic is not None:
            try:
                drone_traffic.close()
            except Exception:
                pass

    # Download remote artefacts
    with client.open_sftp() as sftp:
        download_file(sftp, posixpath.join(remote_root_abs, remote_proxy_json_rel), drone_proxy_json)
        download_file(sftp, posixpath.join(remote_root_abs, remote_traffic_summary_rel), drone_traffic_summary)
        download_file(sftp, posixpath.join(remote_root_abs, remote_traffic_out_rel), drone_traffic_out)

    client.close()

    summary = summarize_run(
        run_dir,
        run_id,
        args.suite,
        args.rekey_suite,
        gcs_proxy_json,
        drone_proxy_json,
        gcs_traffic_summary,
        drone_traffic_summary,
        errors,
    )

    summary_txt = run_dir / "summary.txt"
    summary_txt.write_text(
        "Run ID: {run_id}\nInitial suite: {suite}\nRekey suite: {rekey}\nGCS rekeys_ok: {gcs_ok}\n"
        "Drone rekeys_ok: {drone_ok}\nArtefacts: {root}\n".format(
            run_id=run_id,
            suite=args.suite,
            rekey=args.rekey_suite,
            gcs_ok=summary["gcs"]["counters"].get("rekeys_ok"),
            drone_ok=summary["drone"]["counters"].get("rekeys_ok"),
            root=summary["artifacts"]["root"],
        ),
        encoding="utf-8",
    )

    print(json.dumps(summary, indent=2))


if __name__ == "__main__":
    main()

============================================================

FILE 26/58: strict_mode_demo.py
============================================================
Full Path: C:\Users\burak\Desktop\research\strict_mode_demo.py
Size: 3,479 bytes
Modified: 2025-09-24 23:15:02
------------------------------------------------------------
#!/usr/bin/env python3
"""
Demonstration of strict_mode behavior in PQC AEAD layer
"""
import os
from core.aead import Sender, Receiver, HeaderMismatch, AeadAuthError, ReplayError, AeadIds
from core.config import CONFIG
from core.suites import get_suite, header_ids_for_suite

def demo_strict_mode():
    """Show the difference between strict_mode=True and strict_mode=False"""
    print("🔒 PQC AEAD Strict Mode Demonstration\n")
    
    # Setup
    key = os.urandom(32)
    session_id = b"\xAA" * 8
    suite = get_suite("cs-kyber768-aesgcm-dilithium3")
    header_ids = header_ids_for_suite(suite)
    aead_ids = AeadIds(*header_ids)
    
    sender = Sender(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key)
    
    # Create receivers in both modes
    receiver_strict = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key, 64, strict_mode=True)
    receiver_silent = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key, 64, strict_mode=False)
    
    # Valid packet
    valid_packet = sender.encrypt(b"test payload")
    print("✅ Valid packet decryption:")
    print(f"  Strict mode: {receiver_strict.decrypt(valid_packet)}")
    print(f"  Silent mode: {receiver_silent.decrypt(valid_packet)}\n")
    
    # Test 1: Header tampering
    print("🚨 Test 1: Header Tampering")
    tampered = bytearray(valid_packet)
    tampered[1] ^= 0x01  # Flip bit in kem_id
    tampered = bytes(tampered)
    
    try:
        result = receiver_strict.decrypt(tampered)
        print(f"  Strict mode: {result}")
    except HeaderMismatch as e:
        print(f"  Strict mode: 💥 HeaderMismatch: {e}")
    
    result = receiver_silent.decrypt(tampered)
    print(f"  Silent mode: {result} (fails silently)\n")
    
    # Test 2: Replay attack
    print("🚨 Test 2: Replay Attack")
    # Reset receivers for clean replay test
    receiver_strict_2 = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key, 64, strict_mode=True)
    receiver_silent_2 = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key, 64, strict_mode=False)
    
    valid_packet_2 = sender.encrypt(b"replay test")
    
    # First decryption (should work)
    receiver_strict_2.decrypt(valid_packet_2)
    receiver_silent_2.decrypt(valid_packet_2)
    
    # Replay attempt
    try:
        result = receiver_strict_2.decrypt(valid_packet_2)
        print(f"  Strict mode: {result}")
    except ReplayError as e:
        print(f"  Strict mode: 💥 ReplayError: {e}")
    
    result = receiver_silent_2.decrypt(valid_packet_2)
    print(f"  Silent mode: {result} (fails silently)\n")
    
    # Test 3: Wrong epoch (always silent for security)
    print("🚨 Test 3: Wrong Epoch (Always Silent)")
    receiver_epoch1 = Receiver(CONFIG["WIRE_VERSION"], aead_ids, session_id, 1, key, 64, strict_mode=True)
    sender_epoch0 = Sender(CONFIG["WIRE_VERSION"], aead_ids, session_id, 0, key)
    epoch_packet = sender_epoch0.encrypt(b"wrong epoch")
    
    result = receiver_epoch1.decrypt(epoch_packet)
    print(f"  Strict mode: {result} (always silent for rekeying security)")
    
    print("\n🎯 Summary:")
    print("  • strict_mode=True: Raises exceptions for debugging/testing")
    print("  • strict_mode=False: Returns None silently (production)")
    print("  • Epoch/Session mismatches: Always silent for security")

if __name__ == "__main__":
    demo_strict_mode()

============================================================

FILE 27/58: tools\__init__.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\__init__.py
Size: 69 bytes
Modified: 2025-09-26 15:16:07
------------------------------------------------------------
"""Helper package for tooling scripts used in automated testing."""

============================================================

FILE 28/58: tools\aggregate_lan_results.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\aggregate_lan_results.py
Size: 4,639 bytes
Modified: 2025-09-27 00:33:54
------------------------------------------------------------
"""Aggregate LAN test artifacts into CSV/JSONL/Markdown summaries.

Usage:
    python -m tools.aggregate_lan_results --results-dir results-20250927-120000
"""

from __future__ import annotations

import argparse
import csv
import json
import re
from pathlib import Path
from typing import Iterable, List, Dict

SUMMARY_FIELDS = [
    "suite",
    "side",
    "ptx_out",
    "ptx_in",
    "enc_out",
    "enc_in",
    "drops",
    "drop_replay",
    "drop_auth",
    "drop_header",
    "drop_session_epoch",
    "drop_other",
]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Aggregate LAN matrix artifacts")
    parser.add_argument(
        "--results-dir",
        required=True,
        help="Path to the results directory (e.g., results-YYYYMMDD-HHMMSS)",
    )
    parser.add_argument(
        "--markdown-name",
        default="SUMMARY.md",
        help="Name of the generated Markdown summary file",
    )
    parser.add_argument(
        "--csv-name",
        default="summary.csv",
        help="Name of the generated CSV file",
    )
    parser.add_argument(
        "--jsonl-name",
        default="summary.jsonl",
        help="Name of the generated JSONL file",
    )
    return parser.parse_args()


def load_counters(path: Path) -> Dict[str, int]:
    try:
        data = json.loads(path.read_text("utf-8"))
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Failed to parse JSON from {path}: {exc}")
    return data.get("counters", {})


def discover_runs(results_dir: Path) -> List[Dict[str, object]]:
    rows: List[Dict[str, object]] = []
    for json_path in results_dir.glob("*_debug_*.json"):
        match = re.search(r"_(cs-[^_]+)\.json$", json_path.name)
        suite = match.group(1) if match else "unknown"
        side = "gcs" if "gcs_" in json_path.name else "drone"
        counters = load_counters(json_path)
        row = {"suite": suite, "side": side}
        for key in SUMMARY_FIELDS:
            if key in ("suite", "side"):
                continue
            row[key] = counters.get(key, 0)
        rows.append(row)
    return rows


def write_jsonl(rows: Iterable[Dict[str, object]], path: Path) -> None:
    with path.open("w", encoding="utf-8") as handle:
        for row in rows:
            handle.write(json.dumps(row) + "\n")


def write_csv(rows: Iterable[Dict[str, object]], path: Path) -> None:
    rows = list(rows)
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=SUMMARY_FIELDS)
        writer.writeheader()
        for row in rows:
            record = {field: row.get(field, "") for field in SUMMARY_FIELDS}
            writer.writerow(record)


def suite_pass(rows: List[Dict[str, object]], suite: str) -> bool:
    gcs = next((row for row in rows if row["suite"] == suite and row["side"] == "gcs"), None)
    drone = next((row for row in rows if row["suite"] == suite and row["side"] == "drone"), None)
    if not gcs or not drone:
        return False
    checks = []
    for entry in (gcs, drone):
        checks.append(entry.get("drops", 0) == 0)
        checks.append(entry.get("enc_in", 0) > 0)
        checks.append(entry.get("enc_out", 0) > 0)
        checks.append(entry.get("ptx_in", 0) > 0)
        checks.append(entry.get("ptx_out", 0) > 0)
    return all(checks)


def write_markdown(rows: List[Dict[str, object]], path: Path) -> None:
    suites = sorted(set(row["suite"] for row in rows))
    lines = ["# PQC Drone↔GCS LAN Matrix — Summary", ""]
    for suite in suites:
        lines.append(f"- {suite}: {'PASS' if suite_pass(rows, suite) else 'FAIL'}")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def main() -> None:
    args = parse_args()
    results_dir = Path(args.results_dir).expanduser().resolve()
    if not results_dir.exists():
        raise SystemExit(f"Results directory {results_dir} does not exist")

    rows = discover_runs(results_dir)
    if not rows:
        raise SystemExit(f"No *_debug_*.json files found in {results_dir}")

    jsonl_path = results_dir / args.jsonl_name
    csv_path = results_dir / args.csv_name
    md_path = results_dir / args.markdown_name

    write_jsonl(rows, jsonl_path)
    write_csv(rows, csv_path)
    write_markdown(rows, md_path)

    print(f"Wrote {jsonl_path}")
    print(f"Wrote {csv_path}")
    print(f"Wrote {md_path}")


if __name__ == "__main__":
    main()

============================================================

FILE 29/58: tools\audit_endpoints.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\audit_endpoints.py
Size: 5,511 bytes
Modified: 2025-09-26 04:19:40
------------------------------------------------------------
#!/usr/bin/env python3
"""Audit repository files for hard-coded network endpoints.

This script scans Python (and optional shell/Lua) files for IPv4 literals
and socket usage that should instead reference core.config.CONFIG.
It emits a JSON report of violations and exits non-zero if any are found.
"""

from __future__ import annotations

import ast
import json
import re
import sys
from pathlib import Path
from typing import Iterable, List

ROOT = Path(__file__).resolve().parents[1]
ALLOW_IPS = {"127.0.0.1", "0.0.0.0", "::1"}
CODE_DIRS = ("core", "tools", "drone", "gcs")
IPV4_RE = re.compile(r"\b\d{1,3}(?:\.\d{1,3}){3}\b")
EXCLUDE_PARTS = {"docs", "logs", "__pycache__"}

Violation = dict[str, object]


def iter_files() -> Iterable[Path]:
    for directory in CODE_DIRS:
        base = ROOT / directory
        if not base.exists():
            continue
        for path in base.rglob("*.py"):
            if any(part in EXCLUDE_PARTS for part in path.parts):
                continue
            yield path


def flag(violations: List[Violation], path: Path, lineno: int, kind: str, detail: str, suggestion: str | None = None) -> None:
    rel = str(path.relative_to(ROOT))
    violations.append(
        {
            "file": rel,
            "line": lineno,
            "kind": kind,
            "detail": detail,
            "suggestion": suggestion or "",
        }
    )


def scan_file(path: Path, violations: List[Violation]) -> None:
    try:
        source = path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return

    # Regex sweep for IPv4 literals
    for lineno, line in enumerate(source.splitlines(), start=1):
        for match in IPV4_RE.finditer(line):
            ip = match.group(0)
            if ip not in ALLOW_IPS:
                flag(
                    violations,
                    path,
                    lineno,
                    "ipv4-literal",
                    f"Found IPv4 literal '{ip}'",
                    "Use CONFIG['GCS_HOST'/'DRONE_HOST'] or accept a parameter",
                )

    # AST analysis for socket invocations with literal endpoints
    try:
        tree = ast.parse(source, filename=str(path))
    except SyntaxError:
        return

    def is_literal_str(node: ast.AST) -> bool:
        return isinstance(node, ast.Constant) and isinstance(node.value, str)

    def is_literal_int(node: ast.AST) -> bool:
        return isinstance(node, ast.Constant) and isinstance(node.value, int)

    class Visitor(ast.NodeVisitor):
        def visit_Call(self, node: ast.Call) -> None:
            attr = getattr(node.func, "attr", None)
            if attr in {"bind", "connect"} and node.args:
                target = node.args[0]
                if isinstance(target, ast.Tuple) and len(target.elts) >= 2:
                    host, port = target.elts[0], target.elts[1]
                    if is_literal_str(host) and IPV4_RE.fullmatch(host.value or "") and host.value not in ALLOW_IPS:
                        flag(
                            violations,
                            path,
                            node.lineno,
                            f"{attr}-literal-host",
                            f"socket.{attr} uses literal host '{host.value}'",
                            "Replace with CONFIG['GCS_HOST'/'DRONE_HOST']",
                        )
                    if is_literal_int(port):
                        flag(
                            violations,
                            path,
                            node.lineno,
                            f"{attr}-literal-port",
                            f"socket.{attr} uses literal port {port.value}",
                            "Use CONFIG[...] for ports or pass via args",
                        )
            elif attr == "sendto" and len(node.args) >= 2:
                destination = node.args[1]
                if isinstance(destination, ast.Tuple) and len(destination.elts) >= 2:
                    host, port = destination.elts[0], destination.elts[1]
                    if is_literal_str(host) and IPV4_RE.fullmatch(host.value or "") and host.value not in ALLOW_IPS:
                        flag(
                            violations,
                            path,
                            node.lineno,
                            "sendto-literal-host",
                            f"socket.sendto uses literal host '{host.value}'",
                            "Replace with CONFIG['GCS_HOST'/'DRONE_HOST']",
                        )
                    if is_literal_int(port):
                        flag(
                            violations,
                            path,
                            node.lineno,
                            "sendto-literal-port",
                            f"socket.sendto uses literal port {port.value}",
                            "Use CONFIG[...] for ports",
                        )
            self.generic_visit(node)

    Visitor().visit(tree)


def main() -> int:
    violations: List[Violation] = []
    for path in iter_files():
        scan_file(path, violations)

    print(json.dumps({"violations": violations}, indent=2))
    if violations:
        print(f"\nFound {len(violations)} endpoint violations.", file=sys.stderr)
        return 2
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 30/58: tools\bench_cli.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\bench_cli.py
Size: 841 bytes
Modified: 2025-09-25 00:18:03
------------------------------------------------------------
import os, time, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.aead import Sender, Receiver, AeadIds
from core.suites import header_ids_for_suite
from core.config import CONFIG
def main():
    suite = {"kem_name":"ML-KEM-768","sig_name":"ML-DSA-65","aead":"AES-256-GCM","kdf":"HKDF-SHA256","kem_param":768,"sig_param":65}
    ids = AeadIds(*header_ids_for_suite(suite))
    key = os.urandom(32); sid = os.urandom(8)
    s = Sender(CONFIG["WIRE_VERSION"], ids, sid, 0, key)
    r = Receiver(CONFIG["WIRE_VERSION"], ids, sid, 0, key, CONFIG["REPLAY_WINDOW"])
    t0=time.perf_counter(); n=2000
    for _ in range(n):
        w = s.encrypt(b"x"*64)
        _ = r.decrypt(w)
    dt=time.perf_counter()-t0
    print({"pps": int(n/dt), "lat_us_per_pkt": int(dt/n*1e6)})
if __name__=="__main__": main()

============================================================

FILE 31/58: tools\check_no_hardcoded_ips.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_no_hardcoded_ips.py
Size: 2,448 bytes
Modified: 2025-09-26 14:12:14
------------------------------------------------------------
"""Static check to ensure IPs/ports are sourced from core.config."""
from __future__ import annotations

import re
import sys
from pathlib import Path
from typing import Iterable, List, Tuple

REPO_ROOT = Path(__file__).resolve().parents[1]
TARGET_SUFFIXES = {".py", ".ps1", ".sh"}
ALLOW_DIRS = {".git", "__pycache__", "venv", "env"}
SKIP_PREFIXES = {
    REPO_ROOT / "core" / "config.py",
}
SKIP_DIRS = {REPO_ROOT / "tests" / "fixtures"}

IP_PATTERN = re.compile(r"\b(?:\d{1,3}\.){3}\d{1,3}\b")
PORT_PATTERN = re.compile(r"socket\.(?:bind|connect|sendto)\([^\n\#]*?(\d{4,5})")
ALLOWED_IPS = {"0.0.0.0", "127.0.0.1", "::1"}
ALLOWED_PORTS = {"0", "53"}


def iter_files() -> Iterable[Path]:
    for path in REPO_ROOT.rglob("*"):
        if not path.is_file():
            continue
        if path.suffix not in TARGET_SUFFIXES:
            continue
        if any(part in ALLOW_DIRS for part in path.parts):
            continue
        if any(path.is_relative_to(skip) for skip in SKIP_DIRS):
            continue
        yield path


def find_violations(path: Path) -> Tuple[List[str], List[str]]:
    if path in SKIP_PREFIXES:
        return [], []
    text = path.read_text(encoding="utf-8", errors="ignore")
    ips = []
    for match in IP_PATTERN.finditer(text):
        ip = match.group(0)
        if ip in ALLOWED_IPS:
            continue
        ips.append(f"{path}:{match.start()} -> {ip}")
    ports = []
    for match in PORT_PATTERN.finditer(text):
        port = match.group(1)
        if port in ALLOWED_PORTS:
            continue
        ports.append(f"{path}:{match.start()} -> {port}")
    return ips, ports


def main() -> int:
    ip_violations: List[str] = []
    port_violations: List[str] = []

    for path in iter_files():
        ips, ports = find_violations(path)
        ip_violations.extend(ips)
        port_violations.extend(ports)

    if ip_violations or port_violations:
        if ip_violations:
            print("IP literal violations detected:")
            for item in ip_violations:
                print(f"  {item}")
        if port_violations:
            print("Port literal violations detected:")
            for item in port_violations:
                print(f"  {item}")
        return 1

    print("No hard-coded IPs or forbidden port literals detected.")
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 32/58: tools\check_ports.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\check_ports.py
Size: 3,618 bytes
Modified: 2025-09-25 15:53:08
------------------------------------------------------------
# tools/check_ports.py
"""
A utility to check if the network ports required by the PQC proxy
are available on localhost. Supports both default and manual_4term port profiles.
"""
import argparse
import os
import socket
import sys

# Add the project root to the Python path to allow importing the 'core' module
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

try:
    from core.config import CONFIG as BASE_CONFIG
except ImportError:
    print("❌ Error: Could not import CONFIG from core/config.py.")
    print("   Please run this script from the project's root directory.")
    sys.exit(1)

# Manual 4-terminal testing port configuration
MANUAL_4TERM_CONFIG = {
    "TCP_HANDSHAKE_PORT": 45800,
    "UDP_DRONE_RX": 45801,
    "UDP_GCS_RX": 45802,
    "DRONE_PLAINTEXT_TX": 45803,
    "DRONE_PLAINTEXT_RX": 45804,
    "GCS_PLAINTEXT_TX": 45805,
    "GCS_PLAINTEXT_RX": 45806,
    "WIRE_VERSION": 1,
}

def check_bind(addr: str, proto: str, port: int) -> bool:
    """Attempts to bind to a port to check its availability. Returns True if available."""
    socket_type = socket.SOCK_STREAM if proto == "TCP" else socket.SOCK_DGRAM
    with socket.socket(socket.AF_INET, socket_type) as s:
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        try:
            s.bind((addr, port))
            return True
        except OSError:
            return False

def main():
    parser = argparse.ArgumentParser(description="Check PQC proxy port availability")
    parser.add_argument("--profile", choices=["default", "manual4term"], default="default",
                        help="Which port profile to check (default: default)")
    parser.add_argument("--include-app-ports", action="store_true",
                        help="Also check the app listener ports (Plaintext RX)")
    args = parser.parse_args()

    # Select configuration based on profile
    config = dict(BASE_CONFIG) if args.profile == "default" else MANUAL_4TERM_CONFIG

    print(f"--- Checking ports on 127.0.0.1 for profile: {args.profile} ---")

    # Define ports to check with their bind addresses
    port_checks = [
        ("TCP", config["TCP_HANDSHAKE_PORT"], "GCS Handshake Listener", "0.0.0.0"),
        ("UDP", config["UDP_DRONE_RX"],       "Drone Encrypted Ingress", "0.0.0.0"),
        ("UDP", config["UDP_GCS_RX"],         "GCS Encrypted Ingress",   "0.0.0.0"),
        ("UDP", config["DRONE_PLAINTEXT_TX"], "Drone Plaintext Ingress", "127.0.0.1"),
        ("UDP", config["GCS_PLAINTEXT_TX"],   "GCS Plaintext Ingress",   "127.0.0.1"),
    ]
    
    if args.include_app_ports:
        port_checks += [
            ("UDP", config["DRONE_PLAINTEXT_RX"], "Drone Plaintext RX (app listener)", "127.0.0.1"),
            ("UDP", config["GCS_PLAINTEXT_RX"],   "GCS Plaintext RX (app listener)",   "127.0.0.1"),
        ]

    all_available = True
    for proto, port, label, addr in port_checks:
        is_available = check_bind(addr, proto, port)
        if is_available:
            status = "✅ Available"
        else:
            status = "❌ IN USE"
            all_available = False
            
        print(f"{proto:4} {port:<5} {label:<40} {addr:<9} : {status}")

    print("-" * 70)
    
    if all_available:
        print("✅ All required ports are available.")
        sys.exit(0)
    else:
        print("❌ One or more required ports are in use. Please close the conflicting application.")
        sys.exit(1)

if __name__ == "__main__":
    main()

============================================================

FILE 33/58: tools\counter_utils.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\counter_utils.py
Size: 6,381 bytes
Modified: 2025-09-26 18:45:57
------------------------------------------------------------
"""Utility helpers for reading proxy and traffic counter artifacts.

These helpers keep the orchestration scripts decoupled from the exact JSON
structure emitted by the proxies and traffic generators.
"""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional


@dataclass(frozen=True)
class ProxyCounters:
    """Parsed counters emitted by ``core.run_proxy``.

    Attributes
    ----------
    role:
        ``"gcs"`` or ``"drone"`` as recorded in the JSON payload.
    suite:
        Canonical suite identifier associated with the run.
    counters:
        Raw counter dictionary from the JSON payload.
    ts_stop_ns:
        Optional timestamp (nanoseconds) indicating when the proxy shut down.
    path:
        Filesystem location from which the payload was loaded.
    """

    role: str
    suite: str
    counters: Dict[str, Any]
    ts_stop_ns: Optional[int] = None
    path: Optional[Path] = None

    @property
    def rekeys_ok(self) -> int:
        """Return the number of successful rekeys recorded by the proxy."""

        return int(self.counters.get("rekeys_ok", 0))

    @property
    def rekeys_fail(self) -> int:
        """Return the number of failed rekeys recorded by the proxy."""

        return int(self.counters.get("rekeys_fail", 0))

    @property
    def last_rekey_suite(self) -> Optional[str]:
        """Return the last suite identifier applied during rekey, if any."""

        last_suite = self.counters.get("last_rekey_suite")
        if isinstance(last_suite, str) and last_suite:
            return last_suite
        return None

    def ensure_rekey(self, expected_suite: str) -> None:
        """Validate that at least one rekey succeeded to ``expected_suite``.

        Raises
        ------
        ValueError
            If no successful rekey occurred or the final suite does not match
            ``expected_suite``.
        """

        if self.rekeys_ok < 1:
            raise ValueError(
                f"Proxy {self.role} reported no successful rekeys (path={self.path})"
            )
        final_suite = self.last_rekey_suite
        if final_suite != expected_suite:
            raise ValueError(
                f"Proxy {self.role} last_rekey_suite={final_suite!r} does not match "
                f"expected {expected_suite!r}"
            )


@dataclass(frozen=True)
class TrafficSummary:
    """Counters emitted by ``tools/traffic_*.py``."""

    role: str
    peer_role: Optional[str]
    sent_total: int
    recv_total: int
    tx_bytes_total: int
    rx_bytes_total: int
    first_send_ts: Optional[str]
    last_send_ts: Optional[str]
    first_recv_ts: Optional[str]
    last_recv_ts: Optional[str]
    out_of_order: int
    unique_senders: int
    path: Optional[Path] = None


def _load_json(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Counter file not found: {path}")
    try:
        import json

        return json.loads(path.read_text(encoding="utf-8"))
    except Exception as exc:  # pragma: no cover - defensive logging only
        raise ValueError(f"Failed to parse JSON from {path}: {exc}") from exc


def load_proxy_counters(path: Path | str) -> ProxyCounters:
    """Load proxy counters JSON from ``path``.

    Parameters
    ----------
    path:
        Filesystem path to the JSON payload created by ``--json-out``.

    Returns
    -------
    ProxyCounters
        Dataclass encapsulating the parsed counters.
    """

    target = Path(path)
    payload = _load_json(target)

    role = payload.get("role")
    suite = payload.get("suite")
    counters = payload.get("counters")

    if not isinstance(role, str) or not isinstance(suite, str) or not isinstance(counters, dict):
        raise ValueError(f"Invalid proxy counters JSON schema in {target}")

    ts_stop_ns = payload.get("ts_stop_ns")
    if ts_stop_ns is not None:
        try:
            ts_stop_ns = int(ts_stop_ns)
        except (TypeError, ValueError):
            ts_stop_ns = None

    return ProxyCounters(
        role=role,
        suite=suite,
        counters=counters,
        ts_stop_ns=ts_stop_ns,
        path=target,
    )


def load_traffic_summary(path: Path | str) -> TrafficSummary:
    """Load traffic generator summary JSON.

    Parameters
    ----------
    path:
        Path to the file created via ``--summary``.
    """

    target = Path(path)
    payload = _load_json(target)

    role = payload.get("role")
    peer_role = payload.get("peer_role")

    required_int_fields = {
        "sent_total": int,
        "recv_total": int,
        "tx_bytes_total": int,
        "rx_bytes_total": int,
        "out_of_order": int,
    }

    counters: Dict[str, int] = {}
    for field, field_type in required_int_fields.items():
        value = payload.get(field)
        if not isinstance(value, field_type):
            raise ValueError(f"Summary field {field} missing or wrong type in {target}")
        counters[field] = int(value)

    unique_senders_raw = payload.get("unique_senders")
    unique_senders = int(unique_senders_raw) if unique_senders_raw is not None else 0

    if not isinstance(role, str):
        raise ValueError(f"Summary missing role field in {target}")

    return TrafficSummary(
        role=role,
        peer_role=peer_role if isinstance(peer_role, str) else None,
        sent_total=counters["sent_total"],
        recv_total=counters["recv_total"],
        tx_bytes_total=counters["tx_bytes_total"],
        rx_bytes_total=counters["rx_bytes_total"],
        first_send_ts=_opt_str(payload.get("first_send_ts")),
        last_send_ts=_opt_str(payload.get("last_send_ts")),
        first_recv_ts=_opt_str(payload.get("first_recv_ts")),
        last_recv_ts=_opt_str(payload.get("last_recv_ts")),
        out_of_order=counters["out_of_order"],
        unique_senders=unique_senders,
        path=target,
    )


def _opt_str(value: Any) -> Optional[str]:
    return value if isinstance(value, str) and value else None


__all__ = [
    "ProxyCounters",
    "TrafficSummary",
    "load_proxy_counters",
    "load_traffic_summary",
]

============================================================

FILE 34/58: tools\diag_udp.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\diag_udp.py
Size: 8,245 bytes
Modified: 2025-09-26 03:26:42
------------------------------------------------------------
import socket
import threading
import time
import argparse
import sys
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
# Prefer the ancestor that contains a 'core' directory
for parent in (_HERE.parent.parent, _HERE.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        # Best-effort; fall through
        pass

from core.config import CONFIG  # Defines hosts and all plaintext/handshake ports

def _sendto(sock: socket.socket, host: str, port: int, text: str) -> None:
    sock.sendto(text.encode('utf-8'), (host, port))


def run_udp_test(role, local_ip, remote_ip, local_rx_port, remote_tx_port):
    """
    Sets up a UDP listener and sender to test direct plaintext communication.
    :param role: "GCS" or "DRONE"
    :param local_ip: The IP address this machine should bind its receiver to (usually "0.0.0.0")
    :param remote_ip: The IP address of the remote machine to send messages to
    :param local_rx_port: The port this machine listens on
    :param remote_tx_port: The port the remote machine is listening on (which we send to)
    """
    print(f"\n--- {role} Plaintext UDP Test ---")
    print(f"  Listening on: {local_ip}:{local_rx_port}")
    print(f"  Sending to:   {remote_ip}:{remote_tx_port}")
    print(f"  Type a message and press Enter to send. Ctrl+C to exit.")

    # Setup receiver socket
    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx_sock.bind((local_ip, local_rx_port))
    rx_sock.setblocking(False) # Non-blocking for concurrent read/write

    # Setup sender socket
    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    # Thread for receiving messages
    def receiver():
        while True:
            try:
                data, addr = rx_sock.recvfrom(65535)
                msg = data.decode('utf-8', errors='ignore').strip()
                print(f"\n[{time.strftime('%H:%M:%S')}] Received from {addr[0]}:{addr[1]}: {msg}")
                print(f"Type message: ", end='', flush=True) # Prompt again after receiving
            except BlockingIOError:
                time.sleep(0.01) # Small delay to prevent busy-waiting
            except Exception as e:
                print(f"Error in receiver: {e}")
                break

    # Start receiver thread
    receiver_thread = threading.Thread(target=receiver, daemon=True)
    receiver_thread.start()

    # Main thread for sending messages
    try:
        while True:
            message = input(f"Type message: ")
            if message.lower() == 'exit':
                break
            tx_sock.sendto(message.encode('utf-8'), (remote_ip, remote_tx_port))
    except KeyboardInterrupt:
        print("\nExiting...")
    finally:
        rx_sock.close()
        tx_sock.close()


def run_auto(role: str, *, verbose: bool = False, delay: float = 0.05) -> int:
    """Automatic cross-direction UDP smoke test using CONFIG hosts/ports.

    Flow:
      - Drone listens on DRONE_PLAINTEXT_RX; GCS listens on GCS_PLAINTEXT_RX.
      - Drone sends trigger "HELLO_FROM_DRONE" to GCS_PLAINTEXT_RX.
      - GCS replies "HELLO_FROM_GCS" to DRONE_PLAINTEXT_RX.
      - Each side then sends 5 numbered messages to the other's RX port.
      - Returns 0 on success; non-zero on failure.
    """

    gcs_host = CONFIG.get("GCS_HOST", "127.0.0.1")
    drone_host = CONFIG.get("DRONE_HOST", "127.0.0.1")
    gcs_rx = int(CONFIG["GCS_PLAINTEXT_RX"])  # local RX for GCS
    drone_rx = int(CONFIG["DRONE_PLAINTEXT_RX"])  # local RX for Drone

    # Sockets
    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    if role == "gcs":
        rx.bind(("0.0.0.0", gcs_rx))
        peer_host, peer_port = drone_host, drone_rx
    else:
        rx.bind(("0.0.0.0", drone_rx))
        peer_host, peer_port = gcs_host, gcs_rx

    rx.setblocking(False)

    received = []
    stop = False

    def recv_loop():
        nonlocal stop
        while not stop:
            try:
                data, addr = rx.recvfrom(65535)
            except BlockingIOError:
                time.sleep(0.01)
                continue
            except Exception as e:
                if verbose:
                    print(f"recv error: {e}")
                break
            received.append((time.time(), addr, data))
            if verbose:
                print(f"RX {addr}: {data[:64]!r}")

    t = threading.Thread(target=recv_loop, daemon=True)
    t.start()

    try:
        if role == "drone":
            _sendto(tx, gcs_host, gcs_rx, "HELLO_FROM_DRONE")
        # Wait briefly for trigger; then GCS replies
        deadline = time.time() + 2.0
        replied = False
        while time.time() < deadline:
            if any(b"HELLO_FROM_DRONE" in it[2] for it in received) and role == "gcs":
                _sendto(tx, drone_host, drone_rx, "HELLO_FROM_GCS")
                replied = True
                break
            if any(b"HELLO_FROM_GCS" in it[2] for it in received) and role == "drone":
                replied = True
                break
            time.sleep(0.01)

        if not replied:
            print("Timeout waiting for trigger exchange")
            return 2

        # Now fire 5 numbered messages from both sides
        for i in range(1, 6):
            if role == "gcs":
                _sendto(tx, drone_host, drone_rx, f"GCS_MSG_{i}")
            else:
                _sendto(tx, gcs_host, gcs_rx, f"DRONE_MSG_{i}")
            time.sleep(delay)

        # Allow receive
        time.sleep(0.5)

        # Basic assertions
        rx_texts = [pkt[2].decode("utf-8", errors="ignore") for pkt in received]
        if role == "gcs":
            ok = any("HELLO_FROM_DRONE" in s for s in rx_texts) and sum(1 for s in rx_texts if s.startswith("DRONE_MSG_")) >= 1
        else:
            ok = any("HELLO_FROM_GCS" in s for s in rx_texts) and sum(1 for s in rx_texts if s.startswith("GCS_MSG_")) >= 1
        print(f"Auto test {'PASSED' if ok else 'FAILED'}; received {len(received)} datagrams")
        return 0 if ok else 1
    finally:
        stop = True
        t.join(timeout=0.2)
        try:
            rx.close()
            tx.close()
        except Exception:
            pass

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Test direct UDP plaintext communication between GCS and Drone.")
    parser.add_argument("--role", choices=["gcs", "drone"], required=True, help="Specify if this is the 'gcs' or 'drone' side.")
    parser.add_argument("--local_ip", default="0.0.0.0", help="Local IP to bind the receiver socket to.")
    parser.add_argument("--remote_gcs_ip", help="IP of the GCS machine (required for drone role).")
    parser.add_argument("--remote_drone_ip", help="IP of the Drone machine (required for gcs role).")
    parser.add_argument("--auto", action="store_true", help="Run automatic cross-direction smoke test using CONFIG hosts/ports.")
    args = parser.parse_args()

    if args.auto:
        rc = run_auto(args.role)
        raise SystemExit(rc)

    if args.role == "gcs":
        if not args.remote_drone_ip:
            parser.error("--remote_drone_ip is required for 'gcs' role.")
        run_udp_test(
            role="GCS",
            local_ip=args.local_ip,
            remote_ip=args.remote_drone_ip,
            local_rx_port=CONFIG["GCS_PLAINTEXT_RX"],
            remote_tx_port=CONFIG["DRONE_PLAINTEXT_RX"]
        )
    elif args.role == "drone":
        if not args.remote_gcs_ip:
            parser.error("--remote_gcs_ip is required for 'drone' role.")
        run_udp_test(
            role="DRONE",
            local_ip=args.local_ip,
            remote_ip=args.remote_gcs_ip,
            local_rx_port=CONFIG["DRONE_PLAINTEXT_RX"],
            remote_tx_port=CONFIG["GCS_PLAINTEXT_RX"]
        )

============================================================

FILE 35/58: tools\encrypted_sniffer.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\encrypted_sniffer.py
Size: 1,570 bytes
Modified: 2025-09-25 16:20:53
------------------------------------------------------------
# tools/encrypted_sniffer.py
"""
A simple UDP sniffer to verify that encrypted packets are being sent
by the proxies. Listens on a specified port and prints details of
any received datagrams.
"""
import socket
import sys
import time

def main():
    if len(sys.argv) != 2:
        print(f"Usage: python {sys.argv[0]} <port_to_listen_on>")
        sys.exit(1)

    try:
        listen_port = int(sys.argv[1])
    except ValueError:
        print(f"Error: Invalid port '{sys.argv[1]}'. Please provide a number.")
        sys.exit(1)

    print(f"--- 🕵️ Encrypted Packet Sniffer ---")
    print(f"Listening for UDP packets on 0.0.0.0:{listen_port}...")
    print("Press Ctrl+C to stop.")

    count = 0
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.bind(('0.0.0.0', listen_port))
            while True:
                data, addr = s.recvfrom(2048)
                count += 1
                timestamp = time.strftime("%H:%M:%S")
                print(
                    f"[{timestamp}] Packet #{count}: Received {len(data)} bytes from {addr[0]}:{addr[1]}"
                    f" | Data (hex): {data[:16].hex()}..."
                )
    except OSError as e:
        print(f"\n❌ Error binding to port {listen_port}: {e}")
        print("   Is another application already using this port?")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nSniffer stopped. Received a total of {count} packets.")
        sys.exit(0)

if __name__ == "__main__":
    main()

============================================================

FILE 36/58: tools\full_comm_check.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\full_comm_check.py
Size: 9,657 bytes
Modified: 2025-09-25 00:18:03
------------------------------------------------------------
from __future__ import annotations
import json, os, socket, threading, time, sys
from types import ModuleType

# --------- helpers ---------
def _free_udp_port() -> int:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.bind(("127.0.0.1", 0))
    port = s.getsockname()[1]
    s.close()
    return port

def _clone_config_with_ports(base_cfg: dict) -> dict:
    cfg = dict(base_cfg)
    # Make everything local loopback and unique per run
    cfg["DRONE_HOST"] = "127.0.0.1"
    cfg["GCS_HOST"] = "127.0.0.1"

    # Plaintext app ports (4 distinct)
    cfg["DRONE_PLAINTEXT_TX"] = _free_udp_port()
    cfg["DRONE_PLAINTEXT_RX"] = _free_udp_port()
    while cfg["DRONE_PLAINTEXT_RX"] == cfg["DRONE_PLAINTEXT_TX"]:
        cfg["DRONE_PLAINTEXT_RX"] = _free_udp_port()

    cfg["GCS_PLAINTEXT_TX"] = _free_udp_port()
    cfg["GCS_PLAINTEXT_RX"] = _free_udp_port()
    while cfg["GCS_PLAINTEXT_RX"] == cfg["GCS_PLAINTEXT_TX"]:
        cfg["GCS_PLAINTEXT_RX"] = _free_udp_port()

    # Encrypted RX ports (must be distinct)
    cfg["DRONE_ENCRYPTED_RX"] = _free_udp_port()
    cfg["GCS_ENCRYPTED_RX"] = _free_udp_port()
    while cfg["GCS_ENCRYPTED_RX"] == cfg["DRONE_ENCRYPTED_RX"]:
        cfg["GCS_ENCRYPTED_RX"] = _free_udp_port()

    # Handshake TCP port
    cfg["TCP_HANDSHAKE_PORT"] = max(5800, _free_udp_port())
    return cfg

# --------- step 1: pytest ---------
def run_pytests() -> dict:
    try:
        import pytest  # type: ignore
    except Exception as e:
        return {"status": "ERROR", "detail": f"pytest import failed: {e}"}
    # Run full test suite quietly
    code = pytest.main(["-q"])
    return {"status": "OK" if code == 0 else "FAIL", "exit_code": code}

# --------- step 2: loopback smoke ---------
def smoke_loopback() -> dict:
    try:
        from core.async_proxy import run_proxy
        from oqs.oqs import Signature
    except Exception as e:
        return {"status": "ERROR", "detail": f"cannot import required modules: {e}"}

    # Load baseline config
    try:
        from core.config import CONFIG, load_config, validate_config  # type: ignore
        base_cfg = CONFIG
        # If load_config/validate_config exist, run a quick check
        try:
            tmp = load_config(os.environ) if callable(load_config) else None  # type: ignore
            if callable(validate_config):  # type: ignore
                validate_config(base_cfg)  # type: ignore
        except Exception:
            pass
    except Exception:
        # Fallback: try project_config re-export
        try:
            from core.project_config import CONFIG  # type: ignore
            base_cfg = CONFIG
        except Exception as e2:
            return {"status": "ERROR", "detail": f"cannot load config: {e2}"}

    cfg = _clone_config_with_ports(base_cfg)
    
    # Generate REAL cryptographic keys for testing - SECURITY CRITICAL
    try:
        suite_dict = {"kem_name":"ML-KEM-768","kem_param":768,"sig_name":"ML-DSA-65","sig_param":65,"aead":"AES-256-GCM","kdf":"HKDF-SHA256","nist_level":3}
        sig = Signature(suite_dict["sig_name"])
        gcs_sig_public = sig.generate_keypair()
    except Exception as e:
        return {"status": "ERROR", "detail": f"failed to generate keys: {e}"}

    # Storage for proxy results and errors
    gcs_err = {"error": None}
    drn_err = {"error": None}

    def gcs_thread():
        try:
            run_proxy(
                role="gcs",
                suite=suite_dict,
                cfg=cfg,
                gcs_sig_secret=sig,  # Real signature object - SECURITY CRITICAL
                gcs_sig_public=None,
                stop_after_seconds=2.0,
            )
        except Exception as e:
            gcs_err["error"] = repr(e)

    def drone_thread():
        try:
            time.sleep(0.2)  # let GCS bind first
            run_proxy(
                role="drone",
                suite=suite_dict,
                cfg=cfg,
                gcs_sig_secret=None,
                gcs_sig_public=gcs_sig_public,  # Real public key - SECURITY CRITICAL
                stop_after_seconds=2.0,
            )
        except Exception as e:
            drn_err["error"] = repr(e)

    # Start receivers (apps side)
    received_at_gcs = {"data": None}
    received_at_drone = {"data": None}

    def recv_gcs():
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as r:
                r.bind(("127.0.0.1", cfg["GCS_PLAINTEXT_RX"]))
                r.settimeout(2.0)
                data, _ = r.recvfrom(2048)
                received_at_gcs["data"] = data
        except Exception:
            pass

    def recv_drone():
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as r:
                r.bind(("127.0.0.1", cfg["DRONE_PLAINTEXT_RX"]))
                r.settimeout(2.0)
                data, _ = r.recvfrom(2048)
                received_at_drone["data"] = data
        except Exception:
            pass

    tg = threading.Thread(target=gcs_thread, daemon=True)
    td = threading.Thread(target=drone_thread, daemon=True)
    rg = threading.Thread(target=recv_gcs, daemon=True)
    rd = threading.Thread(target=recv_drone, daemon=True)

    rg.start(); rd.start()
    tg.start(); td.start()

    time.sleep(0.7)  # allow handshake

    # Send both directions via plaintext TX
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.sendto(b"Hello from drone", ("127.0.0.1", cfg["DRONE_PLAINTEXT_TX"]))
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.sendto(b"Hello from GCS", ("127.0.0.1", cfg["GCS_PLAINTEXT_TX"]))
    except Exception as e:
        return {"status": "ERROR", "detail": f"send failed: {e}"}

    rg.join(timeout=2.5); rd.join(timeout=2.5)
    tg.join(timeout=3.0);  td.join(timeout=3.0)

    if gcs_err["error"] or drn_err["error"]:
        return {"status": "FAIL", "detail": {"gcs": gcs_err["error"], "drone": drn_err["error"]}}

    ok = (received_at_gcs["data"] == b"Hello from drone" and
          received_at_drone["data"] == b"Hello from GCS")
    return {"status": "OK" if ok else "FAIL",
            "detail": {
                "gcs_rx": received_at_gcs["data"],
                "drone_rx": received_at_drone["data"],
                "ports": {
                    "DRONE_TX": cfg["DRONE_PLAINTEXT_TX"],
                    "DRONE_RX": cfg["DRONE_PLAINTEXT_RX"],
                    "GCS_TX": cfg["GCS_PLAINTEXT_TX"],
                    "GCS_RX": cfg["GCS_PLAINTEXT_RX"],
                    "ENC_DRONE": cfg["DRONE_ENCRYPTED_RX"],
                    "ENC_GCS": cfg["GCS_ENCRYPTED_RX"],
                    "HS_TCP": cfg["TCP_HANDSHAKE_PORT"],
                }
            }}

# --------- step 3: config checks ---------
def config_checks() -> dict:
    out = {}
    try:
        from core.config import CONFIG, load_config, validate_config  # type: ignore
    except Exception as e:
        return {"status": "UNKNOWN", "detail": f"no load/validate available: {e}"}

    # Base validate
    try:
        validate_config(CONFIG)  # type: ignore
        out["base_validate"] = "OK"
    except Exception as e:
        out["base_validate"] = f"FAIL: {e}"

    # Env override smoke
    try:
        env = os.environ.copy()
        env["DRONE_HOST"] = "127.0.0.1"
        env["GCS_HOST"] = "127.0.0.1"
        env["DRONE_PLAINTEXT_TX"] = "14650"
        env["DRONE_PLAINTEXT_RX"] = "14651"
        env["GCS_PLAINTEXT_TX"] = "15652"
        env["GCS_PLAINTEXT_RX"] = "15653"
        env["DRONE_ENCRYPTED_RX"] = "6810"
        env["GCS_ENCRYPTED_RX"] = "6811"
        cfg2 = load_config(env)  # type: ignore
        validate_config(cfg2)  # type: ignore
        out["env_override"] = "OK"
    except Exception as e:
        out["env_override"] = f"FAIL: {e}"

    # Port dedupe failure
    try:
        bad = dict(CONFIG)
        bad["DRONE_PLAINTEXT_RX"] = bad["DRONE_PLAINTEXT_TX"]
        validate_config(bad)  # type: ignore
        out["dedupe_check"] = "FAIL: expected ValueError"
    except Exception:
        out["dedupe_check"] = "OK"

    status = ("OK" if all(v == "OK" for v in out.values()) else "FAIL")
    out["status"] = status
    return out

# --------- step 4: wrapper import check ---------
def wrapper_imports() -> dict:
    import importlib, pathlib
    results = {"drone": {}, "gcs": {}}
    base = pathlib.Path(__file__).resolve().parents[1]

    for side in ("drone", "gcs"):
        wdir = base / side / "wrappers"
        if not wdir.exists():
            results[side]["status"] = "UNKNOWN: wrappers dir missing"
            continue
        for f in sorted(wdir.glob("*.py")):
            modname = f"{side}.wrappers.{f.stem}"
            try:
                m: ModuleType = importlib.import_module(modname)  # noqa
                results[side][f.name] = "IMPORTED"
            except Exception as e:
                results[side][f.name] = f"IMPORT_FAIL: {e}"
        results[side]["status"] = "OK" if all(v=="IMPORTED" for k,v in results[side].items() if k.endswith(".py")) else "FAIL"
    return results

# --------- main ---------
def main():
    report = {}
    report["pytest"] = run_pytests()
    report["smoke"] = smoke_loopback()
    report["config"] = config_checks()
    report["wrappers"] = wrapper_imports()
    print(json.dumps(report, indent=2, default=str))

if __name__ == "__main__":
    main()

============================================================

FILE 37/58: tools\generate_identity.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\generate_identity.py
Size: 2,266 bytes
Modified: 2025-09-25 08:18:20
------------------------------------------------------------
#!/usr/bin/env python3
"""Generate and persist a post-quantum GCS identity (signature keypair).

Usage:
  python tools/generate_identity.py --suite cs-kyber768-aesgcm-dilithium3 --out-dir keys

Outputs:
  <out-dir>/gcs_sig_public.bin
  <out-dir>/gcs_sig_secret.bin

Security:
  - Secret key file is written with 0o600 permissions where supported.
  - Fails fast on any error; never substitutes random bytes.
"""
import argparse, os, sys, stat
from pathlib import Path
from oqs.oqs import Signature
from core.suites import get_suite


def write_file(path: Path, data: bytes, secret: bool = False):
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(data)
    if secret:
        try:
            path.chmod(stat.S_IRUSR | stat.S_IWUSR)
        except Exception:
            pass  # best effort on non-POSIX


def main():
    ap = argparse.ArgumentParser(description="Generate PQC signature identity keypair")
    ap.add_argument("--suite", required=True, help="Suite ID (must correspond to desired signature algorithm)")
    ap.add_argument("--out-dir", default="identity", help="Output directory for key files")
    args = ap.parse_args()

    try:
        suite = get_suite(args.suite)
    except Exception as e:
        print(f"Error: unknown suite '{args.suite}': {e}")
        sys.exit(2)

    sig_alg = suite["sig_name"]
    try:
        sig = Signature(sig_alg)
        pub = sig.generate_keypair()
        secret = sig.export_secret_key()
    except Exception as e:
        print(f"Failed to generate signature keypair for {sig_alg}: {e}")
        sys.exit(1)

    out_dir = Path(args.out_dir).resolve()
    write_file(out_dir / "gcs_sig_public.bin", pub, secret=False)
    write_file(out_dir / "gcs_sig_secret.bin", secret, secret=True)

    print("Generated PQC signature identity:")
    print(f"  Signature algorithm : {sig_alg}")
    print(f"  Public key (hex)    : {pub.hex()}")
    print(f"  Public key file     : {out_dir / 'gcs_sig_public.bin'}")
    print(f"  Secret key file     : {out_dir / 'gcs_sig_secret.bin'} (mode 600 if supported)")
    print("\nDistribute the public key to drone nodes; keep the secret key private.")

if __name__ == "__main__":
    main()

============================================================

FILE 38/58: tools\manual_4term\drone_autopilot_sim.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\drone_autopilot_sim.py
Size: 3,933 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Drone-side simulator for manual quad-terminal tests.

Generates telemetry frames towards the drone proxy and prints any
commands received from the GCS proxy.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from typing import List

_TELEMETRY_FRAMES: List[str] = [
    "TELEM:POS:37.7749,-122.4194,ALT=120",
    "TELEM:ATT:ROLL=1.2,PITCH=-0.3,YAW=90",
    "TELEM:VEL:N=5.1,E=0.4,D=-0.2",
    "TELEM:BAT:V=23.9,I=12.3,SOC=87",
]

_BUFFER_SIZE = 2048


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Simulate a drone autopilot connected to the proxy")
    parser.add_argument("--send-port", type=int, required=True, help="Port where drone proxy listens for plaintext telemetry")
    parser.add_argument("--recv-port", type=int, required=True, help="Port where drone proxy delivers decrypted commands")
    parser.add_argument("--host", default="127.0.0.1", help="Loopback host for both directions (default: %(default)s)")
    parser.add_argument("--interval", type=float, default=1.5, help="Seconds between telemetry frames (default: %(default)s)")
    parser.add_argument("--loop", action="store_true", help="Loop telemetry frames forever (default: stop after one pass)")
    return parser.parse_args()


def telemetry_loop(sock: socket.socket, host: str, port: int, interval: float, loop: bool, shutdown: threading.Event) -> None:
    print(f"[DRONE] Sending telemetry to {host}:{port}")
    while not shutdown.is_set():
        for frame in _TELEMETRY_FRAMES:
            try:
                payload = frame.encode("utf-8")
                sock.sendto(payload, (host, port))
                timestamp = time.strftime("%H:%M:%S")
                print(f"[DRONE] {timestamp} -> {frame}")
            except OSError as exc:
                print(f"[DRONE] Send error: {exc}")
                shutdown.set()
                break
            if shutdown.wait(interval):
                break
        if not loop:
            break
    print("[DRONE] Telemetry loop stopped")


def command_loop(sock: socket.socket, shutdown: threading.Event) -> None:
    print("[DRONE] Listening for decrypted commands...")
    sock.settimeout(0.5)
    while not shutdown.is_set():
        try:
            data, addr = sock.recvfrom(_BUFFER_SIZE)
        except socket.timeout:
            continue
        except OSError as exc:
            if not shutdown.is_set():
                print(f"[DRONE] Receive error: {exc}")
            break
        timestamp = time.strftime("%H:%M:%S")
        try:
            text = data.decode("utf-8", errors="replace")
        except Exception:
            text = data.hex()
        print(f"[DRONE] {timestamp} <- {text} (from {addr[0]}:{addr[1]})")
    print("[DRONE] Command listener stopped")


def main() -> None:
    args = parse_args()

    shutdown = threading.Event()

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as send_sock, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as recv_sock:
        recv_sock.bind(("0.0.0.0", args.recv_port))

        sender = threading.Thread(target=telemetry_loop, args=(send_sock, args.host, args.send_port, args.interval, args.loop, shutdown), daemon=True)
        receiver = threading.Thread(target=command_loop, args=(recv_sock, shutdown), daemon=True)

        sender.start()
        receiver.start()

        print("[DRONE] Autopilot simulator running. Press Ctrl+C to exit.")
        try:
            while sender.is_alive() or receiver.is_alive():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\n[DRONE] Interrupt received, shutting down")
            shutdown.set()
            sender.join(timeout=1.0)
            receiver.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 39/58: tools\manual_4term\drone_tty.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\drone_tty.py
Size: 4,213 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""Minimal interactive CLI for Drone plaintext tunnel."""

from __future__ import annotations

import argparse
import os
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_ROOT = Path(__file__).resolve().parents[2]
_ROOT_STR = str(_ROOT)
if _ROOT_STR not in sys.path:
    sys.path.insert(0, _ROOT_STR)

from core.config import CONFIG

MAX_PAYLOAD = 4096


def ensure_newline(payload: bytes) -> bytes:
    if payload.endswith(b"\n"):
        return payload
    return payload + b"\n"


def truncate_payload(payload: bytes) -> bytes:
    if len(payload) <= MAX_PAYLOAD:
        return payload
    trimmed = payload[:MAX_PAYLOAD]
    if trimmed[-1:] != b"\n":
        trimmed = trimmed[:-1] + b"\n"
    return trimmed


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Interactive Drone plaintext console")
    parser.add_argument(
        "--host",
        default="127.0.0.1",
        help="Destination host for plaintext telemetry (defaults to local proxy)",
    )
    parser.add_argument("--tx-port", type=int, default=CONFIG["DRONE_PLAINTEXT_TX"], help="Port to send telemetry lines")
    parser.add_argument("--rx-port", type=int, default=CONFIG["DRONE_PLAINTEXT_RX"], help="Port receiving command lines")
    parser.add_argument("--expect", type=int, default=0, help="Exit automatically after receiving N lines")
    parser.add_argument("--verbose", action="store_true", help="Enable debug output to stderr")
    return parser


def main() -> None:
    args = build_parser().parse_args()

    done = threading.Event()
    recv_count = 0
    recv_lock = threading.Lock()

    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx_sock.bind(("0.0.0.0", args.rx_port))
    except OSError as exc:
        sys.stderr.write(
            f"Failed to bind local RX port {args.rx_port}. Is another console or app already using it? ({exc})\n"
        )
        rx_sock.close()
        sys.exit(1)
    rx_sock.settimeout(0.1)

    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    sys.stderr.write(
        f"[Drone TTY] Sending to {args.host}:{args.tx_port} | Listening on 0.0.0.0:{args.rx_port}\n"
    )
    sys.stderr.flush()

    def debug(msg: str) -> None:
        if args.verbose:
            sys.stderr.write(msg + "\n")
            sys.stderr.flush()

    def reader() -> None:
        nonlocal recv_count
        while not done.is_set():
            try:
                data, _ = rx_sock.recvfrom(65535)
            except socket.timeout:
                continue
            except OSError:
                break
            if not data:
                continue
            trimmed = data[:MAX_PAYLOAD]
            text = trimmed.decode("utf-8", errors="replace")
            if not text.endswith("\n"):
                text += "\n"
            sys.stdout.write(text)
            sys.stdout.flush()
            if args.expect:
                with recv_lock:
                    recv_count += 1
                    if recv_count >= args.expect:
                        done.set()
                        os._exit(0)
        try:
            rx_sock.close()
        except OSError:
            pass

    thread = threading.Thread(target=reader, daemon=True)
    thread.start()

    try:
        for line in sys.stdin:
            if done.is_set():
                break
            encoded = ensure_newline(line.encode("utf-8", errors="replace"))
            encoded = truncate_payload(encoded)
            try:
                tx_sock.sendto(encoded, (args.host, args.tx_port))
            except OSError as exc:
                debug(f"sendto failed: {exc}; retrying in 0.5s")
                time.sleep(0.5)
                continue
    except KeyboardInterrupt:
        pass
    finally:
        done.set()
        try:
            tx_sock.close()
        except OSError:
            pass
        thread.join(timeout=0.2)


if __name__ == "__main__":
    main()

============================================================

FILE 40/58: tools\manual_4term\encrypted_bridge_logger.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\encrypted_bridge_logger.py
Size: 4,355 bytes
Modified: 2025-09-25 19:32:10
------------------------------------------------------------
"""Encrypted UDP bridge logger for manual 4-terminal testing.

Listens on two UDP ports (drone->GCS and GCS->drone), forwards the
packets to their true destinations, and prints concise metadata so you
can verify encrypted traffic is flowing in both directions.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from dataclasses import dataclass
from typing import Tuple

_LOG_BYTES_DEFAULT = 32
_BUFFER_SIZE = 2048


@dataclass
class BridgeConfig:
    listen_addr: Tuple[str, int]
    forward_addr: Tuple[str, int]
    label: str


def _format_bytes(data: bytes, limit: int) -> str:
    clipped = data[:limit]
    hex_preview = clipped.hex()
    if len(data) > limit:
        return f"{hex_preview}... ({len(data)} bytes)"
    return f"{hex_preview} ({len(data)} bytes)"


def _bridge_loop(cfg: BridgeConfig, log_bytes: int, shutdown: threading.Event) -> None:
    packet_count = 0
    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as listener, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as forwarder:
        listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        listener.bind(cfg.listen_addr)
        listener.settimeout(0.5)

        print(f"[{cfg.label}] Listening on {cfg.listen_addr[0]}:{cfg.listen_addr[1]} -> forwarding to {cfg.forward_addr[0]}:{cfg.forward_addr[1]}")
        while not shutdown.is_set():
            try:
                data, addr = listener.recvfrom(_BUFFER_SIZE)
            except socket.timeout:
                continue
            except OSError as exc:
                if not shutdown.is_set():
                    print(f"[{cfg.label}] Socket error: {exc}")
                break

            packet_count += 1
            timestamp = time.strftime("%H:%M:%S")
            preview = _format_bytes(data, log_bytes)
            print(f"[{cfg.label}] {timestamp} #{packet_count} from {addr[0]}:{addr[1]} -> {preview}")

            try:
                forwarder.sendto(data, cfg.forward_addr)
            except OSError as exc:
                print(f"[{cfg.label}] Forward error: {exc}")
                break

        print(f"[{cfg.label}] Shutdown (processed {packet_count} packets)")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Log encrypted packets while forwarding between proxies")
    parser.add_argument("--d2g-listen", type=int, required=True, help="Port to bind for Drone -> GCS traffic")
    parser.add_argument("--d2g-forward", required=True, help="host:port to forward Drone -> GCS packets")
    parser.add_argument("--g2d-listen", type=int, required=True, help="Port to bind for GCS -> Drone traffic")
    parser.add_argument("--g2d-forward", required=True, help="host:port to forward GCS -> Drone packets")
    parser.add_argument("--log-bytes", type=int, default=_LOG_BYTES_DEFAULT, help="Number of ciphertext bytes to preview (default: %(default)s)")
    return parser.parse_args()


def _parse_host_port(value: str) -> Tuple[str, int]:
    if ":" not in value:
        raise ValueError(f"Expected host:port, got '{value}'")
    host, port_str = value.rsplit(":", 1)
    return host, int(port_str)


def main() -> None:
    args = parse_args()

    try:
        d2g_forward = _parse_host_port(args.d2g_forward)
        g2d_forward = _parse_host_port(args.g2d_forward)
    except ValueError as exc:
        print(f"Argument error: {exc}")
        sys.exit(1)

    shutdown = threading.Event()
    bridges = [
        BridgeConfig(("0.0.0.0", args.d2g_listen), d2g_forward, "Drone->GCS"),
        BridgeConfig(("0.0.0.0", args.g2d_listen), g2d_forward, "GCS->Drone"),
    ]

    threads = [threading.Thread(target=_bridge_loop, args=(cfg, args.log_bytes, shutdown), daemon=True) for cfg in bridges]

    print("Starting encrypted bridge logger. Press Ctrl+C to stop.")
    for thread in threads:
        thread.start()

    try:
        while any(thread.is_alive() for thread in threads):
            time.sleep(0.5)
    except KeyboardInterrupt:
        print("\nInterrupt received, shutting down...")
        shutdown.set()
        for thread in threads:
            thread.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 41/58: tools\manual_4term\gcs_ground_station_sim.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\gcs_ground_station_sim.py
Size: 3,927 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Minimal GCS ground-station simulator for manual quad-terminal tests.

Sends a rotating set of high-level commands to the GCS proxy plaintext
port and prints any telemetry frames returned from the drone proxy via
GCS_PLAINTEXT_RX.
"""
from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from typing import List

_DEFAULT_COMMANDS: List[str] = [
    "CMD_ARM",
    "CMD_TAKEOFF_ALT_30",
    "CMD_SET_HEADING_090",
    "CMD_LOITER_HOLD",
    "CMD_RTL",
]

_BUFFER_SIZE = 2048


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Simulate a GCS app talking to the proxy")
    parser.add_argument("--send-port", type=int, required=True, help="Port where GCS proxy listens for plaintext commands")
    parser.add_argument("--recv-port", type=int, required=True, help="Port where GCS proxy delivers decrypted telemetry")
    parser.add_argument("--host", default="127.0.0.1", help="Loopback host for both directions (default: %(default)s)")
    parser.add_argument("--interval", type=float, default=2.0, help="Seconds between commands (default: %(default)s)")
    parser.add_argument("--loop", action="store_true", help="Loop command list forever (default: stop after one pass)")
    return parser.parse_args()


def command_loop(sock: socket.socket, host: str, port: int, interval: float, loop: bool, shutdown: threading.Event) -> None:
    print(f"[GCS] Sending plaintext commands to {host}:{port}")
    while not shutdown.is_set():
        for command in _DEFAULT_COMMANDS:
            try:
                payload = command.encode("utf-8")
                sock.sendto(payload, (host, port))
                timestamp = time.strftime("%H:%M:%S")
                print(f"[GCS] {timestamp} -> {command}")
            except OSError as exc:
                print(f"[GCS] Send error: {exc}")
                shutdown.set()
                break
            if shutdown.wait(interval):
                break
        if not loop:
            break
    print("[GCS] Command loop stopped")


def telemetry_loop(sock: socket.socket, shutdown: threading.Event) -> None:
    print("[GCS] Listening for decrypted telemetry...")
    sock.settimeout(0.5)
    while not shutdown.is_set():
        try:
            data, addr = sock.recvfrom(_BUFFER_SIZE)
        except socket.timeout:
            continue
        except OSError as exc:
            if not shutdown.is_set():
                print(f"[GCS] Receive error: {exc}")
            break
        timestamp = time.strftime("%H:%M:%S")
        try:
            text = data.decode("utf-8", errors="replace")
        except Exception:
            text = data.hex()
        print(f"[GCS] {timestamp} <- {text} (from {addr[0]}:{addr[1]})")
    print("[GCS] Telemetry listener stopped")


def main() -> None:
    args = parse_args()

    shutdown = threading.Event()

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as send_sock, \
            socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as recv_sock:
        recv_sock.bind(("0.0.0.0", args.recv_port))

        sender = threading.Thread(target=command_loop, args=(send_sock, args.host, args.send_port, args.interval, args.loop, shutdown), daemon=True)
        receiver = threading.Thread(target=telemetry_loop, args=(recv_sock, shutdown), daemon=True)

        sender.start()
        receiver.start()

        print("[GCS] Ground-station simulator running. Press Ctrl+C to exit.")
        try:
            while sender.is_alive() or receiver.is_alive():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\n[GCS] Interrupt received, shutting down")
            shutdown.set()
            sender.join(timeout=1.0)
            receiver.join(timeout=1.0)


if __name__ == "__main__":
    main()

============================================================

FILE 42/58: tools\manual_4term\gcs_tty.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\gcs_tty.py
Size: 4,207 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""Minimal interactive CLI for GCS plaintext tunnel."""

from __future__ import annotations

import argparse
import os
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_ROOT = Path(__file__).resolve().parents[2]
_ROOT_STR = str(_ROOT)
if _ROOT_STR not in sys.path:
    sys.path.insert(0, _ROOT_STR)

from core.config import CONFIG

MAX_PAYLOAD = 4096


def ensure_newline(payload: bytes) -> bytes:
    if payload.endswith(b"\n"):
        return payload
    return payload + b"\n"


def truncate_payload(payload: bytes) -> bytes:
    if len(payload) <= MAX_PAYLOAD:
        return payload
    trimmed = payload[:MAX_PAYLOAD]
    if trimmed[-1:] != b"\n":
        trimmed = trimmed[:-1] + b"\n"
    return trimmed


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Interactive GCS plaintext console")
    parser.add_argument(
        "--host",
        default="127.0.0.1",
        help="Destination host for plaintext commands (defaults to local proxy)",
    )
    parser.add_argument("--tx-port", type=int, default=CONFIG["GCS_PLAINTEXT_TX"], help="Port to send plaintext commands")
    parser.add_argument("--rx-port", type=int, default=CONFIG["GCS_PLAINTEXT_RX"], help="Port receiving telemetry lines")
    parser.add_argument("--expect", type=int, default=0, help="Exit automatically after receiving N lines")
    parser.add_argument("--verbose", action="store_true", help="Enable debug output to stderr")
    return parser


def main() -> None:
    args = build_parser().parse_args()

    done = threading.Event()
    recv_count = 0
    recv_lock = threading.Lock()

    rx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        rx_sock.bind(("0.0.0.0", args.rx_port))
    except OSError as exc:
        sys.stderr.write(
            f"Failed to bind local RX port {args.rx_port}. Is another console or app already using it? ({exc})\n"
        )
        rx_sock.close()
        sys.exit(1)
    rx_sock.settimeout(0.1)

    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    sys.stderr.write(
        f"[GCS TTY] Sending to {args.host}:{args.tx_port} | Listening on 0.0.0.0:{args.rx_port}\n"
    )
    sys.stderr.flush()

    def debug(msg: str) -> None:
        if args.verbose:
            sys.stderr.write(msg + "\n")
            sys.stderr.flush()

    def reader() -> None:
        nonlocal recv_count
        while not done.is_set():
            try:
                data, _ = rx_sock.recvfrom(65535)
            except socket.timeout:
                continue
            except OSError:
                break
            if not data:
                continue
            trimmed = data[:MAX_PAYLOAD]
            text = trimmed.decode("utf-8", errors="replace")
            if not text.endswith("\n"):
                text += "\n"
            sys.stdout.write(text)
            sys.stdout.flush()
            if args.expect:
                with recv_lock:
                    recv_count += 1
                    if recv_count >= args.expect:
                        done.set()
                        os._exit(0)
        try:
            rx_sock.close()
        except OSError:
            pass

    thread = threading.Thread(target=reader, daemon=True)
    thread.start()

    try:
        for line in sys.stdin:
            if done.is_set():
                break
            encoded = ensure_newline(line.encode("utf-8", errors="replace"))
            encoded = truncate_payload(encoded)
            try:
                tx_sock.sendto(encoded, (args.host, args.tx_port))
            except OSError as exc:
                debug(f"sendto failed: {exc}; retrying in 0.5s")
                time.sleep(0.5)
                continue
    except KeyboardInterrupt:
        pass
    finally:
        done.set()
        try:
            tx_sock.close()
        except OSError:
            pass
        thread.join(timeout=0.2)


if __name__ == "__main__":
    main()

============================================================

FILE 43/58: tools\manual_4term\launch_manual_test.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\manual_4term\launch_manual_test.py
Size: 9,824 bytes
Modified: 2025-09-25 19:29:08
------------------------------------------------------------
"""Launch a four-terminal manual end-to-end test for the PQC proxy.

Processes spawned:
  1. GCS proxy (core.run_proxy gcs)
  2. Drone proxy (core.run_proxy drone)
  3. GCS ground-station simulator (commands -> proxy, telemetry <- proxy)
  4. Drone autopilot simulator (telemetry -> proxy, commands <- proxy)

Optional fifth process:
  - Encrypted bridge logger that sits between the proxies and prints
    ciphertext metadata while forwarding packets in both directions.
"""
from __future__ import annotations

import argparse
import os
import signal
import subprocess
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

REPO_ROOT = Path(__file__).resolve().parents[2]
MANUAL_DIR = Path(__file__).resolve().parent
DEFAULT_SECRETS = REPO_ROOT / "secrets"

PORTS = {
    "TCP_HANDSHAKE": 46000,
    "GCS_ENCRYPTED_BIND": 46011,
    "DRONE_ENCRYPTED_BIND": 46012,
    "INTERCEPT_D2G_LISTEN": 46001,
    "INTERCEPT_G2D_LISTEN": 46002,
    "GCS_PLAINTEXT_TX": 47001,
    "GCS_PLAINTEXT_RX": 47002,
    "DRONE_PLAINTEXT_TX": 47003,
    "DRONE_PLAINTEXT_RX": 47004,
}

_BUFFERED_TEXT = bool(os.name != "nt")  # On Windows CREATE_NEW_CONSOLE forbids capturing


@dataclass
class ProcessSpec:
    label: str
    command: List[str]
    env: Dict[str, str]
    new_window: bool


@dataclass
class ProcessHandle:
    spec: ProcessSpec
    process: subprocess.Popen
    pump_thread: Optional[threading.Thread]


def _ensure_identity(suite: str, secrets_dir: Path) -> None:
    secret_path = secrets_dir / "gcs_signing.key"
    public_path = secrets_dir / "gcs_signing.pub"
    if secret_path.exists() and public_path.exists():
        return

    print(f"[setup] Generating GCS signing identity in {secrets_dir}")
    secrets_dir.mkdir(parents=True, exist_ok=True)
    cmd = [sys.executable, "-m", "core.run_proxy", "init-identity", "--suite", suite, "--output-dir", str(secrets_dir)]
    result = subprocess.run(cmd, cwd=REPO_ROOT)
    if result.returncode != 0:
        raise RuntimeError("Failed to initialise GCS signing identity")


def _stream_output(label: str, proc: subprocess.Popen) -> None:
    assert proc.stdout is not None
    for line in proc.stdout:
        print(f"[{label}] {line.rstrip()}" )
    proc.stdout.close()


def _launch_process(spec: ProcessSpec, cwd: Path) -> ProcessHandle:
    creationflags = 0
    stdout = None
    stderr = None

    if spec.new_window and os.name == "nt":
        creationflags = subprocess.CREATE_NEW_CONSOLE  # type: ignore[attr-defined]
    elif spec.new_window:
        print(f"[warn] '--new-windows' requested but not supported on this platform. Running inline instead for {spec.label}.")

    if not spec.new_window:
        stdout = subprocess.PIPE
        stderr = subprocess.STDOUT

    proc = subprocess.Popen(
        spec.command,
        cwd=cwd,
        env=spec.env,
        stdout=stdout,
        stderr=stderr,
        text=True,
        bufsize=1,
    )

    pump_thread: Optional[threading.Thread] = None
    if stdout is not None and proc.stdout is not None:
        pump_thread = threading.Thread(target=_stream_output, args=(spec.label, proc), daemon=True)
        pump_thread.start()

    return ProcessHandle(spec, proc, pump_thread)


def _build_env(overrides: Dict[str, int]) -> Dict[str, str]:
    env = os.environ.copy()
    for key, value in overrides.items():
        env[key] = str(value)
    return env


def _build_specs(args: argparse.Namespace, secrets_dir: Path) -> List[ProcessSpec]:
    secret_path = secrets_dir / "gcs_signing.key"
    public_path = secrets_dir / "gcs_signing.pub"

    # Base overrides shared by both proxies
    base_overrides = {
        "TCP_HANDSHAKE_PORT": PORTS["TCP_HANDSHAKE"],
        "DRONE_HOST": "127.0.0.1",
        "GCS_HOST": "127.0.0.1",
    }

    if args.with_intercept:
        drone_peer_port = PORTS["INTERCEPT_D2G_LISTEN"]
        gcs_peer_port = PORTS["INTERCEPT_G2D_LISTEN"]
    else:
        drone_peer_port = PORTS["GCS_ENCRYPTED_BIND"]
        gcs_peer_port = PORTS["DRONE_ENCRYPTED_BIND"]

    gcs_env = _build_env({
        **base_overrides,
        "UDP_GCS_RX": PORTS["GCS_ENCRYPTED_BIND"],
        "UDP_DRONE_RX": gcs_peer_port,
        "GCS_PLAINTEXT_TX": PORTS["GCS_PLAINTEXT_TX"],
        "GCS_PLAINTEXT_RX": PORTS["GCS_PLAINTEXT_RX"],
    })

    drone_env = _build_env({
        **base_overrides,
        "UDP_DRONE_RX": PORTS["DRONE_ENCRYPTED_BIND"],
        "UDP_GCS_RX": drone_peer_port,
        "DRONE_PLAINTEXT_TX": PORTS["DRONE_PLAINTEXT_TX"],
        "DRONE_PLAINTEXT_RX": PORTS["DRONE_PLAINTEXT_RX"],
    })

    specs: List[ProcessSpec] = []

    gcs_cmd = [sys.executable, "-m", "core.run_proxy", "gcs", "--suite", args.suite]
    if secret_path != DEFAULT_SECRETS / "gcs_signing.key":
        gcs_cmd += ["--gcs-secret-file", str(secret_path)]
    specs.append(ProcessSpec("GCS", gcs_cmd, gcs_env, args.new_windows))

    drone_cmd = [
        sys.executable,
        "-m",
        "core.run_proxy",
        "drone",
        "--suite",
        args.suite,
        "--peer-pubkey-file",
        str(public_path),
    ]
    specs.append(ProcessSpec("DRONE", drone_cmd, drone_env, args.new_windows))

    gcs_sim_cmd = [
        sys.executable,
        str(MANUAL_DIR / "gcs_ground_station_sim.py"),
        "--send-port",
        str(PORTS["GCS_PLAINTEXT_TX"]),
        "--recv-port",
        str(PORTS["GCS_PLAINTEXT_RX"]),
        "--loop",
    ]
    specs.append(ProcessSpec("GCS-SIM", gcs_sim_cmd, os.environ.copy(), args.new_windows))

    drone_sim_cmd = [
        sys.executable,
        str(MANUAL_DIR / "drone_autopilot_sim.py"),
        "--send-port",
        str(PORTS["DRONE_PLAINTEXT_TX"]),
        "--recv-port",
        str(PORTS["DRONE_PLAINTEXT_RX"]),
        "--loop",
    ]
    specs.append(ProcessSpec("DRONE-SIM", drone_sim_cmd, os.environ.copy(), args.new_windows))

    if args.with_intercept:
        bridge_cmd = [
            sys.executable,
            str(MANUAL_DIR / "encrypted_bridge_logger.py"),
            "--d2g-listen",
            str(PORTS["INTERCEPT_D2G_LISTEN"]),
            "--d2g-forward",
            f"127.0.0.1:{PORTS['GCS_ENCRYPTED_BIND']}",
            "--g2d-listen",
            str(PORTS["INTERCEPT_G2D_LISTEN"]),
            "--g2d-forward",
            f"127.0.0.1:{PORTS['DRONE_ENCRYPTED_BIND']}",
        ]
        specs.append(ProcessSpec("BRIDGE", bridge_cmd, os.environ.copy(), args.new_windows))

    return specs


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Launch a manual four-terminal PQC proxy test")
    parser.add_argument("--suite", default="cs-kyber768-aesgcm-dilithium3", help="Cryptographic suite for both proxies (default: %(default)s)")
    parser.add_argument("--secrets-dir", default=str(DEFAULT_SECRETS), help="Directory containing GCS keypair (default: %(default)s)")
    parser.add_argument("--no-auto-init", action="store_true", help="Do not auto-generate GCS keys if missing")
    parser.add_argument("--with-intercept", action="store_true", help="Launch the encrypted bridge logger between proxies")
    parser.add_argument("--new-windows", action="store_true", help="Attempt to open each process in a new console window (Windows only)")
    return parser.parse_args()


def print_banner(args: argparse.Namespace) -> None:
    print("Manual PQC proxy test launcher")
    print("Repository root:", REPO_ROOT)
    print("Suite:", args.suite)
    print("Secrets directory:", args.secrets_dir)
    print("Intercept enabled:" if args.with_intercept else "Intercept disabled", args.with_intercept)
    print("Ports in use:")
    for key, value in PORTS.items():
        print(f"  {key:<24} {value}")
    print()
    print("Press Ctrl+C in this window to stop all managed processes.")


def main() -> None:
    args = parse_args()
    secrets_dir = Path(args.secrets_dir).resolve()

    if not args.no_auto_init:
        _ensure_identity(args.suite, secrets_dir)

    print_banner(args)

    specs = _build_specs(args, secrets_dir)
    handles: List[ProcessHandle] = []

    try:
        for spec in specs:
            handle = _launch_process(spec, REPO_ROOT)
            handles.append(handle)
            print(f"[launch] Started {spec.label} (PID {handle.process.pid})")

        while True:
            for handle in list(handles):
                code = handle.process.poll()
                if code is not None:
                    print(f"[exit] {handle.spec.label} exited with code {code}")
                    handles.remove(handle)
            if not handles:
                print("[launcher] All processes exited. Stopping launcher.")
                break
            time.sleep(0.5)

    except KeyboardInterrupt:
        print("\n[launcher] Interrupt received, terminating child processes...")
    finally:
        for handle in handles:
            if handle.process.poll() is None:
                try:
                    if os.name == "nt" and hasattr(signal, "CTRL_BREAK_EVENT"):
                        handle.process.send_signal(signal.CTRL_BREAK_EVENT)
                        time.sleep(0.3)
                    handle.process.terminate()
                except Exception:
                    pass
        time.sleep(0.5)
        for handle in handles:
            if handle.process.poll() is None:
                try:
                    handle.process.kill()
                except Exception:
                    pass


if __name__ == "__main__":
    main()

============================================================

FILE 44/58: tools\markers.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\markers.py
Size: 3,323 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""Marker sink implementations for external power instrumentation.

Used by benchmark harnesses to emit precise START/END markers that align with
external power meters or logging systems.
"""

from __future__ import annotations

from typing import Protocol
import socket


class MarkerSink(Protocol):
    """Protocol for marker sinks used to signal run boundaries."""

    def start(self, run_id: str, t_wall_ns: int) -> None:
        """Emit a run start marker."""

    def end(self, run_id: str, t_wall_ns: int) -> None:
        """Emit a run end marker."""

    def close(self) -> None:  # pragma: no cover - optional hook
        """Optional resource cleanup."""


class NullMarker:
    """Marker sink that discards all events."""

    def start(self, run_id: str, t_wall_ns: int) -> None:  # pragma: no cover - trivial
        return

    def end(self, run_id: str, t_wall_ns: int) -> None:  # pragma: no cover - trivial
        return

    def close(self) -> None:  # pragma: no cover - trivial
        return


class FileMarker:
    """Append START/END markers to a text file."""

    def __init__(self, path: str) -> None:
        self.path = path

    def _write(self, tag: str, run_id: str, t_wall_ns: int) -> None:
        with open(self.path, "a", encoding="utf-8") as handle:
            handle.write(f"{tag} {run_id} {t_wall_ns}\n")

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._write("START", run_id, t_wall_ns)

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._write("END", run_id, t_wall_ns)

    def close(self) -> None:  # pragma: no cover - nothing persistent
        return


class SerialMarker:
    """Write markers to a serial port.

    Requires ``pyserial`` to be installed in the environment.
    """

    def __init__(self, port: str, baud: int = 115_200) -> None:
        import serial  # type: ignore

        self._serial = serial.Serial(port=port, baudrate=baud, timeout=1)

    def _send(self, payload: str) -> None:
        self._serial.write(f"{payload}\n".encode("ascii"))
        self._serial.flush()

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"START {run_id} {t_wall_ns}")

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"END {run_id} {t_wall_ns}")

    def close(self) -> None:
        try:
            self._serial.close()
        except Exception:  # pragma: no cover - best effort cleanup
            pass


class UdpMarker:
    """Send markers over UDP to a remote host."""

    def __init__(self, host_port: str) -> None:
        host, port_str = host_port.split(":", 1)
        self.addr = (host, int(port_str))
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    def _send(self, payload: str) -> None:
        self.sock.sendto(payload.encode("ascii"), self.addr)

    def start(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"START {run_id} {t_wall_ns}")

    def end(self, run_id: str, t_wall_ns: int) -> None:
        self._send(f"END {run_id} {t_wall_ns}")

    def close(self) -> None:
        try:
            self.sock.close()
        except Exception:  # pragma: no cover - best effort cleanup
            pass

============================================================

FILE 45/58: tools\merge_power_csv.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\merge_power_csv.py
Size: 5,656 bytes
Modified: 2025-09-25 21:56:07
------------------------------------------------------------
"""Merge external power meter CSV output with benchmark manifests.

For each manifest.json produced by the benchmark runner, slice the power-meter
CSV to the START/END timestamps and compute aggregate energy statistics.
"""

from __future__ import annotations

import argparse
import csv
import json
import math
from pathlib import Path
from typing import Dict, Iterable, List, Optional


def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(description="Merge benchmark manifests with external power meter CSV data")
+    parser.add_argument("--manifest-dir", required=True, help="Directory containing manifest.json files")
+    parser.add_argument("--meter-csv", required=True, help="Power meter CSV file containing timestamped power samples")
+    parser.add_argument("--time-col", default="timestamp_ns", help="Column name for sample timestamps (nanoseconds)")
+    parser.add_argument("--power-col", default="power_w", help="Column name for power samples (watts)")
+    parser.add_argument("--out", default="benchmarks/out/merged.csv", help="Output CSV path with merged statistics")
+    return parser.parse_args()
+
+
+def load_meter_samples(csv_path: Path, time_col: str, power_col: str) -> List[Dict[str, float]]:
+    rows: List[Dict[str, float]] = []
+    with csv_path.open(newline="", encoding="utf-8") as handle:
+        reader = csv.DictReader(handle)
+        if time_col not in reader.fieldnames or power_col not in reader.fieldnames:
+            raise SystemExit(f"Required columns '{time_col}' and/or '{power_col}' missing from meter CSV")
+        for row in reader:
+            try:
+                t_ns = int(row[time_col])
+                p_w = float(row[power_col])
+            except (TypeError, ValueError) as exc:
+                raise SystemExit(f"Invalid meter row: {row}") from exc
+            rows.append({"t_ns": t_ns, "p_w": p_w})
+    if not rows:
+        print("Warning: meter CSV contained no samples")
+    return rows
+
+
+def slice_samples(samples: Iterable[Dict[str, float]], start_ns: int, end_ns: int) -> List[float]:
+    return [sample["p_w"] for sample in samples if start_ns <= sample["t_ns"] < end_ns]
+
+
+def compute_stats(samples: List[float], start_ns: int, end_ns: int) -> Dict[str, Optional[float]]:
+    duration_s = (end_ns - start_ns) / 1e9
+    if not samples:
+        return {
+            "samples": 0,
+            "avg_w": None,
+            "p95_w": None,
+            "max_w": None,
+            "joules": None,
+            "dur_s": duration_s,
+        }
+
+    sorted_samples = sorted(samples)
+    avg = sum(sorted_samples) / len(sorted_samples)
+    max_val = sorted_samples[-1]
+    p95_index = max(0, min(len(sorted_samples) - 1, math.floor(0.95 * (len(sorted_samples) - 1))))
+    p95_val = sorted_samples[p95_index]
+    joules = avg * duration_s
+    return {
+        "samples": len(sorted_samples),
+        "avg_w": avg,
+        "p95_w": p95_val,
+        "max_w": max_val,
+        "joules": joules,
+        "dur_s": duration_s,
+    }
+
+
+def collect_manifests(manifest_dir: Path) -> List[Dict[str, object]]:
+    manifests = []
+    for manifest_path in manifest_dir.rglob("manifest.json"):
+        data = json.loads(manifest_path.read_text(encoding="utf-8"))
+        data["_manifest_path"] = manifest_path
+        manifests.append(data)
+    if not manifests:
+        raise SystemExit(f"No manifest.json files found under {manifest_dir}")
+    manifests.sort(key=lambda entry: (entry.get("start_wall_ns", 0), entry.get("run_id", "")))
+    return manifests
+
+
+def merge(args: argparse.Namespace) -> None:
+    meter_samples = load_meter_samples(Path(args.meter_csv), args.time_col, args.power_col)
+    manifests = collect_manifests(Path(args.manifest_dir))
+
+    output_rows: List[Dict[str, object]] = []
+    for manifest in manifests:
+        start_ns = int(manifest["start_wall_ns"])
+        end_ns = int(manifest["end_wall_ns"])
+        sliced = slice_samples(meter_samples, start_ns, end_ns)
+        stats = compute_stats(sliced, start_ns, end_ns)
+        row: Dict[str, object] = {
+            "run_id": manifest.get("run_id"),
+            "suite": manifest.get("suite"),
+            "kem": manifest.get("kem"),
+            "sig": manifest.get("sig"),
+            "aead": manifest.get("aead"),
+            "repeat_idx": manifest.get("repeat_idx"),
+            "duration_s": manifest.get("duration_s"),
+            "start_wall_ns": start_ns,
+            "end_wall_ns": end_ns,
+            "manifest_path": str(manifest.get("_manifest_path")),
+            **stats,
+        }
+        output_rows.append(row)
+
+    out_path = Path(args.out)
+    out_path.parent.mkdir(parents=True, exist_ok=True)
+    fieldnames = [
+        "run_id",
+        "suite",
+        "kem",
+        "sig",
+        "aead",
+        "repeat_idx",
+        "duration_s",
+        "start_wall_ns",
+        "end_wall_ns",
+        "samples",
+        "avg_w",
+        "p95_w",
+        "max_w",
+        "joules",
+        "dur_s",
+        "manifest_path",
+    ]
+
+    with out_path.open("w", newline="", encoding="utf-8") as handle:
+        writer = csv.DictWriter(handle, fieldnames=fieldnames)
+        writer.writeheader()
+        for row in output_rows:
+            writer.writerow(row)
+    print(f"Merged {len(output_rows)} manifest entries into {out_path}")
+
+
+def main() -> None:
+    args = parse_args()
+    merge(args)
+
+
+if __name__ == "__main__":
+    main()

============================================================

FILE 46/58: tools\netcapture\drone_capture.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\netcapture\drone_capture.py
Size: 3,434 bytes
Modified: 2025-09-26 09:46:35
------------------------------------------------------------
#!/usr/bin/env python3
"""Linux-oriented capture helper for the drone host (Raspberry Pi).

Usage::

    python tools/netcapture/drone_capture.py --iface wlan0 --duration 30 --out captures/drone

The script shells out to ``tcpdump`` (ubiquitous on Linux) and applies
BPF filters for the PQC handshake TCP port and encrypted UDP ports defined in
``core.config.CONFIG``.  The resulting ``.pcap`` can be inspected with Wireshark
on any workstation.
"""

from __future__ import annotations

import argparse
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Iterable

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG

HANDSHAKE_PORT = int(CONFIG["TCP_HANDSHAKE_PORT"])
ENCRYPTED_PORTS = [int(CONFIG["UDP_GCS_RX"]), int(CONFIG["UDP_DRONE_RX"])]


class CaptureError(RuntimeError):
    pass


def ensure_linux() -> None:
    if sys.platform.startswith("win"):
        raise SystemExit("drone_capture.py is intended for Linux hosts only")


def tcpdump_available() -> bool:
    return shutil.which("tcpdump") is not None


def build_filter() -> str:
    ports = {HANDSHAKE_PORT, *ENCRYPTED_PORTS}
    clauses = []
    for port in sorted(ports):
        clauses.append(f"port {port}")
    return " or ".join(clauses)


def run_tcpdump(iface: str, pcap_path: Path, duration: int) -> None:
    if not tcpdump_available():
        raise CaptureError("tcpdump not found in PATH; install it (sudo apt install tcpdump)")

    bpf = build_filter()
    cmd: Iterable[str] = (
        "tcpdump",
        "-i",
        iface,
        "-w",
        str(pcap_path),
        "-G",
        str(duration),
        "-W",
        "1",
        "-n",
        bpf,
    )
    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    if proc.returncode != 0:
        raise CaptureError(f"tcpdump failed ({proc.returncode})\n{proc.stdout}")


def main() -> None:
    ensure_linux()

    ap = argparse.ArgumentParser(description="Capture handshake/encrypted traffic on the drone host")
    ap.add_argument("--iface", required=True, help="Network interface to capture (e.g., wlan0, eth0)")
    ap.add_argument("--duration", type=int, default=20, help="Capture duration in seconds (default: 20)")
    ap.add_argument(
        "--out",
        type=Path,
        default=Path("captures/drone.pcap"),
        help="Output pcap path (default: captures/drone.pcap)",
    )
    args = ap.parse_args()

    args.out.parent.mkdir(parents=True, exist_ok=True)

    try:
        run_tcpdump(args.iface, args.out, args.duration)
    except CaptureError as exc:
        print(f"\n❌ Capture failed: {exc}\n", file=sys.stderr)
        raise SystemExit(2) from exc

    print("\n✅ Capture complete:")
    print(f"  • {args.out}")
    print("\nTip: start this capture, then launch the proxy. Stop the proxy when you have enough packets, or rerun the capture for another segment.")


if __name__ == "__main__":
    main()

============================================================

FILE 47/58: tools\netcapture\gcs_capture.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\netcapture\gcs_capture.py
Size: 5,576 bytes
Modified: 2025-09-26 09:59:28
------------------------------------------------------------
#!/usr/bin/env python3
r"""Windows-oriented capture helper for the GCS host.

Usage examples
--------------
Collect a 30s capture of handshake + encrypted ports into ``captures\gcs``::

    python tools/netcapture/gcs_capture.py --duration 30 --out captures/gcs

The script prefers ``pktmon`` (ships with Windows 10 2004+) and falls back to
``netsh trace``.  It tries to add filters for the PQC handshake and encrypted
UDP ports defined in ``core.config.CONFIG`` so the traces stay focused.

Outputs
-------
* ``<out>.etl``        Raw ETW capture (always produced)
* ``<out>.pcapng``     Packet capture (when ``pktmon`` is available)
* ``<out>.log``        Text summary (when ``pktmon`` is available)

Prerequisites
-------------
* Run from an elevated PowerShell / Command Prompt (admin rights).
* ``pktmon`` or ``netsh`` must be available in ``PATH`` (Windows built-ins).
"""

from __future__ import annotations

import argparse
import shutil
import subprocess
import sys
import tempfile
import time
from pathlib import Path
from typing import Iterable

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG

HANDSHAKE_PORT = int(CONFIG["TCP_HANDSHAKE_PORT"])
ENCRYPTED_PORTS = [int(CONFIG["UDP_GCS_RX"]), int(CONFIG["UDP_DRONE_RX"])]


class CaptureError(RuntimeError):
    pass


def run(cmd: Iterable[str], *, check: bool = True) -> subprocess.CompletedProcess[str]:
    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    if check and proc.returncode != 0:
        raise CaptureError(f"Command failed ({proc.returncode}): {' '.join(cmd)}\n{proc.stdout}")
    return proc


def ensure_windows() -> None:
    if sys.platform != "win32":
        raise SystemExit("gcs_capture.py is intended for Windows hosts only")


def pktmon_available() -> bool:
    return shutil.which("pktmon") is not None


def netsh_available() -> bool:
    return shutil.which("netsh") is not None


def build_default_output(out_base: Path) -> tuple[Path, Path, Path]:
    etl = out_base.with_suffix(".etl")
    pcap = out_base.with_suffix(".pcapng")
    log = out_base.with_suffix(".log")
    return etl, pcap, log


def run_pktmon(out_base: Path, duration: int) -> list[Path]:
    etl, pcap, log = build_default_output(out_base)

    # Reset previous state to keep output predictable
    run(["pktmon", "stop"], check=False)
    run(["pktmon", "reset"], check=False)

    # Apply lightweight port filters so we only capture the PQC traffic
    filter_ports = sorted({HANDSHAKE_PORT, *ENCRYPTED_PORTS})
    for port in filter_ports:
        run(["pktmon", "filter", "add", "--port", str(port)])

    run(["pktmon", "start", "--etw", "--capture"])
    time.sleep(duration)
    run(["pktmon", "stop"])

    temp_etl = Path("PktMon.etl")
    if temp_etl.exists():
        temp_etl.replace(etl)
    else:
        raise CaptureError("pktmon did not produce PktMon.etl")

    run(["pktmon", "format", str(etl), "-o", str(pcap)])
    run(["pktmon", "format", str(etl), "-o", str(log), "--text"])

    run(["pktmon", "reset"], check=False)
    return [etl, pcap, log]


def run_netsh(out_base: Path, duration: int) -> list[Path]:
    if not netsh_available():
        raise CaptureError("Neither pktmon nor netsh is available; cannot capture")

    etl, _, _ = build_default_output(out_base)
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp = Path(tmpdir) / "trace"
        run(
            [
                "netsh",
                "trace",
                "start",
                "capture=yes",
                "tracefile=" + str(tmp),
                "report=no",
                "maxsize=512",
            ]
        )
        time.sleep(duration)
        run(["netsh", "trace", "stop"])
        raw = tmp.with_suffix(".etl")
        if raw.exists():
            raw.replace(etl)
        else:
            raise CaptureError("netsh trace did not produce an .etl file")
    return [etl]


def main() -> None:
    ensure_windows()

    ap = argparse.ArgumentParser(description="Capture handshake/encrypted traffic on the GCS host")
    ap.add_argument("--duration", type=int, default=20, help="Capture duration in seconds (default: 20)")
    ap.add_argument(
        "--out",
        type=Path,
        default=Path("captures/gcs_capture"),
        help="Output file base name (extensions added automatically)",
    )
    args = ap.parse_args()

    args.out.parent.mkdir(parents=True, exist_ok=True)

    try:
        if pktmon_available():
            produced = run_pktmon(args.out, args.duration)
        else:
            produced = run_netsh(args.out, args.duration)
    except CaptureError as exc:
        print(f"\n❌ Capture failed: {exc}\n", file=sys.stderr)
        raise SystemExit(2) from exc

    print("\n✅ Capture complete. Generated files:")
    for path in produced:
        print(f"  • {path}")
    print(
        "\nTip: start this capture, then launch the proxy. Stop the proxy and re-run the capture if you need multiple segments."
    )


if __name__ == "__main__":
    main()

============================================================

FILE 48/58: tools\packet_interceptor.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\packet_interceptor.py
Size: 2,494 bytes
Modified: 2025-09-25 16:20:53
------------------------------------------------------------
# tools/packet_interceptor.py
"""
A packet interceptor that sits between proxy components to monitor encrypted traffic.
This acts as a transparent UDP forwarder that logs all packets passing through.
"""
import socket
import sys
import time
import threading

def main():
    if len(sys.argv) != 4:
        print(f"Usage: python {sys.argv[0]} <listen_port> <forward_to_host> <forward_to_port>")
        print("Example: python packet_interceptor.py 45899 127.0.0.1 45801")
        print("  This listens on 45899 and forwards everything to 127.0.0.1:45801")
        sys.exit(1)

    try:
        listen_port = int(sys.argv[1])
        forward_host = sys.argv[2]
        forward_port = int(sys.argv[3])
    except ValueError as e:
        print(f"Error: Invalid arguments: {e}")
        sys.exit(1)

    print(f"--- 🔍 Packet Interceptor ---")
    print(f"Listening on 0.0.0.0:{listen_port}")
    print(f"Forwarding all traffic to {forward_host}:{forward_port}")
    print("Press Ctrl+C to stop.")
    print()

    packet_count = 0

    try:
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as listener:
            listener.bind(('0.0.0.0', listen_port))
            
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as forwarder:
                while True:
                    data, addr = listener.recvfrom(2048)
                    packet_count += 1
                    timestamp = time.strftime("%H:%M:%S")
                    
                    print(f"[{timestamp}] INTERCEPTED Packet #{packet_count}:")
                    print(f"  From: {addr[0]}:{addr[1]}")
                    print(f"  Size: {len(data)} bytes")
                    print(f"  Data (hex): {data[:32].hex()}...")
                    print(f"  Forwarding to {forward_host}:{forward_port}")
                    
                    # Forward the packet
                    try:
                        forwarder.sendto(data, (forward_host, forward_port))
                        print(f"  ✅ Forwarded successfully")
                    except Exception as e:
                        print(f"  ❌ Forward failed: {e}")
                    print()

    except OSError as e:
        print(f"\n❌ Error binding to port {listen_port}: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nInterceptor stopped. Processed {packet_count} packets.")
        sys.exit(0)

if __name__ == "__main__":
    main()

============================================================

FILE 49/58: tools\power_hooks.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\power_hooks.py
Size: 208 bytes
Modified: 2025-09-24 15:32:25
------------------------------------------------------------
# Placeholder for energy measurements; intentionally empty to avoid fake data.
class PowerHook:
    def __enter__(self): return self
    def __exit__(self, *exc): return False
    def sample(self): return {}

============================================================

FILE 50/58: tools\prepare_matrix_keys.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\prepare_matrix_keys.py
Size: 3,043 bytes
Modified: 2025-09-26 19:54:12
------------------------------------------------------------
#!/usr/bin/env python3
"""Generate per-suite signing identities for matrix tests.

Creates `gcs_signing.key`/`gcs_signing.pub` pairs under
`secrets/matrix/<safe_suite>/` so both the GCS and drone proxies can
reuse deterministic file locations during automated matrix runs.
"""
from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path

from core.suites import list_suites

REPO_ROOT = Path(__file__).resolve().parents[1]


def safe_suite_name(name: str) -> str:
    return "".join(ch if ch.isalnum() or ch in ("-", "_") else "_" for ch in name)


def ensure_identity(suite: str, out_root: Path, *, force: bool = False) -> None:
    safe = safe_suite_name(suite)
    suite_dir = out_root / safe
    secret_path = suite_dir / "gcs_signing.key"
    public_path = suite_dir / "gcs_signing.pub"

    if not force and secret_path.exists() and public_path.exists():
        print(f"[keys] Reusing existing signing identity for {suite} ({suite_dir})")
        return

    print(f"[keys] Generating signing identity for {suite} -> {suite_dir}")
    suite_dir.mkdir(parents=True, exist_ok=True)

    cmd = [
        sys.executable,
        "-m",
        "core.run_proxy",
        "init-identity",
        "--suite",
        suite,
        "--output-dir",
        str(suite_dir),
    ]
    result = subprocess.run(cmd, cwd=REPO_ROOT)
    if result.returncode != 0:
        raise SystemExit(f"Failed to generate signing identity for {suite}")

    if not secret_path.exists() or not public_path.exists():
        raise SystemExit(f"Generated signing identity for {suite} is missing files in {suite_dir}")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Prepare signing identities for matrix tests")
    parser.add_argument(
        "--suite",
        action="append",
        help="Suite ID to generate (may be provided multiple times). Defaults to all registered suites.",
    )
    parser.add_argument(
        "--out-root",
        default=str(REPO_ROOT / "secrets" / "matrix"),
        help="Output directory for matrix key material (default: secrets/matrix)",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Regenerate identities even if files already exist",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    if args.suite:
        suites = list(dict.fromkeys(args.suite))
    else:
        suites = list(list_suites().keys())

    out_root = Path(args.out_root).expanduser()
    if not out_root.is_absolute():
        out_root = (REPO_ROOT / out_root).resolve()
    else:
        out_root.mkdir(parents=True, exist_ok=True)

    out_root.mkdir(parents=True, exist_ok=True)

    for suite in suites:
        ensure_identity(suite, out_root, force=args.force)

    print(f"[keys] Complete. Generated {len(suites)} suites in {out_root}")


if __name__ == "__main__":
    main()

============================================================

FILE 51/58: tools\scaffold_repo.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\scaffold_repo.py
Size: 17,074 bytes
Modified: 2025-09-24 15:32:18
------------------------------------------------------------
# tools/scaffold_repo.py
# Create planned folders/files that aren't in the current tree.
# Safe by default: won't overwrite unless --force is given.

import argparse, os, sys, stat, textwrap
from pathlib import Path
ROOT = Path(__file__).resolve().parents[1]

def write(path: Path, content: str, force=False):
    path.parent.mkdir(parents=True, exist_ok=True)
    if path.exists() and not force:
        print(f"skip  (exists) {path}")
        return False
    path.write_text(textwrap.dedent(content).lstrip(), encoding="utf-8", newline="\n")
    print(f"write {path}")
    return True

def make_executable(path: Path):
    try:
        path.chmod(path.stat().st_mode | stat.S_IEXEC)
    except Exception:
        pass  # windows ok

def main(force=False):
    wrote = 0

    # ---------- core additions ----------
    wrote += write(ROOT / "core" / "project_config.py", """
        # Thin shim so planned path 'project_config.py' exists without breaking tests.
        # Source of truth remains core/config.py
        from .config import CONFIG
        __all__ = ["CONFIG"]
    """, force)

    wrote += write(ROOT / "core" / "logging_utils.py", """
        import json, logging, sys, time
        from typing import Any, Dict

        class JsonFormatter(logging.Formatter):
            def format(self, record: logging.LogRecord) -> str:
                payload = {
                    "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(record.created)),
                    "level": record.levelname,
                    "name": record.name,
                    "msg": record.getMessage(),
                }
                if record.exc_info:
                    payload["exc_info"] = self.formatException(record.exc_info)
                # Allow extra fields via record.__dict__ (filtered)
                for k, v in record.__dict__.items():
                    if k not in ("msg", "args", "exc_info", "exc_text", "stack_info", "stack_level", "created",
                                 "msecs", "relativeCreated", "levelno", "levelname", "pathname", "filename",
                                 "module", "lineno", "funcName", "thread", "threadName", "processName", "process"):
                        try:
                            json.dumps({k: v})
                            payload[k] = v
                        except Exception:
                            payload[k] = str(v)
                return json.dumps(payload)

        def get_logger(name: str = "pqc") -> logging.Logger:
            logger = logging.getLogger(name)
            if logger.handlers:
                return logger
            logger.setLevel(logging.INFO)
            h = logging.StreamHandler(sys.stdout)
            h.setFormatter(JsonFormatter())
            logger.addHandler(h)
            logger.propagate = False
            return logger

        # Very small metrics hook (no deps)
        class Counter:
            def __init__(self): self.value = 0
            def inc(self, n: int = 1): self.value += n

        class Gauge:
            def __init__(self): self.value = 0
            def set(self, v: float): self.value = v

        class Metrics:
            def __init__(self):
                self.counters = {}
                self.gauges = {}
            def counter(self, name: str) -> Counter:
                self.counters.setdefault(name, Counter()); return self.counters[name]
            def gauge(self, name: str) -> Gauge:
                self.gauges.setdefault(name, Gauge()); return self.gauges[name]

        METRICS = Metrics()
    """, force)

    # ---------- wrappers (no-arg launchers) ----------
    WRAPPER_MAP = {
        # drone
        "drone/wrappers/drone_kyber_512.py":        "cs-kyber512-aesgcm-dilithium2",
        "drone/wrappers/drone_kyber_768.py":        "cs-kyber768-aesgcm-dilithium3",
        "drone/wrappers/drone_kyber_1024.py":       "cs-kyber1024-aesgcm-dilithium5",
        "drone/wrappers/drone_dilithium2.py":       "cs-kyber512-aesgcm-dilithium2",
        "drone/wrappers/drone_dilithium3.py":       "cs-kyber768-aesgcm-dilithium3",
        "drone/wrappers/drone_dilithium5.py":       "cs-kyber1024-aesgcm-dilithium5",
        "drone/wrappers/drone_falcon512.py":        "cs-kyber768-aesgcm-falcon512",
        "drone/wrappers/drone_falcon1024.py":       "cs-kyber1024-aesgcm-falcon1024",
        "drone/wrappers/drone_sphincs_sha2_128f.py":"cs-kyber512-aesgcm-sphincs128f_sha2",
        "drone/wrappers/drone_sphincs_sha2_256f.py":"cs-kyber1024-aesgcm-sphincs256f_sha2",
        # gcs
        "gcs/wrappers/gcs_kyber_512.py":            "cs-kyber512-aesgcm-dilithium2",
        "gcs/wrappers/gcs_kyber_768.py":            "cs-kyber768-aesgcm-dilithium3",
        "gcs/wrappers/gcs_kyber_1024.py":           "cs-kyber1024-aesgcm-dilithium5",
        "gcs/wrappers/gcs_dilithium2.py":           "cs-kyber512-aesgcm-dilithium2",
        "gcs/wrappers/gcs_dilithium3.py":           "cs-kyber768-aesgcm-dilithium3",
        "gcs/wrappers/gcs_dilithium5.py":           "cs-kyber1024-aesgcm-dilithium5",
        "gcs/wrappers/gcs_falcon512.py":            "cs-kyber768-aesgcm-falcon512",
        "gcs/wrappers/gcs_falcon1024.py":           "cs-kyber1024-aesgcm-falcon1024",
        "gcs/wrappers/gcs_sphincs_sha2_128f.py":    "cs-kyber512-aesgcm-sphincs128f_sha2",
        "gcs/wrappers/gcs_sphincs_sha2_256f.py":    "cs-kyber1024-aesgcm-sphincs256f_sha2",
    }
    WRAPPER_TMPL = """
        from core.runner import start
        ROLE="{role}"; SUITE_ID="{suite}"
        if __name__ == "__main__":
            start(ROLE, SUITE_ID)
    """
    for rel, suite in WRAPPER_MAP.items():
        role = "drone" if rel.startswith("drone/") else "gcs"
        wrote += write(ROOT / rel, WRAPPER_TMPL.format(role=role, suite=suite), force)

    # ---------- scripts (bash + ps1) ----------
    wrote += write(ROOT / "drone" / "scripts" / "start_suite.sh", """
        #!/usr/bin/env bash
        set -euo pipefail
        suite="${1:-cs-kyber768-aesgcm-dilithium3}"
        case "$suite" in
          cs-kyber512-aesgcm-dilithium2)  py="drone/wrappers/drone_kyber_512.py";;
          cs-kyber768-aesgcm-dilithium3)  py="drone/wrappers/drone_kyber_768.py";;
          cs-kyber1024-aesgcm-dilithium5) py="drone/wrappers/drone_kyber_1024.py";;
          cs-kyber768-aesgcm-falcon512)   py="drone/wrappers/drone_falcon512.py";;
          cs-kyber1024-aesgcm-falcon1024) py="drone/wrappers/drone_falcon1024.py";;
          cs-kyber512-aesgcm-sphincs128f_sha2) py="drone/wrappers/drone_sphincs_sha2_128f.py";;
          cs-kyber1024-aesgcm-sphincs256f_sha2) py="drone/wrappers/drone_sphincs_sha2_256f.py";;
          *) echo "Unknown suite: $suite"; exit 2;;
        esac
        exec python "$py"
    """, force)
    make_executable(ROOT / "drone" / "scripts" / "start_suite.sh")

    wrote += write(ROOT / "gcs" / "scripts" / "start_suite.sh", """
        #!/usr/bin/env bash
        set -euo pipefail
        suite="${1:-cs-kyber768-aesgcm-dilithium3}"
        case "$suite" in
          cs-kyber512-aesgcm-dilithium2)  py="gcs/wrappers/gcs_kyber_512.py";;
          cs-kyber768-aesgcm-dilithium3)  py="gcs/wrappers/gcs_kyber_768.py";;
          cs-kyber1024-aesgcm-dilithium5) py="gcs/wrappers/gcs_kyber_1024.py";;
          cs-kyber768-aesgcm-falcon512)   py="gcs/wrappers/gcs_falcon512.py";;
          cs-kyber1024-aesgcm-falcon1024) py="gcs/wrappers/gcs_falcon1024.py";;
          cs-kyber512-aesgcm-sphincs128f_sha2) py="gcs/wrappers/gcs_sphincs_sha2_128f.py";;
          cs-kyber1024-aesgcm-sphincs256f_sha2) py="gcs/wrappers/gcs_sphincs_sha2_256f.py";;
          *) echo "Unknown suite: $suite"; exit 2;;
        esac
        exec python "$py"
    """, force)
    make_executable(ROOT / "gcs" / "scripts" / "start_suite.sh")

    wrote += write(ROOT / "drone" / "scripts" / "start_suite.ps1", r"""
        param([string]$suite = "cs-kyber768-aesgcm-dilithium3")
        $map = @{
          "cs-kyber512-aesgcm-dilithium2"      = "drone/wrappers/drone_kyber_512.py"
          "cs-kyber768-aesgcm-dilithium3"      = "drone/wrappers/drone_kyber_768.py"
          "cs-kyber1024-aesgcm-dilithium5"     = "drone/wrappers/drone_kyber_1024.py"
          "cs-kyber768-aesgcm-falcon512"       = "drone/wrappers/drone_falcon512.py"
          "cs-kyber1024-aesgcm-falcon1024"     = "drone/wrappers/drone_falcon1024.py"
          "cs-kyber512-aesgcm-sphincs128f_sha2"= "drone/wrappers/drone_sphincs_sha2_128f.py"
          "cs-kyber1024-aesgcm-sphincs256f_sha2"= "drone/wrappers/drone_sphincs_sha2_256f.py"
        }
        if (-not $map.ContainsKey($suite)) { Write-Error "Unknown suite $suite"; exit 2 }
        python $map[$suite]
    """, force)

    wrote += write(ROOT / "gcs" / "scripts" / "start_suite.ps1", r"""
        param([string]$suite = "cs-kyber768-aesgcm-dilithium3")
        $map = @{
          "cs-kyber512-aesgcm-dilithium2"      = "gcs/wrappers/gcs_kyber_512.py"
          "cs-kyber768-aesgcm-dilithium3"      = "gcs/wrappers/gcs_kyber_768.py"
          "cs-kyber1024-aesgcm-dilithium5"     = "gcs/wrappers/gcs_kyber_1024.py"
          "cs-kyber768-aesgcm-falcon512"       = "gcs/wrappers/gcs_falcon512.py"
          "cs-kyber1024-aesgcm-falcon1024"     = "gcs/wrappers/gcs_falcon1024.py"
          "cs-kyber512-aesgcm-sphincs128f_sha2"= "gcs/wrappers/gcs_sphincs_sha2_128f.py"
          "cs-kyber1024-aesgcm-sphincs256f_sha2"= "gcs/wrappers/gcs_sphincs_sha2_256f.py"
        }
        if (-not $map.ContainsKey($suite)) { Write-Error "Unknown suite $suite"; exit 2 }
        python $map[$suite]
    """, force)

    wrote += write(ROOT / "drone" / "scripts" / "env_check.py", """
        import sys
        status = {}
        try:
            import cryptography
            status["cryptography"] = cryptography.__version__
        except Exception as e:
            status["cryptography"] = f"ERROR: {e}"
        try:
            import oqs.oqs as oqs
            status["oqs-python"] = oqs.oqs_version()
        except Exception as e:
            status["oqs-python"] = f"ERROR: {e}"
        print(status); sys.exit(0 if all("ERROR" not in v for v in status.values()) else 1)
    """, force)
    wrote += write(ROOT / "gcs" / "scripts" / "env_check.py", (ROOT / "drone" / "scripts" / "env_check.py").read_text() if (ROOT / "drone" / "scripts" / "env_check.py").exists() else """
        # same as drone/scripts/env_check.py
    """, force)

    # ---------- ddos stubs ----------
    wrote += write(ROOT / "ddos" / "features.py", """
        def extract_features(pkt_batch):
            raise NotImplementedError("DDoS pipeline is out of scope right now.")
    """, force)
    wrote += write(ROOT / "ddos" / "xgb_stage1.py", """
        def score(features):
            raise NotImplementedError("DDoS stage-1 XGBoost not implemented in this phase.")
    """, force)
    wrote += write(ROOT / "ddos" / "tst_stage2.py", """
        def confirm(features):
            raise NotImplementedError("DDoS stage-2 TST not implemented in this phase.")
    """, force)
    wrote += write(ROOT / "ddos" / "mitigations.py", """
        def apply(action):
            raise NotImplementedError("DDoS mitigations controlled by RL/ops; not implemented yet.")
    """, force)

    # ---------- rl stubs ----------
    wrote += write(ROOT / "rl" / "linucb.py", """
        class LinUCB:
            def __init__(self, *_, **__): raise NotImplementedError("RL is out of scope right now.")
    """, force)
    wrote += write(ROOT / "rl" / "agent_runtime.py", """
        def main(): raise NotImplementedError("RL runtime not implemented in this phase.")
        if __name__ == "__main__": main()
    """, force)
    wrote += write(ROOT / "rl" / "safety.py", """
        def guard(action, mission): raise NotImplementedError("RL safety shield not implemented in this phase.")
    """, force)

    # ---------- tools ----------
    wrote += write(ROOT / "tools" / "bench_cli.py", """
        import os, time
        from core.aead import Sender, Receiver
        from core.suites import header_ids_for_suite, AeadIds
        from core.config import CONFIG
        import os as _os
        def main():
            suite = {"kem_name":"ML-KEM-768","sig_name":"ML-DSA-65","aead":"AES-256-GCM","kdf":"HKDF-SHA256","kem_param":768,"sig_param":65}
            ids = AeadIds(*header_ids_for_suite(suite))
            key = os.urandom(32); sid = os.urandom(8)
            s = Sender(CONFIG["WIRE_VERSION"], ids, sid, 0, key)
            r = Receiver(CONFIG["WIRE_VERSION"], ids, sid, 0, key, CONFIG["REPLAY_WINDOW"])
            t0=time.perf_counter(); n=2000
            for _ in range(n):
                w = s.encrypt(b"x"*64)
                _ = r.decrypt(w)
            dt=time.perf_counter()-t0
            print({"pps": int(n/dt), "lat_us_per_pkt": int(dt/n*1e6)})
        if __name__=="__main__": main()
    """, force)
    wrote += write(ROOT / "tools" / "power_hooks.py", """
        # Placeholder for energy measurements; intentionally empty to avoid fake data.
        class PowerHook:
            def __enter__(self): return self
            def __exit__(self, *exc): return False
            def sample(self): return {}
    """, force)
    wrote += write(ROOT / "tools" / "wireshark" / "pqc_tunnel.lua", """
        -- Minimal skeleton dissector (header-only) for dev convenience.
        local p = Proto("pqctun","PQC Tunnel")
        local f_version = ProtoField.uint8("pqctun.version","version", base.DEC)
        local f_kem_id  = ProtoField.uint8("pqctun.kem_id","kem_id", base.DEC)
        local f_kem_prm = ProtoField.uint8("pqctun.kem_param","kem_param", base.DEC)
        local f_sig_id  = ProtoField.uint8("pqctun.sig_id","sig_id", base.DEC)
        local f_sig_prm = ProtoField.uint8("pqctun.sig_param","sig_param", base.DEC)
        local f_sid     = ProtoField.bytes("pqctun.session_id","session_id")
        local f_seq     = ProtoField.uint64("pqctun.seq","seq", base.DEC)
        local f_epoch   = ProtoField.uint8("pqctun.epoch","epoch", base.DEC)
        p.fields = {f_version,f_kem_id,f_kem_prm,f_sig_id,f_sig_prm,f_sid,f_seq,f_epoch}
        function p.dissector(buf,pkt,tree)
          if buf:len() < 1+1+1+1+1+8+8+1 then return end
          local t = tree:add(p, buf(0))
          local o=0
          t:add(f_version, buf(o,1)); o=o+1
          t:add(f_kem_id,  buf(o,1)); o=o+1
          t:add(f_kem_prm, buf(o,1)); o=o+1
          t:add(f_sig_id,  buf(o,1)); o=o+1
          t:add(f_sig_prm, buf(o,1)); o=o+1
          t:add(f_sid,     buf(o,8)); o=o+8
          t:add(f_seq,     buf(o,8)); o=o+8
          t:add(f_epoch,   buf(o,1)); o=o+1
        end
        local udp_table = DissectorTable.get("udp.port")
        -- you can: udp_table:add(5810, p) etc.
    """, force)

    # ---------- benchmarks ----------
    wrote += write(ROOT / "benchmarks" / "matrix.yaml", """
        defaults:
          payloads: [64,256,512,1024]
          suites:
            - cs-kyber768-aesgcm-dilithium3
            - cs-kyber512-aesgcm-dilithium2
            - cs-kyber1024-aesgcm-dilithium5
    """, force)
    wrote += write(ROOT / "benchmarks" / "run_matrix.py", """
        def main():
            raise NotImplementedError("Bench harness will be added later; keeping repo honest.")
        if __name__=="__main__": main()
    """, force)

    # ---------- tests: add placeholder for loss/dup/oom (skipped) ----------
    wrote += write(ROOT / "tests" / "test_loss_dup_oom.py", """
        import pytest
        @pytest.mark.skip(reason="Placeholder; to be implemented when netem/backpressure harness is added.")
        def test_loss_dup_oom():
            pass
    """, force)

    # ---------- docs placeholder folder ----------
    wrote += write(ROOT / "docs" / "README.md", """
        This folder will host consolidated Markdown docs migrated from the top-level .txt design notes.
        Keep core/ as the single source of truth for crypto & transport; update docs when the wire changes.
    """, force)

    # ---------- environment.yml skeleton (optional) ----------
    wrote += write(ROOT / "environment.yml", """
        name: pqc-env
        channels: [conda-forge, defaults]
        dependencies:
          - python>=3.10
          - pip
          - pip:
              - cryptography>=41
              - oqs-python
              - pytest
    """, force)

    print(f"\nDone. Created/updated ~{wrote} files.")
    print("Launch examples:\n  python gcs/wrappers/gcs_kyber_768.py\n  python drone/wrappers/drone_kyber_768.py")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--force", action="store_true", help="overwrite existing files")
    args = ap.parse_args()
    sys.exit(main(force=args.force) or 0)

============================================================

FILE 52/58: tools\traffic_common.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_common.py
Size: 3,551 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""Shared helpers for traffic generators that exercise the plaintext sides of the PQC proxy."""
from __future__ import annotations

import json
import os
import selectors
import socket
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Callable, Dict, Literal, Tuple

from core.config import CONFIG

Role = Literal["gcs", "drone"]


def _timestamp() -> str:
    """Return an ISO-8601 timestamp with UTC timezone."""
    return datetime.now(timezone.utc).isoformat()


def load_ports_and_hosts(role: Role) -> Dict[str, object]:
    """Return resolved host/port information for the given role.

    All values originate from ``core.config.CONFIG`` after environment overrides
    have been applied. The returned dictionary contains:

    ``local_listen_ip`` – interface to bind UDP receivers (default ``0.0.0.0``).
    ``tx_addr`` – tuple of (host, port) for sending plaintext to the local proxy.
    ``rx_bind`` – tuple for binding the UDP receive socket.
    ``peer_role`` – the opposite role string.
    """

    role_upper = role.upper()
    peer_role = "drone" if role == "gcs" else "gcs"

    host_key_tx = f"{role_upper}_PLAINTEXT_HOST"
    host_key_rx = host_key_tx
    tx_port_key = f"{role_upper}_PLAINTEXT_TX"
    rx_port_key = f"{role_upper}_PLAINTEXT_RX"

    tx_host = CONFIG[host_key_tx]
    rx_host = CONFIG[host_key_rx]
    tx_port = CONFIG[tx_port_key]
    rx_port = CONFIG[rx_port_key]

    return {
        "local_listen_ip": os.environ.get("PQC_TRAFFIC_LISTEN_IP", "0.0.0.0"),
        "tx_addr": (tx_host, tx_port),
        "rx_bind": (os.environ.get("PQC_TRAFFIC_BIND_HOST", rx_host), rx_port),
        "peer_role": peer_role,
        "role_host": tx_host,
    }


def open_udp_socket(rx_bind: Tuple[str, int]) -> socket.socket:
    """Create a non-blocking UDP socket bound to ``rx_bind``."""
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    except OSError:
        pass  # Not supported on all platforms (e.g., Windows prior to 10)
    sock.bind(rx_bind)
    sock.setblocking(False)
    return sock


def ndjson_logger(path: Path) -> Tuple[Callable[[Dict[str, object]], None], Callable[[], None]]:
    """Return a simple NDJSON logger factory returning (log_fn, close_fn)."""
    path.parent.mkdir(parents=True, exist_ok=True)
    fp = path.open("a", encoding="utf-8")

    def log(event: Dict[str, object]) -> None:
        payload = {"ts": _timestamp(), **event}
        fp.write(json.dumps(payload, separators=(",", ":")) + "\n")
        fp.flush()

    def close() -> None:
        fp.flush()
        os.fsync(fp.fileno())
        fp.close()

    return log, close


class TokenBucket:
    """Simple token bucket rate limiter."""

    def __init__(self, rate_per_sec: float) -> None:
        self.rate = max(rate_per_sec, 0.0)
        self.tokens = 0.0
        self.last = time.monotonic()

    def consume(self, now: float) -> bool:
        if self.rate <= 0:
            return True
        self.tokens = min(self.rate, self.tokens + (now - self.last) * self.rate)
        self.last = now
        if self.tokens >= 1.0:
            self.tokens -= 1.0
            return True
        return False


def configured_selector(sock: socket.socket) -> selectors.BaseSelector:
    sel = selectors.DefaultSelector()
    sel.register(sock, selectors.EVENT_READ)
    return sel


============================================================

FILE 53/58: tools\traffic_drone.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_drone.py
Size: 206 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""CLI entry point for the drone traffic generator."""
from __future__ import annotations

import sys

from tools.traffic_runner import run


if __name__ == "__main__":
    sys.exit(run("drone"))

============================================================

FILE 54/58: tools\traffic_gcs.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_gcs.py
Size: 202 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""CLI entry point for the GCS traffic generator."""
from __future__ import annotations

import sys

from tools.traffic_runner import run


if __name__ == "__main__":
    sys.exit(run("gcs"))

============================================================

FILE 55/58: tools\traffic_runner.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\traffic_runner.py
Size: 7,778 bytes
Modified: 2025-09-26 16:29:20
------------------------------------------------------------
"""Shared runner for automated plaintext traffic generators."""
from __future__ import annotations

import argparse
import json
import socket
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Optional

from tools.traffic_common import (
    TokenBucket,
    configured_selector,
    load_ports_and_hosts,
    ndjson_logger,
    open_udp_socket,
)


def iso_now() -> str:
    return datetime.now(timezone.utc).isoformat()


def _build_parser(role: str) -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog=f"traffic_{role}",
        description="Generate UDP plaintext traffic for the PQC proxy.",
    )
    parser.add_argument("--count", type=int, default=200, help="Total messages to send (default: 200)")
    parser.add_argument("--rate", type=float, default=50.0, help="Maximum send rate in packets/sec (default: 50)")
    parser.add_argument(
        "--duration",
        type=float,
        default=None,
        help="Optional duration cap in seconds. When omitted, exits after sending all messages and an idle grace period.",
    )
    parser.add_argument("--out", type=Path, default=None, help="Path for NDJSON event log")
    parser.add_argument("--summary", type=Path, default=None, help="Path for JSON summary output")
    parser.add_argument("--peer-hint", type=str, default=None, help="Annotate payloads with expected peer role")
    parser.add_argument(
        "--payload-bytes",
        type=int,
        default=0,
        help="Optional number of '.' bytes appended to each payload for throughput testing.",
    )
    return parser


def _default_paths(role: str) -> Dict[str, Path]:
    ts = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H-%M-%SZ")
    logs_dir = Path("logs")
    return {
        "out": logs_dir / f"{role}_traffic_{ts}.jsonl",
        "summary": logs_dir / f"{role}_traffic_summary_{ts}.json",
    }


def run(role: str, argv: Optional[list[str]] = None) -> int:
    parser = _build_parser(role)
    args = parser.parse_args(argv)

    defaults = _default_paths(role)
    out_path: Path = args.out or defaults["out"]
    summary_path: Path = args.summary or defaults["summary"]

    settings = load_ports_and_hosts(role)  # type: ignore[arg-type]
    rx_host, rx_port = settings["rx_bind"]  # type: ignore[index]
    rx_sock = open_udp_socket((rx_host, rx_port))
    tx_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    selector = configured_selector(rx_sock)
    bucket = TokenBucket(args.rate)

    log_event, close_log = ndjson_logger(out_path)

    payload_pad = b"." * max(args.payload_bytes, 0)

    start = time.monotonic()
    deadline = start + args.duration if args.duration else None
    last_activity = start
    idle_grace = 1.0

    counters: Dict[str, Optional[object]] = {
        "role": role,
        "peer_role": settings["peer_role"],
        "sent_total": 0,
        "recv_total": 0,
        "first_send_ts": None,
        "last_send_ts": None,
        "first_recv_ts": None,
        "last_recv_ts": None,
        "out_of_order": 0,
        "unique_senders": 0,
        "rx_bytes_total": 0,
        "tx_bytes_total": 0,
    }

    expected_seq: Dict[str, int] = {}
    unique_senders = set()

    seq = 0
    send_done = False

    tx_addr = settings["tx_addr"]  # type: ignore[assignment]

    try:
        while True:
            now = time.monotonic()
            if deadline and now >= deadline:
                break

            if not send_done:
                if seq >= args.count:
                    send_done = True
                else:
                    if bucket.consume(now):
                        seq += 1
                        payload = {
                            "role": role,
                            "seq": seq,
                            "t_send_ns": time.monotonic_ns(),
                        }
                        if args.peer_hint:
                            payload["peer_hint"] = args.peer_hint
                        packet = json.dumps(payload, separators=(",", ":")).encode("utf-8") + payload_pad
                        sent_bytes = tx_sock.sendto(packet, tx_addr)
                        counters["sent_total"] = int(counters["sent_total"]) + 1  # type: ignore[arg-type]
                        counters["tx_bytes_total"] = int(counters["tx_bytes_total"]) + sent_bytes  # type: ignore[arg-type]
                        iso_ts = iso_now()
                        counters["last_send_ts"] = iso_ts
                        if counters["first_send_ts"] is None:
                            counters["first_send_ts"] = iso_ts
                        log_event({"event": "send", "seq": seq, "bytes": sent_bytes})
                        last_activity = now

            timeout = 0.05
            if deadline:
                timeout = max(0.0, min(timeout, deadline - now))

            events = selector.select(timeout)
            if events:
                for _key, _mask in events:
                    try:
                        data, addr = rx_sock.recvfrom(4096)
                    except BlockingIOError:
                        continue
                    now = time.monotonic()
                    last_activity = now
                    counters["recv_total"] = int(counters["recv_total"]) + 1  # type: ignore[arg-type]
                    counters["rx_bytes_total"] = int(counters["rx_bytes_total"]) + len(data)  # type: ignore[arg-type]
                    iso_ts = iso_now()
                    counters["last_recv_ts"] = iso_ts
                    if counters["first_recv_ts"] is None:
                        counters["first_recv_ts"] = iso_ts

                    sender_label = f"{addr[0]}:{addr[1]}"
                    try:
                        message = json.loads(data.decode("utf-8"))
                        sender_label = message.get("role", sender_label)
                        seq_val = message.get("seq")
                        if isinstance(seq_val, int):
                            expected = expected_seq.get(sender_label)
                            if expected is None:
                                expected_seq[sender_label] = seq_val + 1
                            else:
                                if seq_val != expected:
                                    counters["out_of_order"] = int(counters["out_of_order"]) + abs(seq_val - expected)  # type: ignore[arg-type]
                                expected_seq[sender_label] = seq_val + 1
                    except (ValueError, UnicodeDecodeError):
                        message = None

                    unique_senders.add(sender_label)
                    log_payload: Dict[str, object] = {
                        "event": "recv",
                        "bytes": len(data),
                        "from": f"{addr[0]}:{addr[1]}",
                        "sender": sender_label,
                    }
                    if isinstance(message, dict) and "seq" in message:
                        log_payload["seq"] = message["seq"]
                    log_event(log_payload)

            if send_done and not events and not deadline:
                if now - last_activity >= idle_grace:
                    break
    except KeyboardInterrupt:
        pass
    finally:
        selector.close()
        rx_sock.close()
        tx_sock.close()
        close_log()

    counters["unique_senders"] = len(unique_senders)

    summary_path.parent.mkdir(parents=True, exist_ok=True)
    summary_path.write_text(json.dumps(counters, indent=2), encoding="utf-8")
    return 0

============================================================

FILE 56/58: tools\udp_dual_probe.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_dual_probe.py
Size: 5,048 bytes
Modified: 2025-09-26 10:15:21
------------------------------------------------------------
#!/usr/bin/env python3
"""Bi-directional UDP probe to verify ports and paths end-to-end.

Run this on both hosts (GCS and Drone) at the same time. It will:
- Bind a local RX port and print every packet received (with source IP:port).
- Periodically send numbered messages to the peer's RX port.
- Log exactly which local ephemeral source port each message leaves from.

Defaults are taken from core.config.CONFIG for the encrypted path (UDP_GCS_RX/UDP_DRONE_RX)
so you can prove the tunnel ports themselves are reachable. You can target plaintext
ports as well with --mode plaintext.

Examples:
  # GCS side (listens on UDP_GCS_RX, sends to DRONE_HOST:UDP_DRONE_RX)
  python tools/udp_dual_probe.py --role gcs --mode encrypted

  # Drone side (listens on UDP_DRONE_RX, sends to GCS_HOST:UDP_GCS_RX)
  python tools/udp_dual_probe.py --role drone --mode encrypted

Stop with Ctrl+C.
"""

from __future__ import annotations

import argparse
import socket
import sys
import threading
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            p = str(parent)
            if p not in sys.path:
                sys.path.insert(0, p)
            break
    except Exception:
        pass

from core.config import CONFIG


def build_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="Bi-directional UDP probe")
    ap.add_argument("--role", choices=["gcs", "drone"], required=True)
    ap.add_argument("--mode", choices=["encrypted", "plaintext"], default="encrypted")
    ap.add_argument("--interval", type=float, default=1.0, help="Seconds between sends")
    ap.add_argument("--count", type=int, default=10, help="Messages to send before exit (0 = infinite)")
    return ap.parse_args()


essential = {
    "gcs": {
        "encrypted_rx": int(CONFIG["UDP_GCS_RX"]),
        "plaintext_tx": int(CONFIG["GCS_PLAINTEXT_TX"]),
        "plaintext_rx": int(CONFIG["GCS_PLAINTEXT_RX"]),
        "peer_host": CONFIG["DRONE_HOST"],
        "peer_encrypted_rx": int(CONFIG["UDP_DRONE_RX"]),
    },
    "drone": {
        "encrypted_rx": int(CONFIG["UDP_DRONE_RX"]),
        "plaintext_tx": int(CONFIG["DRONE_PLAINTEXT_TX"]),
        "plaintext_rx": int(CONFIG["DRONE_PLAINTEXT_RX"]),
        "peer_host": CONFIG["GCS_HOST"],
        "peer_encrypted_rx": int(CONFIG["UDP_GCS_RX"]),
    },
}


def run_probe(role: str, mode: str, interval: float, count: int) -> None:
    cfg = essential[role]

    if mode == "encrypted":
        local_rx_port = cfg["encrypted_rx"]
        peer_host = cfg["peer_host"]
        peer_rx_port = cfg["peer_encrypted_rx"]
        label = "ENC"
    else:
        # plaintext runs on loopback only for each host
        local_rx_port = cfg["plaintext_rx"]
        peer_host = "127.0.0.1"
        peer_rx_port = cfg["plaintext_tx"]
        label = "PTX"

    print(f"[{role.upper()}][{label}] RX bind on 0.0.0.0:{local_rx_port}")
    print(f"[{role.upper()}][{label}] Will send to {peer_host}:{peer_rx_port}")

    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    rx.bind(("0.0.0.0", local_rx_port))
    rx.settimeout(0.2)

    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    # For visibility, bind tx to an ephemeral port so we know the source
    tx.bind(("0.0.0.0", 0))

    stop = threading.Event()

    def receiver() -> None:
        while not stop.is_set():
            try:
                data, addr = rx.recvfrom(2048)
            except socket.timeout:
                continue
            except OSError:
                break
            ts = time.strftime("%H:%M:%S")
            print(f"[{role.upper()}][{label}][{ts}] RX {len(data)}B from {addr[0]}:{addr[1]} :: {data[:64]!r}")

    t = threading.Thread(target=receiver, daemon=True)
    t.start()

    try:
        i = 0
        while count == 0 or i < count:
            i += 1
            ts = time.strftime("%H:%M:%S")
            try:
                # Print the local source address/port before sending
                src_host, src_port = tx.getsockname()
                payload = f"{label}_MSG_{i}@{ts}".encode()
                tx.sendto(payload, (peer_host, peer_rx_port))
                print(f"[{role.upper()}][{label}][{ts}] TX {len(payload)}B from {src_host}:{src_port} -> {peer_host}:{peer_rx_port}")
            except Exception as exc:
                print(f"[{role.upper()}][{label}] TX error: {exc}")
                break
            time.sleep(interval)
    except KeyboardInterrupt:
        pass
    finally:
        stop.set()
        t.join(timeout=0.3)
        try:
            rx.close()
            tx.close()
        except OSError:
            pass


if __name__ == "__main__":
    args = build_args()
    run_probe(args.role, args.mode, args.interval, args.count)

============================================================

FILE 57/58: tools\udp_echo_server.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_echo_server.py
Size: 2,488 bytes
Modified: 2025-09-26 09:59:28
------------------------------------------------------------
#!/usr/bin/env python3
r"""Simple UDP echo server to test network connectivity.

This replaces the complex pktmon capture with a basic UDP listener that
will tell us definitively if packets are reaching the Windows machine.
"""

from __future__ import annotations

import argparse
import socket
import sys
import time
from pathlib import Path

# Ensure repository root is on sys.path when executed directly
_HERE = Path(__file__).resolve()
for parent in (_HERE.parent.parent.parent, _HERE.parent.parent):
    try:
        if (parent / "core").exists():
            parent_str = str(parent)
            if parent_str not in sys.path:
                sys.path.insert(0, parent_str)
            break
    except Exception:
        pass

from core.config import CONFIG


def main() -> None:
    parser = argparse.ArgumentParser(description="UDP Echo Server for Firewall Testing")
    parser.add_argument("--port", type=int, default=CONFIG["UDP_GCS_RX"], help="UDP port to listen on")
    parser.add_argument("--host", default="0.0.0.0", help="Host IP to bind to")
    parser.add_argument("--timeout", type=int, default=30, help="Timeout in seconds")
    args = parser.parse_args()

    print(f"--- UDP Echo Server ---")
    print(f"🚀 Listening for UDP packets on {args.host}:{args.port} for {args.timeout} seconds...")
    print(f"Send a packet from the Pi with: echo 'TEST' | nc -u -w1 <GCS_IP> {args.port}")

    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
        try:
            s.bind((args.host, args.port))
            s.settimeout(args.timeout)
            
            while True:
                try:
                    data, addr = s.recvfrom(2048)
                    timestamp = time.strftime("%H:%M:%S")
                    print(f"\n✅ [{timestamp}] Received '{data.decode()}' from {addr[0]}:{addr[1]}")
                    
                    # Echo back
                    s.sendto(b"ECHO:" + data, addr)
                    print(f"🚀 Echoed back to sender")
                except socket.timeout:
                    print("\n⏰ Timeout reached. No packets received.")
                    break
                except KeyboardInterrupt:
                    print("\n🛑 Stopped by user.")
                    break

        except Exception as e:
            print(f"\n❌ FAILED: {e}")
            return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

============================================================

FILE 58/58: tools\udp_forward_log.py
============================================================
Full Path: C:\Users\burak\Desktop\research\tools\udp_forward_log.py
Size: 2,796 bytes
Modified: 2025-09-26 11:47:33
------------------------------------------------------------
#!/usr/bin/env python3
"""UDP forwarder that logs PQC header metadata while keeping traffic flowing."""

from __future__ import annotations

import argparse
import socket
import struct
import time

HEADER_STRUCT = "!BBBBB8sQB"
HEADER_LEN = struct.calcsize(HEADER_STRUCT)


def parse_header(data: bytes):
    if len(data) < HEADER_LEN:
        return None
    try:
        version, kem_id, kem_param, sig_id, sig_param, session_id, seq, epoch = struct.unpack(
            HEADER_STRUCT, data[:HEADER_LEN]
        )
        return {
            "version": version,
            "kem": (kem_id, kem_param),
            "sig": (sig_id, sig_param),
            "session_id": session_id.hex(),
            "seq": seq,
            "epoch": epoch,
        }
    except Exception:
        return None


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="UDP forwarder with PQC header logging")
    parser.add_argument("--listen", required=True, help="host:port to bind (e.g., 0.0.0.0:46012)")
    parser.add_argument("--forward", required=True, help="host:port to forward to (e.g., 127.0.0.1:56012)")
    parser.add_argument("--label", default="tap", help="Log label for output prefix")
    return parser


def parse_host_port(value: str) -> tuple[str, int]:
    host, port_str = value.rsplit(":", 1)
    return host, int(port_str)


def main() -> None:
    args = build_parser().parse_args()
    listen_host, listen_port = parse_host_port(args.listen)
    forward_host, forward_port = parse_host_port(args.forward)

    rx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    tx = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    try:
        rx.bind((listen_host, listen_port))
        print(f"[{args.label}] listening on {listen_host}:{listen_port} -> forwarding to {forward_host}:{forward_port}")

        while True:
            data, addr = rx.recvfrom(65535)
            meta = parse_header(data)
            ts = time.strftime("%H:%M:%S")
            if meta:
                print(
                    f"[{ts}][{args.label}] {len(data)}B from {addr[0]}:{addr[1]} "
                    f"hdr={{'version': {meta['version']}, 'kem': {meta['kem']}, 'sig': {meta['sig']}, "
                    f"'session_id': '{meta['session_id']}', 'seq': {meta['seq']}, 'epoch': {meta['epoch']}}}"
                )
            else:
                print(
                    f"[{ts}][{args.label}] {len(data)}B from {addr[0]}:{addr[1]} hdr=? first16={data[:16].hex()}"
                )
            tx.sendto(data, (forward_host, forward_port))
    except KeyboardInterrupt:
        pass
    finally:
        rx.close()
        tx.close()


if __name__ == "__main__":
    main()

============================================================

================================================================================
END OF LOG
================================================================================
